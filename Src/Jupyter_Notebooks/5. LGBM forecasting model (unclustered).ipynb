{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Model\n",
    "* RNN was far too slow and hence infeasible given the time limit I am constrained within\n",
    "* So going to use an LGBM\n",
    "\n",
    "# Misc / setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(\"../Data/Prepared_Data/supervised/consumption_all.pkl\")\n",
    "display(df_train)\n",
    "df_preds = pd.read_pickle(\"../Data/Prepared_Data/supervised/consumption_all_preds.pkl\")\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formatting the df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing nans with 0 so we can aggregate up the OOF predictions\n",
    "df_preds[\"meter_reading\"] = df_preds[\"meter_reading\"].fillna(0) \n",
    "#dropping the \"energy n-k\" columns as they are needed for 3D RNN input not 2D LGBM input\n",
    "df_preds = df_preds.drop([\"energy n-7\",\"energy n-6\",\"energy n-5\",\"energy n-4\",\"energy n-3\",\"energy n-2\",\"energy n-1\"], axis=1)\n",
    "df_train = df_train.drop([\"energy n-7\",\"energy n-6\",\"energy n-5\",\"energy n-4\",\"energy n-3\",\"energy n-2\",\"energy n-1\"], axis=1)\n",
    "\n",
    "display(df_train)\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinally encoding the ID's\n",
    "* One hot / binary encoding can actually worsen performance of DT based algorithms\n",
    "* This is a LGBM so a gradient boosted decision tree\n",
    "* Hence I will also now encode the ID ordinally and experiment with both to see which gives the best performing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ordinally encoding id's\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_train[\"meter_id\"])\n",
    "\n",
    "#ordinally encoding with same encoder so will encode the same\n",
    "df_train.insert(1, \"meter_id_ord\", le.transform(df_train[\"meter_id\"]))\n",
    "df_preds.insert(1, \"meter_id_ord\", le.transform(df_preds[\"meter_id\"]))\n",
    "\n",
    "display(df_train)\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining LGBM model hyperparameters\n",
    "* Will need to do those multiple times \n",
    "* Cannot automate this as don't have access to the test data will have to just submit multiple times and check\n",
    "* Will have to do manual hyper parameter tuning\n",
    "\n",
    "## Defining the columns we will use\n",
    "* Multiple configurations to test during manual hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"meter_reading\" #we want to predict the meter_reading\n",
    "\n",
    "# all consumption based variables, no addInfo or cluster, meter_id ordinally encoded\n",
    "# score: \n",
    "X_cols = [\"meter_id_ord\",\"day_of_year_sin\",\"day_of_year_cos\",\"day_of_week\",\"day_of_month\",\"month_ord\",\"month_sin\",\"month_cos\",\"is_weekend\"]\n",
    "X_cat = [\"meter_id_ord\",\"day_of_week\",\"day_of_month\",\"month_ord\",\"is_weekend\"]\n",
    "\n",
    "# description\n",
    "# score: \n",
    "#X = []\n",
    "#X_cat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting categorical columns in the dataframe to be categorical\n",
    "for i in X_cat:\n",
    "    df_train[i] = df_train[i].astype('category')\n",
    "    df_preds[i] = df_preds[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df_train[X_cols].head(3))\n",
    "display(df_preds[X_cols].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model parameters\n",
    "* also will need to be manually hyper tuned after submitting each combination to the comp and getting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt', #gbdt/rf/dart/goss\n",
    "    'metric': 'mae',\n",
    "    'num_threads': 2, # number of threads to run on for speed\n",
    "    \n",
    "    'max_leaf': 256, # limit max numer of leaves in a tree\n",
    "    \"max_depth\":10, # limit max depth of the tree to prevent overfitting\n",
    "    \n",
    "    #defining the models runs\n",
    "    'learning_rate': 0.01,\n",
    "    'num_iterations': 10000,\n",
    "    \n",
    "    # fraction to be bagged/sampled every k iterations\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_freq' : 10,\n",
    "    \n",
    "    'feature_fraction': 0.85, # fraction of features to use at each tree node\n",
    "    \n",
    "    #l1 & l2 regularization to prevent overfitting\n",
    "    \"lambda_l1\": 16,\n",
    "    \"lambda_l2\": 8,\n",
    "\n",
    "    'seed': SEED # all runs with same seed for better comparison between different hyper params\n",
    "    \n",
    "}\n",
    "\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running LGBM with SKF\n",
    "* Using skf on df_train by meter_id with 3 folds\n",
    "    * Meaning for each iteration we use 2/3 of each meters data for training and 1/3 of each meters data for validating\n",
    "* using out of fold predictions, making predictions on each fold and aggregating them together for the final prediction\n",
    "# WHICH IS BETTER?\n",
    "## CALCULATING PREDICTIONS AND RETURNING THEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#function for running the cross fold\n",
    "    #args:\n",
    "        #print_bool = True if we want to print info for each fold\n",
    "        #SEED = random seed used for fair repeatability\n",
    "        #num_folds = number of folds in skf (pretty certain going to keep this at 3 )\n",
    "        #df_train = training dataframe\n",
    "        #df_preds = preds dataframe we are going to populate\n",
    "        #y_col = the name of the label we want to predict (meter_reading)\n",
    "        #X_cols = the name of the feature columns we are using\n",
    "        #X_cat = the name of these features which are categorical\n",
    "        #params = hyper params for the LGBM model\n",
    "    #returns:\n",
    "        #time_of_execution = how long it took to train the model on all folds; will be used as a point of comparison\n",
    "        #valid_score = MAE calculated using the Out-of-Fold Predictions on the df_train, used for hyper-param tuning\n",
    "        #df_train = the training set containing the OOF column (returning so can inspect if I wish)\n",
    "        #df_preds = the prediction set now populated with the average forecast of the folds\n",
    "        \n",
    "def run_lgbm_skf_cv(print_bool, SEED, num_folds, df_train, df_preds, y_col, X_cols, X_cat, params):\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state = SEED) # defining the SKF algorithm\n",
    "\n",
    "    start_time = time.time()\n",
    "    fold_iter=1\n",
    "    #running the startified kfold, splitting df_train by meter_id, so we use 2/3 of each meters reading for training\n",
    "    for train_index, valid_index in skf.split(df_train, df_train[\"meter_id\"]):\n",
    "\n",
    "        print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Fold {fold_iter}{color.END}\")\n",
    "        \n",
    "        #splitting into the features and labels for the train and valid folds\n",
    "        X_train, X_valid = df_train.loc[train_index, X_cols], df_train.loc[valid_index, X_cols]\n",
    "        y_train, y_valid = df_train.loc[train_index, y_col], df_train.loc[valid_index, y_col]\n",
    "        \n",
    "        if(print_bool):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}X_train{color.END}\")\n",
    "            display(X_train.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}y_train{color.END}\")\n",
    "            display(y_train.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}X_valid{color.END}\")\n",
    "            display(X_valid.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}y_valid{color.END}\")\n",
    "            display(y_valid.head(5))\n",
    "            \n",
    "        print(f\"{color.CYAN}{color.UNDERLINE}Training the LGBM{color.END}\")\n",
    "        #instantiating a lgbm regressor with our params\n",
    "        lgbm_model = lgbm.LGBMRegressor(**params)\n",
    "        #fitting the lgbm model on the 2/3 train and evaluating on the 1/3 valid\n",
    "        #printing details every 1000 iters + stopping if no improvement made in 250 iters\n",
    "        lgbm_model.fit(X_train, y_train,\n",
    "                       eval_set=[(X_valid, y_valid)],\n",
    "                       categorical_feature=X_cat,\n",
    "                       verbose=1000,\n",
    "                       early_stopping_rounds=250)\n",
    "        \n",
    "        #saving the OOF prediction for the held out rows (valid rows from df_train) from the lgbm model with the best performing intrinisic parmams \n",
    "        oof_valid = lgbm_model.predict(X_valid, num_iteration=lgbm_model.best_iteration_) # making prediction on the held out rows, X_valid\n",
    "        df_train.loc[valid_index, \"oof\"] = oof_valid #storing the oof rows \n",
    "        \n",
    "        #calculating the average preds by summing the weighted preds for each fold\n",
    "        pred_predictions = lgbm_model.predict(df_preds[X_cols], num_iteration=lgbm_model.best_iteration_) #predicting the unkown df_preds\n",
    "        df_preds[y_col] += pred_predictions / num_folds #weighting the predictions for this fold and adding to df_preds y column \n",
    "        \n",
    "        if(print_bool):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}df_train OOF predictions{color.END}\")\n",
    "            display(df_train.loc[valid_index, \"oof\"].head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}this folds df_preds OOF predictions{color.END}\")\n",
    "            display(pred_predictions[:5])\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}weighted aggregated df_preds OOF predictions so far{color.END}\")\n",
    "            pprint(df_preds[y_col].head(5))\n",
    "               \n",
    "        fold_iter+=1\n",
    "        \n",
    "    df_preds[y_col]=df_preds.meter_reading.clip(lower=0)#clipping the pred results in case any predictions were below 0 \n",
    "    #calculating execution time and the MAE on the training set\n",
    "    time_of_execution = time.time() - start_time\n",
    "    valid_score=mean_absolute_error(df_train[y_col], df_train[\"oof\"]) \n",
    "    return (time_of_execution, valid_score, df_train, df_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#running lgbm with cv skf and storing the results\n",
    "results = run_lgbm_skf_cv(False, SEED, 3, df_train.copy(), df_preds.copy(), y_col, X_cols, X_cat, params)\n",
    "LGBM_TOE = results[0]\n",
    "LGBM_MAE = results[1]\n",
    "LGBM_DF_TRAIN = results[2]\n",
    "LGBM_DF_PREDS = results[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the results\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution{color.END}: {LGBM_TOE} seconds\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set{color.END}: {LGBM_MAE}\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}training set OOF preds vs true{color.END}\")\n",
    "display(LGBM_DF_TRAIN[[\"meter_id\",\"date\",\"meter_reading\",\"oof\"]])\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}preds set with the next years forecasts for each meter{color.END}\")\n",
    "display(LGBM_DF_PREDS[[\"meter_id\",\"date\",\"meter_reading\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR RETURN LGBMS AND CALCULATE PREDICTIONS AFTER?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#function for running the cross fold\n",
    "    #args:\n",
    "        #print_bool = True if we want to print info for each fold\n",
    "        #SEED = random seed used for fair repeatability\n",
    "        #num_folds = number of folds in skf (pretty certain going to keep this at 3 )\n",
    "        #df_train = training dataframe\n",
    "        #y_col = the name of the label we want to predict (meter_reading)\n",
    "        #X_cols = the name of the feature columns we are using\n",
    "        #X_cat = the name of these features which are categorical\n",
    "        #params = hyper params for the LGBM model\n",
    "    #returns:\n",
    "        #time_of_execution = how long it took to train the model on all folds; will be used as a point of comparison\n",
    "        #valid_score = MAE calculated using the Out-of-Fold Predictions on the df_train, used for hyper-param tuning\n",
    "        #df_train = the training set containing the OOF column (returning so can inspect if I wish)\n",
    "        #lgbm_models = array of the different lgbm_models\n",
    "        \n",
    "def run_lgbm_skf_cv(print_bool, SEED, num_folds, df_train, y_col, X_cols, X_cat, params):\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state = SEED) # defining the SKF algorithm\n",
    "\n",
    "    lgbm_models = []\n",
    "    start_time = time.time()\n",
    "    fold_iter=1\n",
    "    #running the startified kfold, splitting df_train by meter_id, so we use 2/3 of each meters reading for training\n",
    "    for train_index, valid_index in skf.split(df_train, df_train[\"meter_id\"]):\n",
    "\n",
    "        print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Fold {fold_iter}{color.END}\")\n",
    "        \n",
    "        #splitting into the features and labels for the train and valid folds\n",
    "        X_train, X_valid = df_train.loc[train_index, X_cols], df_train.loc[valid_index, X_cols]\n",
    "        y_train, y_valid = df_train.loc[train_index, y_col], df_train.loc[valid_index, y_col]\n",
    "        \n",
    "        if(print_bool):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}X_train{color.END}\")\n",
    "            display(X_train.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}y_train{color.END}\")\n",
    "            display(y_train.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}X_valid{color.END}\")\n",
    "            display(X_valid.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}y_valid{color.END}\")\n",
    "            display(y_valid.head(5))\n",
    "            \n",
    "        print(f\"{color.CYAN}{color.UNDERLINE}Training the LGBM{color.END}\")\n",
    "        #instantiating a lgbm regressor with our params\n",
    "        lgbm_model = lgbm.LGBMRegressor(**params)\n",
    "        #fitting the lgbm model on the 2/3 train and evaluating on the 1/3 valid\n",
    "        #printing details every 1000 iters + stopping if no improvement made in 250 iters\n",
    "        lgbm_model.fit(X_train, y_train,\n",
    "                       eval_set=[(X_valid, y_valid)],\n",
    "                       categorical_feature=X_cat,\n",
    "                       verbose=1000,\n",
    "                       early_stopping_rounds=250)\n",
    "        \n",
    "        #saving the OOF prediction for the held out rows (valid rows from df_train) from the lgbm model with the best performing intrinisic parmams \n",
    "        oof_valid = lgbm_model.predict(X_valid, num_iteration=lgbm_model.best_iteration_) # making prediction on the held out rows, X_valid\n",
    "        df_train.loc[valid_index, \"oof\"] = oof_valid #storing the oof rows \n",
    "        if(print_bool):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}df_train OOF predictions{color.END}\")\n",
    "            display(df_train.loc[valid_index, [\"meter_id\",\"oof\"]].head(5))\n",
    "               \n",
    "        #appending this lgbm\n",
    "        lgbm_models.append(lgbm_model)\n",
    "        if(print_bool):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}lgbm_models size{color.END}: {len(lgbm_models)}\")\n",
    "            \n",
    "        fold_iter+=1\n",
    "        \n",
    "    #calculating execution time and the MAE on the training set\n",
    "    time_of_execution = time.time() - start_time\n",
    "    valid_score=mean_absolute_error(df_train[y_col], df_train[\"oof\"]) \n",
    "    return (time_of_execution, valid_score, df_train, lgbm_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#running lgbm with cv skf and storing the results\n",
    "results = run_lgbm_skf_cv(False, SEED, 3, df_train.copy(), y_col, X_cols, X_cat, params)\n",
    "LGBM_TOE = results[0]\n",
    "LGBM_MAE = results[1]\n",
    "LGBM_DF_TRAIN = results[2]\n",
    "LGBM_MODELS = results[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#only make predictions on the best performing LGBM MODELS (one returned by grid search)\n",
    "LGBM_DF_PREDS = df_preds.copy()\n",
    "\n",
    "#calculating the average preds by summing the weighted preds for each fold\n",
    "for lgbm_i in range(len(LGBM_MODELS)):\n",
    "    pred_predictions = lgbm_model.predict(LGBM_DF_PREDS[X_cols], num_iteration=lgbm_model.best_iteration_) #predicting the unkown df_preds\n",
    "    LGBM_DF_PREDS[y_col] += pred_predictions / num_folds #weighting the predictions for this fold and adding to df_preds y column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the results\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution{color.END}: {LGBM_TOE} seconds\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set{color.END}: {LGBM_MAE}\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}training set OOF preds vs true{color.END}\")\n",
    "display(LGBM_DF_TRAIN[[\"meter_id\",\"date\",\"meter_reading\",\"oof\"]])\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}preds set with the next years forecasts for each meter{color.END}\")\n",
    "display(LGBM_DF_PREDS[[\"meter_id\",\"date\",\"meter_reading\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle_tf",
   "language": "python",
   "name": "mle_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
