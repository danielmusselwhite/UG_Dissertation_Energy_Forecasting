{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Model\n",
    "* RNN was far too slow and hence infeasible given the time limit I am constrained within\n",
    "* So going to use an LGBM\n",
    "* Just comment out the plots when running if not needing to regenerate them\n",
    "\n",
    "# Misc / setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SEED = 1337\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>meter_id_8</th>\n",
       "      <th>...</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>energy n-7</th>\n",
       "      <th>energy n-6</th>\n",
       "      <th>energy n-5</th>\n",
       "      <th>energy n-4</th>\n",
       "      <th>energy n-3</th>\n",
       "      <th>energy n-2</th>\n",
       "      <th>energy n-1</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x240e5e22734a44a174b7dabcf1ea00d70d9ec168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.805677</td>\n",
       "      <td>11.942665</td>\n",
       "      <td>11.552484</td>\n",
       "      <td>12.231637</td>\n",
       "      <td>12.903379</td>\n",
       "      <td>12.511848</td>\n",
       "      <td>12.101536</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2ce3d582a1316db5bcfe405cbd6070268944778e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.805677</td>\n",
       "      <td>11.942665</td>\n",
       "      <td>11.552484</td>\n",
       "      <td>12.231637</td>\n",
       "      <td>12.903379</td>\n",
       "      <td>12.511848</td>\n",
       "      <td>12.101536</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x306e6baa9367d3c43fa6ecc2d0054b207d6ef471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.805677</td>\n",
       "      <td>11.942665</td>\n",
       "      <td>11.552484</td>\n",
       "      <td>12.231637</td>\n",
       "      <td>12.903379</td>\n",
       "      <td>12.511848</td>\n",
       "      <td>12.101536</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x391e6c2169c27de797ccbdf2d623365da28a6d3d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.805677</td>\n",
       "      <td>11.942665</td>\n",
       "      <td>11.552484</td>\n",
       "      <td>12.231637</td>\n",
       "      <td>12.903379</td>\n",
       "      <td>12.511848</td>\n",
       "      <td>12.101536</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x423fa805ddb0cba9bdb4460f9a78540287eefd0e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.805677</td>\n",
       "      <td>11.942665</td>\n",
       "      <td>11.552484</td>\n",
       "      <td>12.231637</td>\n",
       "      <td>12.903379</td>\n",
       "      <td>12.511848</td>\n",
       "      <td>12.101536</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617640</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.999000</td>\n",
       "      <td>26.232000</td>\n",
       "      <td>14.036000</td>\n",
       "      <td>15.990000</td>\n",
       "      <td>15.550500</td>\n",
       "      <td>15.111000</td>\n",
       "      <td>16.506000</td>\n",
       "      <td>18.758500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617641</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.232000</td>\n",
       "      <td>14.036000</td>\n",
       "      <td>15.990000</td>\n",
       "      <td>15.550500</td>\n",
       "      <td>15.111000</td>\n",
       "      <td>16.506000</td>\n",
       "      <td>18.758500</td>\n",
       "      <td>21.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617642</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.036000</td>\n",
       "      <td>15.990000</td>\n",
       "      <td>15.550500</td>\n",
       "      <td>15.111000</td>\n",
       "      <td>16.506000</td>\n",
       "      <td>18.758500</td>\n",
       "      <td>21.011000</td>\n",
       "      <td>19.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617643</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.990000</td>\n",
       "      <td>15.550500</td>\n",
       "      <td>15.111000</td>\n",
       "      <td>16.506000</td>\n",
       "      <td>18.758500</td>\n",
       "      <td>21.011000</td>\n",
       "      <td>19.204000</td>\n",
       "      <td>17.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617644</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.550500</td>\n",
       "      <td>15.111000</td>\n",
       "      <td>16.506000</td>\n",
       "      <td>18.758500</td>\n",
       "      <td>21.011000</td>\n",
       "      <td>19.204000</td>\n",
       "      <td>17.397000</td>\n",
       "      <td>15.237000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>617645 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          meter_id  meter_id_0  meter_id_1  \\\n",
       "0       0x240e5e22734a44a174b7dabcf1ea00d70d9ec168           0           0   \n",
       "1       0x2ce3d582a1316db5bcfe405cbd6070268944778e           0           0   \n",
       "2       0x306e6baa9367d3c43fa6ecc2d0054b207d6ef471           0           0   \n",
       "3       0x391e6c2169c27de797ccbdf2d623365da28a6d3d           0           0   \n",
       "4       0x423fa805ddb0cba9bdb4460f9a78540287eefd0e           0           0   \n",
       "...                                            ...         ...         ...   \n",
       "617640  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "617641  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "617642  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "617643  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "617644  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "\n",
       "        meter_id_2  meter_id_3  meter_id_4  meter_id_5  meter_id_6  \\\n",
       "0                0           0           0           0           0   \n",
       "1                0           0           0           0           0   \n",
       "2                0           0           0           0           0   \n",
       "3                0           0           0           0           0   \n",
       "4                0           0           0           0           0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "617640           1           0           0           1           0   \n",
       "617641           1           0           0           1           0   \n",
       "617642           1           0           0           1           0   \n",
       "617643           1           0           0           1           0   \n",
       "617644           1           0           0           1           0   \n",
       "\n",
       "        meter_id_7  meter_id_8  ...  semi_detached  terraced  energy n-7  \\\n",
       "0                0           0  ...            1.0       0.0   11.805677   \n",
       "1                0           0  ...            1.0       0.0   11.805677   \n",
       "2                0           0  ...            1.0       0.0   11.805677   \n",
       "3                0           0  ...            1.0       0.0   11.805677   \n",
       "4                0           0  ...            1.0       0.0   11.805677   \n",
       "...            ...         ...  ...            ...       ...         ...   \n",
       "617640           1           1  ...            0.0       0.0   21.999000   \n",
       "617641           1           1  ...            0.0       0.0   26.232000   \n",
       "617642           1           1  ...            0.0       0.0   14.036000   \n",
       "617643           1           1  ...            0.0       0.0   15.990000   \n",
       "617644           1           1  ...            0.0       0.0   15.550500   \n",
       "\n",
       "        energy n-6 energy n-5  energy n-4  energy n-3  energy n-2  energy n-1  \\\n",
       "0        11.942665  11.552484   12.231637   12.903379   12.511848   12.101536   \n",
       "1        11.942665  11.552484   12.231637   12.903379   12.511848   12.101536   \n",
       "2        11.942665  11.552484   12.231637   12.903379   12.511848   12.101536   \n",
       "3        11.942665  11.552484   12.231637   12.903379   12.511848   12.101536   \n",
       "4        11.942665  11.552484   12.231637   12.903379   12.511848   12.101536   \n",
       "...            ...        ...         ...         ...         ...         ...   \n",
       "617640   26.232000  14.036000   15.990000   15.550500   15.111000   16.506000   \n",
       "617641   14.036000  15.990000   15.550500   15.111000   16.506000   18.758500   \n",
       "617642   15.990000  15.550500   15.111000   16.506000   18.758500   21.011000   \n",
       "617643   15.550500  15.111000   16.506000   18.758500   21.011000   19.204000   \n",
       "617644   15.111000  16.506000   18.758500   21.011000   19.204000   17.397000   \n",
       "\n",
       "        meter_reading  \n",
       "0           11.881495  \n",
       "1           11.881495  \n",
       "2           11.881495  \n",
       "3           11.881495  \n",
       "4           11.881495  \n",
       "...               ...  \n",
       "617640      18.758500  \n",
       "617641      21.011000  \n",
       "617642      19.204000  \n",
       "617643      17.397000  \n",
       "617644      15.237000  \n",
       "\n",
       "[617645 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>meter_id_8</th>\n",
       "      <th>...</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>energy n-7</th>\n",
       "      <th>energy n-6</th>\n",
       "      <th>energy n-5</th>\n",
       "      <th>energy n-4</th>\n",
       "      <th>energy n-3</th>\n",
       "      <th>energy n-2</th>\n",
       "      <th>energy n-1</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185515</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185516</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185517</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185518</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185519</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185520 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           meter_id  meter_id_0  meter_id_1  \\\n",
       "0        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "1        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "2        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "3        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "4        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "...                                             ...         ...         ...   \n",
       "1185515  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185516  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185517  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185518  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185519  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "\n",
       "         meter_id_2  meter_id_3  meter_id_4  meter_id_5  meter_id_6  \\\n",
       "0                 0           0           0           0           0   \n",
       "1                 0           0           0           0           0   \n",
       "2                 0           0           0           0           0   \n",
       "3                 0           0           0           0           0   \n",
       "4                 0           0           0           0           0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "1185515           1           0           0           1           0   \n",
       "1185516           1           0           0           1           0   \n",
       "1185517           1           0           0           1           0   \n",
       "1185518           1           0           0           1           0   \n",
       "1185519           1           0           0           1           0   \n",
       "\n",
       "         meter_id_7  meter_id_8  ...  semi_detached  terraced  energy n-7  \\\n",
       "0                 0           0  ...            0.0       1.0         NaN   \n",
       "1                 0           0  ...            0.0       1.0         NaN   \n",
       "2                 0           0  ...            0.0       1.0         NaN   \n",
       "3                 0           0  ...            0.0       1.0         NaN   \n",
       "4                 0           0  ...            0.0       1.0         NaN   \n",
       "...             ...         ...  ...            ...       ...         ...   \n",
       "1185515           1           1  ...            0.0       0.0         NaN   \n",
       "1185516           1           1  ...            0.0       0.0         NaN   \n",
       "1185517           1           1  ...            0.0       0.0         NaN   \n",
       "1185518           1           1  ...            0.0       0.0         NaN   \n",
       "1185519           1           1  ...            0.0       0.0         NaN   \n",
       "\n",
       "         energy n-6 energy n-5  energy n-4  energy n-3  energy n-2  \\\n",
       "0               NaN        NaN         NaN         NaN         NaN   \n",
       "1               NaN        NaN         NaN         NaN         NaN   \n",
       "2               NaN        NaN         NaN         NaN         NaN   \n",
       "3               NaN        NaN         NaN         NaN         NaN   \n",
       "4               NaN        NaN         NaN         NaN         NaN   \n",
       "...             ...        ...         ...         ...         ...   \n",
       "1185515         NaN        NaN         NaN         NaN         NaN   \n",
       "1185516         NaN        NaN         NaN         NaN         NaN   \n",
       "1185517         NaN        NaN         NaN         NaN         NaN   \n",
       "1185518         NaN        NaN         NaN         NaN         NaN   \n",
       "1185519         NaN        NaN         NaN         NaN         NaN   \n",
       "\n",
       "         energy n-1  meter_reading  \n",
       "0               NaN            NaN  \n",
       "1               NaN            NaN  \n",
       "2               NaN            NaN  \n",
       "3               NaN            NaN  \n",
       "4               NaN            NaN  \n",
       "...             ...            ...  \n",
       "1185515         NaN            NaN  \n",
       "1185516         NaN            NaN  \n",
       "1185517         NaN            NaN  \n",
       "1185518         NaN            NaN  \n",
       "1185519         NaN            NaN  \n",
       "\n",
       "[1185520 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_pickle(\"../Data/Prepared_Data/supervised/consumption_all.pkl\")\n",
    "display(df_train)\n",
    "df_preds = pd.read_pickle(\"../Data/Prepared_Data/supervised/consumption_all_preds.pkl\")\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formatting the df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>meter_id_8</th>\n",
       "      <th>...</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x240e5e22734a44a174b7dabcf1ea00d70d9ec168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2ce3d582a1316db5bcfe405cbd6070268944778e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x306e6baa9367d3c43fa6ecc2d0054b207d6ef471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x391e6c2169c27de797ccbdf2d623365da28a6d3d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x423fa805ddb0cba9bdb4460f9a78540287eefd0e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617640</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.758500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617641</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617642</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617643</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617644</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.237000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>617645 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          meter_id  meter_id_0  meter_id_1  \\\n",
       "0       0x240e5e22734a44a174b7dabcf1ea00d70d9ec168           0           0   \n",
       "1       0x2ce3d582a1316db5bcfe405cbd6070268944778e           0           0   \n",
       "2       0x306e6baa9367d3c43fa6ecc2d0054b207d6ef471           0           0   \n",
       "3       0x391e6c2169c27de797ccbdf2d623365da28a6d3d           0           0   \n",
       "4       0x423fa805ddb0cba9bdb4460f9a78540287eefd0e           0           0   \n",
       "...                                            ...         ...         ...   \n",
       "617640  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "617641  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "617642  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "617643  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "617644  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "\n",
       "        meter_id_2  meter_id_3  meter_id_4  meter_id_5  meter_id_6  \\\n",
       "0                0           0           0           0           0   \n",
       "1                0           0           0           0           0   \n",
       "2                0           0           0           0           0   \n",
       "3                0           0           0           0           0   \n",
       "4                0           0           0           0           0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "617640           1           0           0           1           0   \n",
       "617641           1           0           0           1           0   \n",
       "617642           1           0           0           1           0   \n",
       "617643           1           0           0           1           0   \n",
       "617644           1           0           0           1           0   \n",
       "\n",
       "        meter_id_7  meter_id_8  ...  month_cos  is_weekend  energy_cluster  \\\n",
       "0                0           0  ...   0.841254           1               0   \n",
       "1                0           0  ...   0.841254           1               0   \n",
       "2                0           0  ...   0.841254           1               0   \n",
       "3                0           0  ...   0.841254           1               0   \n",
       "4                0           0  ...   0.841254           1               0   \n",
       "...            ...         ...  ...        ...         ...             ...   \n",
       "617640           1           1  ...   0.841254           0               1   \n",
       "617641           1           1  ...   0.841254           0               1   \n",
       "617642           1           1  ...   0.841254           0               1   \n",
       "617643           1           1  ...   0.841254           1               1   \n",
       "617644           1           1  ...   0.841254           1               1   \n",
       "\n",
       "        num_bedrooms        dwelling_type  detached  flat  semi_detached  \\\n",
       "0                3.0  semi_detached_house       0.0   0.0            1.0   \n",
       "1                3.0  semi_detached_house       0.0   0.0            1.0   \n",
       "2                3.0  semi_detached_house       0.0   0.0            1.0   \n",
       "3                3.0  semi_detached_house       0.0   0.0            1.0   \n",
       "4                3.0  semi_detached_house       0.0   0.0            1.0   \n",
       "...              ...                  ...       ...   ...            ...   \n",
       "617640           3.0       detached_house       1.0   0.0            0.0   \n",
       "617641           3.0       detached_house       1.0   0.0            0.0   \n",
       "617642           3.0       detached_house       1.0   0.0            0.0   \n",
       "617643           3.0       detached_house       1.0   0.0            0.0   \n",
       "617644           3.0       detached_house       1.0   0.0            0.0   \n",
       "\n",
       "        terraced  meter_reading  \n",
       "0            0.0      11.881495  \n",
       "1            0.0      11.881495  \n",
       "2            0.0      11.881495  \n",
       "3            0.0      11.881495  \n",
       "4            0.0      11.881495  \n",
       "...          ...            ...  \n",
       "617640       0.0      18.758500  \n",
       "617641       0.0      21.011000  \n",
       "617642       0.0      19.204000  \n",
       "617643       0.0      17.397000  \n",
       "617644       0.0      15.237000  \n",
       "\n",
       "[617645 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>meter_id_8</th>\n",
       "      <th>...</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185515</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185516</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185517</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185518</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185519</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185520 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           meter_id  meter_id_0  meter_id_1  \\\n",
       "0        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "1        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "2        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "3        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "4        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "...                                             ...         ...         ...   \n",
       "1185515  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185516  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185517  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185518  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185519  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "\n",
       "         meter_id_2  meter_id_3  meter_id_4  meter_id_5  meter_id_6  \\\n",
       "0                 0           0           0           0           0   \n",
       "1                 0           0           0           0           0   \n",
       "2                 0           0           0           0           0   \n",
       "3                 0           0           0           0           0   \n",
       "4                 0           0           0           0           0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "1185515           1           0           0           1           0   \n",
       "1185516           1           0           0           1           0   \n",
       "1185517           1           0           0           1           0   \n",
       "1185518           1           0           0           1           0   \n",
       "1185519           1           0           0           1           0   \n",
       "\n",
       "         meter_id_7  meter_id_8  ...  month_cos  is_weekend  energy_cluster  \\\n",
       "0                 0           0  ...   0.841254           0               0   \n",
       "1                 0           0  ...   0.841254           0               0   \n",
       "2                 0           0  ...   0.841254           0               0   \n",
       "3                 0           0  ...   0.841254           0               0   \n",
       "4                 0           0  ...   0.841254           0               0   \n",
       "...             ...         ...  ...        ...         ...             ...   \n",
       "1185515           1           1  ...   0.841254           0               1   \n",
       "1185516           1           1  ...   0.841254           0               1   \n",
       "1185517           1           1  ...   0.841254           1               1   \n",
       "1185518           1           1  ...   0.841254           1               1   \n",
       "1185519           1           1  ...   0.841254           0               1   \n",
       "\n",
       "         num_bedrooms   dwelling_type  detached  flat  semi_detached  \\\n",
       "0                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "1                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "2                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "3                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "4                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "...               ...             ...       ...   ...            ...   \n",
       "1185515           3.0  detached_house       1.0   0.0            0.0   \n",
       "1185516           3.0  detached_house       1.0   0.0            0.0   \n",
       "1185517           3.0  detached_house       1.0   0.0            0.0   \n",
       "1185518           3.0  detached_house       1.0   0.0            0.0   \n",
       "1185519           3.0  detached_house       1.0   0.0            0.0   \n",
       "\n",
       "         terraced  meter_reading  \n",
       "0             1.0              0  \n",
       "1             1.0              0  \n",
       "2             1.0              0  \n",
       "3             1.0              0  \n",
       "4             1.0              0  \n",
       "...           ...            ...  \n",
       "1185515       0.0              0  \n",
       "1185516       0.0              0  \n",
       "1185517       0.0              0  \n",
       "1185518       0.0              0  \n",
       "1185519       0.0              0  \n",
       "\n",
       "[1185520 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#replacing nans with 0 so we can aggregate up the OOF predictions\n",
    "df_preds[\"meter_reading\"] = df_preds[\"meter_reading\"].fillna(0) \n",
    "#dropping the \"energy n-k\" columns as they are needed for 3D RNN input not 2D LGBM input\n",
    "df_preds = df_preds.drop([\"energy n-7\",\"energy n-6\",\"energy n-5\",\"energy n-4\",\"energy n-3\",\"energy n-2\",\"energy n-1\"], axis=1)\n",
    "df_train = df_train.drop([\"energy n-7\",\"energy n-6\",\"energy n-5\",\"energy n-4\",\"energy n-3\",\"energy n-2\",\"energy n-1\"], axis=1)\n",
    "\n",
    "display(df_train)\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinally encoding the ID's\n",
    "* One hot / binary encoding can actually worsen performance of DT based algorithms\n",
    "* and LGBM supports categorical values; so no need to use the binary encoded meter_id which we planned for the RNN\n",
    "* Hence I will also now encode the ID ordinally and experiment with both to see which gives the best performing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_ord</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>...</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x240e5e22734a44a174b7dabcf1ea00d70d9ec168</td>\n",
       "      <td>425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2ce3d582a1316db5bcfe405cbd6070268944778e</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x306e6baa9367d3c43fa6ecc2d0054b207d6ef471</td>\n",
       "      <td>585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x391e6c2169c27de797ccbdf2d623365da28a6d3d</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x423fa805ddb0cba9bdb4460f9a78540287eefd0e</td>\n",
       "      <td>793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617640</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.758500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617641</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617642</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617643</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617644</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.237000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>617645 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          meter_id  meter_id_ord  meter_id_0  \\\n",
       "0       0x240e5e22734a44a174b7dabcf1ea00d70d9ec168           425           0   \n",
       "1       0x2ce3d582a1316db5bcfe405cbd6070268944778e           542           0   \n",
       "2       0x306e6baa9367d3c43fa6ecc2d0054b207d6ef471           585           0   \n",
       "3       0x391e6c2169c27de797ccbdf2d623365da28a6d3d           688           0   \n",
       "4       0x423fa805ddb0cba9bdb4460f9a78540287eefd0e           793           0   \n",
       "...                                            ...           ...         ...   \n",
       "617640  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "617641  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "617642  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "617643  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "617644  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "\n",
       "        meter_id_1  meter_id_2  meter_id_3  meter_id_4  meter_id_5  \\\n",
       "0                0           0           0           0           0   \n",
       "1                0           0           0           0           0   \n",
       "2                0           0           0           0           0   \n",
       "3                0           0           0           0           0   \n",
       "4                0           0           0           0           0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "617640           1           1           0           0           1   \n",
       "617641           1           1           0           0           1   \n",
       "617642           1           1           0           0           1   \n",
       "617643           1           1           0           0           1   \n",
       "617644           1           1           0           0           1   \n",
       "\n",
       "        meter_id_6  meter_id_7  ...  month_cos  is_weekend  energy_cluster  \\\n",
       "0                0           0  ...   0.841254           1               0   \n",
       "1                0           0  ...   0.841254           1               0   \n",
       "2                0           0  ...   0.841254           1               0   \n",
       "3                0           0  ...   0.841254           1               0   \n",
       "4                0           0  ...   0.841254           1               0   \n",
       "...            ...         ...  ...        ...         ...             ...   \n",
       "617640           0           1  ...   0.841254           0               1   \n",
       "617641           0           1  ...   0.841254           0               1   \n",
       "617642           0           1  ...   0.841254           0               1   \n",
       "617643           0           1  ...   0.841254           1               1   \n",
       "617644           0           1  ...   0.841254           1               1   \n",
       "\n",
       "        num_bedrooms        dwelling_type detached  flat  semi_detached  \\\n",
       "0                3.0  semi_detached_house      0.0   0.0            1.0   \n",
       "1                3.0  semi_detached_house      0.0   0.0            1.0   \n",
       "2                3.0  semi_detached_house      0.0   0.0            1.0   \n",
       "3                3.0  semi_detached_house      0.0   0.0            1.0   \n",
       "4                3.0  semi_detached_house      0.0   0.0            1.0   \n",
       "...              ...                  ...      ...   ...            ...   \n",
       "617640           3.0       detached_house      1.0   0.0            0.0   \n",
       "617641           3.0       detached_house      1.0   0.0            0.0   \n",
       "617642           3.0       detached_house      1.0   0.0            0.0   \n",
       "617643           3.0       detached_house      1.0   0.0            0.0   \n",
       "617644           3.0       detached_house      1.0   0.0            0.0   \n",
       "\n",
       "        terraced  meter_reading  \n",
       "0            0.0      11.881495  \n",
       "1            0.0      11.881495  \n",
       "2            0.0      11.881495  \n",
       "3            0.0      11.881495  \n",
       "4            0.0      11.881495  \n",
       "...          ...            ...  \n",
       "617640       0.0      18.758500  \n",
       "617641       0.0      21.011000  \n",
       "617642       0.0      19.204000  \n",
       "617643       0.0      17.397000  \n",
       "617644       0.0      15.237000  \n",
       "\n",
       "[617645 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_ord</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>...</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185515</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185516</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185517</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185518</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185519</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185520 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           meter_id  meter_id_ord  meter_id_0  \\\n",
       "0        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "1        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "2        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "3        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "4        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "...                                             ...           ...         ...   \n",
       "1185515  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185516  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185517  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185518  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185519  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "\n",
       "         meter_id_1  meter_id_2  meter_id_3  meter_id_4  meter_id_5  \\\n",
       "0                 0           0           0           0           0   \n",
       "1                 0           0           0           0           0   \n",
       "2                 0           0           0           0           0   \n",
       "3                 0           0           0           0           0   \n",
       "4                 0           0           0           0           0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "1185515           1           1           0           0           1   \n",
       "1185516           1           1           0           0           1   \n",
       "1185517           1           1           0           0           1   \n",
       "1185518           1           1           0           0           1   \n",
       "1185519           1           1           0           0           1   \n",
       "\n",
       "         meter_id_6  meter_id_7  ...  month_cos  is_weekend  energy_cluster  \\\n",
       "0                 0           0  ...   0.841254           0               0   \n",
       "1                 0           0  ...   0.841254           0               0   \n",
       "2                 0           0  ...   0.841254           0               0   \n",
       "3                 0           0  ...   0.841254           0               0   \n",
       "4                 0           0  ...   0.841254           0               0   \n",
       "...             ...         ...  ...        ...         ...             ...   \n",
       "1185515           0           1  ...   0.841254           0               1   \n",
       "1185516           0           1  ...   0.841254           0               1   \n",
       "1185517           0           1  ...   0.841254           1               1   \n",
       "1185518           0           1  ...   0.841254           1               1   \n",
       "1185519           0           1  ...   0.841254           0               1   \n",
       "\n",
       "         num_bedrooms   dwelling_type detached  flat  semi_detached  terraced  \\\n",
       "0                 2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "1                 2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "2                 2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "3                 2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "4                 2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "...               ...             ...      ...   ...            ...       ...   \n",
       "1185515           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "1185516           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "1185517           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "1185518           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "1185519           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "\n",
       "         meter_reading  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "1185515              0  \n",
       "1185516              0  \n",
       "1185517              0  \n",
       "1185518              0  \n",
       "1185519              0  \n",
       "\n",
       "[1185520 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ordinally encoding id's\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_train[\"meter_id\"])\n",
    "\n",
    "#ordinally encoding with same encoder so will encode the same\n",
    "df_train.insert(1, \"meter_id_ord\", le.transform(df_train[\"meter_id\"]))\n",
    "df_preds.insert(1, \"meter_id_ord\", le.transform(df_preds[\"meter_id\"]))\n",
    "\n",
    "display(df_train)\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinally encoding the dwelling_type\n",
    "* same reasons for replacing the binary encoded meter_id with ordinal encoding; going to replace one hot encodede dwelling type with ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_ord</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>...</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>dwelling_type_ord</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x240e5e22734a44a174b7dabcf1ea00d70d9ec168</td>\n",
       "      <td>425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2ce3d582a1316db5bcfe405cbd6070268944778e</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x306e6baa9367d3c43fa6ecc2d0054b207d6ef471</td>\n",
       "      <td>585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x391e6c2169c27de797ccbdf2d623365da28a6d3d</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x423fa805ddb0cba9bdb4460f9a78540287eefd0e</td>\n",
       "      <td>793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>semi_detached_house</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.881495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617640</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.758500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617641</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617642</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617643</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617644</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.237000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>617645 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          meter_id  meter_id_ord  meter_id_0  \\\n",
       "0       0x240e5e22734a44a174b7dabcf1ea00d70d9ec168           425           0   \n",
       "1       0x2ce3d582a1316db5bcfe405cbd6070268944778e           542           0   \n",
       "2       0x306e6baa9367d3c43fa6ecc2d0054b207d6ef471           585           0   \n",
       "3       0x391e6c2169c27de797ccbdf2d623365da28a6d3d           688           0   \n",
       "4       0x423fa805ddb0cba9bdb4460f9a78540287eefd0e           793           0   \n",
       "...                                            ...           ...         ...   \n",
       "617640  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "617641  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "617642  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "617643  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "617644  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "\n",
       "        meter_id_1  meter_id_2  meter_id_3  meter_id_4  meter_id_5  \\\n",
       "0                0           0           0           0           0   \n",
       "1                0           0           0           0           0   \n",
       "2                0           0           0           0           0   \n",
       "3                0           0           0           0           0   \n",
       "4                0           0           0           0           0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "617640           1           1           0           0           1   \n",
       "617641           1           1           0           0           1   \n",
       "617642           1           1           0           0           1   \n",
       "617643           1           1           0           0           1   \n",
       "617644           1           1           0           0           1   \n",
       "\n",
       "        meter_id_6  meter_id_7  ...  is_weekend  energy_cluster  num_bedrooms  \\\n",
       "0                0           0  ...           1               0           3.0   \n",
       "1                0           0  ...           1               0           3.0   \n",
       "2                0           0  ...           1               0           3.0   \n",
       "3                0           0  ...           1               0           3.0   \n",
       "4                0           0  ...           1               0           3.0   \n",
       "...            ...         ...  ...         ...             ...           ...   \n",
       "617640           0           1  ...           0               1           3.0   \n",
       "617641           0           1  ...           0               1           3.0   \n",
       "617642           0           1  ...           0               1           3.0   \n",
       "617643           0           1  ...           1               1           3.0   \n",
       "617644           0           1  ...           1               1           3.0   \n",
       "\n",
       "              dwelling_type  dwelling_type_ord detached  flat  semi_detached  \\\n",
       "0       semi_detached_house                  3      0.0   0.0            1.0   \n",
       "1       semi_detached_house                  3      0.0   0.0            1.0   \n",
       "2       semi_detached_house                  3      0.0   0.0            1.0   \n",
       "3       semi_detached_house                  3      0.0   0.0            1.0   \n",
       "4       semi_detached_house                  3      0.0   0.0            1.0   \n",
       "...                     ...                ...      ...   ...            ...   \n",
       "617640       detached_house                  1      1.0   0.0            0.0   \n",
       "617641       detached_house                  1      1.0   0.0            0.0   \n",
       "617642       detached_house                  1      1.0   0.0            0.0   \n",
       "617643       detached_house                  1      1.0   0.0            0.0   \n",
       "617644       detached_house                  1      1.0   0.0            0.0   \n",
       "\n",
       "        terraced  meter_reading  \n",
       "0            0.0      11.881495  \n",
       "1            0.0      11.881495  \n",
       "2            0.0      11.881495  \n",
       "3            0.0      11.881495  \n",
       "4            0.0      11.881495  \n",
       "...          ...            ...  \n",
       "617640       0.0      18.758500  \n",
       "617641       0.0      21.011000  \n",
       "617642       0.0      19.204000  \n",
       "617643       0.0      17.397000  \n",
       "617644       0.0      15.237000  \n",
       "\n",
       "[617645 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_ord</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>...</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>dwelling_type_ord</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185515</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185516</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185517</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185518</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185519</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185520 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           meter_id  meter_id_ord  meter_id_0  \\\n",
       "0        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "1        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "2        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "3        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "4        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "...                                             ...           ...         ...   \n",
       "1185515  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185516  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185517  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185518  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185519  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "\n",
       "         meter_id_1  meter_id_2  meter_id_3  meter_id_4  meter_id_5  \\\n",
       "0                 0           0           0           0           0   \n",
       "1                 0           0           0           0           0   \n",
       "2                 0           0           0           0           0   \n",
       "3                 0           0           0           0           0   \n",
       "4                 0           0           0           0           0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "1185515           1           1           0           0           1   \n",
       "1185516           1           1           0           0           1   \n",
       "1185517           1           1           0           0           1   \n",
       "1185518           1           1           0           0           1   \n",
       "1185519           1           1           0           0           1   \n",
       "\n",
       "         meter_id_6  meter_id_7  ...  is_weekend  energy_cluster  \\\n",
       "0                 0           0  ...           0               0   \n",
       "1                 0           0  ...           0               0   \n",
       "2                 0           0  ...           0               0   \n",
       "3                 0           0  ...           0               0   \n",
       "4                 0           0  ...           0               0   \n",
       "...             ...         ...  ...         ...             ...   \n",
       "1185515           0           1  ...           0               1   \n",
       "1185516           0           1  ...           0               1   \n",
       "1185517           0           1  ...           1               1   \n",
       "1185518           0           1  ...           1               1   \n",
       "1185519           0           1  ...           0               1   \n",
       "\n",
       "         num_bedrooms   dwelling_type  dwelling_type_ord detached  flat  \\\n",
       "0                 2.0  terraced_house                  4      0.0   0.0   \n",
       "1                 2.0  terraced_house                  4      0.0   0.0   \n",
       "2                 2.0  terraced_house                  4      0.0   0.0   \n",
       "3                 2.0  terraced_house                  4      0.0   0.0   \n",
       "4                 2.0  terraced_house                  4      0.0   0.0   \n",
       "...               ...             ...                ...      ...   ...   \n",
       "1185515           3.0  detached_house                  1      1.0   0.0   \n",
       "1185516           3.0  detached_house                  1      1.0   0.0   \n",
       "1185517           3.0  detached_house                  1      1.0   0.0   \n",
       "1185518           3.0  detached_house                  1      1.0   0.0   \n",
       "1185519           3.0  detached_house                  1      1.0   0.0   \n",
       "\n",
       "         semi_detached  terraced  meter_reading  \n",
       "0                  0.0       1.0              0  \n",
       "1                  0.0       1.0              0  \n",
       "2                  0.0       1.0              0  \n",
       "3                  0.0       1.0              0  \n",
       "4                  0.0       1.0              0  \n",
       "...                ...       ...            ...  \n",
       "1185515            0.0       0.0              0  \n",
       "1185516            0.0       0.0              0  \n",
       "1185517            0.0       0.0              0  \n",
       "1185518            0.0       0.0              0  \n",
       "1185519            0.0       0.0              0  \n",
       "\n",
       "[1185520 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ordinally encoding dwelling_type\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_train[\"dwelling_type\"])\n",
    "\n",
    "#ordinally encoding with same encoder so will encode the same\n",
    "df_train.insert(27, \"dwelling_type_ord\", le.transform(df_train[\"dwelling_type\"]))\n",
    "df_preds.insert(27, \"dwelling_type_ord\", le.transform(df_preds[\"dwelling_type\"]))\n",
    "\n",
    "display(df_train)\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKF-CV for training the LGBM\n",
    "* Using skf on df_train by meter_id with 3 folds\n",
    "    * Meaning for each iteration we use 2/3 of each meters data for training and 1/3 of each meters data for validating\n",
    "* using out of fold predictions, making predictions on each fold and aggregating them together for the final prediction\n",
    "\n",
    "* evaluates the model via OOF predictions made on the held out set on each fold\n",
    "* this score is returned and along with the 3 models\n",
    "* genetic algorithm hyper parameter tuning will then be used to find the LGBM hyper param config with the best val score and this will then be used to make predictions using the model which has the best validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this lgbm was partly inspired by the work of Wenlong Wu's proposed model : \"Solution to the IEEE-CIS Second Technical Challenge with Machine Learning Modeling\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#function for running the cross fold\n",
    "    #args:\n",
    "        #disp_fold_info = True if we want to print info for each fold\n",
    "        #disp_end_info = True if we want to display evaluation info at the end\n",
    "        #SEED = random seed used for fair repeatability\n",
    "        #num_folds = number of folds in skf (pretty certain going to keep this at 3 )\n",
    "        #df_train = training dataframe\n",
    "        #y_col = the name of the label we want to predict (meter_reading)\n",
    "        #X_cols = the name of the feature columns we are using\n",
    "        #X_cat = the name of these features which are categorical\n",
    "        #params = hyper params for the LGBM model\n",
    "    #returns:\n",
    "        #time_of_execution = how long it took to train the model on all folds; will be used as a point of comparison\n",
    "        #valid_score = MAE calculated using the Out-of-Fold Predictions on the df_train, used for hyper-param tuning\n",
    "        #lgbm_models = array of the different lgbm_models\n",
    "        \n",
    "def run_lgbm_skf_cv(disp_fold_info, disp_end_info, SEED, num_folds, df_train, y_col, X_cols, X_cat, params):\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state = SEED) # defining the SKF algorithm\n",
    "\n",
    "    lgbm_models = []\n",
    "    start_time = time.time()\n",
    "    fold_iter=1\n",
    "    #running the startified kfold, splitting df_train by meter_id, so we use 2/3 of each meters reading for training\n",
    "    for train_index, valid_index in skf.split(df_train, df_train[\"meter_id\"]):\n",
    "\n",
    "        print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Fold {fold_iter}{color.END}\")\n",
    "        \n",
    "        #splitting into the features and labels for the train and valid folds\n",
    "        X_train, X_valid = df_train.loc[train_index, X_cols], df_train.loc[valid_index, X_cols]\n",
    "        y_train, y_valid = df_train.loc[train_index, y_col], df_train.loc[valid_index, y_col]\n",
    "        \n",
    "        if(disp_fold_info):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}X_train{color.END}\")\n",
    "            display(X_train.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}y_train{color.END}\")\n",
    "            display(y_train.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}X_valid{color.END}\")\n",
    "            display(X_valid.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}y_valid{color.END}\")\n",
    "            display(y_valid.head(5))\n",
    "            \n",
    "        print(f\"{color.CYAN}{color.UNDERLINE}Training the LGBM{color.END}\")\n",
    "        #instantiating a lgbm regressor with our params\n",
    "        lgbm_model = lgbm.LGBMRegressor(**params)\n",
    "        #fitting the lgbm model on the 2/3 train and evaluating on the 1/3 valid\n",
    "        #printing details every 1000 iters + stopping if no improvement made in 250 iters\n",
    "        lgbm_model.fit(X_train, y_train,\n",
    "                       eval_set=[(X_valid, y_valid)],\n",
    "                       categorical_feature=X_cat,\n",
    "                       verbose=3333,\n",
    "                       early_stopping_rounds=250)\n",
    "        \n",
    "        #saving the OOF prediction for the held out rows (valid rows from df_train) from the lgbm model with the best performing intrinisic parmams \n",
    "        oof_valid = lgbm_model.predict(X_valid, num_iteration=lgbm_model.best_iteration_) # making prediction on the held out rows, X_valid\n",
    "        df_train.loc[valid_index, \"oof\"] = oof_valid #storing the oof rows \n",
    "        if(disp_fold_info):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}df_train OOF predictions{color.END}\")\n",
    "            display(df_train.loc[valid_index, [\"meter_id\",\"oof\"]].head(5))\n",
    "               \n",
    "        #appending this lgbm\n",
    "        lgbm_models.append(lgbm_model)\n",
    "        if(disp_fold_info):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}lgbm_models size{color.END}: {len(lgbm_models)}\")\n",
    "            \n",
    "        fold_iter+=1\n",
    "        \n",
    "    \n",
    "    #calculating execution time and the MAE on the training set\n",
    "    time_of_execution = time.time() - start_time\n",
    "    valid_score=mean_absolute_error(df_train[y_col], df_train[\"oof\"]) \n",
    "    \n",
    "    if(disp_end_info):\n",
    "        print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}training set OOF preds vs true{color.END}\")\n",
    "        display(df_train[[\"meter_id\",\"date\",\"meter_reading\",\"oof\"]])\n",
    "        print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution for skf-cv:  {color.END}{str(datetime.timedelta(seconds=round(time_of_execution)))}\\n\")\n",
    "        print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set:{color.END} {valid_score}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (time_of_execution, valid_score, lgbm_models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running GA hyper param optim on the LGBM skf-cv function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"meter_reading\" #we want to predict the meter_reading (this will always be the same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the column types and grouping ones together that should be grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'day_of_month': ['day_of_month'],\n",
      " 'day_of_week': ['day_of_week'],\n",
      " 'day_of_year_cyclic': ['day_of_year_sin', 'day_of_year_cos'],\n",
      " 'dwelling_type_onehot': ['detached', 'flat', 'semi_detached', 'terraced'],\n",
      " 'dwelling_type_ord': ['dwelling_type_ord'],\n",
      " 'energy_cluster': ['energy_cluster'],\n",
      " 'is_weekend': ['is_weekend'],\n",
      " 'meter_id_binary': ['meter_id_0',\n",
      "                     'meter_id_1',\n",
      "                     'meter_id_2',\n",
      "                     'meter_id_3',\n",
      "                     'meter_id_4',\n",
      "                     'meter_id_5',\n",
      "                     'meter_id_6',\n",
      "                     'meter_id_7',\n",
      "                     'meter_id_8',\n",
      "                     'meter_id_9',\n",
      "                     'meter_id_10',\n",
      "                     'meter_id_11',\n",
      "                     'meter_id_12'],\n",
      " 'meter_id_ord': ['meter_id_ord'],\n",
      " 'month_cyclic': ['month_sin', 'month_cos'],\n",
      " 'month_ord': ['month_ord'],\n",
      " 'num_bedrooms': ['num_bedrooms']}\n"
     ]
    }
   ],
   "source": [
    "#dictionary to hold all groups of columns which could be chosen\n",
    "#done as if we just pick columns completely random we may get just \"meter_id_3\" from the binary encoded meter_id's\n",
    "#wouldn't make any sense without the other respective binary encoded meter_id columns\n",
    "\n",
    "possible_columns = {}\n",
    "possible_columns[\"meter_id_ord\"] = [\"meter_id_ord\"]\n",
    "possible_columns[\"meter_id_binary\"] = ['meter_id_0', 'meter_id_1', 'meter_id_2',\n",
    "       'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7',\n",
    "       'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12']\n",
    "possible_columns[\"day_of_year_cyclic\"] = [\"day_of_year_sin\",\"day_of_year_cos\"]\n",
    "possible_columns[\"day_of_week\"] = [\"day_of_week\"]\n",
    "possible_columns[\"day_of_month\"] = [\"day_of_month\"]\n",
    "possible_columns[\"month_ord\"] = [\"month_ord\"]\n",
    "possible_columns[\"month_cyclic\"] = [\"month_sin\",\"month_cos\"]\n",
    "possible_columns[\"is_weekend\"] = [\"is_weekend\"]\n",
    "possible_columns[\"energy_cluster\"] = [\"energy_cluster\"]\n",
    "possible_columns[\"num_bedrooms\"] = [\"num_bedrooms\"]\n",
    "possible_columns[\"dwelling_type_ord\"] = [\"dwelling_type_ord\"]\n",
    "possible_columns[\"dwelling_type_onehot\"] = ['detached', 'flat', 'semi_detached', 'terraced']\n",
    "pprint(possible_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting categorical columns\n",
    "\n",
    "all_cat = [\"meter_id_ord\", 'meter_id_0', 'meter_id_1', 'meter_id_2',\n",
    "           'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7',\n",
    "           'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12',\n",
    "           \"day_of_week\", \"day_of_month\", \"month_ord\", \"is_weekend\", \"energy_cluster\",\n",
    "           \"dwelling_type_ord\", \"detached\", \"flat\", \"semi_detached\", \"terraced\"] #all categorical values\n",
    "\n",
    "# setting categorical columns in the dataframe to be categorical\n",
    "#X_cat[0] holds all columns (besides clusters but we aren't using that) \n",
    "for i in all_cat:\n",
    "    df_train[i] = df_train[i].astype('category')\n",
    "    df_preds[i] = df_preds[i].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model parameters for GA\n",
    "* sensible different combinations of params for the model\n",
    "\n",
    "* default values which make sense and the others have place holders as they will be found in GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.99999,\n",
      " 'bagging_freq': 99999,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.99999,\n",
      " 'lambda_l1': 99999,\n",
      " 'lambda_l2': 99999,\n",
      " 'learning_rate': 0.99999,\n",
      " 'max_depth': 99999,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 99999,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n"
     ]
    }
   ],
   "source": [
    "#default params (including ones we will override and those we won't)\n",
    "params = {\n",
    "    ### won't be tuned ###\n",
    "    'boosting_type': 'gbdt', #gbdt/rf/dart/goss\n",
    "    'metric': 'mae', \n",
    "    'num_threads': -1, # number of threads to run on for speed (auto)\n",
    "    'num_iterations': 10000, #defining the models runs\n",
    "    'seed': SEED, # all runs with same seed for better comparison between different hyper params\n",
    "    \n",
    "    \n",
    "    ### will be tuned (replace these with the best performing) ###\n",
    "    'learning_rate': 0.99999,\n",
    "    'num_leaves': 99999, # limit max numer of leaves in a tree\n",
    "    \"max_depth\":99999, # limit max depth of the tree to prevent overfitting\n",
    "    # fraction to be bagged/sampled every k iterations\n",
    "    'bagging_fraction': 0.99999,\n",
    "    'bagging_freq' : 99999,\n",
    "    'feature_fraction': 0.99999, # fraction of features to use at each tree node\n",
    "    #l1 & l2 regularization to prevent overfitting\n",
    "    \"lambda_l1\": 99999,\n",
    "    \"lambda_l2\": 99999\n",
    "}\n",
    "\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of names of keys for the params we tune in the dic ; will be used in mutation of GA\n",
    "tuned_hyper_names = [\"learning_rate\",\"num_leaves\",\"max_depth\",\"bagging_fraction\",\"bagging_freq\",\"feature_fraction\",\"lambda_l1\",\"lambda_l2\"]\n",
    "whole_number_hyper_names = [\"num_leaves\",\"max_depth\",\"bagging_freq\",\"lambda_l1\",\"lambda_l2\"]\n",
    "fractional_hyper_names = [\"bagging_fraction\",\"feature_fraction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Genetic Algorithm Hyper Param Optimization\n",
    "### creating the initial population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe initial population is\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 0\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.95,\n",
      " 'bagging_freq': 10,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.93,\n",
      " 'lambda_l1': 14,\n",
      " 'lambda_l2': 8,\n",
      " 'learning_rate': 0.06,\n",
      " 'max_depth': 10,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 695,\n",
      " 'num_threads': -1,\n",
      " 'seed': 137}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 1\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.95,\n",
      " 'bagging_freq': 10,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.93,\n",
      " 'lambda_l1': 14,\n",
      " 'lambda_l2': 8,\n",
      " 'learning_rate': 0.06,\n",
      " 'max_depth': 10,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 695,\n",
      " 'num_threads': -1,\n",
      " 'seed': 137}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 2\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.98,\n",
      " 'bagging_freq': 16,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.56,\n",
      " 'lambda_l1': 17,\n",
      " 'lambda_l2': 16,\n",
      " 'learning_rate': 0.06,\n",
      " 'max_depth': 11,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 1443,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 3\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['num_bedrooms']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['num_bedrooms']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.6,\n",
      " 'bagging_freq': 15,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.93,\n",
      " 'lambda_l1': 18,\n",
      " 'lambda_l2': 12,\n",
      " 'learning_rate': 0.025,\n",
      " 'max_depth': 9,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 382,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 4\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_binary', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.9,\n",
      " 'bagging_freq': 11,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.62,\n",
      " 'lambda_l1': 7,\n",
      " 'lambda_l2': 13,\n",
      " 'learning_rate': 0.016,\n",
      " 'max_depth': 11,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 1059,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 5\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['day_of_week', 'day_of_month', 'month_sin', 'month_cos', 'is_weekend', 'num_bedrooms', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['day_of_week', 'day_of_month', 'month_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.63,\n",
      " 'bagging_freq': 24,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.61,\n",
      " 'lambda_l1': 9,\n",
      " 'lambda_l2': 5,\n",
      " 'learning_rate': 0.081,\n",
      " 'max_depth': 11,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 1653,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 6\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.66,\n",
      " 'bagging_freq': 7,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.95,\n",
      " 'lambda_l1': 8,\n",
      " 'lambda_l2': 5,\n",
      " 'learning_rate': 0.081,\n",
      " 'max_depth': 10,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 775,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 7\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'month_ord', 'month_sin', 'month_cos', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.97,\n",
      " 'bagging_freq': 9,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.53,\n",
      " 'lambda_l1': 18,\n",
      " 'lambda_l2': 15,\n",
      " 'learning_rate': 0.015,\n",
      " 'max_depth': 9,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 403,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 8\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'month_sin', 'month_cos', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.85,\n",
      " 'bagging_freq': 13,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.6,\n",
      " 'lambda_l1': 11,\n",
      " 'lambda_l2': 14,\n",
      " 'learning_rate': 0.071,\n",
      " 'max_depth': 9,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 475,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 9\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.91,\n",
      " 'bagging_freq': 18,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.69,\n",
      " 'lambda_l1': 14,\n",
      " 'lambda_l2': 16,\n",
      " 'learning_rate': 0.015,\n",
      " 'max_depth': 6,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 44,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 10\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_sin', 'month_cos', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_cyclic', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.79,\n",
      " 'bagging_freq': 5,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.71,\n",
      " 'lambda_l1': 6,\n",
      " 'lambda_l2': 12,\n",
      " 'learning_rate': 0.04,\n",
      " 'max_depth': 9,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 299,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 11\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.53,\n",
      " 'bagging_freq': 20,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.95,\n",
      " 'lambda_l1': 10,\n",
      " 'lambda_l2': 15,\n",
      " 'learning_rate': 0.095,\n",
      " 'max_depth': 7,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 102,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 12\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.68,\n",
      " 'bagging_freq': 5,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.59,\n",
      " 'lambda_l1': 8,\n",
      " 'lambda_l2': 18,\n",
      " 'learning_rate': 0.015,\n",
      " 'max_depth': 11,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 2040,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 13\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.95,\n",
      " 'bagging_freq': 19,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.79,\n",
      " 'lambda_l1': 16,\n",
      " 'lambda_l2': 13,\n",
      " 'learning_rate': 0.038,\n",
      " 'max_depth': 11,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 1110,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 14\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.93,\n",
      " 'bagging_freq': 11,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.56,\n",
      " 'lambda_l1': 6,\n",
      " 'lambda_l2': 9,\n",
      " 'learning_rate': 0.094,\n",
      " 'max_depth': 7,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 84,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 15\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.54,\n",
      " 'bagging_freq': 9,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.73,\n",
      " 'lambda_l1': 12,\n",
      " 'lambda_l2': 16,\n",
      " 'learning_rate': 0.034,\n",
      " 'max_depth': 6,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 36,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 16\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'month_sin', 'month_cos']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_cyclic']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.76,\n",
      " 'bagging_freq': 14,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.81,\n",
      " 'lambda_l1': 15,\n",
      " 'lambda_l2': 5,\n",
      " 'learning_rate': 0.046,\n",
      " 'max_depth': 7,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 64,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 17\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'day_of_week', 'day_of_month', 'month_sin', 'month_cos', 'energy_cluster', 'num_bedrooms', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'day_of_week', 'day_of_month', 'month_cyclic', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.5,\n",
      " 'bagging_freq': 20,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.93,\n",
      " 'lambda_l1': 9,\n",
      " 'lambda_l2': 10,\n",
      " 'learning_rate': 0.06,\n",
      " 'max_depth': 9,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 344,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 18\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'month_sin', 'month_cos', 'energy_cluster', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_binary', 'day_of_year_cyclic', 'month_cyclic', 'energy_cluster', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.51,\n",
      " 'bagging_freq': 18,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.83,\n",
      " 'lambda_l1': 13,\n",
      " 'lambda_l2': 7,\n",
      " 'learning_rate': 0.074,\n",
      " 'max_depth': 7,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 119,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 19\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_week', 'day_of_month', 'month_ord', 'month_sin', 'month_cos', 'energy_cluster', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'energy_cluster', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.84,\n",
      " 'bagging_freq': 5,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.94,\n",
      " 'lambda_l1': 5,\n",
      " 'lambda_l2': 16,\n",
      " 'learning_rate': 0.099,\n",
      " 'max_depth': 7,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 77,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "population = []\n",
    "# loading the description of the best model from RS and the RS main effects to be used as 2 of the original population\n",
    "rs_best_model = pd.read_pickle(\"../Results/Unclustered Random Search/128_best_model_desc.pkl\")\n",
    "rs_best_model_features = rs_best_model[\"features\"]\n",
    "rs_best_model_col_groups = []\n",
    "for key in possible_columns.keys():\n",
    "    if(possible_columns[key][0] in rs_best_model_features):\n",
    "        rs_best_model_col_groups+=[key]\n",
    "population.append((rs_best_model_features,rs_best_model[\"params\"], rs_best_model_col_groups))\n",
    "\n",
    "rs_main_effects_model = pd.read_pickle(\"../Results/Unclustered Random Search/128_main_effects_desc.pkl\")\n",
    "rs_main_effects_features = rs_main_effects_model[\"features\"]\n",
    "rs_main_effects_col_groups = []\n",
    "for key in possible_columns.keys():\n",
    "    if(possible_columns[key][0] in rs_main_effects_features):\n",
    "        rs_main_effects_col_groups+=[key]\n",
    "population.append((rs_main_effects_features,rs_best_model[\"params\"], rs_main_effects_col_groups))\n",
    "\n",
    "#filling the rest of the population with random models\n",
    "while (len(population)<population_size):\n",
    "    #firstly randomly picking the features we will use\n",
    "    X_cols = []#this will store the X_cols we use\n",
    "    X_col_groups = []\n",
    "    #generating probability of accepting each column\n",
    "    prob_to_beat = random.randrange(30,100)/100 #between 0.3 and 1\n",
    "    #iterating through each column and randomly decide whether or not to pick it\n",
    "    for key in possible_columns.keys():\n",
    "        #randomly generate a decimal for this column group\n",
    "        this_prob = random.randrange(0,100)/100 #between 0 and 1\n",
    "        #if this is less than the probability to beat then accept it\n",
    "        if(this_prob<=prob_to_beat):\n",
    "            X_col_groups+=[key]\n",
    "            X_cols+=possible_columns[key]\n",
    "\n",
    "    #then get LGBM hyper parameters\n",
    "    this_params = params.copy()\n",
    "    this_params[\"learning_rate\"] = random.randrange(10,100)/1000 #between 0.01 and 0.1\n",
    "    this_params[\"max_depth\"] = random.randrange(6,12)\n",
    "    this_params[\"num_leaves\"] = random.randrange(np.round(2**(this_params[\"max_depth\"])*0.5), np.round(2**(this_params[\"max_depth\"])*1)) #picking a random max leaves less than 2^(max_depth) to prevent over fitting (between 50 and 100%)\n",
    "    this_params[\"bagging_fraction\"] = random.randrange(50,100)/100 #between 0.5 and 1\n",
    "    this_params[\"bagging_freq\"] = random.randrange(5,25)\n",
    "    this_params[\"feature_fraction\"] = random.randrange(50,100)/100 #between 0.5 and 1\n",
    "    this_params[\"lambda_l1\"] = random.randrange(4,20)\n",
    "    this_params[\"lambda_l2\"] = random.randrange(4,20)\n",
    "    \n",
    "    #adding this random model to the initial population\n",
    "    population.append((X_cols,this_params,X_col_groups))\n",
    "    \n",
    "#viewing the initial population\n",
    "print(f\"{color.BOLD}The initial population is{color.END}\\n\")\n",
    "for i in range(len(population)):\n",
    "    print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}population member {i}{color.END}\")\n",
    "    print(f\"{color.BOLD}features{color.END}\\n\",population[i][0])\n",
    "    print(f\"{color.BOLD}feature groups{color.END}\\n\",population[i][2])\n",
    "    print(f\"{color.BOLD}labels{color.END}\")\n",
    "    pprint(population[i][1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the genetic algorithm\n",
    "* Selection : Elitism\n",
    "    * pick the best elitism_n models as the parents\n",
    "* Cross Over : Uniform\n",
    "    * for each child pick 2 random parents from the parents found from elitism (each has equal chance of being picked)\n",
    "    * iterate through each column group and hyper parameter and give a 50% chance of it being chosen from each parent\n",
    "* Mutation : \n",
    "    * Column groups : Flip Bit\n",
    "        * Iteratively pick column groups to flip their usage based on the mutation rate\n",
    "            * If all columns are deactive then randomly pick 1 to activate\n",
    "    * Hyper parameters : Gaussian\n",
    "        * Iteratively pick hyper params to +/- up to 25% based on mutation rate\n",
    "        \n",
    "\n",
    "<b> this one doesn't store the lgbm model as my machine was running out of memory due to the GA being more complicated. Instead will just save the description and will have to retrain the best one with that description at the end of the algorithm </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mGenetic Algorithm hyper parameter optimization\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb04fc5b5b7407fa93963293c8c68a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bc13b87f6a4401a55df06cfb000e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 137, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76219\n",
      "[6666]\tvalid_0's l1: 1.73416\n",
      "[9999]\tvalid_0's l1: 1.71722\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.71721\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76347\n",
      "[6666]\tvalid_0's l1: 1.73625\n",
      "[9999]\tvalid_0's l1: 1.72\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9990]\tvalid_0's l1: 1.71999\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.77098\n",
      "[6666]\tvalid_0's l1: 1.74148\n",
      "[9999]\tvalid_0's l1: 1.72288\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9993]\tvalid_0's l1: 1.72287\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 137, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2480]\tvalid_0's l1: 1.8352\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1474]\tvalid_0's l1: 1.84145\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2442]\tvalid_0's l1: 1.8419\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 1443, 'max_depth': 11, 'bagging_fraction': 0.98, 'bagging_freq': 16, 'feature_fraction': 0.56, 'lambda_l1': 17, 'lambda_l2': 16}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=17, reg_alpha=0.0 will be ignored. Current value: lambda_l1=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.98, subsample=1.0 will be ignored. Current value: bagging_fraction=0.98\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.86364\n",
      "[6666]\tvalid_0's l1: 1.85069\n",
      "Early stopping, best iteration is:\n",
      "[6623]\tvalid_0's l1: 1.8505\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=17, reg_alpha=0.0 will be ignored. Current value: lambda_l1=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.98, subsample=1.0 will be ignored. Current value: bagging_fraction=0.98\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.86602\n",
      "Early stopping, best iteration is:\n",
      "[5514]\tvalid_0's l1: 1.85508\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=17, reg_alpha=0.0 will be ignored. Current value: lambda_l1=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.98, subsample=1.0 will be ignored. Current value: bagging_fraction=0.98\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.8699\n",
      "[6666]\tvalid_0's l1: 1.85631\n",
      "Early stopping, best iteration is:\n",
      "[8386]\tvalid_0's l1: 1.85286\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.025, 'num_leaves': 382, 'max_depth': 9, 'bagging_fraction': 0.6, 'bagging_freq': 15, 'feature_fraction': 0.93, 'lambda_l1': 18, 'lambda_l2': 12}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=18, reg_alpha=0.0 will be ignored. Current value: lambda_l1=18\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=12, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's l1: 4.77682\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=18, reg_alpha=0.0 will be ignored. Current value: lambda_l1=18\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=12, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's l1: 4.76848\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=18, reg_alpha=0.0 will be ignored. Current value: lambda_l1=18\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=12, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's l1: 4.77812\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.016, 'num_leaves': 1059, 'max_depth': 11, 'bagging_fraction': 0.9, 'bagging_freq': 11, 'feature_fraction': 0.62, 'lambda_l1': 7, 'lambda_l2': 13}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.62, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.62\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.76842\n",
      "[6666]\tvalid_0's l1: 2.72782\n",
      "[9999]\tvalid_0's l1: 2.70748\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 2.70747\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.62, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.62\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.76862\n",
      "[6666]\tvalid_0's l1: 2.72714\n",
      "[9999]\tvalid_0's l1: 2.70711\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9976]\tvalid_0's l1: 2.70704\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.62, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.62\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.7747\n",
      "[6666]\tvalid_0's l1: 2.73049\n",
      "[9999]\tvalid_0's l1: 2.70961\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9965]\tvalid_0's l1: 2.70955\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'day_of_month', 'month_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.081, 'num_leaves': 1653, 'max_depth': 11, 'bagging_fraction': 0.63, 'bagging_freq': 24, 'feature_fraction': 0.61, 'lambda_l1': 9, 'lambda_l2': 5}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.61, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.61\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.63, subsample=1.0 will be ignored. Current value: bagging_fraction=0.63\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's l1: 4.60671\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.61, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.61\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.63, subsample=1.0 will be ignored. Current value: bagging_fraction=0.63\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's l1: 4.60596\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.61, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.61\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.63, subsample=1.0 will be ignored. Current value: bagging_fraction=0.63\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's l1: 4.61766\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.081, 'num_leaves': 775, 'max_depth': 10, 'bagging_fraction': 0.66, 'bagging_freq': 7, 'feature_fraction': 0.95, 'lambda_l1': 8, 'lambda_l2': 5}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97062\n",
      "[6666]\tvalid_0's l1: 1.94725\n",
      "[9999]\tvalid_0's l1: 1.94132\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9871]\tvalid_0's l1: 1.94107\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97683\n",
      "[6666]\tvalid_0's l1: 1.95679\n",
      "Early stopping, best iteration is:\n",
      "[8883]\tvalid_0's l1: 1.95136\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98507\n",
      "[6666]\tvalid_0's l1: 1.96244\n",
      "Early stopping, best iteration is:\n",
      "[8505]\tvalid_0's l1: 1.95654\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.015, 'num_leaves': 403, 'max_depth': 9, 'bagging_fraction': 0.97, 'bagging_freq': 9, 'feature_fraction': 0.53, 'lambda_l1': 18, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.53, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.53\n",
      "[LightGBM] [Warning] lambda_l1 is set=18, reg_alpha=0.0 will be ignored. Current value: lambda_l1=18\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9389\n",
      "[6666]\tvalid_0's l1: 1.89196\n",
      "[9999]\tvalid_0's l1: 1.86944\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9998]\tvalid_0's l1: 1.86944\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.53, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.53\n",
      "[LightGBM] [Warning] lambda_l1 is set=18, reg_alpha=0.0 will be ignored. Current value: lambda_l1=18\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94257\n",
      "[6666]\tvalid_0's l1: 1.89653\n",
      "[9999]\tvalid_0's l1: 1.87082\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9996]\tvalid_0's l1: 1.87081\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.53, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.53\n",
      "[LightGBM] [Warning] lambda_l1 is set=18, reg_alpha=0.0 will be ignored. Current value: lambda_l1=18\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3333]\tvalid_0's l1: 1.95011\n",
      "[6666]\tvalid_0's l1: 1.90512\n",
      "[9999]\tvalid_0's l1: 1.88248\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9998]\tvalid_0's l1: 1.88248\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.071, 'num_leaves': 475, 'max_depth': 9, 'bagging_fraction': 0.85, 'bagging_freq': 13, 'feature_fraction': 0.6, 'lambda_l1': 11, 'lambda_l2': 14}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92388\n",
      "[6666]\tvalid_0's l1: 1.86953\n",
      "[9999]\tvalid_0's l1: 1.84342\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9974]\tvalid_0's l1: 1.84341\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93011\n",
      "[6666]\tvalid_0's l1: 1.8796\n",
      "[9999]\tvalid_0's l1: 1.8503\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9955]\tvalid_0's l1: 1.85022\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93683\n",
      "[6666]\tvalid_0's l1: 1.88354\n",
      "[9999]\tvalid_0's l1: 1.85468\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.85468\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.015, 'num_leaves': 44, 'max_depth': 6, 'bagging_fraction': 0.91, 'bagging_freq': 18, 'feature_fraction': 0.69, 'lambda_l1': 14, 'lambda_l2': 16}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.69, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.69\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.91, subsample=1.0 will be ignored. Current value: bagging_fraction=0.91\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.03886\n",
      "[6666]\tvalid_0's l1: 2.01107\n",
      "[9999]\tvalid_0's l1: 1.99938\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9974]\tvalid_0's l1: 1.99937\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.69, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.69\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.91, subsample=1.0 will be ignored. Current value: bagging_fraction=0.91\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.04557\n",
      "[6666]\tvalid_0's l1: 2.01795\n",
      "[9999]\tvalid_0's l1: 2.00593\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9982]\tvalid_0's l1: 2.00591\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.69, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.69\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.91, subsample=1.0 will be ignored. Current value: bagging_fraction=0.91\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.05233\n",
      "[6666]\tvalid_0's l1: 2.02322\n",
      "[9999]\tvalid_0's l1: 2.01162\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 2.01162\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_cyclic', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.04, 'num_leaves': 299, 'max_depth': 9, 'bagging_fraction': 0.79, 'bagging_freq': 5, 'feature_fraction': 0.71, 'lambda_l1': 6, 'lambda_l2': 12}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.79, subsample=1.0 will be ignored. Current value: bagging_fraction=0.79\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=12, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.03841\n",
      "[6666]\tvalid_0's l1: 1.99546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9999]\tvalid_0's l1: 1.97294\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9996]\tvalid_0's l1: 1.97293\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.79, subsample=1.0 will be ignored. Current value: bagging_fraction=0.79\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=12, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.03565\n",
      "[6666]\tvalid_0's l1: 1.99482\n",
      "[9999]\tvalid_0's l1: 1.97167\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9996]\tvalid_0's l1: 1.97164\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.79, subsample=1.0 will be ignored. Current value: bagging_fraction=0.79\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=12, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.03968\n",
      "[6666]\tvalid_0's l1: 1.99904\n",
      "[9999]\tvalid_0's l1: 1.97638\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9984]\tvalid_0's l1: 1.97636\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.095, 'num_leaves': 102, 'max_depth': 7, 'bagging_fraction': 0.53, 'bagging_freq': 20, 'feature_fraction': 0.95, 'lambda_l1': 10, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.53, subsample=1.0 will be ignored. Current value: bagging_fraction=0.53\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3042]\tvalid_0's l1: 1.9399\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.53, subsample=1.0 will be ignored. Current value: bagging_fraction=0.53\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93909\n",
      "Early stopping, best iteration is:\n",
      "[3302]\tvalid_0's l1: 1.93816\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.95, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.95\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.53, subsample=1.0 will be ignored. Current value: bagging_fraction=0.53\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94517\n",
      "Early stopping, best iteration is:\n",
      "[3635]\tvalid_0's l1: 1.94403\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.015, 'num_leaves': 2040, 'max_depth': 11, 'bagging_fraction': 0.68, 'bagging_freq': 5, 'feature_fraction': 0.59, 'lambda_l1': 8, 'lambda_l2': 18}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.59, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.59\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.68, subsample=1.0 will be ignored. Current value: bagging_fraction=0.68\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=18, reg_lambda=0.0 will be ignored. Current value: lambda_l2=18\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.952\n",
      "[6666]\tvalid_0's l1: 1.9275\n",
      "[9999]\tvalid_0's l1: 1.91462\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9995]\tvalid_0's l1: 1.91461\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.59, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.59\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.68, subsample=1.0 will be ignored. Current value: bagging_fraction=0.68\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=18, reg_lambda=0.0 will be ignored. Current value: lambda_l2=18\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.95476\n",
      "[6666]\tvalid_0's l1: 1.92962\n",
      "[9999]\tvalid_0's l1: 1.91687\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.91687\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.59, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.59\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.68, subsample=1.0 will be ignored. Current value: bagging_fraction=0.68\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=18, reg_lambda=0.0 will be ignored. Current value: lambda_l2=18\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.96152\n",
      "[6666]\tvalid_0's l1: 1.93504\n",
      "[9999]\tvalid_0's l1: 1.92221\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9996]\tvalid_0's l1: 1.9222\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.038, 'num_leaves': 1110, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 19, 'feature_fraction': 0.79, 'lambda_l1': 16, 'lambda_l2': 13}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.79, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.79\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[779]\tvalid_0's l1: 3.29248\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.79, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.79\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[779]\tvalid_0's l1: 3.29249\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.79, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.79\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[760]\tvalid_0's l1: 3.29694\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 84, 'max_depth': 7, 'bagging_fraction': 0.93, 'bagging_freq': 11, 'feature_fraction': 0.56, 'lambda_l1': 6, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.93, subsample=1.0 will be ignored. Current value: bagging_fraction=0.93\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92614\n",
      "[6666]\tvalid_0's l1: 1.86382\n",
      "[9999]\tvalid_0's l1: 1.82933\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.82932\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.93, subsample=1.0 will be ignored. Current value: bagging_fraction=0.93\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92732\n",
      "[6666]\tvalid_0's l1: 1.86522\n",
      "[9999]\tvalid_0's l1: 1.8312\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.83118\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.93, subsample=1.0 will be ignored. Current value: bagging_fraction=0.93\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9371\n",
      "[6666]\tvalid_0's l1: 1.87484\n",
      "[9999]\tvalid_0's l1: 1.84153\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.84151\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.034, 'num_leaves': 36, 'max_depth': 6, 'bagging_fraction': 0.54, 'bagging_freq': 9, 'feature_fraction': 0.73, 'lambda_l1': 12, 'lambda_l2': 16}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.73, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.73\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.54, subsample=1.0 will be ignored. Current value: bagging_fraction=0.54\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.0052\n",
      "[6666]\tvalid_0's l1: 1.97679\n",
      "[9999]\tvalid_0's l1: 1.96078\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9971]\tvalid_0's l1: 1.96057\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.73, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.73\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.54, subsample=1.0 will be ignored. Current value: bagging_fraction=0.54\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.01329\n",
      "[6666]\tvalid_0's l1: 1.98207\n",
      "[9999]\tvalid_0's l1: 1.96545\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 1.96545\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.73, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.73\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.54, subsample=1.0 will be ignored. Current value: bagging_fraction=0.54\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.01694\n",
      "[6666]\tvalid_0's l1: 1.98642\n",
      "[9999]\tvalid_0's l1: 1.96969\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.96967\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 16\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_cyclic']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046, 'num_leaves': 64, 'max_depth': 7, 'bagging_fraction': 0.76, 'bagging_freq': 14, 'feature_fraction': 0.81, 'lambda_l1': 15, 'lambda_l2': 5}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.81, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.81\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99115\n",
      "[6666]\tvalid_0's l1: 1.93117\n",
      "[9999]\tvalid_0's l1: 1.89258\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.89255\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.81, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.81\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9935\n",
      "[6666]\tvalid_0's l1: 1.92875\n",
      "[9999]\tvalid_0's l1: 1.89187\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.89186\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.81, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.81\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99635\n",
      "[6666]\tvalid_0's l1: 1.93449\n",
      "[9999]\tvalid_0's l1: 1.89758\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9983]\tvalid_0's l1: 1.89755\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 17\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'month_cyclic', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 344, 'max_depth': 9, 'bagging_fraction': 0.5, 'bagging_freq': 20, 'feature_fraction': 0.93, 'lambda_l1': 9, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[471]\tvalid_0's l1: 1.99293\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[669]\tvalid_0's l1: 1.99717\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[741]\tvalid_0's l1: 2.00909\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 18\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_year_cyclic', 'month_cyclic', 'energy_cluster', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.074, 'num_leaves': 119, 'max_depth': 7, 'bagging_fraction': 0.51, 'bagging_freq': 18, 'feature_fraction': 0.83, 'lambda_l1': 13, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83\n",
      "[LightGBM] [Warning] lambda_l1 is set=13, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.51, subsample=1.0 will be ignored. Current value: bagging_fraction=0.51\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.27613\n",
      "[6666]\tvalid_0's l1: 2.21737\n",
      "[9999]\tvalid_0's l1: 2.19084\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 2.19084\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83\n",
      "[LightGBM] [Warning] lambda_l1 is set=13, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.51, subsample=1.0 will be ignored. Current value: bagging_fraction=0.51\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.27\n",
      "[6666]\tvalid_0's l1: 2.21324\n",
      "[9999]\tvalid_0's l1: 2.18219\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 2.18214\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.83, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.83\n",
      "[LightGBM] [Warning] lambda_l1 is set=13, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.51, subsample=1.0 will be ignored. Current value: bagging_fraction=0.51\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.2858\n",
      "[6666]\tvalid_0's l1: 2.22728\n",
      "[9999]\tvalid_0's l1: 2.19275\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9988]\tvalid_0's l1: 2.19263\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 19\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'energy_cluster', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.099, 'num_leaves': 77, 'max_depth': 7, 'bagging_fraction': 0.84, 'bagging_freq': 5, 'feature_fraction': 0.94, 'lambda_l1': 5, 'lambda_l2': 16}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.84, subsample=1.0 will be ignored. Current value: bagging_fraction=0.84\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1547]\tvalid_0's l1: 1.94616\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.84, subsample=1.0 will be ignored. Current value: bagging_fraction=0.84\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1547]\tvalid_0's l1: 1.95357\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.94, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.94\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.84, subsample=1.0 will be ignored. Current value: bagging_fraction=0.84\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1920]\tvalid_0's l1: 1.96124\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.7200211653369024\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.834002860539185\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.8395147313183635\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.8494370166675087\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 7 from 1\n",
      "inherited bagging_fraction value of 0.93 from 1\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.56 from 1\n",
      "inherited lambda_l1 value of 6 from 1\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 5 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.071 from 3\n",
      "inherited num_leaves value of 475 from 3\n",
      "inherited max_depth value of 9 from 3\n",
      "inherited bagging_fraction value of 0.95 from 0\n",
      "inherited bagging_freq value of 13 from 3\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 14 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 6 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 2\n",
      "inherited num_leaves value of 84 from 1\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.93 from 1\n",
      "inherited bagging_freq value of 11 from 1\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 7 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 1\n",
      "inherited num_leaves value of 84 from 1\n",
      "inherited max_depth value of 7 from 1\n",
      "inherited bagging_fraction value of 0.85 from 3\n",
      "inherited bagging_freq value of 11 from 1\n",
      "inherited feature_fraction value of 0.56 from 1\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 9 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited non-use of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 8 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 84 from 1\n",
      "inherited max_depth value of 7 from 1\n",
      "inherited bagging_fraction value of 0.93 from 1\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.56 from 1\n",
      "inherited lambda_l1 value of 6 from 1\n",
      "inherited lambda_l2 value of 9 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 9 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 0\n",
      "inherited bagging_fraction value of 0.93 from 1\n",
      "inherited bagging_freq value of 11 from 1\n",
      "inherited feature_fraction value of 0.56 from 1\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 9 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 10 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 1\n",
      "inherited num_leaves value of 475 from 3\n",
      "inherited max_depth value of 7 from 1\n",
      "inherited bagging_fraction value of 0.85 from 3\n",
      "inherited bagging_freq value of 11 from 1\n",
      "inherited feature_fraction value of 0.6 from 3\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 14 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited non-use of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited non-use of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 11 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 1\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 6 from 1\n",
      "inherited lambda_l2 value of 9 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 12 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 1\n",
      "inherited num_leaves value of 84 from 1\n",
      "inherited max_depth value of 7 from 1\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.56 from 1\n",
      "inherited lambda_l1 value of 6 from 1\n",
      "inherited lambda_l2 value of 9 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited non-use of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 13 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 2\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.95 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 14 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.071 from 3\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 0\n",
      "inherited bagging_fraction value of 0.85 from 3\n",
      "inherited bagging_freq value of 13 from 3\n",
      "inherited feature_fraction value of 0.6 from 3\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 14 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited non-use of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 15 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 1\n",
      "inherited num_leaves value of 475 from 3\n",
      "inherited max_depth value of 9 from 3\n",
      "inherited bagging_fraction value of 0.85 from 3\n",
      "inherited bagging_freq value of 13 from 3\n",
      "inherited feature_fraction value of 0.56 from 1\n",
      "inherited lambda_l1 value of 6 from 1\n",
      "inherited lambda_l2 value of 14 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited non-use of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited non-use of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 16 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 475 from 3\n",
      "inherited max_depth value of 10 from 0\n",
      "inherited bagging_fraction value of 0.95 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 14 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 17 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 1\n",
      "inherited num_leaves value of 475 from 3\n",
      "inherited max_depth value of 7 from 1\n",
      "inherited bagging_fraction value of 0.85 from 3\n",
      "inherited bagging_freq value of 11 from 1\n",
      "inherited feature_fraction value of 0.56 from 1\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 9 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited non-use of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 18 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 1\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.93 from 1\n",
      "inherited bagging_freq value of 11 from 1\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 19 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 23.0% from 695 to 535\n",
      "Decreased max_depth by 10.0% from 7 to 6\n",
      "Decreased bagging_fraction by 14.000000000000002% from 0.93 to 0.7998000000000001\n",
      "Increased feature_fraction by 16.0% from 0.56 to 0.6496000000000001\n",
      "Increased lambda_l1 by 3.0% from 6 to 6\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 4.0% from 0.071 to 0.07383999999999999\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_fraction by 23.0% from 0.93 to 1\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 2.0% from 695 to 709\n",
      "Increased bagging_fraction by 12.0% from 0.93 to 1\n",
      "Increased feature_fraction by 8.0% from 0.56 to 0.6048\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 9.0% from 475 to 518\n",
      "Decreased max_depth by 23.0% from 7 to 5\n",
      "Increased lambda_l1 by 6.0% from 11 to 12\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_fraction by 3.0% from 0.95 to 0.9784999999999999\n",
      "Decreased feature_fraction by 17.0% from 0.93 to 0.7719\n",
      "Increased lambda_l1 by 11.0% from 6 to 7\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_freq by 2.0% from 10 to 10\n",
      "Decreased lambda_l1 by 4.0% from 6 to 6\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 11.0% from 10 to 9\n",
      "Decreased feature_fraction by 4.0% from 0.93 to 0.8928\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 6.0% from 0.85 to 0.7989999999999999\n",
      "Decreased lambda_l2 by 19.0% from 14 to 11\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 16\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 20.0% from 0.06 to 0.072\n",
      "Decreased num_leaves by 7.000000000000001% from 475 to 442\n",
      "Increased lambda_l1 by 19.0% from 14 to 17\n",
      "\u001b[1m\u001b[92mChild 17\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using energy_cluster\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 17.0% from 7 to 8\n",
      "Decreased lambda_l2 by 19.0% from 9 to 7\n",
      "\u001b[1m\u001b[92mChild 18\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 19\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 22.0% from 0.06 to 0.046799999999999994\n",
      "Increased max_depth by 6.0% from 10 to 11\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e37955015734dadbe2808048a20c3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 137, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76219\n",
      "[6666]\tvalid_0's l1: 1.73416\n",
      "[9999]\tvalid_0's l1: 1.71722\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.71721\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76347\n",
      "[6666]\tvalid_0's l1: 1.73625\n",
      "[9999]\tvalid_0's l1: 1.72\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9990]\tvalid_0's l1: 1.71999\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.77098\n",
      "[6666]\tvalid_0's l1: 1.74148\n",
      "[9999]\tvalid_0's l1: 1.72288\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9993]\tvalid_0's l1: 1.72287\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 84, 'max_depth': 7, 'bagging_fraction': 0.93, 'bagging_freq': 11, 'feature_fraction': 0.56, 'lambda_l1': 6, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.93, subsample=1.0 will be ignored. Current value: bagging_fraction=0.93\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92614\n",
      "[6666]\tvalid_0's l1: 1.86382\n",
      "[9999]\tvalid_0's l1: 1.82933\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.82932\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.93, subsample=1.0 will be ignored. Current value: bagging_fraction=0.93\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92732\n",
      "[6666]\tvalid_0's l1: 1.86522\n",
      "[9999]\tvalid_0's l1: 1.8312\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.83118\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.93, subsample=1.0 will be ignored. Current value: bagging_fraction=0.93\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9371\n",
      "[6666]\tvalid_0's l1: 1.87484\n",
      "[9999]\tvalid_0's l1: 1.84155\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.84152\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 137, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2480]\tvalid_0's l1: 1.8352\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1474]\tvalid_0's l1: 1.84145\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2442]\tvalid_0's l1: 1.8419\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.071, 'num_leaves': 475, 'max_depth': 9, 'bagging_fraction': 0.85, 'bagging_freq': 13, 'feature_fraction': 0.6, 'lambda_l1': 11, 'lambda_l2': 14}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92388\n",
      "[6666]\tvalid_0's l1: 1.86953\n",
      "[9999]\tvalid_0's l1: 1.84342\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9974]\tvalid_0's l1: 1.84341\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93011\n",
      "[6666]\tvalid_0's l1: 1.8796\n",
      "[9999]\tvalid_0's l1: 1.8503\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9955]\tvalid_0's l1: 1.85022\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93683\n",
      "[6666]\tvalid_0's l1: 1.88354\n",
      "[9999]\tvalid_0's l1: 1.85468\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.85468\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 535, 'max_depth': 6, 'bagging_fraction': 0.7998000000000001, 'bagging_freq': 10, 'feature_fraction': 0.6496000000000001, 'lambda_l1': 6, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6496000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6496000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7998000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7998000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.03102\n",
      "[6666]\tvalid_0's l1: 2.01909\n",
      "Early stopping, best iteration is:\n",
      "[6755]\tvalid_0's l1: 2.01878\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6496000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6496000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7998000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7998000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.03818\n",
      "Early stopping, best iteration is:\n",
      "[6046]\tvalid_0's l1: 2.02674\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6496000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6496000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7998000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7998000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.03955\n",
      "Early stopping, best iteration is:\n",
      "[5571]\tvalid_0's l1: 2.02913\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.07383999999999999, 'num_leaves': 475, 'max_depth': 9, 'bagging_fraction': 0.95, 'bagging_freq': 13, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 14}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.89434\n",
      "[6666]\tvalid_0's l1: 1.8888\n",
      "Early stopping, best iteration is:\n",
      "[7194]\tvalid_0's l1: 1.88843\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90354\n",
      "Early stopping, best iteration is:\n",
      "[5863]\tvalid_0's l1: 1.90046\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90876\n",
      "Early stopping, best iteration is:\n",
      "[5083]\tvalid_0's l1: 1.90521\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 84, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 11, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.09273\n",
      "Early stopping, best iteration is:\n",
      "[3473]\tvalid_0's l1: 2.09006\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2548]\tvalid_0's l1: 2.11551\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2850]\tvalid_0's l1: 2.10898\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 84, 'max_depth': 7, 'bagging_fraction': 0.85, 'bagging_freq': 11, 'feature_fraction': 0.56, 'lambda_l1': 11, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98243\n",
      "[6666]\tvalid_0's l1: 1.92072\n",
      "[9999]\tvalid_0's l1: 1.8846\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.88458\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98519\n",
      "[6666]\tvalid_0's l1: 1.92143\n",
      "[9999]\tvalid_0's l1: 1.88384\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.88377\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9903\n",
      "[6666]\tvalid_0's l1: 1.92794\n",
      "[9999]\tvalid_0's l1: 1.89162\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.8916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 84, 'max_depth': 7, 'bagging_fraction': 0.93, 'bagging_freq': 10, 'feature_fraction': 0.56, 'lambda_l1': 6, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.93, subsample=1.0 will be ignored. Current value: bagging_fraction=0.93\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[810]\tvalid_0's l1: 2.64519\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.93, subsample=1.0 will be ignored. Current value: bagging_fraction=0.93\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[876]\tvalid_0's l1: 2.64246\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.93, subsample=1.0 will be ignored. Current value: bagging_fraction=0.93\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[960]\tvalid_0's l1: 2.64609\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 709, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 11, 'feature_fraction': 0.6048, 'lambda_l1': 14, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6048, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6048\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2542]\tvalid_0's l1: 1.86017\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6048, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6048\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2385]\tvalid_0's l1: 1.86632\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6048, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6048\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2542]\tvalid_0's l1: 1.87205\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'is_weekend', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 518, 'max_depth': 5, 'bagging_fraction': 0.85, 'bagging_freq': 11, 'feature_fraction': 0.6, 'lambda_l1': 12, 'lambda_l2': 14}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.04405\n",
      "[6666]\tvalid_0's l1: 1.98032\n",
      "[9999]\tvalid_0's l1: 1.94337\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.94333\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.04676\n",
      "[6666]\tvalid_0's l1: 1.98391\n",
      "[9999]\tvalid_0's l1: 1.94589\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.94586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.05307\n",
      "[6666]\tvalid_0's l1: 1.98727\n",
      "[9999]\tvalid_0's l1: 1.95238\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.95238\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.9784999999999999, 'bagging_freq': 10, 'feature_fraction': 0.7719, 'lambda_l1': 7, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.7636\n",
      "[6666]\tvalid_0's l1: 1.73539\n",
      "[9999]\tvalid_0's l1: 1.72104\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.72103\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.7653\n",
      "[6666]\tvalid_0's l1: 1.73765\n",
      "[9999]\tvalid_0's l1: 1.72309\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.72308\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.77283\n",
      "[6666]\tvalid_0's l1: 1.7423\n",
      "[9999]\tvalid_0's l1: 1.72694\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9998]\tvalid_0's l1: 1.72694\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'is_weekend']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 84, 'max_depth': 7, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.56, 'lambda_l1': 6, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92697\n",
      "[6666]\tvalid_0's l1: 1.86189\n",
      "[9999]\tvalid_0's l1: 1.82589\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.82585\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93264\n",
      "[6666]\tvalid_0's l1: 1.86694\n",
      "[9999]\tvalid_0's l1: 1.82932\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.82928\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94518\n",
      "[6666]\tvalid_0's l1: 1.87479\n",
      "[9999]\tvalid_0's l1: 1.83505\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.83503\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 9, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.8928, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8928, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8928\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.86142\n",
      "[6666]\tvalid_0's l1: 1.84896\n",
      "[9999]\tvalid_0's l1: 1.8409\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9998]\tvalid_0's l1: 1.84089\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8928, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8928\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.86992\n",
      "[6666]\tvalid_0's l1: 1.85704\n",
      "[9999]\tvalid_0's l1: 1.84897\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9998]\tvalid_0's l1: 1.84896\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8928, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8928\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.87223\n",
      "[6666]\tvalid_0's l1: 1.86007\n",
      "[9999]\tvalid_0's l1: 1.8515\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.8515\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.071, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.7989999999999999, 'bagging_freq': 13, 'feature_fraction': 0.6, 'lambda_l1': 11, 'lambda_l2': 11}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7989999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7989999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1625]\tvalid_0's l1: 2.62045\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7989999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7989999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1143]\tvalid_0's l1: 2.61876\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7989999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7989999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1890]\tvalid_0's l1: 2.61833\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'is_weekend', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 475, 'max_depth': 9, 'bagging_fraction': 0.85, 'bagging_freq': 13, 'feature_fraction': 0.56, 'lambda_l1': 6, 'lambda_l2': 14}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1092]\tvalid_0's l1: 2.65998\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[858]\tvalid_0's l1: 2.65736\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1027]\tvalid_0's l1: 2.65838\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 16\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.072, 'num_leaves': 442, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 17, 'lambda_l2': 14}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=17, reg_alpha=0.0 will be ignored. Current value: lambda_l1=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1199]\tvalid_0's l1: 1.93376\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=17, reg_alpha=0.0 will be ignored. Current value: lambda_l1=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1581]\tvalid_0's l1: 1.94515\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=17, reg_alpha=0.0 will be ignored. Current value: lambda_l1=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1013]\tvalid_0's l1: 1.9467\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 17\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 475, 'max_depth': 8, 'bagging_fraction': 0.85, 'bagging_freq': 11, 'feature_fraction': 0.56, 'lambda_l1': 11, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.96314\n",
      "[6666]\tvalid_0's l1: 1.94327\n",
      "[9999]\tvalid_0's l1: 1.93327\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9928]\tvalid_0's l1: 1.9331\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9704\n",
      "[6666]\tvalid_0's l1: 1.95185\n",
      "[9999]\tvalid_0's l1: 1.94283\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9929]\tvalid_0's l1: 1.94253\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97367\n",
      "[6666]\tvalid_0's l1: 1.95437\n",
      "[9999]\tvalid_0's l1: 1.94522\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9802]\tvalid_0's l1: 1.94495\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 18\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.93, 'bagging_freq': 11, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.93, subsample=1.0 will be ignored. Current value: bagging_fraction=0.93\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's l1: 2.92544\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.93, subsample=1.0 will be ignored. Current value: bagging_fraction=0.93\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's l1: 2.92487\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.93, subsample=1.0 will be ignored. Current value: bagging_fraction=0.93\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l1: 2.93939\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 19\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.71787\n",
      "[6666]\tvalid_0's l1: 1.68738\n",
      "[9999]\tvalid_0's l1: 1.67067\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67066\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.72286\n",
      "[6666]\tvalid_0's l1: 1.69304\n",
      "[9999]\tvalid_0's l1: 1.67599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67598\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.73257\n",
      "[6666]\tvalid_0's l1: 1.70233\n",
      "[9999]\tvalid_0's l1: 1.68486\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.68486\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.677165409201709\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.7200211653369024\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.7236834967734167\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.8300527033905172\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.9784999999999999 from 2\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.7719 from 2\n",
      "inherited lambda_l1 value of 7 from 2\n",
      "inherited lambda_l2 value of 9 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 5 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 3\n",
      "inherited num_leaves value of 84 from 3\n",
      "inherited max_depth value of 7 from 3\n",
      "inherited bagging_fraction value of 0.95 from 3\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.56 from 3\n",
      "inherited lambda_l1 value of 7 from 2\n",
      "inherited lambda_l2 value of 9 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited non-use of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 6 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 84 from 3\n",
      "inherited max_depth value of 7 from 3\n",
      "inherited bagging_fraction value of 0.95 from 0\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.56 from 3\n",
      "inherited lambda_l1 value of 6 from 3\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited non-use of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 7 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.95 from 3\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.56 from 3\n",
      "inherited lambda_l1 value of 6 from 3\n",
      "inherited lambda_l2 value of 9 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 8 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 1\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.95 from 1\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 9 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.95 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 10 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.95 from 1\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 6 from 3\n",
      "inherited lambda_l2 value of 9 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 11 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.95 from 1\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 12 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 1\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.9784999999999999 from 2\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 7 from 2\n",
      "inherited lambda_l2 value of 9 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 13 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.9784999999999999 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 7 from 2\n",
      "inherited lambda_l2 value of 9 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited non-use of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 14 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 1\n",
      "inherited num_leaves value of 84 from 3\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.95 from 3\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.56 from 3\n",
      "inherited lambda_l1 value of 6 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 15 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 3\n",
      "inherited num_leaves value of 84 from 3\n",
      "inherited max_depth value of 7 from 3\n",
      "inherited bagging_fraction value of 0.95 from 3\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 9 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited non-use of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 16 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 3\n",
      "inherited num_leaves value of 84 from 3\n",
      "inherited max_depth value of 7 from 3\n",
      "inherited bagging_fraction value of 0.95 from 3\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.56 from 3\n",
      "inherited lambda_l1 value of 6 from 3\n",
      "inherited lambda_l2 value of 9 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 17 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 3\n",
      "inherited num_leaves value of 84 from 3\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.9784999999999999 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.7719 from 2\n",
      "inherited lambda_l1 value of 7 from 2\n",
      "inherited lambda_l2 value of 9 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 18 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 3\n",
      "inherited num_leaves value of 84 from 3\n",
      "inherited max_depth value of 7 from 3\n",
      "inherited bagging_fraction value of 0.9784999999999999 from 2\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.56 from 3\n",
      "inherited lambda_l1 value of 6 from 3\n",
      "inherited lambda_l2 value of 9 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited non-use of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 19 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.95 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_fraction by 6.0% from 0.9784999999999999 to 1\n",
      "Increased feature_fraction by 12.0% from 0.7719 to 0.8645280000000001\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 4.0% from 0.046799999999999994 to 0.044927999999999996\n",
      "Increased bagging_freq by 3.0% from 10 to 10\n",
      "Decreased feature_fraction by 8.0% from 0.56 to 0.5152000000000001\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to stop using dwelling_type_ord\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 18.0% from 0.046799999999999994 to 0.03837599999999999\n",
      "Increased max_depth by 16.0% from 10 to 12\n",
      "Decreased bagging_fraction by 14.000000000000002% from 0.95 to 0.817\n",
      "Increased lambda_l2 by 24.0% from 8 to 10\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 9.0% from 695 to 758\n",
      "Increased max_depth by 13.0% from 10 to 11\n",
      "Decreased bagging_fraction by 3.0% from 0.95 to 0.9215\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 20.0% from 695 to 834\n",
      "Increased bagging_fraction by 19.0% from 0.95 to 1\n",
      "Decreased lambda_l2 by 10.0% from 8 to 7\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 20.0% from 0.06 to 0.048\n",
      "Decreased max_depth by 20.0% from 10 to 8\n",
      "Increased bagging_fraction by 4.0% from 0.9784999999999999 to 1\n",
      "Increased bagging_freq by 22.0% from 10 to 12\n",
      "Decreased feature_fraction by 6.0% from 0.93 to 0.8742000000000001\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using dwelling_type_ord\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 13.0% from 0.9784999999999999 to 0.8512949999999999\n",
      "Increased lambda_l1 by 24.0% from 7 to 9\n",
      "Increased lambda_l2 by 24.0% from 9 to 11\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 1.0% from 84 to 83\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 6.0% from 84 to 79\n",
      "\u001b[1m\u001b[92mChild 16\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 19.0% from 0.95 to 0.7695\n",
      "\u001b[1m\u001b[92mChild 17\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 24.0% from 10 to 12\n",
      "Decreased bagging_fraction by 18.0% from 0.9784999999999999 to 0.8023699999999999\n",
      "Increased bagging_freq by 8.0% from 10 to 11\n",
      "Increased lambda_l1 by 10.0% from 7 to 8\n",
      "\u001b[1m\u001b[92mChild 18\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_freq by 21.0% from 10 to 12\n",
      "Decreased lambda_l2 by 4.0% from 9 to 9\n",
      "\u001b[1m\u001b[92mChild 19\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 11.0% from 10 to 11\n",
      "Increased bagging_fraction by 2.0% from 0.95 to 0.969\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeee6b107e8943f3a776c4333ad5a9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.71787\n",
      "[6666]\tvalid_0's l1: 1.68738\n",
      "[9999]\tvalid_0's l1: 1.67067\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67066\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.72286\n",
      "[6666]\tvalid_0's l1: 1.69304\n",
      "[9999]\tvalid_0's l1: 1.67599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67598\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.73257\n",
      "[6666]\tvalid_0's l1: 1.70233\n",
      "[9999]\tvalid_0's l1: 1.68486\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.68486\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 137, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76219\n",
      "[6666]\tvalid_0's l1: 1.73416\n",
      "[9999]\tvalid_0's l1: 1.71722\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.71721\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76347\n",
      "[6666]\tvalid_0's l1: 1.73625\n",
      "[9999]\tvalid_0's l1: 1.72\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9990]\tvalid_0's l1: 1.71999\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.77098\n",
      "[6666]\tvalid_0's l1: 1.74148\n",
      "[9999]\tvalid_0's l1: 1.7225\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9990]\tvalid_0's l1: 1.72247\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.9784999999999999, 'bagging_freq': 10, 'feature_fraction': 0.7719, 'lambda_l1': 7, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.7636\n",
      "[6666]\tvalid_0's l1: 1.73539\n",
      "[9999]\tvalid_0's l1: 1.72104\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.72103\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.7653\n",
      "[6666]\tvalid_0's l1: 1.73765\n",
      "[9999]\tvalid_0's l1: 1.72309\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.72308\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.77283\n",
      "[6666]\tvalid_0's l1: 1.7423\n",
      "[9999]\tvalid_0's l1: 1.72694\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9998]\tvalid_0's l1: 1.72694\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'is_weekend']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 84, 'max_depth': 7, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.56, 'lambda_l1': 6, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92697\n",
      "[6666]\tvalid_0's l1: 1.86189\n",
      "[9999]\tvalid_0's l1: 1.82589\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.82585\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93264\n",
      "[6666]\tvalid_0's l1: 1.86694\n",
      "[9999]\tvalid_0's l1: 1.82932\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.82928\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94518\n",
      "[6666]\tvalid_0's l1: 1.87479\n",
      "[9999]\tvalid_0's l1: 1.83505\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.83503\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.8645280000000001, 'lambda_l1': 7, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8645280000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8645280000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1693]\tvalid_0's l1: 1.8658\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8645280000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8645280000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1747]\tvalid_0's l1: 1.87293\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8645280000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8645280000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1700]\tvalid_0's l1: 1.87819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 84, 'max_depth': 7, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.56, 'lambda_l1': 7, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.03149\n",
      "[6666]\tvalid_0's l1: 2.01264\n",
      "[9999]\tvalid_0's l1: 2.00709\n",
      "Early stopping, best iteration is:\n",
      "[9750]\tvalid_0's l1: 2.00689\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.04114\n",
      "[6666]\tvalid_0's l1: 2.02053\n",
      "Early stopping, best iteration is:\n",
      "[8590]\tvalid_0's l1: 2.01513\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.04091\n",
      "[6666]\tvalid_0's l1: 2.02279\n",
      "[9999]\tvalid_0's l1: 2.01614\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 2.01613\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.044927999999999996, 'num_leaves': 84, 'max_depth': 7, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.5152000000000001, 'lambda_l1': 6, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5152000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5152000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.10379\n",
      "[6666]\tvalid_0's l1: 2.07512\n",
      "[9999]\tvalid_0's l1: 2.06086\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9980]\tvalid_0's l1: 2.06079\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5152000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5152000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.11473\n",
      "[6666]\tvalid_0's l1: 2.08677\n",
      "[9999]\tvalid_0's l1: 2.07185\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 2.07183\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5152000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5152000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.12464\n",
      "[6666]\tvalid_0's l1: 2.09389\n",
      "[9999]\tvalid_0's l1: 2.07738\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9965]\tvalid_0's l1: 2.07731\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'month_cyclic', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.56, 'lambda_l1': 6, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.01467\n",
      "Early stopping, best iteration is:\n",
      "[4598]\tvalid_0's l1: 2.00914\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02016\n",
      "Early stopping, best iteration is:\n",
      "[5140]\tvalid_0's l1: 2.01312\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02536\n",
      "Early stopping, best iteration is:\n",
      "[5098]\tvalid_0's l1: 2.01997\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92642\n",
      "[6666]\tvalid_0's l1: 1.91684\n",
      "Early stopping, best iteration is:\n",
      "[7367]\tvalid_0's l1: 1.91586\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93708\n",
      "[6666]\tvalid_0's l1: 1.92788\n",
      "Early stopping, best iteration is:\n",
      "[7821]\tvalid_0's l1: 1.92649\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93934\n",
      "[6666]\tvalid_0's l1: 1.93115\n",
      "Early stopping, best iteration is:\n",
      "[6470]\tvalid_0's l1: 1.931\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.03837599999999999, 'num_leaves': 695, 'max_depth': 12, 'bagging_fraction': 0.817, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.817, subsample=1.0 will be ignored. Current value: bagging_fraction=0.817\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1302]\tvalid_0's l1: 1.92058\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.817, subsample=1.0 will be ignored. Current value: bagging_fraction=0.817\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[930]\tvalid_0's l1: 1.9287\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.817, subsample=1.0 will be ignored. Current value: bagging_fraction=0.817\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[903]\tvalid_0's l1: 1.93388\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'month_ord', 'is_weekend', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 758, 'max_depth': 11, 'bagging_fraction': 0.9215, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 6, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9215, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9215\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's l1: 4.87369\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9215, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9215\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's l1: 4.86796\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9215, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9215\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's l1: 4.8793\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 834, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2095]\tvalid_0's l1: 1.74113\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2316]\tvalid_0's l1: 1.74436\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2682]\tvalid_0's l1: 1.75019\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.048, 'num_leaves': 695, 'max_depth': 8, 'bagging_fraction': 1, 'bagging_freq': 12, 'feature_fraction': 0.8742000000000001, 'lambda_l1': 7, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8742000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8742000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.65603\n",
      "Early stopping, best iteration is:\n",
      "[5860]\tvalid_0's l1: 2.65489\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8742000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8742000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.65264\n",
      "Early stopping, best iteration is:\n",
      "[5692]\tvalid_0's l1: 2.64448\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8742000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8742000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.65802\n",
      "[6666]\tvalid_0's l1: 2.65213\n",
      "[9999]\tvalid_0's l1: 2.64908\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9994]\tvalid_0's l1: 2.64908\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.8512949999999999, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 9, 'lambda_l2': 11}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8512949999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8512949999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's l1: 2.85192\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8512949999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8512949999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's l1: 2.85179\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8512949999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8512949999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's l1: 2.86742\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 83, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.56, 'lambda_l1': 6, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[890]\tvalid_0's l1: 2.91535\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[900]\tvalid_0's l1: 2.91861\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[961]\tvalid_0's l1: 2.93061\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 79, 'max_depth': 7, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's l1: 4.59899\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's l1: 4.5979\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's l1: 4.60909\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 16\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'month_cyclic', 'is_weekend']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 84, 'max_depth': 7, 'bagging_fraction': 0.7695, 'bagging_freq': 10, 'feature_fraction': 0.56, 'lambda_l1': 6, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7695\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.06512\n",
      "[6666]\tvalid_0's l1: 2.03552\n",
      "[9999]\tvalid_0's l1: 2.02338\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9870]\tvalid_0's l1: 2.02242\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7695\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.07436\n",
      "[6666]\tvalid_0's l1: 2.04523\n",
      "[9999]\tvalid_0's l1: 2.03138\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9952]\tvalid_0's l1: 2.03107\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7695\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.07458\n",
      "[6666]\tvalid_0's l1: 2.04709\n",
      "[9999]\tvalid_0's l1: 2.03379\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9957]\tvalid_0's l1: 2.03334\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 17\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 84, 'max_depth': 12, 'bagging_fraction': 0.8023699999999999, 'bagging_freq': 11, 'feature_fraction': 0.7719, 'lambda_l1': 8, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8023699999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8023699999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's l1: 4.87342\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8023699999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8023699999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's l1: 4.86831\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8023699999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8023699999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's l1: 4.87877\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 18\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 84, 'max_depth': 7, 'bagging_fraction': 0.9784999999999999, 'bagging_freq': 12, 'feature_fraction': 0.56, 'lambda_l1': 6, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's l1: 5.03273\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[468]\tvalid_0's l1: 5.0254\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.56, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.56\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[468]\tvalid_0's l1: 5.03297\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 19\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['month_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.969, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.969\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's l1: 2.91613\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.969\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[328]\tvalid_0's l1: 2.91964\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.969\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[690]\tvalid_0's l1: 2.93164\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.677165409201709\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.7198903229917002\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.7236834967726207\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.745226057055279\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.95 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.7719 from 2\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 5 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.7719 from 2\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 7 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 6 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 7 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.9784999999999999 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.7719 from 2\n",
      "inherited lambda_l1 value of 7 from 2\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 8 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 834 from 3\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.7719 from 2\n",
      "inherited lambda_l1 value of 7 from 2\n",
      "inherited lambda_l2 value of 7 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited non-use of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 9 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 0.9784999999999999 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.7719 from 2\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 9 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited usage of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 10 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.95 from 1\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 11 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.95 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 12 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 2\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.95 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 13 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.95 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 14 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.094 from 2\n",
      "inherited num_leaves value of 834 from 3\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 0.9784999999999999 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 7 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 15 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 0.9784999999999999 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 7 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited non-use of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 16 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 834 from 3\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 7 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 17 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 1\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.9784999999999999 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.7719 from 2\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 9 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 18 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.95 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 19 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 834 from 3\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.7719 from 2\n",
      "inherited lambda_l1 value of 7 from 2\n",
      "inherited lambda_l2 value of 9 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited usage of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 17.0% from 695 to 577\n",
      "Decreased bagging_fraction by 14.000000000000002% from 0.95 to 0.817\n",
      "Increased lambda_l1 by 3.0% from 14 to 14\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_freq by 9.0% from 10 to 9\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l2 by 6.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to start using day_of_month\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 10.0% from 695 to 764\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 18.0% from 1 to 0.8200000000000001\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using day_of_month\n",
      "Mutated to start using dwelling_type_ord\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 4.0% from 0.046799999999999994 to 0.04867199999999999\n",
      "Decreased feature_fraction by 21.0% from 0.93 to 0.7347\n",
      "Increased lambda_l2 by 23.0% from 8 to 10\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 11.0% from 0.094 to 0.08366\n",
      "Increased bagging_fraction by 1.0% from 0.95 to 0.9594999999999999\n",
      "Decreased lambda_l2 by 8.0% from 8 to 7\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l1 by 6.0% from 14 to 13\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l2 by 16.0% from 7 to 6\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 9.0% from 0.046799999999999994 to 0.051011999999999995\n",
      "Decreased lambda_l2 by 0.0% from 7 to 7\n",
      "\u001b[1m\u001b[92mChild 16\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l2 by 4.0% from 7 to 7\n",
      "\u001b[1m\u001b[92mChild 17\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 8.0% from 10 to 11\n",
      "\u001b[1m\u001b[92mChild 18\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 22.0% from 695 to 848\n",
      "Decreased bagging_freq by 21.0% from 10 to 8\n",
      "\u001b[1m\u001b[92mChild 19\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to start using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b376145ac1147f4b40583eeb0a0200f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.71787\n",
      "[6666]\tvalid_0's l1: 1.68738\n",
      "[9999]\tvalid_0's l1: 1.67067\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67066\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.72286\n",
      "[6666]\tvalid_0's l1: 1.69304\n",
      "[9999]\tvalid_0's l1: 1.67599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67598\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.73257\n",
      "[6666]\tvalid_0's l1: 1.70233\n",
      "[9999]\tvalid_0's l1: 1.68486\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.68486\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 137, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76219\n",
      "[6666]\tvalid_0's l1: 1.73416\n",
      "[9999]\tvalid_0's l1: 1.71722\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.71721\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76347\n",
      "[6666]\tvalid_0's l1: 1.73625\n",
      "[9999]\tvalid_0's l1: 1.72\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9990]\tvalid_0's l1: 1.71999\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.77098\n",
      "[6666]\tvalid_0's l1: 1.74148\n",
      "[9999]\tvalid_0's l1: 1.72288\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9993]\tvalid_0's l1: 1.72287\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.9784999999999999, 'bagging_freq': 10, 'feature_fraction': 0.7719, 'lambda_l1': 7, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.7636\n",
      "[6666]\tvalid_0's l1: 1.73539\n",
      "[9999]\tvalid_0's l1: 1.72104\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.72103\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.7653\n",
      "[6666]\tvalid_0's l1: 1.73765\n",
      "[9999]\tvalid_0's l1: 1.72309\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.72308\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.77283\n",
      "[6666]\tvalid_0's l1: 1.7423\n",
      "[9999]\tvalid_0's l1: 1.72694\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9998]\tvalid_0's l1: 1.72694\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 834, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2095]\tvalid_0's l1: 1.74113\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2316]\tvalid_0's l1: 1.74436\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2682]\tvalid_0's l1: 1.75019\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'month_cyclic', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 577, 'max_depth': 10, 'bagging_fraction': 0.817, 'bagging_freq': 10, 'feature_fraction': 0.7719, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.817, subsample=1.0 will be ignored. Current value: bagging_fraction=0.817\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97219\n",
      "Early stopping, best iteration is:\n",
      "[6018]\tvalid_0's l1: 1.96176\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.817, subsample=1.0 will be ignored. Current value: bagging_fraction=0.817\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9811\n",
      "[6666]\tvalid_0's l1: 1.9692\n",
      "Early stopping, best iteration is:\n",
      "[8749]\tvalid_0's l1: 1.96509\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.817, subsample=1.0 will be ignored. Current value: bagging_fraction=0.817\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98657\n",
      "[6666]\tvalid_0's l1: 1.97577\n",
      "Early stopping, best iteration is:\n",
      "[7291]\tvalid_0's l1: 1.97396\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'is_weekend', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 9, 'feature_fraction': 0.7719, 'lambda_l1': 14, 'lambda_l2': 7}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.77359\n",
      "[6666]\tvalid_0's l1: 1.71207\n",
      "[9999]\tvalid_0's l1: 1.69008\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9884]\tvalid_0's l1: 1.69005\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.77761\n",
      "[6666]\tvalid_0's l1: 1.71773\n",
      "[9999]\tvalid_0's l1: 1.69704\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.69703\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.78208\n",
      "[6666]\tvalid_0's l1: 1.71744\n",
      "[9999]\tvalid_0's l1: 1.69408\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 1.69408\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66724\n",
      "Early stopping, best iteration is:\n",
      "[5311]\tvalid_0's l1: 1.65073\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.6715\n",
      "Early stopping, best iteration is:\n",
      "[4751]\tvalid_0's l1: 1.66031\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67988\n",
      "Early stopping, best iteration is:\n",
      "[6297]\tvalid_0's l1: 1.65944\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 764, 'max_depth': 10, 'bagging_fraction': 0.9784999999999999, 'bagging_freq': 10, 'feature_fraction': 0.7719, 'lambda_l1': 7, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[805]\tvalid_0's l1: 1.90714\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[750]\tvalid_0's l1: 1.91649\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1249]\tvalid_0's l1: 1.92288\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 834, 'max_depth': 10, 'bagging_fraction': 0.8200000000000001, 'bagging_freq': 10, 'feature_fraction': 0.7719, 'lambda_l1': 7, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8200000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8200000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.69196\n",
      "[6666]\tvalid_0's l1: 2.66601\n",
      "[9999]\tvalid_0's l1: 2.65484\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 2.65481\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8200000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8200000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.69021\n",
      "[6666]\tvalid_0's l1: 2.66356\n",
      "Early stopping, best iteration is:\n",
      "[9720]\tvalid_0's l1: 2.65223\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8200000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8200000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.69706\n",
      "[6666]\tvalid_0's l1: 2.66787\n",
      "Early stopping, best iteration is:\n",
      "[9720]\tvalid_0's l1: 2.65689\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.9784999999999999, 'bagging_freq': 10, 'feature_fraction': 0.7719, 'lambda_l1': 14, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98988\n",
      "[6666]\tvalid_0's l1: 1.96658\n",
      "[9999]\tvalid_0's l1: 1.95436\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.95436\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.00056\n",
      "[6666]\tvalid_0's l1: 1.97782\n",
      "[9999]\tvalid_0's l1: 1.96688\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9978]\tvalid_0's l1: 1.96687\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.00755\n",
      "[6666]\tvalid_0's l1: 1.98332\n",
      "[9999]\tvalid_0's l1: 1.97009\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9996]\tvalid_0's l1: 1.97007\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_ord', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.04867199999999999, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.7347, 'lambda_l1': 14, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.96103\n",
      "[6666]\tvalid_0's l1: 1.94784\n",
      "[9999]\tvalid_0's l1: 1.94107\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9980]\tvalid_0's l1: 1.941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97097\n",
      "[6666]\tvalid_0's l1: 1.95841\n",
      "[9999]\tvalid_0's l1: 1.95148\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.95148\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97569\n",
      "[6666]\tvalid_0's l1: 1.96377\n",
      "[9999]\tvalid_0's l1: 1.9574\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9954]\tvalid_0's l1: 1.95729\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'month_cyclic', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1293]\tvalid_0's l1: 1.90915\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1157]\tvalid_0's l1: 1.91863\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[947]\tvalid_0's l1: 1.92292\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.08366, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.9594999999999999, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9594999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9594999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.91523\n",
      "Early stopping, best iteration is:\n",
      "[4418]\tvalid_0's l1: 1.91368\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9594999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9594999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9271\n",
      "[6666]\tvalid_0's l1: 1.92343\n",
      "Early stopping, best iteration is:\n",
      "[6760]\tvalid_0's l1: 1.92325\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9594999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9594999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93249\n",
      "Early stopping, best iteration is:\n",
      "[4342]\tvalid_0's l1: 1.93093\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 13, 'lambda_l2': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=13, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1300]\tvalid_0's l1: 1.93854\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=13, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1350]\tvalid_0's l1: 1.9436\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=13, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1320]\tvalid_0's l1: 1.95308\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_week', 'month_ord', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.094, 'num_leaves': 834, 'max_depth': 10, 'bagging_fraction': 0.9784999999999999, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 6}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.09446\n",
      "Early stopping, best iteration is:\n",
      "[5026]\tvalid_0's l1: 2.08814\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.10201\n",
      "Early stopping, best iteration is:\n",
      "[3707]\tvalid_0's l1: 2.10115\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3026]\tvalid_0's l1: 2.10573\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.051011999999999995, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.9784999999999999, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[330]\tvalid_0's l1: 2.62599\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[312]\tvalid_0's l1: 2.62384\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[343]\tvalid_0's l1: 2.62527\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 16\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 834, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[872]\tvalid_0's l1: 2.22117\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[989]\tvalid_0's l1: 2.20525\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[912]\tvalid_0's l1: 2.20393\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 17\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.9784999999999999, 'bagging_freq': 10, 'feature_fraction': 0.7719, 'lambda_l1': 14, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2140]\tvalid_0's l1: 1.9199\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1968]\tvalid_0's l1: 1.92284\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9784999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9784999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2366]\tvalid_0's l1: 1.93199\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 18\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 848, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 8, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3048]\tvalid_0's l1: 2.64011\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1614]\tvalid_0's l1: 2.63776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1328]\tvalid_0's l1: 2.64221\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 19\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_month', 'month_ord', 'month_cyclic', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 834, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.7719, 'lambda_l1': 7, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2544]\tvalid_0's l1: 1.80611\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1850]\tvalid_0's l1: 1.81762\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2328]\tvalid_0's l1: 1.81769\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.6568275706156865\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.677165409201709\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.693721270694547\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.7200211653369024\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 3\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 5 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited non-use of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 6 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 3\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.95 from 3\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 7 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 7 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 8 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.95 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.7719 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 7 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited non-use of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 9 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 0\n",
      "inherited bagging_fraction value of 0.95 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 10 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 0\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.7719 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 7 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited non-use of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 11 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 7 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 12 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 13 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 14 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 0.95 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 15 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 16 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 9 from 2\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 7 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 17 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.95 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 18 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 19 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited non-use of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 9.0% from 0.06 to 0.054599999999999996\n",
      "Decreased num_leaves by 0.0% from 695 to 695\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using num_bedrooms\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased lambda_l1 by 1.0% from 14 to 14\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 9.0% from 0.06 to 0.054599999999999996\n",
      "Increased max_depth by 11.0% from 10 to 11\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 12.0% from 11 to 12\n",
      "Decreased bagging_fraction by 7.000000000000001% from 1 to 0.9299999999999999\n",
      "Decreased feature_fraction by 21.0% from 0.93 to 0.7347\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 11.0% from 695 to 619\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 6.0% from 0.95 to 0.893\n",
      "Decreased bagging_freq by 21.0% from 10 to 8\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 18.0% from 10 to 12\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_month\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 12.0% from 695 to 778\n",
      "Increased feature_fraction by 3.0% from 0.93 to 0.9579000000000001\n",
      "Increased lambda_l1 by 15.0% from 14 to 16\n",
      "Decreased lambda_l2 by 5.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l1 by 18.0% from 14 to 11\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 16\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 8.0% from 0.046799999999999994 to 0.05054399999999999\n",
      "Increased num_leaves by 5.0% from 695 to 730\n",
      "\u001b[1m\u001b[92mChild 17\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using day_of_month\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l1 by 7.000000000000001% from 14 to 13\n",
      "\u001b[1m\u001b[92mChild 18\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 0.0% from 10 to 10\n",
      "Decreased feature_fraction by 16.0% from 0.93 to 0.7812\n",
      "Decreased lambda_l2 by 11.0% from 8 to 7\n",
      "\u001b[1m\u001b[92mChild 19\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73669c6592640efb662043ae4892b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66724\n",
      "Early stopping, best iteration is:\n",
      "[5311]\tvalid_0's l1: 1.65073\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.6715\n",
      "Early stopping, best iteration is:\n",
      "[4751]\tvalid_0's l1: 1.66031\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67988\n",
      "Early stopping, best iteration is:\n",
      "[6297]\tvalid_0's l1: 1.65944\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.71787\n",
      "[6666]\tvalid_0's l1: 1.68738\n",
      "[9999]\tvalid_0's l1: 1.67067\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67066\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.72286\n",
      "[6666]\tvalid_0's l1: 1.69304\n",
      "[9999]\tvalid_0's l1: 1.67599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67598\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.73257\n",
      "[6666]\tvalid_0's l1: 1.70233\n",
      "[9999]\tvalid_0's l1: 1.68486\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.68486\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'is_weekend', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 9, 'feature_fraction': 0.7719, 'lambda_l1': 14, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.77359\n",
      "[6666]\tvalid_0's l1: 1.71207\n",
      "[9999]\tvalid_0's l1: 1.69066\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9967]\tvalid_0's l1: 1.69063\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.77761\n",
      "[6666]\tvalid_0's l1: 1.71773\n",
      "[9999]\tvalid_0's l1: 1.69704\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.69703\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.78208\n",
      "[6666]\tvalid_0's l1: 1.71744\n",
      "[9999]\tvalid_0's l1: 1.69408\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 1.69408\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 137, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76219\n",
      "[6666]\tvalid_0's l1: 1.73416\n",
      "[9999]\tvalid_0's l1: 1.71722\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.71721\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76347\n",
      "[6666]\tvalid_0's l1: 1.73625\n",
      "[9999]\tvalid_0's l1: 1.72\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9990]\tvalid_0's l1: 1.71999\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.77098\n",
      "[6666]\tvalid_0's l1: 1.74148\n",
      "[9999]\tvalid_0's l1: 1.72288\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9993]\tvalid_0's l1: 1.72287\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.054599999999999996, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1054]\tvalid_0's l1: 1.85817\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1007]\tvalid_0's l1: 1.86743\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1061]\tvalid_0's l1: 1.87074\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70055\n",
      "[6666]\tvalid_0's l1: 1.68202\n",
      "Early stopping, best iteration is:\n",
      "[6987]\tvalid_0's l1: 1.68138\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70533\n",
      "[6666]\tvalid_0's l1: 1.68941\n",
      "Early stopping, best iteration is:\n",
      "[8518]\tvalid_0's l1: 1.686\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70896\n",
      "[6666]\tvalid_0's l1: 1.69178\n",
      "Early stopping, best iteration is:\n",
      "[7076]\tvalid_0's l1: 1.69114\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.054599999999999996, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's l1: 2.9185\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's l1: 2.92107\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's l1: 2.93412\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 12, 'bagging_fraction': 0.9299999999999999, 'bagging_freq': 10, 'feature_fraction': 0.7347, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9299999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9299999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1870]\tvalid_0's l1: 1.95015\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9299999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9299999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2624]\tvalid_0's l1: 1.95488\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9299999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9299999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3030]\tvalid_0's l1: 1.95993\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_cyclic', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 619, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.7719, 'lambda_l1': 14, 'lambda_l2': 7}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.01758\n",
      "[6666]\tvalid_0's l1: 2.0079\n",
      "Early stopping, best iteration is:\n",
      "[6595]\tvalid_0's l1: 2.00775\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02616\n",
      "[6666]\tvalid_0's l1: 2.01491\n",
      "Early stopping, best iteration is:\n",
      "[7414]\tvalid_0's l1: 2.01385\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.03112\n",
      "[6666]\tvalid_0's l1: 2.02031\n",
      "Early stopping, best iteration is:\n",
      "[8600]\tvalid_0's l1: 2.01804\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_year_cyclic', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.893, 'bagging_freq': 8, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.893, subsample=1.0 will be ignored. Current value: bagging_fraction=0.893\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's l1: 2.92377\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.893, subsample=1.0 will be ignored. Current value: bagging_fraction=0.893\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's l1: 2.92227\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.893, subsample=1.0 will be ignored. Current value: bagging_fraction=0.893\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's l1: 2.9372\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.7719, 'lambda_l1': 14, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.65396\n",
      "[6666]\tvalid_0's l1: 2.65314\n",
      "Early stopping, best iteration is:\n",
      "[9398]\tvalid_0's l1: 2.65288\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.64984\n",
      "[6666]\tvalid_0's l1: 2.64899\n",
      "[9999]\tvalid_0's l1: 2.6486\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9984]\tvalid_0's l1: 2.6486\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7719, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7719\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.65278\n",
      "[6666]\tvalid_0's l1: 2.65172\n",
      "[9999]\tvalid_0's l1: 2.65104\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9965]\tvalid_0's l1: 2.65103\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1102]\tvalid_0's l1: 1.81626\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1041]\tvalid_0's l1: 1.82604\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1344]\tvalid_0's l1: 1.8295\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 778, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.9579000000000001, 'lambda_l1': 16, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9579000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9579000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[868]\tvalid_0's l1: 2.32556\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9579000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9579000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1049]\tvalid_0's l1: 2.31953\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9579000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9579000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[737]\tvalid_0's l1: 2.32352\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1207]\tvalid_0's l1: 1.86096\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1038]\tvalid_0's l1: 1.87263\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1096]\tvalid_0's l1: 1.87543\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.06, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.7525\n",
      "[6666]\tvalid_0's l1: 1.72385\n",
      "[9999]\tvalid_0's l1: 1.70945\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.70944\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.7551\n",
      "[6666]\tvalid_0's l1: 1.72643\n",
      "[9999]\tvalid_0's l1: 1.71169\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.71169\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76301\n",
      "[6666]\tvalid_0's l1: 1.73431\n",
      "[9999]\tvalid_0's l1: 1.71855\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.71854\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.65862\n",
      "[6666]\tvalid_0's l1: 1.64199\n",
      "Early stopping, best iteration is:\n",
      "[6499]\tvalid_0's l1: 1.64173\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66616\n",
      "Early stopping, best iteration is:\n",
      "[5504]\tvalid_0's l1: 1.65251\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66939\n",
      "Early stopping, best iteration is:\n",
      "[6177]\tvalid_0's l1: 1.65565\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 16\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.05054399999999999, 'num_leaves': 730, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 9, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1100]\tvalid_0's l1: 1.85805\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1069]\tvalid_0's l1: 1.86729\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1039]\tvalid_0's l1: 1.87126\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 17\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 13, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=13, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1088]\tvalid_0's l1: 1.86174\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=13, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1113]\tvalid_0's l1: 1.87515\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=13, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[960]\tvalid_0's l1: 1.88144\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 18\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_month', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.7812, 'lambda_l1': 14, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2333]\tvalid_0's l1: 1.80601\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.81214\n",
      "Early stopping, best iteration is:\n",
      "[3439]\tvalid_0's l1: 1.81169\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2011]\tvalid_0's l1: 1.82638\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 19\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_ord', 'month_cyclic', 'energy_cluster', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1038]\tvalid_0's l1: 1.89532\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1021]\tvalid_0's l1: 1.90481\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1076]\tvalid_0's l1: 1.9104\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.6499669073999559\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.6568275706156865\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.677165409201709\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.6861707764164902\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 5 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 6 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 7 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 8 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited non-use of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 9 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 10 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited non-use of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 11 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 12 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited non-use of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 13 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 14 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 15 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 16 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 17 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 18 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 19 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited non-use of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 13.0% from 695 to 785\n",
      "Decreased bagging_freq by 13.0% from 10 to 9\n",
      "Decreased lambda_l1 by 21.0% from 14 to 11\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 20.0% from 0.046799999999999994 to 0.056159999999999995\n",
      "Increased num_leaves by 6.0% from 695 to 737\n",
      "Increased bagging_freq by 18.0% from 10 to 12\n",
      "Increased lambda_l2 by 6.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 11.0% from 695 to 771\n",
      "Decreased bagging_fraction by 14.000000000000002% from 0.95 to 0.817\n",
      "Increased bagging_freq by 9.0% from 10 to 11\n",
      "Decreased lambda_l2 by 24.0% from 8 to 6\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 19.0% from 0.046799999999999994 to 0.037908\n",
      "Increased max_depth by 24.0% from 11 to 14\n",
      "Decreased lambda_l1 by 12.0% from 14 to 12\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_freq by 19.0% from 10 to 12\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 14.000000000000002% from 695 to 598\n",
      "Increased max_depth by 8.0% from 10 to 11\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 23.0% from 10 to 8\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 3.0% from 695 to 716\n",
      "Decreased bagging_fraction by 15.0% from 0.95 to 0.8075\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l2 by 2.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 24.0% from 695 to 862\n",
      "Decreased lambda_l2 by 6.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased lambda_l2 by 9.0% from 8 to 9\n",
      "\u001b[1m\u001b[92mChild 16\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 17\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 16.0% from 695 to 806\n",
      "\u001b[1m\u001b[92mChild 18\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 6.0% from 0.046799999999999994 to 0.04960799999999999\n",
      "Decreased bagging_freq by 23.0% from 10 to 8\n",
      "\u001b[1m\u001b[92mChild 19\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 3.0% from 0.046799999999999994 to 0.04539599999999999\n",
      "Decreased num_leaves by 14.000000000000002% from 695 to 598\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d625599cab46e1b57fbeb266848ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.65862\n",
      "[6666]\tvalid_0's l1: 1.64199\n",
      "Early stopping, best iteration is:\n",
      "[6499]\tvalid_0's l1: 1.64173\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66616\n",
      "Early stopping, best iteration is:\n",
      "[5504]\tvalid_0's l1: 1.65251\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66939\n",
      "Early stopping, best iteration is:\n",
      "[6177]\tvalid_0's l1: 1.65565\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66724\n",
      "Early stopping, best iteration is:\n",
      "[5311]\tvalid_0's l1: 1.65073\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.6715\n",
      "Early stopping, best iteration is:\n",
      "[4751]\tvalid_0's l1: 1.66031\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67988\n",
      "Early stopping, best iteration is:\n",
      "[6297]\tvalid_0's l1: 1.65944\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.71787\n",
      "[6666]\tvalid_0's l1: 1.68738\n",
      "[9999]\tvalid_0's l1: 1.67067\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67066\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.72286\n",
      "[6666]\tvalid_0's l1: 1.69304\n",
      "[9999]\tvalid_0's l1: 1.67599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67598\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.73257\n",
      "[6666]\tvalid_0's l1: 1.70294\n",
      "[9999]\tvalid_0's l1: 1.68491\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.68491\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70055\n",
      "[6666]\tvalid_0's l1: 1.68202\n",
      "Early stopping, best iteration is:\n",
      "[6987]\tvalid_0's l1: 1.68138\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70533\n",
      "[6666]\tvalid_0's l1: 1.68941\n",
      "Early stopping, best iteration is:\n",
      "[8518]\tvalid_0's l1: 1.686\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70896\n",
      "[6666]\tvalid_0's l1: 1.69178\n",
      "Early stopping, best iteration is:\n",
      "[7076]\tvalid_0's l1: 1.69114\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 785, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 9, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[910]\tvalid_0's l1: 1.84408\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[868]\tvalid_0's l1: 1.85393\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[797]\tvalid_0's l1: 1.85774\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.056159999999999995, 'num_leaves': 737, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 12, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's l1: 2.84279\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's l1: 2.84348\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's l1: 2.85764\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_cyclic', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 771, 'max_depth': 11, 'bagging_fraction': 0.817, 'bagging_freq': 11, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 6}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.817, subsample=1.0 will be ignored. Current value: bagging_fraction=0.817\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92988\n",
      "Early stopping, best iteration is:\n",
      "[4127]\tvalid_0's l1: 1.92718\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.817, subsample=1.0 will be ignored. Current value: bagging_fraction=0.817\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94015\n",
      "Early stopping, best iteration is:\n",
      "[4447]\tvalid_0's l1: 1.93648\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.817, subsample=1.0 will be ignored. Current value: bagging_fraction=0.817\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94433\n",
      "[6666]\tvalid_0's l1: 1.93757\n",
      "Early stopping, best iteration is:\n",
      "[8387]\tvalid_0's l1: 1.93576\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.037908, 'num_leaves': 695, 'max_depth': 14, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 12, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[857]\tvalid_0's l1: 1.86071\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[685]\tvalid_0's l1: 1.86925\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[730]\tvalid_0's l1: 1.87375\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 12, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2485]\tvalid_0's l1: 1.90008\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2359]\tvalid_0's l1: 1.91146\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2425]\tvalid_0's l1: 1.91324\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 598, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61579\n",
      "[6666]\tvalid_0's l1: 2.61492\n",
      "Early stopping, best iteration is:\n",
      "[9254]\tvalid_0's l1: 2.61464\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61253\n",
      "[6666]\tvalid_0's l1: 2.61152\n",
      "Early stopping, best iteration is:\n",
      "[7922]\tvalid_0's l1: 2.61136\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61444\n",
      "[6666]\tvalid_0's l1: 2.61348\n",
      "Early stopping, best iteration is:\n",
      "[8790]\tvalid_0's l1: 2.61315\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 8, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2161]\tvalid_0's l1: 1.85993\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2049]\tvalid_0's l1: 1.86612\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2094]\tvalid_0's l1: 1.87106\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 716, 'max_depth': 11, 'bagging_fraction': 0.8075, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8075, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8075\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1270]\tvalid_0's l1: 2.65645\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8075, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8075\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[880]\tvalid_0's l1: 2.65432\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8075, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8075\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[880]\tvalid_0's l1: 2.65542\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.88802\n",
      "Early stopping, best iteration is:\n",
      "[4418]\tvalid_0's l1: 1.88586\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90078\n",
      "Early stopping, best iteration is:\n",
      "[4510]\tvalid_0's l1: 1.89913\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90312\n",
      "Early stopping, best iteration is:\n",
      "[6060]\tvalid_0's l1: 1.89988\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 862, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2014]\tvalid_0's l1: 2.61136\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2529]\tvalid_0's l1: 2.6081\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1615]\tvalid_0's l1: 2.61027\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[311]\tvalid_0's l1: 2.62552\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[322]\tvalid_0's l1: 2.62419\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's l1: 2.62731\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['month_ord', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's l1: 4.64141\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l1: 4.63692\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's l1: 4.65151\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 16\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1132]\tvalid_0's l1: 1.86096\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[995]\tvalid_0's l1: 1.87187\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1172]\tvalid_0's l1: 1.87375\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 17\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 806, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1474]\tvalid_0's l1: 2.64749\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1663]\tvalid_0's l1: 2.64417\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.64627\n",
      "[6666]\tvalid_0's l1: 2.64534\n",
      "[9999]\tvalid_0's l1: 2.64485\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9962]\tvalid_0's l1: 2.64485\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 18\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.04960799999999999, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 8, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1409]\tvalid_0's l1: 1.86041\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1282]\tvalid_0's l1: 1.87266\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1338]\tvalid_0's l1: 1.87507\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 19\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_week', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.04539599999999999, 'num_leaves': 598, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.71558\n",
      "[6666]\tvalid_0's l1: 2.70071\n",
      "Early stopping, best iteration is:\n",
      "[7830]\tvalid_0's l1: 2.69737\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.70961\n",
      "[6666]\tvalid_0's l1: 2.69576\n",
      "[9999]\tvalid_0's l1: 2.68955\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 2.68954\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.71178\n",
      "[6666]\tvalid_0's l1: 2.69943\n",
      "[9999]\tvalid_0's l1: 2.69225\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 2.69225\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.6499669073999559\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.6568275706156865\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.6771822068192994\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.6861707764164902\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 5 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 6 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 7 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 8 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 9 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 10 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 11 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 12 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited non-use of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 13 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 14 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 15 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 16 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited non-use of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 17 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 18 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 19 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 0.0% from 695 to 695\n",
      "Decreased lambda_l1 by 18.0% from 14 to 11\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 20.0% from 0.046799999999999994 to 0.037439999999999994\n",
      "Decreased bagging_fraction by 18.0% from 1 to 0.8200000000000001\n",
      "Decreased lambda_l1 by 12.0% from 14 to 12\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 2.0% from 0.046799999999999994 to 0.047735999999999994\n",
      "Increased bagging_fraction by 24.0% from 1 to 1\n",
      "Decreased feature_fraction by 6.0% from 0.93 to 0.8742000000000001\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 18.0% from 11 to 9\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 14.000000000000002% from 0.046799999999999994 to 0.053352\n",
      "Decreased max_depth by 13.0% from 10 to 9\n",
      "Increased lambda_l1 by 0.0% from 14 to 14\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 9.0% from 0.046799999999999994 to 0.042587999999999994\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 8.0% from 0.046799999999999994 to 0.05054399999999999\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using num_bedrooms\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 16.0% from 0.046799999999999994 to 0.054287999999999996\n",
      "Increased lambda_l1 by 4.0% from 14 to 15\n",
      "Increased lambda_l2 by 13.0% from 8 to 9\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased feature_fraction by 8.0% from 0.93 to 0.8556\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 22.0% from 695 to 542\n",
      "Decreased max_depth by 16.0% from 11 to 9\n",
      "Decreased bagging_fraction by 24.0% from 0.95 to 0.722\n",
      "Increased lambda_l2 by 5.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 16\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 3.0% from 0.046799999999999994 to 0.04539599999999999\n",
      "Decreased max_depth by 19.0% from 11 to 9\n",
      "Increased feature_fraction by 16.0% from 0.93 to 1\n",
      "Increased lambda_l2 by 5.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 17\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 23.0% from 695 to 535\n",
      "Decreased bagging_fraction by 14.000000000000002% from 1 to 0.86\n",
      "\u001b[1m\u001b[92mChild 18\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_week\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 19\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased feature_fraction by 8.0% from 0.93 to 0.8556\n",
      "Decreased lambda_l1 by 22.0% from 14 to 11\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4b2318b09f42d4b956805543ad6c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.65862\n",
      "[6666]\tvalid_0's l1: 1.64199\n",
      "Early stopping, best iteration is:\n",
      "[6499]\tvalid_0's l1: 1.64173\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66616\n",
      "Early stopping, best iteration is:\n",
      "[5504]\tvalid_0's l1: 1.65251\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66939\n",
      "Early stopping, best iteration is:\n",
      "[6177]\tvalid_0's l1: 1.65565\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66724\n",
      "Early stopping, best iteration is:\n",
      "[5311]\tvalid_0's l1: 1.65073\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.6715\n",
      "Early stopping, best iteration is:\n",
      "[4751]\tvalid_0's l1: 1.66031\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67988\n",
      "Early stopping, best iteration is:\n",
      "[6297]\tvalid_0's l1: 1.65944\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.71787\n",
      "[6666]\tvalid_0's l1: 1.68738\n",
      "[9999]\tvalid_0's l1: 1.67067\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67066\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.72286\n",
      "[6666]\tvalid_0's l1: 1.69304\n",
      "[9999]\tvalid_0's l1: 1.67599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67598\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.73257\n",
      "[6666]\tvalid_0's l1: 1.70233\n",
      "[9999]\tvalid_0's l1: 1.68486\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.68486\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70055\n",
      "[6666]\tvalid_0's l1: 1.68202\n",
      "Early stopping, best iteration is:\n",
      "[6987]\tvalid_0's l1: 1.68138\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70533\n",
      "[6666]\tvalid_0's l1: 1.68941\n",
      "Early stopping, best iteration is:\n",
      "[8518]\tvalid_0's l1: 1.686\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70896\n",
      "[6666]\tvalid_0's l1: 1.69178\n",
      "Early stopping, best iteration is:\n",
      "[7076]\tvalid_0's l1: 1.69114\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_month', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's l1: 3.27493\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's l1: 3.27323\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's l1: 3.28277\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_month', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.037439999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.8200000000000001, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 12, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8200000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8200000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90096\n",
      "[6666]\tvalid_0's l1: 1.89193\n",
      "Early stopping, best iteration is:\n",
      "[8859]\tvalid_0's l1: 1.88795\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8200000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8200000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90609\n",
      "Early stopping, best iteration is:\n",
      "[5518]\tvalid_0's l1: 1.90048\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8200000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8200000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90847\n",
      "[6666]\tvalid_0's l1: 1.90078\n",
      "Early stopping, best iteration is:\n",
      "[9161]\tvalid_0's l1: 1.89705\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.047735999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.8742000000000001, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8742000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8742000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2513]\tvalid_0's l1: 1.86507\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8742000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8742000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2435]\tvalid_0's l1: 1.87472\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8742000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8742000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2350]\tvalid_0's l1: 1.88425\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 9, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid_0's l1: 2.89576\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's l1: 2.89409\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's l1: 2.91049\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'month_cyclic', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.053352, 'num_leaves': 695, 'max_depth': 9, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2069]\tvalid_0's l1: 1.86362\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1796]\tvalid_0's l1: 1.86953\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1861]\tvalid_0's l1: 1.8749\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'month_cyclic', 'energy_cluster', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.042587999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1373]\tvalid_0's l1: 1.85762\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1324]\tvalid_0's l1: 1.86542\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1421]\tvalid_0's l1: 1.86964\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.05054399999999999, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1560]\tvalid_0's l1: 1.86754\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1611]\tvalid_0's l1: 1.8802\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1431]\tvalid_0's l1: 1.87735\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.054287999999999996, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 15, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1447]\tvalid_0's l1: 1.85991\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1338]\tvalid_0's l1: 1.86743\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1422]\tvalid_0's l1: 1.87343\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70026\n",
      "[6666]\tvalid_0's l1: 1.68205\n",
      "Early stopping, best iteration is:\n",
      "[6951]\tvalid_0's l1: 1.68176\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.7085\n",
      "[6666]\tvalid_0's l1: 1.69123\n",
      "Early stopping, best iteration is:\n",
      "[6856]\tvalid_0's l1: 1.69073\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.711\n",
      "[6666]\tvalid_0's l1: 1.69341\n",
      "Early stopping, best iteration is:\n",
      "[6926]\tvalid_0's l1: 1.69274\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.74243\n",
      "[6666]\tvalid_0's l1: 1.7104\n",
      "[9999]\tvalid_0's l1: 1.69128\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.69127\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.74338\n",
      "[6666]\tvalid_0's l1: 1.71058\n",
      "[9999]\tvalid_0's l1: 1.69308\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.69307\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.75496\n",
      "[6666]\tvalid_0's l1: 1.72209\n",
      "[9999]\tvalid_0's l1: 1.70277\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9995]\tvalid_0's l1: 1.70276\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.8556, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8556\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70901\n",
      "[6666]\tvalid_0's l1: 1.68609\n",
      "Early stopping, best iteration is:\n",
      "[8751]\tvalid_0's l1: 1.67985\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8556\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.71175\n",
      "[6666]\tvalid_0's l1: 1.68849\n",
      "Early stopping, best iteration is:\n",
      "[8436]\tvalid_0's l1: 1.68353\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8556\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.72149\n",
      "[6666]\tvalid_0's l1: 1.69618\n",
      "Early stopping, best iteration is:\n",
      "[6902]\tvalid_0's l1: 1.6958\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 542, 'max_depth': 9, 'bagging_fraction': 0.722, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.722, subsample=1.0 will be ignored. Current value: bagging_fraction=0.722\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1566]\tvalid_0's l1: 1.95399\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.722, subsample=1.0 will be ignored. Current value: bagging_fraction=0.722\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2103]\tvalid_0's l1: 1.95946\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.722, subsample=1.0 will be ignored. Current value: bagging_fraction=0.722\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2560]\tvalid_0's l1: 1.96686\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 16\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.04539599999999999, 'num_leaves': 695, 'max_depth': 9, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 1, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1913]\tvalid_0's l1: 1.87931\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2451]\tvalid_0's l1: 1.88796\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1959]\tvalid_0's l1: 1.88695\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 17\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 535, 'max_depth': 11, 'bagging_fraction': 0.86, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.86, subsample=1.0 will be ignored. Current value: bagging_fraction=0.86\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[860]\tvalid_0's l1: 2.62324\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.86, subsample=1.0 will be ignored. Current value: bagging_fraction=0.86\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1609]\tvalid_0's l1: 2.61994\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.86, subsample=1.0 will be ignored. Current value: bagging_fraction=0.86\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[790]\tvalid_0's l1: 2.62254\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 18\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_year_cyclic', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's l1: 2.87677\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's l1: 2.87455\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's l1: 2.8906\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 19\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.8556, 'lambda_l1': 11, 'lambda_l2': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8556\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2352]\tvalid_0's l1: 1.86259\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8556\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2262]\tvalid_0's l1: 1.8734\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8556\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2337]\tvalid_0's l1: 1.87704\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.6499669073999559\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.6568275706156865\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.677165409201709\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.6861707764164902\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 5 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 6 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited non-use of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 7 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 8 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 9 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 10 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited non-use of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 11 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 12 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 13 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 14 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited non-use of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 15 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 16 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited non-use of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 17 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 18 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited non-use of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 19 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.95 from 2\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 24.0% from 0.046799999999999994 to 0.035567999999999995\n",
      "Increased lambda_l2 by 11.0% from 8 to 9\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to start using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 20.0% from 0.046799999999999994 to 0.037439999999999994\n",
      "Increased num_leaves by 21.0% from 695 to 841\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 16.0% from 0.046799999999999994 to 0.03931199999999999\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased lambda_l1 by 14.000000000000002% from 14 to 16\n",
      "Increased lambda_l2 by 12.0% from 8 to 9\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using dwelling_type_ord\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased feature_fraction by 2.0% from 0.93 to 0.9114000000000001\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_week\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 16\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 2.0% from 0.046799999999999994 to 0.047735999999999994\n",
      "Decreased feature_fraction by 6.0% from 0.93 to 0.8742000000000001\n",
      "\u001b[1m\u001b[92mChild 17\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 18.0% from 695 to 820\n",
      "Increased bagging_freq by 2.0% from 10 to 10\n",
      "\u001b[1m\u001b[92mChild 18\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_fraction by 2.0% from 1 to 1\n",
      "Decreased feature_fraction by 21.0% from 0.93 to 0.7347\n",
      "\u001b[1m\u001b[92mChild 19\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_fraction by 2.0% from 0.95 to 0.969\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1752f6ad81884240977e770e7da0b668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.65862\n",
      "[6666]\tvalid_0's l1: 1.64199\n",
      "Early stopping, best iteration is:\n",
      "[6499]\tvalid_0's l1: 1.64173\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66616\n",
      "Early stopping, best iteration is:\n",
      "[5504]\tvalid_0's l1: 1.65251\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66939\n",
      "Early stopping, best iteration is:\n",
      "[6177]\tvalid_0's l1: 1.65565\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66724\n",
      "Early stopping, best iteration is:\n",
      "[5311]\tvalid_0's l1: 1.65073\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.6715\n",
      "Early stopping, best iteration is:\n",
      "[4751]\tvalid_0's l1: 1.66031\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67988\n",
      "Early stopping, best iteration is:\n",
      "[6297]\tvalid_0's l1: 1.65944\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.71787\n",
      "[6666]\tvalid_0's l1: 1.68738\n",
      "[9999]\tvalid_0's l1: 1.67067\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67066\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.72286\n",
      "[6666]\tvalid_0's l1: 1.69304\n",
      "[9999]\tvalid_0's l1: 1.67599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.67598\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.73257\n",
      "[6666]\tvalid_0's l1: 1.70294\n",
      "[9999]\tvalid_0's l1: 1.68491\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.68491\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70055\n",
      "[6666]\tvalid_0's l1: 1.68202\n",
      "Early stopping, best iteration is:\n",
      "[6987]\tvalid_0's l1: 1.68138\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70533\n",
      "[6666]\tvalid_0's l1: 1.68941\n",
      "Early stopping, best iteration is:\n",
      "[8518]\tvalid_0's l1: 1.686\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.70896\n",
      "[6666]\tvalid_0's l1: 1.69178\n",
      "Early stopping, best iteration is:\n",
      "[7076]\tvalid_0's l1: 1.69114\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'month_cyclic', 'is_weekend', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2427]\tvalid_0's l1: 1.89977\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2249]\tvalid_0's l1: 1.91095\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2614]\tvalid_0's l1: 1.91211\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.035567999999999995, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.68015\n",
      "Early stopping, best iteration is:\n",
      "[5678]\tvalid_0's l1: 1.6553\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.68113\n",
      "[6666]\tvalid_0's l1: 1.65464\n",
      "Early stopping, best iteration is:\n",
      "[7308]\tvalid_0's l1: 1.65255\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.69179\n",
      "Early stopping, best iteration is:\n",
      "[6169]\tvalid_0's l1: 1.66395\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67531\n",
      "[6666]\tvalid_0's l1: 1.65629\n",
      "Early stopping, best iteration is:\n",
      "[7728]\tvalid_0's l1: 1.65396\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67952\n",
      "[6666]\tvalid_0's l1: 1.65568\n",
      "Early stopping, best iteration is:\n",
      "[7114]\tvalid_0's l1: 1.6548\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.68714\n",
      "Early stopping, best iteration is:\n",
      "[5913]\tvalid_0's l1: 1.66645\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.037439999999999994, 'num_leaves': 841, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2617]\tvalid_0's l1: 1.89185\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2627]\tvalid_0's l1: 1.90045\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2698]\tvalid_0's l1: 1.90412\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.03931199999999999, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90195\n",
      "Early stopping, best iteration is:\n",
      "[3823]\tvalid_0's l1: 1.90123\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.91089\n",
      "Early stopping, best iteration is:\n",
      "[4230]\tvalid_0's l1: 1.9102\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92596\n",
      "Early stopping, best iteration is:\n",
      "[4094]\tvalid_0's l1: 1.91462\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 16, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1590]\tvalid_0's l1: 1.90711\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1350]\tvalid_0's l1: 1.91689\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1320]\tvalid_0's l1: 1.92481\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.9114000000000001, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9114000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9114000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2319]\tvalid_0's l1: 1.88901\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9114000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9114000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2112]\tvalid_0's l1: 1.89985\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9114000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9114000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2256]\tvalid_0's l1: 1.8952\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1411]\tvalid_0's l1: 1.91854\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1722]\tvalid_0's l1: 1.9259\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1630]\tvalid_0's l1: 1.93422\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.83972\n",
      "[6666]\tvalid_0's l1: 1.82889\n",
      "[9999]\tvalid_0's l1: 1.82313\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9968]\tvalid_0's l1: 1.82309\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.84389\n",
      "[6666]\tvalid_0's l1: 1.83349\n",
      "[9999]\tvalid_0's l1: 1.82761\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.8276\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.84706\n",
      "[6666]\tvalid_0's l1: 1.83678\n",
      "[9999]\tvalid_0's l1: 1.82972\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9992]\tvalid_0's l1: 1.8297\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_year_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's l1: 2.82348\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's l1: 2.82305\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's l1: 2.83834\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['month_ord', 'is_weekend']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's l1: 4.89854\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's l1: 4.89564\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's l1: 4.90389\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.95, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1074]\tvalid_0's l1: 1.90087\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[781]\tvalid_0's l1: 1.91167\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.95, subsample=1.0 will be ignored. Current value: bagging_fraction=0.95\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[927]\tvalid_0's l1: 1.91933\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 16\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'month_cyclic', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.047735999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.8742000000000001, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8742000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8742000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1909]\tvalid_0's l1: 1.91963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8742000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8742000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1816]\tvalid_0's l1: 1.92725\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8742000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8742000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2150]\tvalid_0's l1: 1.9286\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 17\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 820, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's l1: 2.63024\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's l1: 2.6284\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's l1: 2.63364\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 18\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.7347, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1331]\tvalid_0's l1: 2.65227\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1447]\tvalid_0's l1: 2.64828\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1824]\tvalid_0's l1: 2.64985\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 19\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.969, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.969\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.91291\n",
      "[6666]\tvalid_0's l1: 1.90597\n",
      "[9999]\tvalid_0's l1: 1.90227\n",
      "Early stopping, best iteration is:\n",
      "[9750]\tvalid_0's l1: 1.90225\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.969\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92271\n",
      "[6666]\tvalid_0's l1: 1.91573\n",
      "[9999]\tvalid_0's l1: 1.91266\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9966]\tvalid_0's l1: 1.91265\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.969\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92806\n",
      "[6666]\tvalid_0's l1: 1.92121\n",
      "[9999]\tvalid_0's l1: 1.91731\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9952]\tvalid_0's l1: 1.91728\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.6499669073999559\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.6568275706156865\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.6572667138822392\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.6584059692666362\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.035567999999999995 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 9 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 5 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 6 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 7 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 8 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.035567999999999995 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 9 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 9 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 10 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 11 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 12 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 13 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 14 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 15 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 16 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 17 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited non-use of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 18 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 9 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 19 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_fraction by 0.0% from 1 to 1.0\n",
      "Decreased bagging_freq by 19.0% from 10 to 8\n",
      "Increased lambda_l1 by 14.000000000000002% from 14 to 16\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using day_of_month\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased lambda_l2 by 22.0% from 8 to 10\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 1.0% from 10 to 10\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 11.0% from 0.046799999999999994 to 0.041651999999999995\n",
      "Increased feature_fraction by 17.0% from 0.93 to 1\n",
      "Decreased lambda_l1 by 13.0% from 14 to 12\n",
      "Decreased lambda_l2 by 4.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_week\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l1 by 1.0% from 14 to 14\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 13.0% from 1 to 0.87\n",
      "Decreased lambda_l1 by 1.0% from 14 to 14\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_freq by 4.0% from 10 to 10\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l1 by 1.0% from 14 to 14\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 2.0% from 695 to 681\n",
      "Decreased max_depth by 4.0% from 10 to 10\n",
      "Decreased lambda_l1 by 11.0% from 14 to 12\n",
      "Decreased lambda_l2 by 12.0% from 8 to 7\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 20.0% from 11 to 9\n",
      "\u001b[1m\u001b[92mChild 16\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 8.0% from 0.046799999999999994 to 0.05054399999999999\n",
      "Increased num_leaves by 3.0% from 695 to 716\n",
      "Increased max_depth by 16.0% from 10 to 12\n",
      "Increased lambda_l1 by 9.0% from 14 to 15\n",
      "Decreased lambda_l2 by 4.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 17\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_freq by 2.0% from 10 to 10\n",
      "Decreased lambda_l1 by 19.0% from 14 to 11\n",
      "\u001b[1m\u001b[92mChild 18\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 24.0% from 1 to 0.76\n",
      "Increased lambda_l1 by 3.0% from 14 to 14\n",
      "\u001b[1m\u001b[92mChild 19\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc53be29bdb420980305f269f902ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.65862\n",
      "[6666]\tvalid_0's l1: 1.64199\n",
      "Early stopping, best iteration is:\n",
      "[6499]\tvalid_0's l1: 1.64173\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66616\n",
      "Early stopping, best iteration is:\n",
      "[5504]\tvalid_0's l1: 1.65251\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66939\n",
      "Early stopping, best iteration is:\n",
      "[6177]\tvalid_0's l1: 1.65565\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66724\n",
      "Early stopping, best iteration is:\n",
      "[5311]\tvalid_0's l1: 1.65073\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.6715\n",
      "Early stopping, best iteration is:\n",
      "[4751]\tvalid_0's l1: 1.66031\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67988\n",
      "Early stopping, best iteration is:\n",
      "[6297]\tvalid_0's l1: 1.65944\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.035567999999999995, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.68015\n",
      "Early stopping, best iteration is:\n",
      "[5678]\tvalid_0's l1: 1.6553\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.68113\n",
      "[6666]\tvalid_0's l1: 1.65464\n",
      "Early stopping, best iteration is:\n",
      "[7308]\tvalid_0's l1: 1.65255\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.69179\n",
      "Early stopping, best iteration is:\n",
      "[6169]\tvalid_0's l1: 1.66395\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67531\n",
      "[6666]\tvalid_0's l1: 1.65629\n",
      "Early stopping, best iteration is:\n",
      "[7728]\tvalid_0's l1: 1.65396\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67952\n",
      "[6666]\tvalid_0's l1: 1.65568\n",
      "Early stopping, best iteration is:\n",
      "[8247]\tvalid_0's l1: 1.65261\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.68714\n",
      "Early stopping, best iteration is:\n",
      "[5913]\tvalid_0's l1: 1.66645\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.035567999999999995, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1.0, 'bagging_freq': 8, 'feature_fraction': 0.93, 'lambda_l1': 16, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76488\n",
      "[6666]\tvalid_0's l1: 1.72818\n",
      "Early stopping, best iteration is:\n",
      "[7854]\tvalid_0's l1: 1.72097\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76575\n",
      "[6666]\tvalid_0's l1: 1.72985\n",
      "[9999]\tvalid_0's l1: 1.72126\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9978]\tvalid_0's l1: 1.72124\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.76883\n",
      "[6666]\tvalid_0's l1: 1.73896\n",
      "[9999]\tvalid_0's l1: 1.72492\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.72492\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2832]\tvalid_0's l1: 1.74998\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3056]\tvalid_0's l1: 1.74971\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2637]\tvalid_0's l1: 1.75674\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1778]\tvalid_0's l1: 1.75814\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2148]\tvalid_0's l1: 1.76399\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2122]\tvalid_0's l1: 1.76374\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_ord', 'month_cyclic', 'is_weekend']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.041651999999999995, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 1, 'lambda_l1': 12, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.89412\n",
      "Early stopping, best iteration is:\n",
      "[3507]\tvalid_0's l1: 1.89408\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2956]\tvalid_0's l1: 1.90537\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2538]\tvalid_0's l1: 1.90787\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.035567999999999995, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's l1: 2.89792\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's l1: 2.89513\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's l1: 2.91264\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[916]\tvalid_0's l1: 1.82605\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[874]\tvalid_0's l1: 1.83626\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[910]\tvalid_0's l1: 1.83864\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.87, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.87, subsample=1.0 will be ignored. Current value: bagging_fraction=0.87\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90497\n",
      "[6666]\tvalid_0's l1: 1.8974\n",
      "Early stopping, best iteration is:\n",
      "[9013]\tvalid_0's l1: 1.89425\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.87, subsample=1.0 will be ignored. Current value: bagging_fraction=0.87\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.91445\n",
      "Early stopping, best iteration is:\n",
      "[4650]\tvalid_0's l1: 1.91056\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.87, subsample=1.0 will be ignored. Current value: bagging_fraction=0.87\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92044\n",
      "[6666]\tvalid_0's l1: 1.91267\n",
      "Early stopping, best iteration is:\n",
      "[7030]\tvalid_0's l1: 1.91168\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66091\n",
      "[6666]\tvalid_0's l1: 1.64648\n",
      "Early stopping, best iteration is:\n",
      "[7035]\tvalid_0's l1: 1.64607\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66467\n",
      "[6666]\tvalid_0's l1: 1.65078\n",
      "Early stopping, best iteration is:\n",
      "[6737]\tvalid_0's l1: 1.65066\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66986\n",
      "[6666]\tvalid_0's l1: 1.65464\n",
      "Early stopping, best iteration is:\n",
      "[6669]\tvalid_0's l1: 1.65462\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2807]\tvalid_0's l1: 1.93447\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2710]\tvalid_0's l1: 1.9448\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2988]\tvalid_0's l1: 1.94936\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1206]\tvalid_0's l1: 1.86015\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1147]\tvalid_0's l1: 1.87169\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1360]\tvalid_0's l1: 1.87514\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 681, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 12, 'lambda_l2': 7}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1823]\tvalid_0's l1: 1.86256\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1703]\tvalid_0's l1: 1.87336\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=7, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1671]\tvalid_0's l1: 1.87525\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 9, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1660]\tvalid_0's l1: 1.86124\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1579]\tvalid_0's l1: 1.87232\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1685]\tvalid_0's l1: 1.87511\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 16\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.05054399999999999, 'num_leaves': 716, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 15, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[820]\tvalid_0's l1: 1.86097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[769]\tvalid_0's l1: 1.87275\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[818]\tvalid_0's l1: 1.87524\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 17\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66826\n",
      "Early stopping, best iteration is:\n",
      "[6322]\tvalid_0's l1: 1.64996\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67179\n",
      "[6666]\tvalid_0's l1: 1.65348\n",
      "Early stopping, best iteration is:\n",
      "[7759]\tvalid_0's l1: 1.64955\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.68343\n",
      "Early stopping, best iteration is:\n",
      "[5476]\tvalid_0's l1: 1.66759\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 18\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.76, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90838\n",
      "Early stopping, best iteration is:\n",
      "[5234]\tvalid_0's l1: 1.90277\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.91728\n",
      "Early stopping, best iteration is:\n",
      "[4672]\tvalid_0's l1: 1.91331\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.91956\n",
      "Early stopping, best iteration is:\n",
      "[5824]\tvalid_0's l1: 1.91232\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 8, Individual 19\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_month', 'month_ord', 'month_cyclic', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2100]\tvalid_0's l1: 1.78772\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2114]\tvalid_0's l1: 1.79795\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2526]\tvalid_0's l1: 1.80116\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.6499669073999559\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.6504470888670446\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.6556983285937616\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.6568275706156865\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 5 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 6 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 7 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 8 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 11 from 2\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 9 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 11 from 2\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 10 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 11 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 12 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 13 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 14 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 15 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 11 from 2\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 16 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 11 from 2\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 17 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 18 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 19 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 22.0% from 0.046799999999999994 to 0.036503999999999995\n",
      "Increased max_depth by 22.0% from 11 to 13\n",
      "Decreased bagging_freq by 11.0% from 10 to 9\n",
      "Increased lambda_l1 by 15.0% from 14 to 16\n",
      "Decreased lambda_l2 by 19.0% from 8 to 6\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 6.0% from 0.046799999999999994 to 0.043991999999999996\n",
      "Decreased num_leaves by 16.0% from 695 to 584\n",
      "Decreased bagging_freq by 4.0% from 10 to 10\n",
      "Decreased lambda_l1 by 16.0% from 14 to 12\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 19.0% from 695 to 827\n",
      "Decreased max_depth by 20.0% from 11 to 9\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l2 by 5.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_fraction by 21.0% from 1 to 1\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 10.0% from 695 to 764\n",
      "Increased max_depth by 16.0% from 10 to 12\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 24.0% from 11 to 8\n",
      "Increased bagging_fraction by 21.0% from 1 to 1\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l1 by 19.0% from 14 to 11\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 4.0% from 10 to 10\n",
      "Decreased bagging_fraction by 2.0% from 1 to 0.98\n",
      "Decreased bagging_freq by 8.0% from 10 to 9\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 7.000000000000001% from 0.046799999999999994 to 0.050075999999999996\n",
      "Increased lambda_l2 by 21.0% from 8 to 10\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 3.0% from 1 to 0.97\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 23.0% from 10 to 12\n",
      "Decreased lambda_l1 by 10.0% from 11 to 10\n",
      "\u001b[1m\u001b[92mChild 16\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased feature_fraction by 15.0% from 0.93 to 1\n",
      "\u001b[1m\u001b[92mChild 17\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 18\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_freq by 13.0% from 10 to 11\n",
      "Decreased lambda_l1 by 15.0% from 14 to 12\n",
      "\u001b[1m\u001b[92mChild 19\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_freq by 8.0% from 10 to 11\n",
      "Increased lambda_l2 by 0.0% from 8 to 8\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31552db6c4cc47c5a2a13bc10ac87d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.65862\n",
      "[6666]\tvalid_0's l1: 1.64199\n",
      "Early stopping, best iteration is:\n",
      "[6499]\tvalid_0's l1: 1.64173\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66616\n",
      "Early stopping, best iteration is:\n",
      "[5504]\tvalid_0's l1: 1.65251\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66939\n",
      "Early stopping, best iteration is:\n",
      "[6177]\tvalid_0's l1: 1.65565\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66091\n",
      "[6666]\tvalid_0's l1: 1.64648\n",
      "Early stopping, best iteration is:\n",
      "[7035]\tvalid_0's l1: 1.64607\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66467\n",
      "[6666]\tvalid_0's l1: 1.65078\n",
      "Early stopping, best iteration is:\n",
      "[6737]\tvalid_0's l1: 1.65066\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66986\n",
      "[6666]\tvalid_0's l1: 1.65464\n",
      "Early stopping, best iteration is:\n",
      "[6669]\tvalid_0's l1: 1.65462\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66826\n",
      "Early stopping, best iteration is:\n",
      "[6322]\tvalid_0's l1: 1.64996\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67179\n",
      "[6666]\tvalid_0's l1: 1.65348\n",
      "Early stopping, best iteration is:\n",
      "[7759]\tvalid_0's l1: 1.64955\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.68343\n",
      "Early stopping, best iteration is:\n",
      "[5476]\tvalid_0's l1: 1.66759\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66724\n",
      "Early stopping, best iteration is:\n",
      "[5311]\tvalid_0's l1: 1.65073\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.6715\n",
      "Early stopping, best iteration is:\n",
      "[4751]\tvalid_0's l1: 1.66031\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67988\n",
      "Early stopping, best iteration is:\n",
      "[6297]\tvalid_0's l1: 1.65944\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.036503999999999995, 'num_leaves': 695, 'max_depth': 13, 'bagging_fraction': 1, 'bagging_freq': 9, 'feature_fraction': 0.93, 'lambda_l1': 16, 'lambda_l2': 6}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[989]\tvalid_0's l1: 1.89731\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[761]\tvalid_0's l1: 1.90676\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[904]\tvalid_0's l1: 1.91219\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.043991999999999996, 'num_leaves': 584, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 12, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61509\n",
      "[6666]\tvalid_0's l1: 2.61435\n",
      "[9999]\tvalid_0's l1: 2.61408\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 2.61408\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61223\n",
      "[6666]\tvalid_0's l1: 2.6113\n",
      "Early stopping, best iteration is:\n",
      "[9543]\tvalid_0's l1: 2.61089\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61426\n",
      "[6666]\tvalid_0's l1: 2.61325\n",
      "Early stopping, best iteration is:\n",
      "[9742]\tvalid_0's l1: 2.61291\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_cyclic', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 827, 'max_depth': 9, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.89727\n",
      "Early stopping, best iteration is:\n",
      "[3329]\tvalid_0's l1: 1.89726\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90772\n",
      "Early stopping, best iteration is:\n",
      "[3418]\tvalid_0's l1: 1.90771\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9123\n",
      "Early stopping, best iteration is:\n",
      "[3351]\tvalid_0's l1: 1.9123\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_month', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1731]\tvalid_0's l1: 1.79465\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2233]\tvalid_0's l1: 1.80191\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1547]\tvalid_0's l1: 1.80261\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61549\n",
      "[6666]\tvalid_0's l1: 2.61465\n",
      "Early stopping, best iteration is:\n",
      "[8860]\tvalid_0's l1: 2.61412\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.6119\n",
      "Early stopping, best iteration is:\n",
      "[6280]\tvalid_0's l1: 2.61105\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61356\n",
      "[6666]\tvalid_0's l1: 2.61256\n",
      "Early stopping, best iteration is:\n",
      "[9442]\tvalid_0's l1: 2.61221\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 764, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.65008\n",
      "Early stopping, best iteration is:\n",
      "[4198]\tvalid_0's l1: 1.64561\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66163\n",
      "Early stopping, best iteration is:\n",
      "[5368]\tvalid_0's l1: 1.6511\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66476\n",
      "Early stopping, best iteration is:\n",
      "[6203]\tvalid_0's l1: 1.65371\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'month_cyclic', 'is_weekend', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 8, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.91207\n",
      "Early stopping, best iteration is:\n",
      "[5400]\tvalid_0's l1: 1.90605\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92099\n",
      "Early stopping, best iteration is:\n",
      "[4538]\tvalid_0's l1: 1.91826\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9274\n",
      "Early stopping, best iteration is:\n",
      "[5647]\tvalid_0's l1: 1.92078\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_ord', 'month_cyclic', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.91079\n",
      "Early stopping, best iteration is:\n",
      "[4954]\tvalid_0's l1: 1.90924\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92283\n",
      "Early stopping, best iteration is:\n",
      "[4355]\tvalid_0's l1: 1.92125\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9259\n",
      "Early stopping, best iteration is:\n",
      "[4826]\tvalid_0's l1: 1.9243\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.98, 'bagging_freq': 9, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.98, subsample=1.0 will be ignored. Current value: bagging_fraction=0.98\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1656]\tvalid_0's l1: 1.89742\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.98, subsample=1.0 will be ignored. Current value: bagging_fraction=0.98\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1125]\tvalid_0's l1: 1.90647\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.98, subsample=1.0 will be ignored. Current value: bagging_fraction=0.98\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1206]\tvalid_0's l1: 1.91045\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.050075999999999996, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1249]\tvalid_0's l1: 1.86123\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1112]\tvalid_0's l1: 1.87235\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1131]\tvalid_0's l1: 1.87633\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.95959\n",
      "[6666]\tvalid_0's l1: 1.94263\n",
      "[9999]\tvalid_0's l1: 1.93591\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9979]\tvalid_0's l1: 1.93588\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97002\n",
      "[6666]\tvalid_0's l1: 1.95076\n",
      "[9999]\tvalid_0's l1: 1.94435\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.94435\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9736\n",
      "[6666]\tvalid_0's l1: 1.95601\n",
      "[9999]\tvalid_0's l1: 1.94836\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9950]\tvalid_0's l1: 1.94835\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 10, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[696]\tvalid_0's l1: 1.81896\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[728]\tvalid_0's l1: 1.83533\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[685]\tvalid_0's l1: 1.8366\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 16\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 1, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[340]\tvalid_0's l1: 2.89571\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[271]\tvalid_0's l1: 2.8943\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[274]\tvalid_0's l1: 2.91053\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 17\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61533\n",
      "[6666]\tvalid_0's l1: 2.61424\n",
      "Early stopping, best iteration is:\n",
      "[8152]\tvalid_0's l1: 2.61409\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61213\n",
      "[6666]\tvalid_0's l1: 2.61115\n",
      "[9999]\tvalid_0's l1: 2.61092\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9962]\tvalid_0's l1: 2.61092\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61413\n",
      "[6666]\tvalid_0's l1: 2.61318\n",
      "[9999]\tvalid_0's l1: 2.61284\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9995]\tvalid_0's l1: 2.61283\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 18\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 11, 'feature_fraction': 0.93, 'lambda_l1': 12, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1119]\tvalid_0's l1: 1.85788\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1006]\tvalid_0's l1: 1.86669\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1042]\tvalid_0's l1: 1.87064\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 9, Individual 19\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'is_weekend']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 11, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1892]\tvalid_0's l1: 1.87753\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2058]\tvalid_0's l1: 1.88576\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2158]\tvalid_0's l1: 1.88631\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.6499669073999559\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.6501424230874289\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.650447080818474\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.6556983285937616\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 764 from 1\n",
      "inherited max_depth value of 12 from 1\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 11 from 1\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 5 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 12 from 1\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 6 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 764 from 1\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 7 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 8 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 764 from 1\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 11 from 1\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 9 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 764 from 1\n",
      "inherited max_depth value of 12 from 1\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 10 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 764 from 1\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 11 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 764 from 1\n",
      "inherited max_depth value of 12 from 1\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 12 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 13 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 14 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 15 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 12 from 1\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 16 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 764 from 1\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 17 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 12 from 1\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 18 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 19 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 12 from 1\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 14.000000000000002% from 0.046799999999999994 to 0.053352\n",
      "Increased max_depth by 5.0% from 12 to 13\n",
      "Decreased bagging_freq by 5.0% from 10 to 10\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 0.0% from 695 to 695\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_freq by 7.000000000000001% from 10 to 9\n",
      "Increased lambda_l2 by 19.0% from 8 to 10\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 23.0% from 0.046799999999999994 to 0.036036\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 18.0% from 0.046799999999999994 to 0.03837599999999999\n",
      "Decreased feature_fraction by 15.0% from 0.93 to 0.7905\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased feature_fraction by 5.0% from 0.93 to 0.9765\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased lambda_l1 by 1.0% from 11 to 11\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l1 by 12.0% from 14 to 12\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 11.0% from 0.046799999999999994 to 0.041651999999999995\n",
      "Decreased bagging_freq by 22.0% from 10 to 8\n",
      "\u001b[1m\u001b[92mChild 16\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased feature_fraction by 16.0% from 0.93 to 1\n",
      "Increased lambda_l2 by 14.000000000000002% from 8 to 9\n",
      "\u001b[1m\u001b[92mChild 17\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased lambda_l1 by 23.0% from 11 to 14\n",
      "\u001b[1m\u001b[92mChild 18\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_week\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 20.0% from 1 to 0.8\n",
      "Decreased feature_fraction by 21.0% from 0.93 to 0.7347\n",
      "\u001b[1m\u001b[92mChild 19\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37f6c815e1b4c9db88088c67afcf3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.65862\n",
      "[6666]\tvalid_0's l1: 1.64199\n",
      "Early stopping, best iteration is:\n",
      "[6499]\tvalid_0's l1: 1.64173\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66616\n",
      "Early stopping, best iteration is:\n",
      "[5504]\tvalid_0's l1: 1.65251\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66939\n",
      "Early stopping, best iteration is:\n",
      "[6177]\tvalid_0's l1: 1.65565\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 764, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.65008\n",
      "Early stopping, best iteration is:\n",
      "[4198]\tvalid_0's l1: 1.64561\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66163\n",
      "Early stopping, best iteration is:\n",
      "[5368]\tvalid_0's l1: 1.6511\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66476\n",
      "Early stopping, best iteration is:\n",
      "[6203]\tvalid_0's l1: 1.65371\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66091\n",
      "[6666]\tvalid_0's l1: 1.64648\n",
      "Early stopping, best iteration is:\n",
      "[7035]\tvalid_0's l1: 1.64607\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66467\n",
      "[6666]\tvalid_0's l1: 1.65078\n",
      "Early stopping, best iteration is:\n",
      "[6737]\tvalid_0's l1: 1.65066\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66986\n",
      "[6666]\tvalid_0's l1: 1.65464\n",
      "Early stopping, best iteration is:\n",
      "[6669]\tvalid_0's l1: 1.65462\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66826\n",
      "Early stopping, best iteration is:\n",
      "[6322]\tvalid_0's l1: 1.64996\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.67179\n",
      "[6666]\tvalid_0's l1: 1.65348\n",
      "Early stopping, best iteration is:\n",
      "[7759]\tvalid_0's l1: 1.64955\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.68343\n",
      "Early stopping, best iteration is:\n",
      "[5476]\tvalid_0's l1: 1.66759\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.053352, 'num_leaves': 764, 'max_depth': 13, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3011]\tvalid_0's l1: 1.65212\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66004\n",
      "Early stopping, best iteration is:\n",
      "[3657]\tvalid_0's l1: 1.65757\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66411\n",
      "Early stopping, best iteration is:\n",
      "[4753]\tvalid_0's l1: 1.65671\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[987]\tvalid_0's l1: 1.86122\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[893]\tvalid_0's l1: 1.87229\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[880]\tvalid_0's l1: 1.87531\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 764, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 9, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[582]\tvalid_0's l1: 2.74146\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[632]\tvalid_0's l1: 2.73599\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[518]\tvalid_0's l1: 2.74498\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[835]\tvalid_0's l1: 1.85954\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[897]\tvalid_0's l1: 1.86816\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[959]\tvalid_0's l1: 1.87223\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.036036, 'num_leaves': 764, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.7677\n",
      "[6666]\tvalid_0's l1: 1.71757\n",
      "[9999]\tvalid_0's l1: 1.70026\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.70025\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.77749\n",
      "[6666]\tvalid_0's l1: 1.72064\n",
      "[9999]\tvalid_0's l1: 1.70574\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.70573\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.78134\n",
      "[6666]\tvalid_0's l1: 1.72783\n",
      "[9999]\tvalid_0's l1: 1.71155\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.71155\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.03837599999999999, 'num_leaves': 764, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.7905, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7905\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1703]\tvalid_0's l1: 1.85916\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7905\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1660]\tvalid_0's l1: 1.86748\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7905\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1694]\tvalid_0's l1: 1.87224\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 764, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.9765, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9765, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9765\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[672]\tvalid_0's l1: 2.19869\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9765, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9765\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[741]\tvalid_0's l1: 2.16223\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9765, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9765\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[579]\tvalid_0's l1: 2.23202\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 764, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[909]\tvalid_0's l1: 1.86178\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[829]\tvalid_0's l1: 1.87285\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[941]\tvalid_0's l1: 1.87582\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_ord', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2184]\tvalid_0's l1: 1.88874\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1939]\tvalid_0's l1: 1.89601\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2099]\tvalid_0's l1: 1.89591\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66003\n",
      "Early stopping, best iteration is:\n",
      "[4218]\tvalid_0's l1: 1.65159\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66294\n",
      "Early stopping, best iteration is:\n",
      "[5015]\tvalid_0's l1: 1.65525\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66977\n",
      "Early stopping, best iteration is:\n",
      "[5941]\tvalid_0's l1: 1.6545\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 12, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2043]\tvalid_0's l1: 1.8949\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1929]\tvalid_0's l1: 1.90719\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2099]\tvalid_0's l1: 1.90786\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.041651999999999995, 'num_leaves': 695, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 8, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.63883\n",
      "Early stopping, best iteration is:\n",
      "[4545]\tvalid_0's l1: 2.6387\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.63518\n",
      "[6666]\tvalid_0's l1: 2.63491\n",
      "Early stopping, best iteration is:\n",
      "[6838]\tvalid_0's l1: 2.63489\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.63962\n",
      "Early stopping, best iteration is:\n",
      "[4306]\tvalid_0's l1: 2.63948\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 16\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 764, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 1, 'lambda_l1': 14, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1738]\tvalid_0's l1: 1.89355\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1768]\tvalid_0's l1: 1.90081\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1729]\tvalid_0's l1: 1.90448\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 17\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[987]\tvalid_0's l1: 1.86122\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[893]\tvalid_0's l1: 1.87229\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[880]\tvalid_0's l1: 1.87531\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 18\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 10, 'bagging_fraction': 0.8, 'bagging_freq': 10, 'feature_fraction': 0.7347, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.33022\n",
      "Early stopping, best iteration is:\n",
      "[4387]\tvalid_0's l1: 2.32274\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.32653\n",
      "Early stopping, best iteration is:\n",
      "[5327]\tvalid_0's l1: 2.31959\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7347, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7347\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.34296\n",
      "Early stopping, best iteration is:\n",
      "[4342]\tvalid_0's l1: 2.33562\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 10, Individual 19\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_year_cyclic', 'month_ord', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's l1: 2.92291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's l1: 2.92213\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's l1: 2.93702\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.6499669073999559\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.6501424230873631\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.6504470808183798\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.653781064309434\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 5 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 6 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 12 from 1\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 7 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 12 from 1\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 8 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 764 from 1\n",
      "inherited max_depth value of 12 from 1\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 9 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 3\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 10 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 764 from 1\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 1\n",
      "inherited lambda_l1 value of 11 from 1\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 11 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 12 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 13 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 2\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited non-use of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 14 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 0\n",
      "inherited feature_fraction value of 0.93 from 2\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited non-use of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 15 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 1\n",
      "inherited num_leaves value of 764 from 1\n",
      "inherited max_depth value of 12 from 1\n",
      "inherited bagging_fraction value of 1 from 1\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 11 from 3\n",
      "inherited lambda_l2 value of 8 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited non-use of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 16 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 764 from 1\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 1 from 3\n",
      "inherited bagging_freq value of 10 from 1\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 11 from 1\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited non-use of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 17 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 18 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 3\n",
      "inherited num_leaves value of 695 from 3\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 1 from 2\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 3\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited non-use of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 19 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.046799999999999994 from 0\n",
      "inherited num_leaves value of 695 from 0\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 1 from 0\n",
      "inherited bagging_freq value of 10 from 2\n",
      "inherited feature_fraction value of 0.93 from 0\n",
      "inherited lambda_l1 value of 14 from 0\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited non-use of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased feature_fraction by 22.0% from 0.93 to 1\n",
      "Decreased lambda_l2 by 4.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_fraction by 20.0% from 1 to 1\n",
      "Increased lambda_l1 by 24.0% from 14 to 17\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 9.0% from 12 to 11\n",
      "Decreased bagging_freq by 5.0% from 10 to 10\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 7.000000000000001% from 12 to 11\n",
      "Decreased lambda_l1 by 12.0% from 14 to 12\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 3.0% from 0.046799999999999994 to 0.04539599999999999\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_freq by 0.0% from 10 to 10\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using num_bedrooms\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 16\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 24.0% from 11 to 8\n",
      "Increased bagging_fraction by 16.0% from 1 to 1\n",
      "\u001b[1m\u001b[92mChild 17\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_freq by 18.0% from 10 to 12\n",
      "\u001b[1m\u001b[92mChild 18\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_week\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 11.0% from 695 to 619\n",
      "Increased bagging_freq by 8.0% from 10 to 11\n",
      "Increased feature_fraction by 20.0% from 0.93 to 1\n",
      "\u001b[1m\u001b[92mChild 19\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 4.0% from 11 to 11\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb765860f5284bae847f2fbd8e526bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.65862\n",
      "[6666]\tvalid_0's l1: 1.64199\n",
      "Early stopping, best iteration is:\n",
      "[6499]\tvalid_0's l1: 1.64173\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66616\n",
      "Early stopping, best iteration is:\n",
      "[5504]\tvalid_0's l1: 1.65251\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66939\n",
      "Early stopping, best iteration is:\n",
      "[6177]\tvalid_0's l1: 1.65565\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 764, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.65008\n",
      "Early stopping, best iteration is:\n",
      "[4198]\tvalid_0's l1: 1.64561\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66163\n",
      "Early stopping, best iteration is:\n",
      "[5368]\tvalid_0's l1: 1.6511\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66476\n",
      "Early stopping, best iteration is:\n",
      "[6203]\tvalid_0's l1: 1.65371\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66091\n",
      "[6666]\tvalid_0's l1: 1.64648\n",
      "Early stopping, best iteration is:\n",
      "[7035]\tvalid_0's l1: 1.64607\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66467\n",
      "[6666]\tvalid_0's l1: 1.65078\n",
      "Early stopping, best iteration is:\n",
      "[6737]\tvalid_0's l1: 1.65066\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66986\n",
      "[6666]\tvalid_0's l1: 1.65464\n",
      "Early stopping, best iteration is:\n",
      "[6669]\tvalid_0's l1: 1.65462\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66003\n",
      "Early stopping, best iteration is:\n",
      "[4218]\tvalid_0's l1: 1.65159\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66294\n",
      "Early stopping, best iteration is:\n",
      "[5015]\tvalid_0's l1: 1.65525\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66977\n",
      "Early stopping, best iteration is:\n",
      "[5941]\tvalid_0's l1: 1.6545\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'is_weekend']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 1, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2192]\tvalid_0's l1: 1.87941\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1748]\tvalid_0's l1: 1.88559\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1924]\tvalid_0's l1: 1.88339\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2297]\tvalid_0's l1: 1.93051\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1628]\tvalid_0's l1: 1.93967\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2260]\tvalid_0's l1: 1.94469\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 17, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=17, reg_alpha=0.0 will be ignored. Current value: lambda_l1=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1042]\tvalid_0's l1: 1.86034\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=17, reg_alpha=0.0 will be ignored. Current value: lambda_l1=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1092]\tvalid_0's l1: 1.87162\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=17, reg_alpha=0.0 will be ignored. Current value: lambda_l1=17\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1178]\tvalid_0's l1: 1.8738\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66091\n",
      "[6666]\tvalid_0's l1: 1.64648\n",
      "Early stopping, best iteration is:\n",
      "[7035]\tvalid_0's l1: 1.64607\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66467\n",
      "[6666]\tvalid_0's l1: 1.65078\n",
      "Early stopping, best iteration is:\n",
      "[6737]\tvalid_0's l1: 1.65066\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66986\n",
      "[6666]\tvalid_0's l1: 1.65464\n",
      "Early stopping, best iteration is:\n",
      "[6669]\tvalid_0's l1: 1.65462\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_month', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 764, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 12, 'lambda_l2': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[499]\tvalid_0's l1: 2.65431\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[458]\tvalid_0's l1: 2.6487\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[479]\tvalid_0's l1: 2.65582\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61589\n",
      "[6666]\tvalid_0's l1: 2.61502\n",
      "Early stopping, best iteration is:\n",
      "[7885]\tvalid_0's l1: 2.61477\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61248\n",
      "[6666]\tvalid_0's l1: 2.6115\n",
      "Early stopping, best iteration is:\n",
      "[7257]\tvalid_0's l1: 2.61142\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.6142\n",
      "[6666]\tvalid_0's l1: 2.61334\n",
      "Early stopping, best iteration is:\n",
      "[9650]\tvalid_0's l1: 2.61307\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['month_ord', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 764, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's l1: 2.95148\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's l1: 2.95096\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's l1: 2.96563\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.04539599999999999, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61551\n",
      "[6666]\tvalid_0's l1: 2.61459\n",
      "Early stopping, best iteration is:\n",
      "[8992]\tvalid_0's l1: 2.61421\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61222\n",
      "[6666]\tvalid_0's l1: 2.61117\n",
      "[9999]\tvalid_0's l1: 2.61094\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9964]\tvalid_0's l1: 2.61093\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.61408\n",
      "[6666]\tvalid_0's l1: 2.61327\n",
      "Early stopping, best iteration is:\n",
      "[8505]\tvalid_0's l1: 2.61304\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.87649\n",
      "Early stopping, best iteration is:\n",
      "[4445]\tvalid_0's l1: 1.87482\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3067]\tvalid_0's l1: 1.8887\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.8888\n",
      "Early stopping, best iteration is:\n",
      "[3894]\tvalid_0's l1: 1.88746\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'is_weekend']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1841]\tvalid_0's l1: 1.87441\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1840]\tvalid_0's l1: 1.88495\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1900]\tvalid_0's l1: 1.88736\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2131]\tvalid_0's l1: 1.89947\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1979]\tvalid_0's l1: 1.90532\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2221]\tvalid_0's l1: 1.90871\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_month', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 764, 'max_depth': 12, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2190]\tvalid_0's l1: 1.77889\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1310]\tvalid_0's l1: 1.79087\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1345]\tvalid_0's l1: 1.79377\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 16\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 764, 'max_depth': 8, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2316]\tvalid_0's l1: 1.86281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2213]\tvalid_0's l1: 1.87341\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2311]\tvalid_0's l1: 1.87676\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 17\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 12, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[292]\tvalid_0's l1: 2.89587\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's l1: 2.89399\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's l1: 2.91067\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 18\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_year_cyclic', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 619, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 11, 'feature_fraction': 1, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's l1: 2.92395\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's l1: 2.92352\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's l1: 2.93812\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 11, Individual 19\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'day_of_month', 'month_ord', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 1337, 'learning_rate': 0.046799999999999994, 'num_leaves': 695, 'max_depth': 11, 'bagging_fraction': 1, 'bagging_freq': 10, 'feature_fraction': 0.93, 'lambda_l1': 14, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's l1: 2.90781\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's l1: 2.91038\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's l1: 2.9224\n",
      "\u001b[1mThis is the final generation so don't need to generation children\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mGenetic algorithm ran 12 generations with a population of 20 in 2 days, 7:22:17\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mutation_rate = 0.2 # 20% mutation rate\n",
    "gaussian_limit = 25 # increase/decrease by up to 25% (divide by 100 after random.randrange())\n",
    "elitism_n = 4 # pick the 4 best at each generation to be the parents\n",
    "number_of_generations=12 #going to test n hyper parameter configurations\n",
    "\n",
    "num_folds = 3 # 3 fold skf; so we use 2/3 of each meters readings for training at each iteration \n",
    "i=0 #just used to print the index of each skf-cv run\n",
    "all_results = [] # will hold array of all the tuples of results + hyper params\n",
    "\n",
    "print(f\"{color.BOLD}Genetic Algorithm hyper parameter optimization{color.END}\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "#iterate through the generations\n",
    "for g in tqdm(range(number_of_generations)):\n",
    "    ### Training each model in the population ###\n",
    "    generation_results = []\n",
    "    for p in tqdm(range(len(population))):\n",
    "        print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}Generation {g}, Individual {p}{color.END}\")\n",
    "            \n",
    "        \n",
    "        #getting this models columns\n",
    "        X_col_groups = population[p][2]\n",
    "        X_cols = population[p][0]\n",
    "        this_X_cats = list(set(X_cols).intersection(all_cat)) #getting the categorical values for this X\n",
    "        #getting this models hyper parameters\n",
    "        this_params = population[p][1]\n",
    "        \n",
    "        #inspecting\n",
    "        print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Feature groups{color.END}\")\n",
    "        print(X_col_groups)\n",
    "        print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Hyper parameters{color.END}\")\n",
    "        print(this_params)\n",
    "        \n",
    "        #training this model and storing its results (excluding the lgbm model itself as was running out of memory)\n",
    "        this_run = run_lgbm_skf_cv(False, False, SEED, num_folds, df_train.copy(), y_col, X_cols, this_X_cats, this_params)\n",
    "        generation_results.append(((this_run[0],this_run[1]), # MAE and TOE (not this_run[2] (lgbm_models) to stop running out of memory)\n",
    "                                  (X_cols,this_params,X_col_groups))) # models description so we can train and use the best lgbm models without having to store all in memory\n",
    "    #adding this populations results to all_results\n",
    "    all_results = all_results + generation_results\n",
    "    \n",
    "    #if this isn't the last generation then generate children\n",
    "    if(g<number_of_generations-1):\n",
    "        \n",
    "        ### Elitism selection mechanism for parents ### \n",
    "\n",
    "        sorted_generation_results = sorted(generation_results, key=lambda tup: tup[0][1]) # sorting the population by the maes\n",
    "        parents = []\n",
    "        #picking the best elitism_n models to be used as the parents\n",
    "        for ne in range(elitism_n):\n",
    "            print(f\"{color.YELLOW}{color.BOLD}Parent {len(parents)}{color.END} has a mae of {sorted_generation_results[0][0][1]}\")\n",
    "            parents.append(sorted_generation_results.pop(0))\n",
    "            \n",
    "        #deleting the previous population; no longer need it now we have parents\n",
    "        del population\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "        ### generating the children from the parents (cross over) ###\n",
    "        print(f\"{color.BOLD}{color.BLUE}Generating the children{color.END}\")\n",
    "        population = []\n",
    "        \n",
    "\n",
    "        # including the best of this generation in the next generation\n",
    "        for parent in parents:\n",
    "            population.append((parent[1][0],parent[1][1],parent[1][2]))\n",
    "\n",
    "        #generating the remaining population by combining the parents genes via uniform XO\n",
    "        while (len(population)<population_size):\n",
    "\n",
    "            # randomly picking 2 of the parents to create the children\n",
    "            parent_indexes = list(range(len(parents)))\n",
    "            random.shuffle(parent_indexes)\n",
    "\n",
    "            #picking the first 2 to be the parents\n",
    "            father_index = parent_indexes[0]\n",
    "            mother_index = parent_indexes[1]\n",
    "            father = parents[father_index]\n",
    "            mother = parents[mother_index]\n",
    "\n",
    "            print(f\"{color.BOLD}{color.GREEN}Child {len(population)} parents = {father_index} and {mother_index}{color.END}\")\n",
    "\n",
    "            #iteratively picking the hyperparameters [1][1]\n",
    "            print(f\"{color.BOLD}{color.YELLOW}inherited hyper parameters{color.END}\")\n",
    "            child_params = params.copy()\n",
    "            for key in tuned_hyper_names:\n",
    "                #50% chance of getting from father\n",
    "                if(random.choice([0,1])==0):\n",
    "                    child_params[key]=father[1][1][key]\n",
    "                    print(f\"inherited {key} value of {child_params[key]} from {father_index}\")\n",
    "                #50% chance of getting from mother\n",
    "                else:\n",
    "                    child_params[key]=mother[1][1][key]\n",
    "                    print(f\"inherited {key} value of {child_params[key]} from {mother_index}\")\n",
    "\n",
    "            #iteratively picking X_col_groups [1][2] (will turn this into X_cols [1][0] after mutation)\n",
    "            print(f\"{color.BOLD}{color.YELLOW}inherited feature groups{color.END}\")\n",
    "            child_X_col_groups = []\n",
    "            for key in possible_columns.keys():\n",
    "                #50% chance to pick whether or not to use this column group based on father\n",
    "                if(random.choice([0,1])==0):\n",
    "                    #check if father contains this column group and if it does, add this column group to the child\n",
    "                    if(possible_columns[key][0] in father[1][2]):\n",
    "                        child_X_col_groups = child_X_col_groups + [key]\n",
    "                        print(f\"inherited usage of feature group {key} from {father_index}\")\n",
    "                    else:\n",
    "                        print(f\"inherited non-use of feature group {key} from {father_index}\")\n",
    "                #50% chance to pick whether or not to use this column group based on mother\n",
    "                else:\n",
    "                    #check if mother contains this column group and if it does, add this column group to the child\n",
    "                    if(possible_columns[key][0] in mother[1][2]):\n",
    "                        child_X_col_groups = child_X_col_groups + [key]\n",
    "                        print(f\"inherited usage of feature group {key} from {mother_index}\")\n",
    "                    else:\n",
    "                        print(f\"inherited non-use of feature group {key} from {father_index}\")\n",
    "            #appending the population with this child\n",
    "            #[0] for X_cols currently empty; will fill this after mutating the groups\n",
    "            population.append(([], child_params,child_X_col_groups))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ### applying mutation to the children *not the parents stored within the population*### \n",
    "        print(f\"{color.BOLD}{color.BLUE}Mutating the children{color.END}\")\n",
    "        #for each child\n",
    "        for child_i in range(elitism_n,population_size):\n",
    "            print(f\"{color.BOLD}{color.GREEN}Child {child_i}{color.END}\")\n",
    "            child = population[child_i] # getting the child\n",
    "\n",
    "            ## mutating the childs column groups via flip bit ##\n",
    "            print(f\"{color.BOLD}{color.YELLOW}Mutating Columns Groups via Bit Flip{color.END}\")\n",
    "            mutated_col_groups = []\n",
    "            mutated_X_cols = []\n",
    "            #iterating through each possible key\n",
    "            for key in possible_columns.keys():\n",
    "                #if we randomly chose to mutate this column...\n",
    "                if(random.random()<mutation_rate):\n",
    "                    #add this column to mutated columns if it doesn't already exist in keys, flipping it's usage\n",
    "                    if(key not in child[2]):\n",
    "                        mutated_col_groups+=[key]\n",
    "                        mutated_X_cols+=possible_columns[key]\n",
    "                        print(f\"Mutated to start using {key}\")\n",
    "                    #else if this column does already exist in keys, don't add it to mutated keys, flipping it's usage\n",
    "                    else:\n",
    "                        print(f\"Mutated to stop using {key}\")\n",
    "                #if we aren't mutating this column...\n",
    "                else:\n",
    "                    #add this column to mutated columns if it already exists in keys\n",
    "                    if(key in child[2]):\n",
    "                        mutated_col_groups+=[key]\n",
    "                        mutated_X_cols+=possible_columns[key]\n",
    "\n",
    "            #if mutated keys is empty after mutation; randomly pick 1 column to keep; clipping it to a length of 1\n",
    "            if(len(mutated_col_groups)<=0):\n",
    "                mutated_col_groups=[random.choice(list(possible_columns.keys()))]\n",
    "                mutated_X_cols+=possible_columns[key]\n",
    "                print(f\"No columns clipping length to 1 so randomly choosing to use {key}\")\n",
    "\n",
    "\n",
    "\n",
    "            ## mutating the childs hyper parameters via gaussian ## \n",
    "            print(f\"{color.BOLD}{color.YELLOW}Mutating hyper parameters via gaussian{color.END}\")\n",
    "            mutated_params = population[child_i][1].copy()\n",
    "            #iterate through each hyper parameter we tuned\n",
    "            for key in tuned_hyper_names:\n",
    "                #if we randomly chose to mutate this hyper...\n",
    "                if(random.random()<mutation_rate):\n",
    "                    #generate the random gaussian percentage\n",
    "                    gaussian_percentage = random.randrange(gaussian_limit)/100\n",
    "                    #50% chance to add\n",
    "                    if(random.choice([0,1])==0):\n",
    "                        mutated_params[key]+=population[child_i][1][key]*gaussian_percentage\n",
    "                        #if this key needs to be a whole number, round it\n",
    "                        if(key in whole_number_hyper_names):\n",
    "                            mutated_params[key] = round(mutated_params[key])\n",
    "                        #clipping fractional keys between 0 and 1\n",
    "                        if(key in fractional_hyper_names):\n",
    "                            mutated_params[key] = max(0.01, min(mutated_params[key],1))\n",
    "                        print(f\"Increased {key} by {gaussian_percentage*100}% from {population[child_i][1][key]} to {mutated_params[key]}\")\n",
    "                    #50% chance to subtract\n",
    "                    else:\n",
    "                        mutated_params[key]-=population[child_i][1][key]*gaussian_percentage\n",
    "                        #if this key needs to be a whole number, round it\n",
    "                        if(key in whole_number_hyper_names):\n",
    "                            mutated_params[key] = round(mutated_params[key])\n",
    "                        #clipping fractional keys between 0 and 1\n",
    "                        if(key in fractional_hyper_names):\n",
    "                            mutated_params[key] = max(0.01, min(mutated_params[key],1))\n",
    "                        print(f\"Decreased {key} by {gaussian_percentage*100}% from {population[child_i][1][key]} to {mutated_params[key]}\")\n",
    "\n",
    "            #overriding X_cols and X_col_groups and params for this child\n",
    "            population[child_i] = (mutated_X_cols, mutated_params,mutated_col_groups)\n",
    "    else:\n",
    "        print(f\"{color.BOLD}This is the final generation so don't need to generation children{color.END}\")\n",
    "        \n",
    "    #deleting generation_results\n",
    "    del generation_results\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"\\n\\n\\n\")\n",
    "time_of_execution = time.time()-start_time\n",
    "print(f\"{color.BOLD}Genetic algorithm ran {number_of_generations} generations with a population of {population_size} in {str(datetime.timedelta(seconds=round(time_of_execution)))}{color.END}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising information from the genetic algorithm results\n",
    "### Box plots of the MAE for the different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced5f3e4dcee449db80429acf180ea4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_maes = {} #dictionary of each columns maes\n",
    "columnless_mae = {}\n",
    "#iterating through each column and randomly decide whether or not to pick it\n",
    "for key in tqdm(possible_columns.keys()):\n",
    "    column = possible_columns[key][0] # only want to check against one column for the 'in'\n",
    "    \n",
    "    # if this column doesn't yet exist in the dict, create it\n",
    "    if key not in columns_maes:\n",
    "        columns_maes[key]=[]\n",
    "    # if this column doesn't yet exist in the dict, create it\n",
    "    if key not in columnless_mae:\n",
    "        columnless_mae[key]=[]\n",
    "\n",
    "    #iterating through every single models results\n",
    "    for i in range(len(all_results)):\n",
    "        \n",
    "        #if this column was used by the model\n",
    "        if column in all_results[i][1][0]:\n",
    "            # adding this models mae to the dict entry for this column\n",
    "            columns_maes[key].append(all_results[i][0][1])\n",
    "            \n",
    "        #else this column wasn't used by the model\n",
    "        else:\n",
    "            # adding this models mae to the dict entry for this column\n",
    "            columnless_mae[key].append(all_results[i][0][1])\n",
    "\n",
    "# print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}MAEs for each model which contains columns of each type{color.END}\")\n",
    "# pprint(columns_maes)\n",
    "\n",
    "# function for setting the box colour\n",
    "def set_box_color(bp, color_line, color_fill):\n",
    "    plt.setp(bp['whiskers'], color=color_line)\n",
    "    plt.setp(bp['caps'], color=color_line)\n",
    "    plt.setp(bp['medians'], color=color_line)\n",
    "    plt.setp(bp['fliers'], color=color_fill)\n",
    "    plt.setp(bp['boxes'], color=color_fill)\n",
    "    plt.setp(bp['means'], color=color_line)\n",
    "\n",
    "    \n",
    "### plotting a boxplot of these ###\n",
    "# getting the 2 dicts we will plot\n",
    "labels, data_columns = columns_maes.keys(), columns_maes.values()\n",
    "data_columnless = columnless_mae.values()\n",
    "\n",
    "#plotting these 2 dicts next to each other\n",
    "fig = plt.figure(figsize=(25,10))\n",
    "bp_dict_columns = plt.boxplot(data_columns,showmeans=True,positions=np.array(range(len(labels)))*2.0-0.4,patch_artist=True) # getting dictionary returned from boxplot\n",
    "bp_dict_columnless = plt.boxplot(data_columnless,showmeans=True,positions=np.array(range(len(labels)))*2.0+0.4,patch_artist=True) # getting dictionary returned from boxplot\n",
    "\n",
    "#colouring them\n",
    "set_box_color(bp_dict_columns, '#416338','#b0dba4')\n",
    "set_box_color(bp_dict_columnless, '#783d2b','#dbb1a4')\n",
    "\n",
    "#annotating the plot\n",
    "plt.title(\"Box plot of MAEs for the different columns\", fontsize=20)\n",
    "plt.xlabel(\"Column groups\", fontsize=17)\n",
    "plt.ylabel(\"MAE\", fontsize=17)\n",
    "\n",
    "#creating the legend\n",
    "plt.plot([], c='#b0dba4',label=\"MAEs of models that used this column\")\n",
    "plt.plot([], c='#dbb1a4',label=\"MAEs of models that didn't use this column\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "## adding overlayed values to the boxplot\n",
    "\n",
    "# stats for with columns\n",
    "column_means = []\n",
    "column_medians = []\n",
    "column_std = []\n",
    "for key in columns_maes.keys():\n",
    "    column_means.append(np.mean(columns_maes[key]))\n",
    "    column_medians.append(np.median(columns_maes[key]))\n",
    "    column_std.append(np.std(columns_maes[key]))\n",
    "for i, line in enumerate(bp_dict_columns['medians']):\n",
    "    x, y = line.get_xydata()[1]\n",
    "    text = ' μ={:.2f}\\n m={:.2f}\\n σ={:.2f}'.format(column_means[i], column_medians[i], column_std[i])\n",
    "    plt.text(x, y, text, horizontalalignment='center')\n",
    "    \n",
    "# stats for without columns\n",
    "columnless_means = []\n",
    "columnless_medians = []\n",
    "columnless_std = []\n",
    "for key in columnless_mae.keys():\n",
    "    columnless_means.append(np.mean(columnless_mae[key]))\n",
    "    columnless_medians.append(np.median(columnless_mae[key]))\n",
    "    columnless_std.append(np.std(columnless_mae[key]))\n",
    "for i, line in enumerate(bp_dict_columnless['medians']):\n",
    "    x, y = line.get_xydata()[1]\n",
    "    text = ' μ={:.2f}\\n m={:.2f}\\n σ={:.2f}'.format(columnless_means[i], columnless_medians[i], columnless_std[i])\n",
    "    plt.text(x, y, text, horizontalalignment='center')\n",
    "\n",
    "\n",
    "plt.xticks(range(0, len(labels)*2,2), labels)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f\"..\\\\Results\\\\Genetic Algorithm\\\\Plots\\\\p{population_size}_g{number_of_generations}_Box_MAEs.png\")\n",
    "\n",
    "plt.close(fig)\n",
    "del fig\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box and swarm plot to better inspect the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10226"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colourBlindFriendly = False # make graph colourBlindFriendly (pink to blue instead of red to green)\n",
    "\n",
    "#gradient of green to red based on each columns stats\n",
    "box_grad_palette = {}\n",
    "for i in range(len(column_std)):\n",
    "    box_grad_palette[i] = [column_std[i], 1-column_std[i],1 if colourBlindFriendly else 0] #based on std\n",
    "\n",
    "fig=plt.figure(figsize=(25,10))\n",
    "sns.set(context='notebook', style='white')\n",
    "sns.utils.axlabel(xlabel=\"Column Groups\", ylabel=\"MAE\", fontsize=16)\n",
    "sns.boxplot(data=list(data_columns), width=.18, palette=box_grad_palette)\n",
    "\n",
    "#slightly paler gradient to make it stand out from the box\n",
    "swarm_grad_palette = box_grad_palette.copy()\n",
    "for i in range(len(swarm_grad_palette)):\n",
    "    #fading it to white\n",
    "    #adding to red to make it paler\n",
    "    swarm_grad_palette[i][0] = swarm_grad_palette[i][0]+0.3 if swarm_grad_palette[i][0]+0.3<1 else 1\n",
    "    #adding to green to make it paler\n",
    "    swarm_grad_palette[i][1] = swarm_grad_palette[i][1]+0.3 if swarm_grad_palette[i][1]+0.3<1 else 1\n",
    "    #adding to blue to make it paler\n",
    "    if colourBlindFriendly:\n",
    "        swarm_grad_palette[i][2] = swarm_grad_palette[i][2]+0.3 if swarm_grad_palette[i][2]+0.3<1 else 1\n",
    "\n",
    "\n",
    "sns.swarmplot(data=list(data_columns), size=7, edgecolor=\"black\", linewidth=.6, palette=swarm_grad_palette)\n",
    "\n",
    "plt.xticks(plt.xticks()[0], labels)\n",
    "\n",
    "plt.title(\"Box and Swarm plots of MAEs for the different columns\", fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f\"..\\\\Results\\\\Genetic Algorithm\\\\Plots\\\\p{population_size}_g{number_of_generations}_BoxSwarm_MAEs_GRAD_STD.png\")\n",
    "plt.close(fig)\n",
    "del fig\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Effects Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7890e0fa52974d8f89d9444fcd9ef04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.036036</td>\n",
       "      <td>1.705847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate       MAE\n",
       "5       0.036036  1.705847"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.036036])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>785.0</td>\n",
       "      <td>1.851919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_leaves       MAE\n",
       "33       785.0  1.851919"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.036036]), array([785.])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.780444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth       MAE\n",
       "8       13.0  1.780444"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.036036]), array([785.]), array([13.])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.98</td>\n",
       "      <td>1.878798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bagging_fraction       MAE\n",
       "35              0.98  1.878798"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.036036]), array([785.]), array([13.]), array([0.98])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bagging_freq</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.852816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bagging_freq       MAE\n",
       "10          16.0  1.852816"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.036036]), array([785.]), array([13.]), array([0.98]), array([16.])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.8556</td>\n",
       "      <td>1.778701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_fraction       MAE\n",
       "19            0.8556  1.778701"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.036036]), array([785.]), array([13.]), array([0.98]), array([16.]), array([0.8556])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda_l1</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.876853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lambda_l1       MAE\n",
       "10       15.0  1.876853"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.036036]), array([785.]), array([13.]), array([0.98]), array([16.]), array([0.8556]), array([15.])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda_l2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.90747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lambda_l2      MAE\n",
       "10       15.0  1.90747"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.036036]), array([785.]), array([13.]), array([0.98]), array([16.]), array([0.8556]), array([15.]), array([15.])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#array of the hyperparameters we tuned\n",
    "arr_hypers = [\"learning_rate\",\"num_leaves\",\"max_depth\",\"bagging_fraction\",\"bagging_freq\",\"feature_fraction\",\"lambda_l1\",\"lambda_l2\"]\n",
    "arr_best_hypers = []\n",
    "#iterate through each of these hypers\n",
    "for hyper in tqdm(arr_hypers):\n",
    "\n",
    "    df_max_depth = pd.DataFrame(columns = [hyper,\"MAE\"])\n",
    "\n",
    "    #iterating through each column and randomly decide whether or not to pick it\n",
    "    #iterating through every single models results\n",
    "    for i in range(len(all_results)):\n",
    "        # adding this models mae to the dict entry for this column\n",
    "        df_max_depth.loc[i] = [all_results[i][1][1][hyper],all_results[i][0][1]]\n",
    "\n",
    "    #sort in ascending order by the params values\n",
    "    df_all = df_max_depth.sort_values(by=[hyper])\n",
    "    # display(df_all)\n",
    "\n",
    "    #grouping together by value and calculating mean\n",
    "    grouped_df = df_all.groupby(hyper)\n",
    "    mean_df = grouped_df.mean().reset_index()\n",
    "    #display(mean_df)\n",
    "    \n",
    "    # the minimum point\n",
    "    df_min = mean_df[mean_df['MAE']==mean_df['MAE'].min()]\n",
    "    arr_best_hypers.append(df_min[hyper].values)\n",
    "    display(df_min)\n",
    "\n",
    "    #plotting the stats for this param \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    print(arr_best_hypers)\n",
    "    \n",
    "    plt.scatter(df_min[hyper], df_min.MAE, label=\"Minimum Average MAE\", color=\"lime\", marker=\"o\",s=200)\n",
    "    plt.plot(mean_df[hyper], mean_df.MAE, label=\"Line of mean MAEs\", color=\"black\") # line of means\n",
    "    plt.scatter(df_all[hyper], df_all.MAE, label=\"Scatter of MAE values\", color=\"darkorange\", marker=\"x\") # scatter of values\n",
    "    plt.plot(np.unique(df_all[hyper]), \n",
    "             np.poly1d(np.polyfit(df_all[hyper], df_all.MAE, 3))\n",
    "             (np.unique(df_all[hyper])), label=\"3rd Degr Regressor Line\", color=\"mediumorchid\") # line of best fit from a simple regressor\n",
    "\n",
    "    plt.title(f\"MAEs for {hyper} values\", fontsize=15)\n",
    "    plt.xlabel(f\"{hyper} values\", fontsize=13)\n",
    "    plt.ylabel(\"MAE\", fontsize=13)\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(f\"..\\\\Results\\\\Genetic Algorithm\\\\Plots\\\\p{population_size}_g{number_of_generations}_scatter_{hyper}.png\")\n",
    "    plt.close(fig)\n",
    "    del fig\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspecting stats on all models TOE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[92m\u001b[4mmin time of execution = \u001b[0m0:00:13\n",
      "\u001b[1m\u001b[92m\u001b[4mmax time of execution = \u001b[0m0:47:46\n",
      "\u001b[1m\u001b[92m\u001b[4mmean time of execution = \u001b[0m0:13:50\n",
      "\n",
      "\u001b[1m\u001b[92m\u001b[4mmin MAE = \u001b[0m1.6499669073999559\n",
      "\u001b[1m\u001b[92m\u001b[4mmax MAE= \u001b[0m5.030368885382504\n",
      "\u001b[1m\u001b[92m\u001b[4mmean MAE = \u001b[0m2.1081562421565576\n"
     ]
    }
   ],
   "source": [
    "#inspecting the min/max/mean of time of execution of the models we tested in genetic algorithm\n",
    "all_toes = []\n",
    "all_maes = [] \n",
    "\n",
    "for i in range(len(all_results)):\n",
    "    #getting the results for this model\n",
    "    all_toes.append(all_results[i][0][0])\n",
    "    all_maes.append(all_results[i][0][1])\n",
    "    \n",
    "print()\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}min time of execution = {color.END}{str(datetime.timedelta(seconds=round(min(all_toes))))}\")\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}max time of execution = {color.END}{str(datetime.timedelta(seconds=round(max(all_toes))))}\")\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}mean time of execution = {color.END}{str(datetime.timedelta(seconds=round(np.mean(all_toes))))}\")\n",
    "print()\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}min MAE = {color.END}{min(all_maes)}\")\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}max MAE= {color.END}{max(all_maes)}\")\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}mean MAE = {color.END}{np.mean(all_maes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the results of the hyper parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:34:23\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7200211653369024\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:09:07\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8395147313183635\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:33:23\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8528158532482133\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:17\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 4.774471085650912\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:29:03\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.708020699329726\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:50\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 4.6101094036487185\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:29:23\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9496601500258213\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:33:13\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8742425571983397\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:30:39\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8494370166675087\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:20:22\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.005634352859496\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:32:56\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9736438493472512\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:07:28\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9406964802003837\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:47:46\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.917893764680132\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:23\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 3.293971105463281\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:23:35\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.834002860539185\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:17:46\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9652330215637503\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 16 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:20:05\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.893988147990083\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 17 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.999730066914801\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 18 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:20:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.1885349172966535\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 19 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:38\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9536564120649138\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:34:52\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7200211653369024\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:23:27\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8340055581875205\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:09:09\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8395147313183635\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:30:33\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8494370166675087\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:13:23\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.0248813347875436\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:16:25\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.898033312678312\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:04\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.104849433304229\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:20:14\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8866462372231927\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:50\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6445794672826373\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8661813043995343\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:15:24\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9471872672736952\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:35:26\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7236834967734167\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:20:55\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8300527033905172\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:34:00\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.847118343951068\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:04:02\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.619180928360862\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:18\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.658571069324941\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 16 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9418707150121852\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 17 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:25:20\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9401923219088741\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 18 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:47\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.9299025946674924\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 19 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:35:03\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.677165409201709\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:35:32\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.677165409201709\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:34:24\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7198903229917002\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:35:58\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7236834967726207\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:20:42\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8300527033903842\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:33\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8723081975033966\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:23:39\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.0127151789838558\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:17:41\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.0699777203120004\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:12:56\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.0140758178788043\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:43\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9244468964554955\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:42\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9277176824196123\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:34\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 4.873651907302197\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:08:26\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.745226057055279\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:10:56\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.64948228863537\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:49\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.8570423658530015\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:28\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.921523856892312\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:35\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 4.6019911601867625\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 16 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:18:15\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.0289425970202046\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 17 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:28\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 4.873500437973866\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 18 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:34\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 5.030368885382504\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 19 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:08\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.922468761566084\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:34:51\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.677165409201709\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:34:38\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7200211653369024\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:35:17\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7236834967734167\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:08:26\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.745226057055279\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:19:59\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.966936580701071\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:29:43\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.693721270694547\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:18:26\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6568275706156865\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:24\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9155026937659592\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:24:34\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6546426508778276\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:30:47\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9637656291816263\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:27:04\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.949922171351018\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:28\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9169015152445616\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:14:47\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9226173864730285\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:57\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9450753633743554\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:14:30\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.098338744687076\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:20\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6250344456435095\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 16 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:10\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.2101187469673085\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 17 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:07:15\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9249095127468774\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 18 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:09\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.640027801656368\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 19 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:08:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8138063684061345\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:18:43\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6568275706156865\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:37:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.677165409201709\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:28:42\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.693912201838719\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:34:36\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7200211653369024\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:52\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8654459592243697\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:27:21\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6861707764164902\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:49\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.9245604338153544\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:10:09\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9549856956463338\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:21:39\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.013211380035837\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:51\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.927745042494237\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:20:13\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6508362622558788\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:38\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8239321892436866\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:31\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.322870904197177\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:44\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.869671239672361\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:34:20\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7132229475178269\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:10\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6499669073999559\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 16 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:56\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.86553200539931\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 17 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:55\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8727766851281609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 18 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:08:14\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.81469389678143\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 19 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:06\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9035126511037403\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:05\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6499669073999559\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:18:28\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6568275706156865\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:34:57\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6771822068192994\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:27:27\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6861707764164902\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:49\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8519188452612543\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:40\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.8479727268006303\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:17:43\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.933138693765415\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:19\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8679014574137183\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:06:58\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9082592894789925\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:17:23\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6130488390644784\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:04:49\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8657047998722511\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:42\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.655398317580561\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:15:52\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8949551943969734\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:04:47\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.609912755986899\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:22\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.625672805169612\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:17\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 4.64328229755546\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 16 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:19\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8688558841482183\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 17 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:08:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6455038308806693\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 18 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:21\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8693815480063591\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 19 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:30:34\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.693053778465517\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:11\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6499669073999559\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:18:20\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6568275706156865\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:35:16\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.677165409201709\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:27:23\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6861707764164902\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:43\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 3.2769749340264833\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:26:23\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.895160553135453\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:27\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8746810119242763\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:30\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.9001126414074165\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:04:54\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8693510736931596\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:04:16\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.864226853297532\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:05\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8750306810723605\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:55\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8669202272801881\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:24:35\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6884111208642016\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:35:24\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.695702737928547\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:27:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6863918147625179\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:24\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9601050705097485\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 16 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:54\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8847399094458592\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 17 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:58\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.621908337353639\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 18 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:46\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.8806421053448767\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 19 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:06:18\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.871009436157233\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:05\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6499669073999559\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:18:21\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6568275706156865\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:35:38\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6771822068192994\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:26:49\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6861707764164902\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:06:58\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9076089606440605\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:21:39\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6572667138822392\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:25:42\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6584059692666362\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:08:29\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8988082360307734\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:10:02\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9086809659970094\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:04:09\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9162698909037168\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:07:32\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8946900797481376\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:01\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9262190370936145\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:40:20\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8267961680524367\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:08\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.828289937466887\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:13\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 4.899356697183551\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:06\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9106254712983182\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 16 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:06:31\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9251592210222677\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 17 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:07\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.630761243096929\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 18 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:35\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6501338917650936\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 19 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:28:05\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.91072749332625\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:11\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6499669073999559\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:18:24\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6568275706156865\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:00\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6572667138823343\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:26:43\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.657674939589575\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:28:04\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7223750686139647\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:11:56\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7521448799185375\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:07:32\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7619577397736381\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:08:09\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9024391988055598\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:44\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.9018964887981813\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:56\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8336505003316914\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:17\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9054966262552533\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:24:47\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6504470888670446\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:07:05\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9428739872430763\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:38\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8689923276776086\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:04:33\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8703870409215304\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:31\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8695581261853713\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 16 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:44\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8696518063346408\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 17 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:21\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6556983285937616\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 18 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:16:45\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9094645736870186\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 8 individual 19 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:09:20\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7956144085750971\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:26\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6499669073999559\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:24:33\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.650447080818474\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:23\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6556983285937616\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:18:31\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6568275706156865\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:11\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.905419202776597\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:20:57\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6126275225052966\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:08:07\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.905755114143914\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:06:27\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7997274976238269\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:17:08\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6124604996618226\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:21:14\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6501424230874289\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:10:29\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.915031652356501\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 11 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:13:24\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.918261605407196\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:04:04\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9047807533370826\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:05\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8699732389278105\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:29:43\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9428586496918872\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:54\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8302953307885323\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 16 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:37\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.900179384208627\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 17 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:19:34\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6126131060821782\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 18 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:20\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8650706832079638\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 9 individual 19 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:06:02\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8831973927046874\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:20\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6499669073999559\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:20:52\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6501424230873631\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:24:09\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6504470808183798\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:11\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6556983285937616\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:17:01\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6554693415368367\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8696055235130071\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:14\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.7408111579795276\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:44\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8666438839382284\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:30:00\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7058470656011433\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:45\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8662931917027668\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:49\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.197645217696604\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:44\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8701530226032783\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:06:13\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8935543108124515\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:18:12\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.653781064309434\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:37\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.903316411045528\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:12:28\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.63769197666276\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 16 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:31\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.899612073466009\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 17 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:49\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8696055235130071\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 18 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:18:40\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.3259823355849685\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 10 individual 19 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:34\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.9273529471352746\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:22:00\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6499669073999559\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:20:35\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6501424230873603\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:24:13\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6504470808183798\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:18:08\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.653781064309481\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:06:27\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8827997986797849\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:29\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9382900237020906\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:42\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8685871780357943\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:24:24\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6504470888669498\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:35\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.652944013690211\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:17:18\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.613084079716023\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:20\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.9560238359238435\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:19:17\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.612727082514093\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:11:14\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8836603881819447\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:06:03\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.88224136497148\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:06:17\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.904497394619897\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:07:10\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7878415336502318\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 16 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:04:26\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8709926268319028\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 17 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:33\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.9001769814288\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 18 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:38\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.9285315251561332\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 11 individual 19 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:47\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.9135328377637206\n",
      "\n",
      "best model is at generation 4 individual 15 with a MAE of 1.6499669073999559\n"
     ]
    }
   ],
   "source": [
    "best_index = 0\n",
    "best_mae = 999999\n",
    "\n",
    "for i in range(len(all_results)):\n",
    "    #getting the results for this model\n",
    "    LGBM_TOE = all_results[i][0][0]\n",
    "    LGBM_MAE = all_results[i][0][1]\n",
    "    #displaying the results\n",
    "    print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}generation {int(i/population_size)} individual {i%population_size} {color.END}\")\n",
    "    print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution for skf-cv:{color.END} {str(datetime.timedelta(seconds=round(LGBM_TOE)))}\")\n",
    "    print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set:{color.END} {LGBM_MAE}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    #keeping track of the best performing model\n",
    "    if(LGBM_MAE<best_mae):\n",
    "        best_mae=LGBM_MAE\n",
    "        best_index = i\n",
    "print(\"best model is at generation\",int(best_index/population_size),\"individual\",best_index%population_size,\"with a MAE of\",best_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model based on the best models \n",
    "* Done this as no longer storing the models in memory as was running out\n",
    "* So instead just storing the configuration\n",
    "* Then this is used to retrain a model with that configuration\n",
    "    * Should fix the problem of running out of memory whilst running the GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no longer need all results only the best one\n",
    "best_results = all_results[best_index]\n",
    "del all_results\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.65862\n",
      "[6666]\tvalid_0's l1: 1.64199\n",
      "Early stopping, best iteration is:\n",
      "[6499]\tvalid_0's l1: 1.64173\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66616\n",
      "Early stopping, best iteration is:\n",
      "[5504]\tvalid_0's l1: 1.65251\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.93, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.93\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=1, subsample=1.0 will be ignored. Current value: bagging_fraction=1\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.66939\n",
      "Early stopping, best iteration is:\n",
      "[6177]\tvalid_0's l1: 1.65565\n"
     ]
    }
   ],
   "source": [
    "best_X_cols = best_results[1][0]\n",
    "best_X_cats = list(set(best_X_cols).intersection(all_cat)) #getting the categorical values for this X\n",
    "best_params = best_results[1][1]\n",
    "best_run = run_lgbm_skf_cv(False, False, SEED, num_folds, df_train.copy(), y_col, best_X_cols, best_X_cats, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions based on the best performing model and displaying it's information\n",
    "BEST_LGBM_MODELS = best_run[2] #getting the lgbm_models from the best index\n",
    "BEST_LGBM_FORECASTS = df_preds.copy()\n",
    "start_time = time.time() \n",
    "\n",
    "#calculating the average preds by summing the weighted preds for each folds model\n",
    "for i in range(len(BEST_LGBM_MODELS)):\n",
    "    pred_forecasts = BEST_LGBM_MODELS[i].predict(BEST_LGBM_FORECASTS[best_results[1][0]], num_iteration=BEST_LGBM_MODELS[i].best_iteration_) #predicting the unkown df_preds\n",
    "    BEST_LGBM_FORECASTS[y_col] += pred_forecasts / num_folds #weighting the predictions for BEST_LGBM_FORECASTS for this fold and adding to df_preds y column \n",
    "BEST_LGBM_FORECASTS[\"meter_reading\"] = BEST_LGBM_FORECASTS.meter_reading.clip(lower=0) #clip meter_reading so no predictions lower than 0\n",
    "execution_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting information on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mbest model came from generation 4 individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mEvaluation and results\u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:  \u001b[0m0:22:10\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for predictions: \u001b[0m0:52:27\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mTotal time of execution: \u001b[0m1:14:36\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6499669073999559\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mpreds set with the next years forecasts for each meter\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>date</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5.483787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>5.600278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>5.522255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>5.492496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>5.443891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185515</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>17.827099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185516</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>20.842867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185517</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>19.131323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185518</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>18.138269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185519</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>16.850715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185520 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           meter_id       date  meter_reading\n",
       "0        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7 2018-01-01       5.483787\n",
       "1        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7 2018-01-02       5.600278\n",
       "2        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7 2018-01-03       5.522255\n",
       "3        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7 2018-01-04       5.492496\n",
       "4        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7 2018-01-05       5.443891\n",
       "...                                             ...        ...            ...\n",
       "1185515  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd 2018-12-27      17.827099\n",
       "1185516  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd 2018-12-28      20.842867\n",
       "1185517  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd 2018-12-29      19.131323\n",
       "1185518  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd 2018-12-30      18.138269\n",
       "1185519  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd 2018-12-31      16.850715\n",
       "\n",
       "[1185520 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mHyper-parameters\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mX_cols:\u001b[0m\n",
      "\n",
      "['meter_id_ord',\n",
      " 'day_of_year_sin',\n",
      " 'day_of_year_cos',\n",
      " 'month_ord',\n",
      " 'is_weekend',\n",
      " 'energy_cluster',\n",
      " 'num_bedrooms']\n",
      "\u001b[1m\u001b[96m\u001b[4mmodel params:  \u001b[0m\n",
      "{'bagging_fraction': 1,\n",
      " 'bagging_freq': 10,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.93,\n",
      " 'lambda_l1': 14,\n",
      " 'lambda_l2': 8,\n",
      " 'learning_rate': 0.046799999999999994,\n",
      " 'max_depth': 11,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 695,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n"
     ]
    }
   ],
   "source": [
    "#printing the forecasts and other evaluation info\n",
    "print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}best model came from generation {int(best_index/population_size)} individual {best_index%population_size}{color.END}\")\n",
    "#displaying the results\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Evaluation and results{color.END}\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution for skf-cv:  {color.END}{str(datetime.timedelta(seconds=round(best_results[0][0])))}\\n\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution for predictions: {color.END}{str(datetime.timedelta(seconds=round(execution_time)))}\\n\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Total time of execution: {color.END}{str(datetime.timedelta(seconds=round(best_results[0][0]+execution_time)))}\\n\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set:{color.END} {best_results[0][1]}\\n\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}preds set with the next years forecasts for each meter{color.END}\")\n",
    "display(BEST_LGBM_FORECASTS[[\"meter_id\",\"date\",\"meter_reading\"]])\n",
    "#displaying the hyperparameters\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Hyper-parameters{color.END}\")\n",
    "print(f\"\\n{color.BOLD}{color.CYAN}{color.UNDERLINE}X_cols:{color.END}\\n\")\n",
    "pprint(best_results[1][0])\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}model params:  {color.END}\")\n",
    "pprint(best_results[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the description of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_LGBM_FORECASTS.to_pickle(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_best_model_daily_forecasts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE': 1.6499669073999559,\n",
      " 'features': ['meter_id_ord',\n",
      "              'day_of_year_sin',\n",
      "              'day_of_year_cos',\n",
      "              'month_ord',\n",
      "              'is_weekend',\n",
      "              'energy_cluster',\n",
      "              'num_bedrooms'],\n",
      " 'params': {'bagging_fraction': 1,\n",
      "            'bagging_freq': 10,\n",
      "            'boosting_type': 'gbdt',\n",
      "            'feature_fraction': 0.93,\n",
      "            'lambda_l1': 14,\n",
      "            'lambda_l2': 8,\n",
      "            'learning_rate': 0.046799999999999994,\n",
      "            'max_depth': 11,\n",
      "            'metric': 'mae',\n",
      "            'num_iterations': 10000,\n",
      "            'num_leaves': 695,\n",
      "            'num_threads': -1,\n",
      "            'seed': 1337},\n",
      " 'time_of_execution_preds': '0:52:27',\n",
      " 'time_of_execution_skf-cv': '0:22:10',\n",
      " 'time_of_execution_total': '1:14:36'}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "desc_disc = {\n",
    "    \"time_of_execution_skf-cv\":str(datetime.timedelta(seconds=round(best_results[0][0]))),\n",
    "    \"time_of_execution_preds\":str(datetime.timedelta(seconds=round(execution_time))),\n",
    "    \"time_of_execution_total\":str(datetime.timedelta(seconds=round(best_results[0][0]+execution_time))),\n",
    "    \"MAE\":best_results[0][1],\n",
    "    \"features\":best_results[1][0],\n",
    "    \"params\":best_results[1][1]\n",
    "}\n",
    "\n",
    "with open(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_best_model_desc.pkl\", 'wb') as handle:\n",
    "    pickle.dump(desc_disc, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "pprint(desc_disc)\n",
    "    \n",
    "# verifying it saved correctly and can be loaded back\n",
    "with open(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_best_model_desc.pkl\", 'rb') as handle:\n",
    "    desc_disc_loaded = pickle.load(handle)\n",
    "print(desc_disc == desc_disc_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting into monthly forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>130.434412</td>\n",
       "      <td>126.541093</td>\n",
       "      <td>125.121806</td>\n",
       "      <td>123.591578</td>\n",
       "      <td>135.249048</td>\n",
       "      <td>125.916794</td>\n",
       "      <td>129.188633</td>\n",
       "      <td>129.599268</td>\n",
       "      <td>129.503983</td>\n",
       "      <td>134.588367</td>\n",
       "      <td>76.437996</td>\n",
       "      <td>109.657461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>749.395472</td>\n",
       "      <td>726.084622</td>\n",
       "      <td>626.621292</td>\n",
       "      <td>448.234747</td>\n",
       "      <td>433.530684</td>\n",
       "      <td>385.508423</td>\n",
       "      <td>389.930913</td>\n",
       "      <td>398.597950</td>\n",
       "      <td>421.259680</td>\n",
       "      <td>531.666622</td>\n",
       "      <td>598.329654</td>\n",
       "      <td>650.166880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>228.719887</td>\n",
       "      <td>206.057362</td>\n",
       "      <td>208.016235</td>\n",
       "      <td>199.298978</td>\n",
       "      <td>205.328054</td>\n",
       "      <td>195.976054</td>\n",
       "      <td>205.946318</td>\n",
       "      <td>206.659702</td>\n",
       "      <td>199.389214</td>\n",
       "      <td>204.060606</td>\n",
       "      <td>199.001221</td>\n",
       "      <td>241.526700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>166.811517</td>\n",
       "      <td>147.260071</td>\n",
       "      <td>150.326960</td>\n",
       "      <td>141.307440</td>\n",
       "      <td>133.354207</td>\n",
       "      <td>131.046783</td>\n",
       "      <td>135.399844</td>\n",
       "      <td>130.534567</td>\n",
       "      <td>130.558063</td>\n",
       "      <td>142.153148</td>\n",
       "      <td>145.217827</td>\n",
       "      <td>158.552771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>305.602593</td>\n",
       "      <td>269.577118</td>\n",
       "      <td>270.317055</td>\n",
       "      <td>237.744606</td>\n",
       "      <td>232.373112</td>\n",
       "      <td>221.665814</td>\n",
       "      <td>229.492894</td>\n",
       "      <td>230.827122</td>\n",
       "      <td>230.094909</td>\n",
       "      <td>258.540434</td>\n",
       "      <td>279.064930</td>\n",
       "      <td>316.010312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>180.965565</td>\n",
       "      <td>152.684302</td>\n",
       "      <td>156.783968</td>\n",
       "      <td>134.193231</td>\n",
       "      <td>128.327145</td>\n",
       "      <td>132.859713</td>\n",
       "      <td>135.376392</td>\n",
       "      <td>121.289698</td>\n",
       "      <td>132.958015</td>\n",
       "      <td>146.591239</td>\n",
       "      <td>163.986609</td>\n",
       "      <td>178.972877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>687.210425</td>\n",
       "      <td>658.654396</td>\n",
       "      <td>729.729855</td>\n",
       "      <td>709.923802</td>\n",
       "      <td>613.610546</td>\n",
       "      <td>471.215289</td>\n",
       "      <td>452.039279</td>\n",
       "      <td>458.700198</td>\n",
       "      <td>499.852930</td>\n",
       "      <td>552.543010</td>\n",
       "      <td>575.905036</td>\n",
       "      <td>606.360798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>485.745576</td>\n",
       "      <td>437.609067</td>\n",
       "      <td>394.726242</td>\n",
       "      <td>364.510169</td>\n",
       "      <td>362.273555</td>\n",
       "      <td>255.811260</td>\n",
       "      <td>270.501767</td>\n",
       "      <td>274.716217</td>\n",
       "      <td>294.164445</td>\n",
       "      <td>333.287683</td>\n",
       "      <td>419.273157</td>\n",
       "      <td>522.813442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>423.777705</td>\n",
       "      <td>361.463514</td>\n",
       "      <td>343.534614</td>\n",
       "      <td>403.536814</td>\n",
       "      <td>206.946507</td>\n",
       "      <td>188.329178</td>\n",
       "      <td>182.297461</td>\n",
       "      <td>188.799935</td>\n",
       "      <td>206.879259</td>\n",
       "      <td>256.681954</td>\n",
       "      <td>327.283670</td>\n",
       "      <td>402.867806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>269.829511</td>\n",
       "      <td>216.074650</td>\n",
       "      <td>231.689394</td>\n",
       "      <td>212.351942</td>\n",
       "      <td>221.794081</td>\n",
       "      <td>205.807302</td>\n",
       "      <td>216.345218</td>\n",
       "      <td>218.840938</td>\n",
       "      <td>236.995349</td>\n",
       "      <td>252.376238</td>\n",
       "      <td>252.945855</td>\n",
       "      <td>254.310126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id         Jan         Feb  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c  130.434412  126.541093   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82  749.395472  726.084622   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734  228.719887  206.057362   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a  166.811517  147.260071   \n",
       "4     0x005958406351bb29580475df698b5f1070096397  305.602593  269.577118   \n",
       "...                                          ...         ...         ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f  180.965565  152.684302   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb  687.210425  658.654396   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5  485.745576  437.609067   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02  423.777705  361.463514   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4  269.829511  216.074650   \n",
       "\n",
       "             Mar         Apr         May         Jun         Jul         Aug  \\\n",
       "0     125.121806  123.591578  135.249048  125.916794  129.188633  129.599268   \n",
       "1     626.621292  448.234747  433.530684  385.508423  389.930913  398.597950   \n",
       "2     208.016235  199.298978  205.328054  195.976054  205.946318  206.659702   \n",
       "3     150.326960  141.307440  133.354207  131.046783  135.399844  130.534567   \n",
       "4     270.317055  237.744606  232.373112  221.665814  229.492894  230.827122   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3243  156.783968  134.193231  128.327145  132.859713  135.376392  121.289698   \n",
       "3244  729.729855  709.923802  613.610546  471.215289  452.039279  458.700198   \n",
       "3245  394.726242  364.510169  362.273555  255.811260  270.501767  274.716217   \n",
       "3246  343.534614  403.536814  206.946507  188.329178  182.297461  188.799935   \n",
       "3247  231.689394  212.351942  221.794081  205.807302  216.345218  218.840938   \n",
       "\n",
       "             Sep         Oct         Nov         Dec  \n",
       "0     129.503983  134.588367   76.437996  109.657461  \n",
       "1     421.259680  531.666622  598.329654  650.166880  \n",
       "2     199.389214  204.060606  199.001221  241.526700  \n",
       "3     130.558063  142.153148  145.217827  158.552771  \n",
       "4     230.094909  258.540434  279.064930  316.010312  \n",
       "...          ...         ...         ...         ...  \n",
       "3243  132.958015  146.591239  163.986609  178.972877  \n",
       "3244  499.852930  552.543010  575.905036  606.360798  \n",
       "3245  294.164445  333.287683  419.273157  522.813442  \n",
       "3246  206.879259  256.681954  327.283670  402.867806  \n",
       "3247  236.995349  252.376238  252.945855  254.310126  \n",
       "\n",
       "[3248 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#restructuring into the original multiple time series format\n",
    "#aggregating up the total sum of the months predictions\n",
    "df_monthly_forecasts = BEST_LGBM_FORECASTS.groupby([\"meter_id\", \"month_ord\"])[\"meter_reading\"].sum().unstack()\n",
    "\n",
    "#rename ordinal encoded month with its corresponding name\n",
    "df_monthly_forecasts.rename(columns={1:\"Jan\", 2:\"Feb\",3:\"Mar\",4:\"Apr\",5:\"May\",6:\"Jun\",7:\"Jul\",8:\"Aug\",9:\"Sep\",10:\"Oct\",11:\"Nov\",12:\"Dec\"}, inplace=True)\n",
    "#resetting the index \n",
    "df_monthly_forecasts.reset_index(inplace=True)\n",
    "df_monthly_forecasts.index.name = None # removing index column\n",
    "df_monthly_forecasts.columns.name = None # removing columns name\n",
    "\n",
    "display(df_monthly_forecasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving these monthly predictions to be submitted to competition\n",
    "* Saving predictions ready to be submitted so I can get the MAE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_forecasts.to_csv(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_best_model_monthly_forecasts.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting these monthly forecasts\n",
    "## Renaming months to dates for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "      <th>2018-05</th>\n",
       "      <th>2018-06</th>\n",
       "      <th>2018-07</th>\n",
       "      <th>2018-08</th>\n",
       "      <th>2018-09</th>\n",
       "      <th>2018-10</th>\n",
       "      <th>2018-11</th>\n",
       "      <th>2018-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>130.434412</td>\n",
       "      <td>126.541093</td>\n",
       "      <td>125.121806</td>\n",
       "      <td>123.591578</td>\n",
       "      <td>135.249048</td>\n",
       "      <td>125.916794</td>\n",
       "      <td>129.188633</td>\n",
       "      <td>129.599268</td>\n",
       "      <td>129.503983</td>\n",
       "      <td>134.588367</td>\n",
       "      <td>76.437996</td>\n",
       "      <td>109.657461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>749.395472</td>\n",
       "      <td>726.084622</td>\n",
       "      <td>626.621292</td>\n",
       "      <td>448.234747</td>\n",
       "      <td>433.530684</td>\n",
       "      <td>385.508423</td>\n",
       "      <td>389.930913</td>\n",
       "      <td>398.597950</td>\n",
       "      <td>421.259680</td>\n",
       "      <td>531.666622</td>\n",
       "      <td>598.329654</td>\n",
       "      <td>650.166880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>228.719887</td>\n",
       "      <td>206.057362</td>\n",
       "      <td>208.016235</td>\n",
       "      <td>199.298978</td>\n",
       "      <td>205.328054</td>\n",
       "      <td>195.976054</td>\n",
       "      <td>205.946318</td>\n",
       "      <td>206.659702</td>\n",
       "      <td>199.389214</td>\n",
       "      <td>204.060606</td>\n",
       "      <td>199.001221</td>\n",
       "      <td>241.526700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>166.811517</td>\n",
       "      <td>147.260071</td>\n",
       "      <td>150.326960</td>\n",
       "      <td>141.307440</td>\n",
       "      <td>133.354207</td>\n",
       "      <td>131.046783</td>\n",
       "      <td>135.399844</td>\n",
       "      <td>130.534567</td>\n",
       "      <td>130.558063</td>\n",
       "      <td>142.153148</td>\n",
       "      <td>145.217827</td>\n",
       "      <td>158.552771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>305.602593</td>\n",
       "      <td>269.577118</td>\n",
       "      <td>270.317055</td>\n",
       "      <td>237.744606</td>\n",
       "      <td>232.373112</td>\n",
       "      <td>221.665814</td>\n",
       "      <td>229.492894</td>\n",
       "      <td>230.827122</td>\n",
       "      <td>230.094909</td>\n",
       "      <td>258.540434</td>\n",
       "      <td>279.064930</td>\n",
       "      <td>316.010312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>180.965565</td>\n",
       "      <td>152.684302</td>\n",
       "      <td>156.783968</td>\n",
       "      <td>134.193231</td>\n",
       "      <td>128.327145</td>\n",
       "      <td>132.859713</td>\n",
       "      <td>135.376392</td>\n",
       "      <td>121.289698</td>\n",
       "      <td>132.958015</td>\n",
       "      <td>146.591239</td>\n",
       "      <td>163.986609</td>\n",
       "      <td>178.972877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>687.210425</td>\n",
       "      <td>658.654396</td>\n",
       "      <td>729.729855</td>\n",
       "      <td>709.923802</td>\n",
       "      <td>613.610546</td>\n",
       "      <td>471.215289</td>\n",
       "      <td>452.039279</td>\n",
       "      <td>458.700198</td>\n",
       "      <td>499.852930</td>\n",
       "      <td>552.543010</td>\n",
       "      <td>575.905036</td>\n",
       "      <td>606.360798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>485.745576</td>\n",
       "      <td>437.609067</td>\n",
       "      <td>394.726242</td>\n",
       "      <td>364.510169</td>\n",
       "      <td>362.273555</td>\n",
       "      <td>255.811260</td>\n",
       "      <td>270.501767</td>\n",
       "      <td>274.716217</td>\n",
       "      <td>294.164445</td>\n",
       "      <td>333.287683</td>\n",
       "      <td>419.273157</td>\n",
       "      <td>522.813442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>423.777705</td>\n",
       "      <td>361.463514</td>\n",
       "      <td>343.534614</td>\n",
       "      <td>403.536814</td>\n",
       "      <td>206.946507</td>\n",
       "      <td>188.329178</td>\n",
       "      <td>182.297461</td>\n",
       "      <td>188.799935</td>\n",
       "      <td>206.879259</td>\n",
       "      <td>256.681954</td>\n",
       "      <td>327.283670</td>\n",
       "      <td>402.867806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>269.829511</td>\n",
       "      <td>216.074650</td>\n",
       "      <td>231.689394</td>\n",
       "      <td>212.351942</td>\n",
       "      <td>221.794081</td>\n",
       "      <td>205.807302</td>\n",
       "      <td>216.345218</td>\n",
       "      <td>218.840938</td>\n",
       "      <td>236.995349</td>\n",
       "      <td>252.376238</td>\n",
       "      <td>252.945855</td>\n",
       "      <td>254.310126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id     2018-01     2018-02  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c  130.434412  126.541093   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82  749.395472  726.084622   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734  228.719887  206.057362   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a  166.811517  147.260071   \n",
       "4     0x005958406351bb29580475df698b5f1070096397  305.602593  269.577118   \n",
       "...                                          ...         ...         ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f  180.965565  152.684302   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb  687.210425  658.654396   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5  485.745576  437.609067   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02  423.777705  361.463514   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4  269.829511  216.074650   \n",
       "\n",
       "         2018-03     2018-04     2018-05     2018-06     2018-07     2018-08  \\\n",
       "0     125.121806  123.591578  135.249048  125.916794  129.188633  129.599268   \n",
       "1     626.621292  448.234747  433.530684  385.508423  389.930913  398.597950   \n",
       "2     208.016235  199.298978  205.328054  195.976054  205.946318  206.659702   \n",
       "3     150.326960  141.307440  133.354207  131.046783  135.399844  130.534567   \n",
       "4     270.317055  237.744606  232.373112  221.665814  229.492894  230.827122   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3243  156.783968  134.193231  128.327145  132.859713  135.376392  121.289698   \n",
       "3244  729.729855  709.923802  613.610546  471.215289  452.039279  458.700198   \n",
       "3245  394.726242  364.510169  362.273555  255.811260  270.501767  274.716217   \n",
       "3246  343.534614  403.536814  206.946507  188.329178  182.297461  188.799935   \n",
       "3247  231.689394  212.351942  221.794081  205.807302  216.345218  218.840938   \n",
       "\n",
       "         2018-09     2018-10     2018-11     2018-12  \n",
       "0     129.503983  134.588367   76.437996  109.657461  \n",
       "1     421.259680  531.666622  598.329654  650.166880  \n",
       "2     199.389214  204.060606  199.001221  241.526700  \n",
       "3     130.558063  142.153148  145.217827  158.552771  \n",
       "4     230.094909  258.540434  279.064930  316.010312  \n",
       "...          ...         ...         ...         ...  \n",
       "3243  132.958015  146.591239  163.986609  178.972877  \n",
       "3244  499.852930  552.543010  575.905036  606.360798  \n",
       "3245  294.164445  333.287683  419.273157  522.813442  \n",
       "3246  206.879259  256.681954  327.283670  402.867806  \n",
       "3247  236.995349  252.376238  252.945855  254.310126  \n",
       "\n",
       "[3248 rows x 13 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_monthly_forecasts.rename(columns={\"Jan\":\"2018-01\", \"Feb\":\"2018-02\",\"Mar\":\"2018-03\",\"Apr\":\"2018-04\",\"May\":\"2018-05\",\"Jun\":\"2018-06\",\"Jul\":\"2018-07\",\"Aug\":\"2018-08\",\"Sep\":\"2018-09\",\"Oct\":\"2018-10\",\"Nov\":\"2018-11\",\"Dec\":\"2018-12\"}, inplace=True)\n",
    "df_monthly_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructuring forecasts into daily predictions to plot on top of monthly preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <th>2018-01-02 00:00:00</th>\n",
       "      <th>2018-01-03 00:00:00</th>\n",
       "      <th>2018-01-04 00:00:00</th>\n",
       "      <th>2018-01-05 00:00:00</th>\n",
       "      <th>2018-01-06 00:00:00</th>\n",
       "      <th>2018-01-07 00:00:00</th>\n",
       "      <th>2018-01-08 00:00:00</th>\n",
       "      <th>2018-01-09 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-12-22 00:00:00</th>\n",
       "      <th>2018-12-23 00:00:00</th>\n",
       "      <th>2018-12-24 00:00:00</th>\n",
       "      <th>2018-12-25 00:00:00</th>\n",
       "      <th>2018-12-26 00:00:00</th>\n",
       "      <th>2018-12-27 00:00:00</th>\n",
       "      <th>2018-12-28 00:00:00</th>\n",
       "      <th>2018-12-29 00:00:00</th>\n",
       "      <th>2018-12-30 00:00:00</th>\n",
       "      <th>2018-12-31 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>4.405209</td>\n",
       "      <td>4.734874</td>\n",
       "      <td>4.842884</td>\n",
       "      <td>4.949531</td>\n",
       "      <td>5.048475</td>\n",
       "      <td>5.207154</td>\n",
       "      <td>5.323307</td>\n",
       "      <td>5.439335</td>\n",
       "      <td>5.282851</td>\n",
       "      <td>...</td>\n",
       "      <td>5.449202</td>\n",
       "      <td>5.138456</td>\n",
       "      <td>4.814531</td>\n",
       "      <td>4.658261</td>\n",
       "      <td>4.136119</td>\n",
       "      <td>4.095768</td>\n",
       "      <td>4.008181</td>\n",
       "      <td>3.908025</td>\n",
       "      <td>3.881541</td>\n",
       "      <td>4.138007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>17.456879</td>\n",
       "      <td>18.311606</td>\n",
       "      <td>17.487827</td>\n",
       "      <td>16.554814</td>\n",
       "      <td>18.613385</td>\n",
       "      <td>20.315977</td>\n",
       "      <td>20.762857</td>\n",
       "      <td>25.759917</td>\n",
       "      <td>26.441592</td>\n",
       "      <td>...</td>\n",
       "      <td>24.129715</td>\n",
       "      <td>23.542774</td>\n",
       "      <td>22.293864</td>\n",
       "      <td>21.197164</td>\n",
       "      <td>17.012481</td>\n",
       "      <td>19.267979</td>\n",
       "      <td>20.896306</td>\n",
       "      <td>18.571856</td>\n",
       "      <td>16.798909</td>\n",
       "      <td>16.863091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>8.393179</td>\n",
       "      <td>8.403022</td>\n",
       "      <td>8.207449</td>\n",
       "      <td>7.966857</td>\n",
       "      <td>7.745199</td>\n",
       "      <td>8.213668</td>\n",
       "      <td>7.874431</td>\n",
       "      <td>7.126639</td>\n",
       "      <td>7.014257</td>\n",
       "      <td>...</td>\n",
       "      <td>7.941196</td>\n",
       "      <td>7.885483</td>\n",
       "      <td>8.025185</td>\n",
       "      <td>8.958962</td>\n",
       "      <td>8.486892</td>\n",
       "      <td>8.898983</td>\n",
       "      <td>9.207433</td>\n",
       "      <td>9.364958</td>\n",
       "      <td>8.753773</td>\n",
       "      <td>8.632668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>6.027726</td>\n",
       "      <td>5.326378</td>\n",
       "      <td>4.768001</td>\n",
       "      <td>4.577678</td>\n",
       "      <td>4.171902</td>\n",
       "      <td>4.731726</td>\n",
       "      <td>5.014541</td>\n",
       "      <td>4.302991</td>\n",
       "      <td>4.387453</td>\n",
       "      <td>...</td>\n",
       "      <td>4.104089</td>\n",
       "      <td>4.785338</td>\n",
       "      <td>3.905889</td>\n",
       "      <td>3.507822</td>\n",
       "      <td>3.532570</td>\n",
       "      <td>4.124606</td>\n",
       "      <td>4.910868</td>\n",
       "      <td>5.916148</td>\n",
       "      <td>6.178395</td>\n",
       "      <td>5.867188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>9.686349</td>\n",
       "      <td>9.521868</td>\n",
       "      <td>9.456802</td>\n",
       "      <td>9.462039</td>\n",
       "      <td>9.406794</td>\n",
       "      <td>10.080112</td>\n",
       "      <td>10.132090</td>\n",
       "      <td>9.948235</td>\n",
       "      <td>9.839072</td>\n",
       "      <td>...</td>\n",
       "      <td>10.648161</td>\n",
       "      <td>10.368608</td>\n",
       "      <td>9.993617</td>\n",
       "      <td>10.544488</td>\n",
       "      <td>10.115285</td>\n",
       "      <td>10.039212</td>\n",
       "      <td>10.126287</td>\n",
       "      <td>10.496353</td>\n",
       "      <td>10.104756</td>\n",
       "      <td>9.587263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>6.716090</td>\n",
       "      <td>6.460495</td>\n",
       "      <td>6.075110</td>\n",
       "      <td>5.787279</td>\n",
       "      <td>5.448029</td>\n",
       "      <td>6.267273</td>\n",
       "      <td>6.534463</td>\n",
       "      <td>5.916853</td>\n",
       "      <td>5.984210</td>\n",
       "      <td>...</td>\n",
       "      <td>6.736900</td>\n",
       "      <td>6.524169</td>\n",
       "      <td>5.372955</td>\n",
       "      <td>5.149643</td>\n",
       "      <td>5.147607</td>\n",
       "      <td>5.569405</td>\n",
       "      <td>6.275564</td>\n",
       "      <td>7.378559</td>\n",
       "      <td>7.282792</td>\n",
       "      <td>6.456349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>19.602782</td>\n",
       "      <td>18.732406</td>\n",
       "      <td>18.696658</td>\n",
       "      <td>18.468398</td>\n",
       "      <td>18.313520</td>\n",
       "      <td>18.186203</td>\n",
       "      <td>18.031042</td>\n",
       "      <td>21.024445</td>\n",
       "      <td>22.199804</td>\n",
       "      <td>...</td>\n",
       "      <td>17.684878</td>\n",
       "      <td>17.973519</td>\n",
       "      <td>18.208344</td>\n",
       "      <td>18.499778</td>\n",
       "      <td>18.171361</td>\n",
       "      <td>19.575200</td>\n",
       "      <td>20.793119</td>\n",
       "      <td>20.173509</td>\n",
       "      <td>20.348742</td>\n",
       "      <td>18.931508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>15.151277</td>\n",
       "      <td>14.953972</td>\n",
       "      <td>14.762257</td>\n",
       "      <td>14.674468</td>\n",
       "      <td>14.241020</td>\n",
       "      <td>13.904252</td>\n",
       "      <td>13.961137</td>\n",
       "      <td>14.503147</td>\n",
       "      <td>14.259260</td>\n",
       "      <td>...</td>\n",
       "      <td>13.767074</td>\n",
       "      <td>13.929053</td>\n",
       "      <td>14.604362</td>\n",
       "      <td>15.011350</td>\n",
       "      <td>15.097990</td>\n",
       "      <td>16.029524</td>\n",
       "      <td>17.126633</td>\n",
       "      <td>15.611609</td>\n",
       "      <td>14.552832</td>\n",
       "      <td>15.415145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>13.080290</td>\n",
       "      <td>13.469463</td>\n",
       "      <td>13.406499</td>\n",
       "      <td>13.379569</td>\n",
       "      <td>13.210309</td>\n",
       "      <td>12.676897</td>\n",
       "      <td>12.673106</td>\n",
       "      <td>13.631858</td>\n",
       "      <td>13.560682</td>\n",
       "      <td>...</td>\n",
       "      <td>12.135597</td>\n",
       "      <td>12.105221</td>\n",
       "      <td>12.727147</td>\n",
       "      <td>13.358236</td>\n",
       "      <td>13.206190</td>\n",
       "      <td>13.468193</td>\n",
       "      <td>14.116615</td>\n",
       "      <td>12.703703</td>\n",
       "      <td>11.749266</td>\n",
       "      <td>12.481751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>8.180424</td>\n",
       "      <td>8.553455</td>\n",
       "      <td>8.492707</td>\n",
       "      <td>8.520393</td>\n",
       "      <td>8.596234</td>\n",
       "      <td>8.846991</td>\n",
       "      <td>8.980675</td>\n",
       "      <td>9.178356</td>\n",
       "      <td>9.305209</td>\n",
       "      <td>...</td>\n",
       "      <td>7.848319</td>\n",
       "      <td>7.715863</td>\n",
       "      <td>7.743413</td>\n",
       "      <td>7.996891</td>\n",
       "      <td>7.489932</td>\n",
       "      <td>7.729546</td>\n",
       "      <td>8.052923</td>\n",
       "      <td>7.694621</td>\n",
       "      <td>7.381839</td>\n",
       "      <td>7.761439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id  2018-01-01 00:00:00  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c             4.405209   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82            17.456879   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734             8.393179   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a             6.027726   \n",
       "4     0x005958406351bb29580475df698b5f1070096397             9.686349   \n",
       "...                                          ...                  ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f             6.716090   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb            19.602782   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5            15.151277   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02            13.080290   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4             8.180424   \n",
       "\n",
       "      2018-01-02 00:00:00  2018-01-03 00:00:00  2018-01-04 00:00:00  \\\n",
       "0                4.734874             4.842884             4.949531   \n",
       "1               18.311606            17.487827            16.554814   \n",
       "2                8.403022             8.207449             7.966857   \n",
       "3                5.326378             4.768001             4.577678   \n",
       "4                9.521868             9.456802             9.462039   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             6.460495             6.075110             5.787279   \n",
       "3244            18.732406            18.696658            18.468398   \n",
       "3245            14.953972            14.762257            14.674468   \n",
       "3246            13.469463            13.406499            13.379569   \n",
       "3247             8.553455             8.492707             8.520393   \n",
       "\n",
       "      2018-01-05 00:00:00  2018-01-06 00:00:00  2018-01-07 00:00:00  \\\n",
       "0                5.048475             5.207154             5.323307   \n",
       "1               18.613385            20.315977            20.762857   \n",
       "2                7.745199             8.213668             7.874431   \n",
       "3                4.171902             4.731726             5.014541   \n",
       "4                9.406794            10.080112            10.132090   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             5.448029             6.267273             6.534463   \n",
       "3244            18.313520            18.186203            18.031042   \n",
       "3245            14.241020            13.904252            13.961137   \n",
       "3246            13.210309            12.676897            12.673106   \n",
       "3247             8.596234             8.846991             8.980675   \n",
       "\n",
       "      2018-01-08 00:00:00  2018-01-09 00:00:00  ...  2018-12-22 00:00:00  \\\n",
       "0                5.439335             5.282851  ...             5.449202   \n",
       "1               25.759917            26.441592  ...            24.129715   \n",
       "2                7.126639             7.014257  ...             7.941196   \n",
       "3                4.302991             4.387453  ...             4.104089   \n",
       "4                9.948235             9.839072  ...            10.648161   \n",
       "...                   ...                  ...  ...                  ...   \n",
       "3243             5.916853             5.984210  ...             6.736900   \n",
       "3244            21.024445            22.199804  ...            17.684878   \n",
       "3245            14.503147            14.259260  ...            13.767074   \n",
       "3246            13.631858            13.560682  ...            12.135597   \n",
       "3247             9.178356             9.305209  ...             7.848319   \n",
       "\n",
       "      2018-12-23 00:00:00  2018-12-24 00:00:00  2018-12-25 00:00:00  \\\n",
       "0                5.138456             4.814531             4.658261   \n",
       "1               23.542774            22.293864            21.197164   \n",
       "2                7.885483             8.025185             8.958962   \n",
       "3                4.785338             3.905889             3.507822   \n",
       "4               10.368608             9.993617            10.544488   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             6.524169             5.372955             5.149643   \n",
       "3244            17.973519            18.208344            18.499778   \n",
       "3245            13.929053            14.604362            15.011350   \n",
       "3246            12.105221            12.727147            13.358236   \n",
       "3247             7.715863             7.743413             7.996891   \n",
       "\n",
       "      2018-12-26 00:00:00  2018-12-27 00:00:00  2018-12-28 00:00:00  \\\n",
       "0                4.136119             4.095768             4.008181   \n",
       "1               17.012481            19.267979            20.896306   \n",
       "2                8.486892             8.898983             9.207433   \n",
       "3                3.532570             4.124606             4.910868   \n",
       "4               10.115285            10.039212            10.126287   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             5.147607             5.569405             6.275564   \n",
       "3244            18.171361            19.575200            20.793119   \n",
       "3245            15.097990            16.029524            17.126633   \n",
       "3246            13.206190            13.468193            14.116615   \n",
       "3247             7.489932             7.729546             8.052923   \n",
       "\n",
       "      2018-12-29 00:00:00  2018-12-30 00:00:00  2018-12-31 00:00:00  \n",
       "0                3.908025             3.881541             4.138007  \n",
       "1               18.571856            16.798909            16.863091  \n",
       "2                9.364958             8.753773             8.632668  \n",
       "3                5.916148             6.178395             5.867188  \n",
       "4               10.496353            10.104756             9.587263  \n",
       "...                   ...                  ...                  ...  \n",
       "3243             7.378559             7.282792             6.456349  \n",
       "3244            20.173509            20.348742            18.931508  \n",
       "3245            15.611609            14.552832            15.415145  \n",
       "3246            12.703703            11.749266            12.481751  \n",
       "3247             7.694621             7.381839             7.761439  \n",
       "\n",
       "[3248 rows x 366 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#daily forecasts to plot on top of monthly\n",
    "df_daily_forecasts = BEST_LGBM_FORECASTS.groupby([\"meter_id\",\"date\"])[\"meter_reading\"].sum().unstack()\n",
    "\n",
    "#resetting the index \n",
    "df_daily_forecasts.reset_index(inplace=True)\n",
    "df_daily_forecasts.index.name = None # removing index column\n",
    "df_daily_forecasts.columns.name = None # removing columns name\n",
    "\n",
    "df_daily_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading training data and aggregating into months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e56cf1380af42aea6c602997f7faebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2017-01-02</th>\n",
       "      <th>2017-01-03</th>\n",
       "      <th>2017-01-04</th>\n",
       "      <th>2017-01-05</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017-01-07</th>\n",
       "      <th>2017-01-08</th>\n",
       "      <th>2017-01-09</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-12-22</th>\n",
       "      <th>2017-12-23</th>\n",
       "      <th>2017-12-24</th>\n",
       "      <th>2017-12-25</th>\n",
       "      <th>2017-12-26</th>\n",
       "      <th>2017-12-27</th>\n",
       "      <th>2017-12-28</th>\n",
       "      <th>2017-12-29</th>\n",
       "      <th>2017-12-30</th>\n",
       "      <th>2017-12-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.030</td>\n",
       "      <td>5.397</td>\n",
       "      <td>5.1075</td>\n",
       "      <td>4.818</td>\n",
       "      <td>3.931</td>\n",
       "      <td>4.2170</td>\n",
       "      <td>4.503</td>\n",
       "      <td>4.8160</td>\n",
       "      <td>5.129</td>\n",
       "      <td>5.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x459c834d1f6cfb5b734b82aa9f5410fa97fb70da</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.101</td>\n",
       "      <td>14.327</td>\n",
       "      <td>14.6315</td>\n",
       "      <td>14.936</td>\n",
       "      <td>16.174</td>\n",
       "      <td>20.3960</td>\n",
       "      <td>24.618</td>\n",
       "      <td>19.8925</td>\n",
       "      <td>15.167</td>\n",
       "      <td>11.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x4a1ed36825360a058cec2bdd409fc2459e1ce54f</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.201</td>\n",
       "      <td>7.320</td>\n",
       "      <td>7.3520</td>\n",
       "      <td>7.384</td>\n",
       "      <td>14.425</td>\n",
       "      <td>16.0650</td>\n",
       "      <td>17.705</td>\n",
       "      <td>13.3355</td>\n",
       "      <td>8.966</td>\n",
       "      <td>4.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x5b76d3c0e0aefc6e0a8d1d031f96388a23263407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.833</td>\n",
       "      <td>12.477</td>\n",
       "      <td>11.7255</td>\n",
       "      <td>10.974</td>\n",
       "      <td>19.646</td>\n",
       "      <td>21.8195</td>\n",
       "      <td>23.993</td>\n",
       "      <td>19.9170</td>\n",
       "      <td>15.841</td>\n",
       "      <td>14.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x943ebe39ef2be6ef807c42c5a647e27112ca5b0f</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>39.440</td>\n",
       "      <td>35.538</td>\n",
       "      <td>21.9445</td>\n",
       "      <td>8.351</td>\n",
       "      <td>9.957</td>\n",
       "      <td>17.9140</td>\n",
       "      <td>25.871</td>\n",
       "      <td>36.0725</td>\n",
       "      <td>46.274</td>\n",
       "      <td>16.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0x7dd7a7b8ee1bec7c44b24f738c752482f6161065</td>\n",
       "      <td>2.317</td>\n",
       "      <td>2.301</td>\n",
       "      <td>2.352</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.229</td>\n",
       "      <td>2.354</td>\n",
       "      <td>2.397</td>\n",
       "      <td>2.397</td>\n",
       "      <td>2.269</td>\n",
       "      <td>...</td>\n",
       "      <td>9.390</td>\n",
       "      <td>9.231</td>\n",
       "      <td>9.2235</td>\n",
       "      <td>9.216</td>\n",
       "      <td>9.336</td>\n",
       "      <td>9.6840</td>\n",
       "      <td>10.032</td>\n",
       "      <td>9.8945</td>\n",
       "      <td>9.757</td>\n",
       "      <td>9.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xfdaf9f857621ec06f2cf801f42a020a322835090</td>\n",
       "      <td>14.437</td>\n",
       "      <td>16.274</td>\n",
       "      <td>7.031</td>\n",
       "      <td>17.018</td>\n",
       "      <td>17.603</td>\n",
       "      <td>15.005</td>\n",
       "      <td>8.987</td>\n",
       "      <td>8.490</td>\n",
       "      <td>10.136</td>\n",
       "      <td>...</td>\n",
       "      <td>4.141</td>\n",
       "      <td>2.828</td>\n",
       "      <td>3.8230</td>\n",
       "      <td>4.818</td>\n",
       "      <td>3.357</td>\n",
       "      <td>8.1315</td>\n",
       "      <td>12.906</td>\n",
       "      <td>8.0140</td>\n",
       "      <td>3.122</td>\n",
       "      <td>3.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xd28f2f001e0cd4d6c121a3cb2e1427207e170e18</td>\n",
       "      <td>7.824</td>\n",
       "      <td>7.517</td>\n",
       "      <td>5.398</td>\n",
       "      <td>6.788</td>\n",
       "      <td>7.360</td>\n",
       "      <td>6.898</td>\n",
       "      <td>7.321</td>\n",
       "      <td>8.042</td>\n",
       "      <td>8.207</td>\n",
       "      <td>...</td>\n",
       "      <td>6.767</td>\n",
       "      <td>5.919</td>\n",
       "      <td>5.9980</td>\n",
       "      <td>6.077</td>\n",
       "      <td>7.761</td>\n",
       "      <td>6.6080</td>\n",
       "      <td>5.455</td>\n",
       "      <td>5.5670</td>\n",
       "      <td>5.679</td>\n",
       "      <td>8.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0x47218b46abb2fcaade487a211911406dc6e13730</td>\n",
       "      <td>23.965</td>\n",
       "      <td>28.689</td>\n",
       "      <td>27.664</td>\n",
       "      <td>29.229</td>\n",
       "      <td>29.548</td>\n",
       "      <td>27.909</td>\n",
       "      <td>26.923</td>\n",
       "      <td>21.277</td>\n",
       "      <td>23.452</td>\n",
       "      <td>...</td>\n",
       "      <td>20.747</td>\n",
       "      <td>19.979</td>\n",
       "      <td>20.1925</td>\n",
       "      <td>20.406</td>\n",
       "      <td>23.668</td>\n",
       "      <td>27.7900</td>\n",
       "      <td>31.912</td>\n",
       "      <td>29.1125</td>\n",
       "      <td>26.313</td>\n",
       "      <td>24.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>11.302</td>\n",
       "      <td>14.178</td>\n",
       "      <td>15.499</td>\n",
       "      <td>11.853</td>\n",
       "      <td>17.431</td>\n",
       "      <td>14.506</td>\n",
       "      <td>12.812</td>\n",
       "      <td>10.472</td>\n",
       "      <td>10.879</td>\n",
       "      <td>...</td>\n",
       "      <td>14.036</td>\n",
       "      <td>15.990</td>\n",
       "      <td>15.5505</td>\n",
       "      <td>15.111</td>\n",
       "      <td>16.506</td>\n",
       "      <td>18.7585</td>\n",
       "      <td>21.011</td>\n",
       "      <td>19.2040</td>\n",
       "      <td>17.397</td>\n",
       "      <td>15.237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id  2017-01-01  2017-01-02  \\\n",
       "0     0xa62b9f23553ff183f61e2bf943aab3d5983d02d7       0.000       0.000   \n",
       "1     0x459c834d1f6cfb5b734b82aa9f5410fa97fb70da       0.000       0.000   \n",
       "2     0x4a1ed36825360a058cec2bdd409fc2459e1ce54f       0.000       0.000   \n",
       "3     0x5b76d3c0e0aefc6e0a8d1d031f96388a23263407       0.000       0.000   \n",
       "4     0x943ebe39ef2be6ef807c42c5a647e27112ca5b0f       0.000       0.000   \n",
       "...                                          ...         ...         ...   \n",
       "3243  0x7dd7a7b8ee1bec7c44b24f738c752482f6161065       2.317       2.301   \n",
       "3244  0xfdaf9f857621ec06f2cf801f42a020a322835090      14.437      16.274   \n",
       "3245  0xd28f2f001e0cd4d6c121a3cb2e1427207e170e18       7.824       7.517   \n",
       "3246  0x47218b46abb2fcaade487a211911406dc6e13730      23.965      28.689   \n",
       "3247  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd      11.302      14.178   \n",
       "\n",
       "      2017-01-03  2017-01-04  2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "0          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "1          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "2          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "3          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "4          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3243       2.352       2.516       2.229       2.354       2.397       2.397   \n",
       "3244       7.031      17.018      17.603      15.005       8.987       8.490   \n",
       "3245       5.398       6.788       7.360       6.898       7.321       8.042   \n",
       "3246      27.664      29.229      29.548      27.909      26.923      21.277   \n",
       "3247      15.499      11.853      17.431      14.506      12.812      10.472   \n",
       "\n",
       "      2017-01-09  ...  2017-12-22  2017-12-23  2017-12-24  2017-12-25  \\\n",
       "0          0.000  ...       4.030       5.397      5.1075       4.818   \n",
       "1          0.000  ...      13.101      14.327     14.6315      14.936   \n",
       "2          0.000  ...      10.201       7.320      7.3520       7.384   \n",
       "3          0.000  ...      14.833      12.477     11.7255      10.974   \n",
       "4          0.000  ...      39.440      35.538     21.9445       8.351   \n",
       "...          ...  ...         ...         ...         ...         ...   \n",
       "3243       2.269  ...       9.390       9.231      9.2235       9.216   \n",
       "3244      10.136  ...       4.141       2.828      3.8230       4.818   \n",
       "3245       8.207  ...       6.767       5.919      5.9980       6.077   \n",
       "3246      23.452  ...      20.747      19.979     20.1925      20.406   \n",
       "3247      10.879  ...      14.036      15.990     15.5505      15.111   \n",
       "\n",
       "      2017-12-26  2017-12-27  2017-12-28  2017-12-29  2017-12-30  2017-12-31  \n",
       "0          3.931      4.2170       4.503      4.8160       5.129       5.395  \n",
       "1         16.174     20.3960      24.618     19.8925      15.167      11.751  \n",
       "2         14.425     16.0650      17.705     13.3355       8.966       4.633  \n",
       "3         19.646     21.8195      23.993     19.9170      15.841      14.452  \n",
       "4          9.957     17.9140      25.871     36.0725      46.274      16.901  \n",
       "...          ...         ...         ...         ...         ...         ...  \n",
       "3243       9.336      9.6840      10.032      9.8945       9.757       9.480  \n",
       "3244       3.357      8.1315      12.906      8.0140       3.122       3.401  \n",
       "3245       7.761      6.6080       5.455      5.5670       5.679       8.148  \n",
       "3246      23.668     27.7900      31.912     29.1125      26.313      24.201  \n",
       "3247      16.506     18.7585      21.011     19.2040      17.397      15.237  \n",
       "\n",
       "[3248 rows x 366 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2017-01</th>\n",
       "      <th>2017-02</th>\n",
       "      <th>2017-03</th>\n",
       "      <th>2017-04</th>\n",
       "      <th>2017-05</th>\n",
       "      <th>2017-06</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.39450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>553.18400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>368.90957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>534.84650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>946.06400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>72.7050</td>\n",
       "      <td>63.245</td>\n",
       "      <td>68.4335</td>\n",
       "      <td>66.6265</td>\n",
       "      <td>69.0480</td>\n",
       "      <td>100.430</td>\n",
       "      <td>177.1735</td>\n",
       "      <td>177.4100</td>\n",
       "      <td>216.7245</td>\n",
       "      <td>279.164500</td>\n",
       "      <td>351.481000</td>\n",
       "      <td>312.08800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>371.4390</td>\n",
       "      <td>269.691</td>\n",
       "      <td>179.3430</td>\n",
       "      <td>141.6590</td>\n",
       "      <td>138.4835</td>\n",
       "      <td>122.910</td>\n",
       "      <td>164.2285</td>\n",
       "      <td>100.9610</td>\n",
       "      <td>118.0520</td>\n",
       "      <td>123.135500</td>\n",
       "      <td>187.140000</td>\n",
       "      <td>186.88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>209.8065</td>\n",
       "      <td>169.858</td>\n",
       "      <td>184.0130</td>\n",
       "      <td>166.7280</td>\n",
       "      <td>134.1760</td>\n",
       "      <td>169.489</td>\n",
       "      <td>157.5775</td>\n",
       "      <td>165.9640</td>\n",
       "      <td>177.0105</td>\n",
       "      <td>185.701833</td>\n",
       "      <td>192.288667</td>\n",
       "      <td>200.61950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>845.6630</td>\n",
       "      <td>608.449</td>\n",
       "      <td>588.7765</td>\n",
       "      <td>503.3050</td>\n",
       "      <td>291.1320</td>\n",
       "      <td>177.605</td>\n",
       "      <td>183.5345</td>\n",
       "      <td>182.0350</td>\n",
       "      <td>244.2255</td>\n",
       "      <td>371.458333</td>\n",
       "      <td>695.878667</td>\n",
       "      <td>858.83950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>428.7345</td>\n",
       "      <td>670.505</td>\n",
       "      <td>462.1050</td>\n",
       "      <td>354.8660</td>\n",
       "      <td>287.9950</td>\n",
       "      <td>200.321</td>\n",
       "      <td>227.0855</td>\n",
       "      <td>231.7585</td>\n",
       "      <td>246.3005</td>\n",
       "      <td>344.210167</td>\n",
       "      <td>516.290333</td>\n",
       "      <td>734.61800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id   2017-01  2017-02   2017-03  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c    0.0000    0.000    0.0000   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82    0.0000    0.000    0.0000   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734    0.0000    0.000    0.0000   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a    0.0000    0.000    0.0000   \n",
       "4     0x005958406351bb29580475df698b5f1070096397    0.0000    0.000    0.0000   \n",
       "...                                          ...       ...      ...       ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f   72.7050   63.245   68.4335   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb  371.4390  269.691  179.3430   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5  209.8065  169.858  184.0130   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02  845.6630  608.449  588.7765   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4  428.7345  670.505  462.1050   \n",
       "\n",
       "       2017-04   2017-05  2017-06   2017-07   2017-08   2017-09     2017-10  \\\n",
       "0       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "1       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "2       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "3       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "4       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "...        ...       ...      ...       ...       ...       ...         ...   \n",
       "3243   66.6265   69.0480  100.430  177.1735  177.4100  216.7245  279.164500   \n",
       "3244  141.6590  138.4835  122.910  164.2285  100.9610  118.0520  123.135500   \n",
       "3245  166.7280  134.1760  169.489  157.5775  165.9640  177.0105  185.701833   \n",
       "3246  503.3050  291.1320  177.605  183.5345  182.0350  244.2255  371.458333   \n",
       "3247  354.8660  287.9950  200.321  227.0855  231.7585  246.3005  344.210167   \n",
       "\n",
       "         2017-11    2017-12  \n",
       "0       0.000000  128.39450  \n",
       "1       0.000000  553.18400  \n",
       "2       0.000000  368.90957  \n",
       "3       0.000000  534.84650  \n",
       "4       0.000000  946.06400  \n",
       "...          ...        ...  \n",
       "3243  351.481000  312.08800  \n",
       "3244  187.140000  186.88400  \n",
       "3245  192.288667  200.61950  \n",
       "3246  695.878667  858.83950  \n",
       "3247  516.290333  734.61800  \n",
       "\n",
       "[3248 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading the training data\n",
    "print(\"training data\")\n",
    "df_train_daily = pd.read_pickle(\"../Data/Preprocessed_Data/consumption_daily_nan_interpolated.pkl\").fillna(0)\n",
    "\n",
    "#aggregating up into months\n",
    "meter_id=df_monthly_forecasts[\"meter_id\"]\n",
    "df_train_monthly = pd.DataFrame(columns=[\"meter_id\"])\n",
    "df_train_monthly[\"meter_id\"] = meter_id\n",
    "\n",
    "\n",
    "#for each month in the range of dates\n",
    "resample_size=\"M\"\n",
    "for new_sample in tqdm(pd.date_range(datetime.datetime(2017, 1, 1), datetime.datetime(2017, 12, 31), freq = resample_size),position=0):\n",
    "\n",
    "    #get this columns name as a string\n",
    "    columnName = str(new_sample.date())[:7]\n",
    "    #get all columns that relate to this new sample\n",
    "    columns = [i for i in df_train_daily.columns.values[1:] if i.startswith(columnName)]\n",
    "\n",
    "    #sum these up into a value for the new sample size\n",
    "    df_train_monthly[columnName] = df_train_daily[columns].sum(axis=1)\n",
    "\n",
    "display(df_train_daily)\n",
    "display(df_train_monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the predictions against the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots = 10\n",
    "for pid in tqdm(range(0,3248)):\n",
    "    if pid>num_plots:\n",
    "        break\n",
    "        \n",
    "    #getting the row corresponding to this meter_id\n",
    "    meter_id = df_daily_forecasts.iloc[pid,0]\n",
    "    this_train_month = df_train_monthly.loc[df_train_monthly['meter_id'] == meter_id].T[1:]\n",
    "    this_preds_month = df_monthly_forecasts.loc[df_train_monthly['meter_id'] == meter_id].T[1:]\n",
    "    \n",
    "    #converting index to datetime for ease of plots key\n",
    "    this_train_month.index=pd.to_datetime(this_train_month.index)\n",
    "    this_preds_month.index=pd.to_datetime(this_preds_month.index)\n",
    "    \n",
    "    #creating figure\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    \n",
    "    #plotting the monthly predictions\n",
    "    plt.title(\"Meter '\"+str(meter_id)+\"' monthly forecasts and historical data\", fontsize=15)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Energy Usage kWh\")\n",
    "    plt.plot(this_train_month, label=\"training monthly energy\", lw=1,color=\"skyblue\", marker=\"x\")\n",
    "    plt.plot(this_preds_month, label=\"forecast monthly energy\", lw=1,color=\"mediumorchid\", marker=\"x\")\n",
    "    \n",
    "    #annotations\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.locator_params(nbins=24)\n",
    "    \n",
    "    #plt.show()\n",
    "    fig.savefig(f\"..\\\\Results\\\\Genetic Algorithm\\\\Plots\\\\forecasts\\\\p{population_size}_g{number_of_generations}_forecasts_{pid}_{meter_id}.png\")\n",
    "\n",
    "    fig.clf()\n",
    "    fig.clear()\n",
    "    plt.close()\n",
    "    del fig, this_train_month, this_preds_month\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model based on the main effects\n",
    "* Running on the hyper params determined by main effects (setting that gave the lowest mean result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meter_id_ord True\n",
      "meter_id_binary True\n",
      "day_of_year_cyclic True\n",
      "day_of_week False\n",
      "day_of_month True\n",
      "month_ord True\n",
      "month_cyclic True\n",
      "is_weekend True\n",
      "energy_cluster True\n",
      "num_bedrooms True\n",
      "dwelling_type_ord True\n",
      "dwelling_type_onehot False\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n"
     ]
    }
   ],
   "source": [
    "# treating columns like main effects: accepting those whose mean error with the column is better than that without the column\n",
    "main_columm_types = []\n",
    "i=0\n",
    "for key in possible_columns.keys():\n",
    "    print(key,column_means[i]<columnless_means[i])\n",
    "    main_columm_types.append(key)\n",
    "    i+=1 \n",
    "print(main_columm_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learning_rate', 'num_leaves', 'max_depth', 'bagging_fraction', 'bagging_freq', 'feature_fraction', 'lambda_l1', 'lambda_l2']\n",
      "[array([0.036036]), array([785.]), array([13.]), array([0.98]), array([16.]), array([0.8556]), array([15.]), array([15.])]\n"
     ]
    }
   ],
   "source": [
    "#inspecting the stored best values for each hyper as determined by the main effects plot\n",
    "#(value which resulted in the lowest average MAE on the val set)\n",
    "print(arr_hypers)\n",
    "print(arr_best_hypers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mRunning with main effects determined configuration\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mUsing the features\u001b[0m\n",
      "['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1m\u001b[94m\u001b[4mUsing the main effects hyper parameters\u001b[0m\n",
      "{'bagging_fraction': 0.98,\n",
      " 'bagging_freq': 16,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.8556,\n",
      " 'lambda_l1': 15,\n",
      " 'lambda_l2': 15,\n",
      " 'learning_rate': 0.036036,\n",
      " 'max_depth': 13,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 785,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8556\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.98, subsample=1.0 will be ignored. Current value: bagging_fraction=0.98\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.801\n",
      "Early stopping, best iteration is:\n",
      "[3520]\tvalid_0's l1: 1.80047\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8556\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.98, subsample=1.0 will be ignored. Current value: bagging_fraction=0.98\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.8087\n",
      "Early stopping, best iteration is:\n",
      "[3849]\tvalid_0's l1: 1.80787\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8556\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.98, subsample=1.0 will be ignored. Current value: bagging_fraction=0.98\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2495]\tvalid_0's l1: 1.81103\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mTrained the model in 0:19:39\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}Running with main effects determined configuration{color.END}\")\n",
    "\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Using the features{color.END}\")\n",
    "X_cols =[]\n",
    "\n",
    "for key in main_columm_types:\n",
    "    X_cols+=(possible_columns[key])\n",
    "this_X_cats = list(set(X_cols).intersection(all_cat)) #getting the categorical values for this X\n",
    "print(X_cols)\n",
    "\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Using the main effects hyper parameters{color.END}\")\n",
    "this_params = params.copy()\n",
    "this_params[\"learning_rate\"] = arr_best_hypers[0][0]\n",
    "this_params[\"max_depth\"] = int(arr_best_hypers[2][0])\n",
    "this_params[\"num_leaves\"] = int(arr_best_hypers[1][0])\n",
    "this_params[\"bagging_fraction\"] = arr_best_hypers[3][0]\n",
    "this_params[\"bagging_freq\"] = int(arr_best_hypers[4][0])\n",
    "this_params[\"feature_fraction\"] = arr_best_hypers[5][0]\n",
    "this_params[\"lambda_l1\"] = int(arr_best_hypers[6][0])\n",
    "this_params[\"lambda_l2\"] = int(arr_best_hypers[7][0])\n",
    "pprint(this_params)\n",
    "\n",
    "#train the model with this hyper param config and store it's results\n",
    "results=((run_lgbm_skf_cv(False, False, SEED, num_folds, df_train.copy(), y_col, X_cols, this_X_cats, this_params),(X_cols,this_params)))\n",
    "print(\"\\n\\n\\n\")\n",
    "time_of_execution = time.time()-start_time\n",
    "print(f\"{color.BOLD}Trained the model in {str(datetime.timedelta(seconds=round(time_of_execution)))}{color.END}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting from the main effects model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_ord</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>...</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>dwelling_type_ord</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.495903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.583185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.501434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.427291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.503763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185515</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.372549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185516</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.281953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185517</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.636214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185518</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.096826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185519</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.056135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185520 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           meter_id meter_id_ord meter_id_0  \\\n",
       "0        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7         2073          0   \n",
       "1        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7         2073          0   \n",
       "2        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7         2073          0   \n",
       "3        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7         2073          0   \n",
       "4        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7         2073          0   \n",
       "...                                             ...          ...        ...   \n",
       "1185515  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd         2605          0   \n",
       "1185516  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd         2605          0   \n",
       "1185517  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd         2605          0   \n",
       "1185518  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd         2605          0   \n",
       "1185519  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd         2605          0   \n",
       "\n",
       "        meter_id_1 meter_id_2 meter_id_3 meter_id_4 meter_id_5 meter_id_6  \\\n",
       "0                0          0          0          0          0          0   \n",
       "1                0          0          0          0          0          0   \n",
       "2                0          0          0          0          0          0   \n",
       "3                0          0          0          0          0          0   \n",
       "4                0          0          0          0          0          0   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "1185515          1          1          0          0          1          0   \n",
       "1185516          1          1          0          0          1          0   \n",
       "1185517          1          1          0          0          1          0   \n",
       "1185518          1          1          0          0          1          0   \n",
       "1185519          1          1          0          0          1          0   \n",
       "\n",
       "        meter_id_7  ... is_weekend energy_cluster num_bedrooms  \\\n",
       "0                0  ...          0              0          2.0   \n",
       "1                0  ...          0              0          2.0   \n",
       "2                0  ...          0              0          2.0   \n",
       "3                0  ...          0              0          2.0   \n",
       "4                0  ...          0              0          2.0   \n",
       "...            ...  ...        ...            ...          ...   \n",
       "1185515          1  ...          0              1          3.0   \n",
       "1185516          1  ...          0              1          3.0   \n",
       "1185517          1  ...          1              1          3.0   \n",
       "1185518          1  ...          1              1          3.0   \n",
       "1185519          1  ...          0              1          3.0   \n",
       "\n",
       "          dwelling_type dwelling_type_ord detached  flat  semi_detached  \\\n",
       "0        terraced_house                 4      0.0   0.0            0.0   \n",
       "1        terraced_house                 4      0.0   0.0            0.0   \n",
       "2        terraced_house                 4      0.0   0.0            0.0   \n",
       "3        terraced_house                 4      0.0   0.0            0.0   \n",
       "4        terraced_house                 4      0.0   0.0            0.0   \n",
       "...                 ...               ...      ...   ...            ...   \n",
       "1185515  detached_house                 1      1.0   0.0            0.0   \n",
       "1185516  detached_house                 1      1.0   0.0            0.0   \n",
       "1185517  detached_house                 1      1.0   0.0            0.0   \n",
       "1185518  detached_house                 1      1.0   0.0            0.0   \n",
       "1185519  detached_house                 1      1.0   0.0            0.0   \n",
       "\n",
       "        terraced meter_reading  \n",
       "0            1.0      5.495903  \n",
       "1            1.0      5.583185  \n",
       "2            1.0      5.501434  \n",
       "3            1.0      5.427291  \n",
       "4            1.0      5.503763  \n",
       "...          ...           ...  \n",
       "1185515      0.0     20.372549  \n",
       "1185516      0.0     22.281953  \n",
       "1185517      0.0     21.636214  \n",
       "1185518      0.0     20.096826  \n",
       "1185519      0.0     18.056135  \n",
       "\n",
       "[1185520 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#making predictions based on the best performing model and displaying it's information\n",
    "main_effects_models = results[0][2] #getting the lgbm_models from the best index\n",
    "main_effects_forecasts = df_preds.copy()\n",
    "\n",
    "#calculating the average preds by summing the weighted preds for each folds model\n",
    "for i in range(len(main_effects_models)):\n",
    "    pred_forecasts = main_effects_models[i].predict(main_effects_forecasts[results[1][0]], num_iteration=main_effects_models[i].best_iteration_) #predicting the unkown df_preds\n",
    "    main_effects_forecasts[y_col] += pred_forecasts / num_folds #weighting the predictions for BEST_LGBM_FORECASTS for this fold and adding to df_preds y column \n",
    "main_effects_forecasts[\"meter_reading\"] = main_effects_forecasts.meter_reading.clip(lower=0) #clip meter_reading so no predictions lower than 0\n",
    "\n",
    "display(main_effects_forecasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the val error of the main effects vs the best from genetic algorithm tuning\n",
    "## Genetic Algorithm summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGA best model came from generation 4 individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mEvaluation and results\u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.6499669073999559\n",
      "\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper-parameters\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mX_cols:\u001b[0m\n",
      "\n",
      "['meter_id_ord',\n",
      " 'day_of_year_sin',\n",
      " 'day_of_year_cos',\n",
      " 'month_ord',\n",
      " 'is_weekend',\n",
      " 'energy_cluster',\n",
      " 'num_bedrooms']\n",
      "\u001b[1m\u001b[96m\u001b[4mmodel params:  \u001b[0m\n",
      "{'bagging_fraction': 1,\n",
      " 'bagging_freq': 10,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.93,\n",
      " 'lambda_l1': 14,\n",
      " 'lambda_l2': 8,\n",
      " 'learning_rate': 0.046799999999999994,\n",
      " 'max_depth': 11,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 695,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n"
     ]
    }
   ],
   "source": [
    "#printing the forecasts and other evaluation info\n",
    "print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}GA best model came from generation {int(best_index/population_size)} individual {best_index%population_size}{color.END}\")\n",
    "#displaying the results\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Evaluation and results{color.END}\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set:{color.END} {best_results[0][1]}\\n\")\n",
    "#displaying the hyperparameters\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Hyper-parameters{color.END}\")\n",
    "print(f\"\\n{color.BOLD}{color.CYAN}{color.UNDERLINE}X_cols:{color.END}\\n\")\n",
    "pprint(best_results[1][0])\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}model params:  {color.END}\")\n",
    "pprint(best_results[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main effects based model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mMain effects model based on results of GA\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mEvaluation and results\u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8064566067325212\n",
      "\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper-parameters\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mX_cols:\u001b[0m\n",
      "\n",
      "['meter_id_ord',\n",
      " 'meter_id_0',\n",
      " 'meter_id_1',\n",
      " 'meter_id_2',\n",
      " 'meter_id_3',\n",
      " 'meter_id_4',\n",
      " 'meter_id_5',\n",
      " 'meter_id_6',\n",
      " 'meter_id_7',\n",
      " 'meter_id_8',\n",
      " 'meter_id_9',\n",
      " 'meter_id_10',\n",
      " 'meter_id_11',\n",
      " 'meter_id_12',\n",
      " 'day_of_year_sin',\n",
      " 'day_of_year_cos',\n",
      " 'day_of_week',\n",
      " 'day_of_month',\n",
      " 'month_ord',\n",
      " 'month_sin',\n",
      " 'month_cos',\n",
      " 'is_weekend',\n",
      " 'energy_cluster',\n",
      " 'num_bedrooms',\n",
      " 'dwelling_type_ord',\n",
      " 'detached',\n",
      " 'flat',\n",
      " 'semi_detached',\n",
      " 'terraced']\n",
      "\u001b[1m\u001b[96m\u001b[4mmodel params:  \u001b[0m\n",
      "{'bagging_fraction': 0.98,\n",
      " 'bagging_freq': 16,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'feature_fraction': 0.8556,\n",
      " 'lambda_l1': 15,\n",
      " 'lambda_l2': 15,\n",
      " 'learning_rate': 0.036036,\n",
      " 'max_depth': 13,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 785,\n",
      " 'num_threads': -1,\n",
      " 'seed': 1337}\n"
     ]
    }
   ],
   "source": [
    "#printing the forecasts and other evaluation info\n",
    "print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}Main effects model based on results of GA{color.END}\")\n",
    "#displaying the results\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Evaluation and results{color.END}\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set:{color.END} {results[0][1]}\\n\")\n",
    "#displaying the hyperparameters\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Hyper-parameters{color.END}\")\n",
    "print(f\"\\n{color.BOLD}{color.CYAN}{color.UNDERLINE}X_cols:{color.END}\\n\")\n",
    "pprint(results[1][0])\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}model params:  {color.END}\")\n",
    "pprint(results[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "the best model from the GA is way better than the main effects of the GA\n",
    "\n",
    "\n",
    "# Save the main effects description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE': 1.8064566067325212,\n",
      " 'features': ['meter_id_ord',\n",
      "              'meter_id_0',\n",
      "              'meter_id_1',\n",
      "              'meter_id_2',\n",
      "              'meter_id_3',\n",
      "              'meter_id_4',\n",
      "              'meter_id_5',\n",
      "              'meter_id_6',\n",
      "              'meter_id_7',\n",
      "              'meter_id_8',\n",
      "              'meter_id_9',\n",
      "              'meter_id_10',\n",
      "              'meter_id_11',\n",
      "              'meter_id_12',\n",
      "              'day_of_year_sin',\n",
      "              'day_of_year_cos',\n",
      "              'day_of_week',\n",
      "              'day_of_month',\n",
      "              'month_ord',\n",
      "              'month_sin',\n",
      "              'month_cos',\n",
      "              'is_weekend',\n",
      "              'energy_cluster',\n",
      "              'num_bedrooms',\n",
      "              'dwelling_type_ord',\n",
      "              'detached',\n",
      "              'flat',\n",
      "              'semi_detached',\n",
      "              'terraced'],\n",
      " 'params': {'bagging_fraction': 0.98,\n",
      "            'bagging_freq': 16,\n",
      "            'boosting_type': 'gbdt',\n",
      "            'feature_fraction': 0.8556,\n",
      "            'lambda_l1': 15,\n",
      "            'lambda_l2': 15,\n",
      "            'learning_rate': 0.036036,\n",
      "            'max_depth': 13,\n",
      "            'metric': 'mae',\n",
      "            'num_iterations': 10000,\n",
      "            'num_leaves': 785,\n",
      "            'num_threads': -1,\n",
      "            'seed': 1337}}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "a = {'hello': 'world'}\n",
    "desc_disc = {\n",
    "    \"MAE\":results[0][1],\n",
    "    \"features\":results[1][0],\n",
    "    \"params\":results[1][1]\n",
    "}\n",
    "\n",
    "with open(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_main_effects_desc.pkl\", 'wb') as handle:\n",
    "    pickle.dump(desc_disc, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "pprint(desc_disc)\n",
    "    \n",
    "# verifying it saved correctly and can be loaded back\n",
    "with open(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_main_effects_desc.pkl\", 'rb') as handle:\n",
    "    desc_disc_loaded = pickle.load(handle)\n",
    "print(desc_disc == desc_disc_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting the main effects forecasts and saving them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting into monthly forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>140.550585</td>\n",
       "      <td>126.254200</td>\n",
       "      <td>129.486919</td>\n",
       "      <td>109.331424</td>\n",
       "      <td>107.760850</td>\n",
       "      <td>108.498140</td>\n",
       "      <td>113.134209</td>\n",
       "      <td>122.598525</td>\n",
       "      <td>121.132539</td>\n",
       "      <td>126.843396</td>\n",
       "      <td>93.682955</td>\n",
       "      <td>112.089917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>633.924615</td>\n",
       "      <td>611.238636</td>\n",
       "      <td>546.933045</td>\n",
       "      <td>472.594531</td>\n",
       "      <td>458.690497</td>\n",
       "      <td>407.904490</td>\n",
       "      <td>395.598676</td>\n",
       "      <td>416.875115</td>\n",
       "      <td>455.260060</td>\n",
       "      <td>520.178718</td>\n",
       "      <td>601.147425</td>\n",
       "      <td>640.695160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>232.015137</td>\n",
       "      <td>199.593366</td>\n",
       "      <td>211.323644</td>\n",
       "      <td>189.028358</td>\n",
       "      <td>184.301136</td>\n",
       "      <td>178.100952</td>\n",
       "      <td>180.298847</td>\n",
       "      <td>190.635324</td>\n",
       "      <td>186.842949</td>\n",
       "      <td>199.120596</td>\n",
       "      <td>203.736933</td>\n",
       "      <td>246.390543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>180.492360</td>\n",
       "      <td>156.647834</td>\n",
       "      <td>152.640211</td>\n",
       "      <td>133.144262</td>\n",
       "      <td>139.092132</td>\n",
       "      <td>136.542045</td>\n",
       "      <td>134.197360</td>\n",
       "      <td>137.901143</td>\n",
       "      <td>133.477302</td>\n",
       "      <td>142.392257</td>\n",
       "      <td>147.622021</td>\n",
       "      <td>157.887842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>319.757639</td>\n",
       "      <td>281.177082</td>\n",
       "      <td>279.579042</td>\n",
       "      <td>240.198417</td>\n",
       "      <td>228.687678</td>\n",
       "      <td>227.537923</td>\n",
       "      <td>230.776717</td>\n",
       "      <td>229.668158</td>\n",
       "      <td>226.060855</td>\n",
       "      <td>260.403675</td>\n",
       "      <td>283.436860</td>\n",
       "      <td>323.131433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>212.936038</td>\n",
       "      <td>165.048189</td>\n",
       "      <td>156.966087</td>\n",
       "      <td>141.281841</td>\n",
       "      <td>138.390691</td>\n",
       "      <td>135.407719</td>\n",
       "      <td>138.247417</td>\n",
       "      <td>132.720426</td>\n",
       "      <td>135.592074</td>\n",
       "      <td>147.145661</td>\n",
       "      <td>157.466356</td>\n",
       "      <td>169.989886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>636.889283</td>\n",
       "      <td>587.571281</td>\n",
       "      <td>715.958104</td>\n",
       "      <td>685.919098</td>\n",
       "      <td>597.365085</td>\n",
       "      <td>475.169224</td>\n",
       "      <td>467.205432</td>\n",
       "      <td>478.384166</td>\n",
       "      <td>507.746454</td>\n",
       "      <td>557.249736</td>\n",
       "      <td>565.271463</td>\n",
       "      <td>603.364795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>475.484800</td>\n",
       "      <td>402.400621</td>\n",
       "      <td>400.968486</td>\n",
       "      <td>361.098933</td>\n",
       "      <td>339.872479</td>\n",
       "      <td>270.054946</td>\n",
       "      <td>275.860401</td>\n",
       "      <td>281.862637</td>\n",
       "      <td>293.809702</td>\n",
       "      <td>341.432573</td>\n",
       "      <td>416.076795</td>\n",
       "      <td>506.863190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>455.374399</td>\n",
       "      <td>372.407903</td>\n",
       "      <td>349.220337</td>\n",
       "      <td>355.733947</td>\n",
       "      <td>213.915435</td>\n",
       "      <td>194.473441</td>\n",
       "      <td>193.479341</td>\n",
       "      <td>200.056858</td>\n",
       "      <td>213.628613</td>\n",
       "      <td>261.986663</td>\n",
       "      <td>320.610028</td>\n",
       "      <td>389.115239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>264.881644</td>\n",
       "      <td>226.552965</td>\n",
       "      <td>240.217036</td>\n",
       "      <td>215.445147</td>\n",
       "      <td>226.141542</td>\n",
       "      <td>207.719002</td>\n",
       "      <td>215.880305</td>\n",
       "      <td>216.961960</td>\n",
       "      <td>223.893901</td>\n",
       "      <td>235.857788</td>\n",
       "      <td>252.513716</td>\n",
       "      <td>259.287229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id         Jan         Feb  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c  140.550585  126.254200   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82  633.924615  611.238636   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734  232.015137  199.593366   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a  180.492360  156.647834   \n",
       "4     0x005958406351bb29580475df698b5f1070096397  319.757639  281.177082   \n",
       "...                                          ...         ...         ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f  212.936038  165.048189   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb  636.889283  587.571281   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5  475.484800  402.400621   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02  455.374399  372.407903   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4  264.881644  226.552965   \n",
       "\n",
       "             Mar         Apr         May         Jun         Jul         Aug  \\\n",
       "0     129.486919  109.331424  107.760850  108.498140  113.134209  122.598525   \n",
       "1     546.933045  472.594531  458.690497  407.904490  395.598676  416.875115   \n",
       "2     211.323644  189.028358  184.301136  178.100952  180.298847  190.635324   \n",
       "3     152.640211  133.144262  139.092132  136.542045  134.197360  137.901143   \n",
       "4     279.579042  240.198417  228.687678  227.537923  230.776717  229.668158   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3243  156.966087  141.281841  138.390691  135.407719  138.247417  132.720426   \n",
       "3244  715.958104  685.919098  597.365085  475.169224  467.205432  478.384166   \n",
       "3245  400.968486  361.098933  339.872479  270.054946  275.860401  281.862637   \n",
       "3246  349.220337  355.733947  213.915435  194.473441  193.479341  200.056858   \n",
       "3247  240.217036  215.445147  226.141542  207.719002  215.880305  216.961960   \n",
       "\n",
       "             Sep         Oct         Nov         Dec  \n",
       "0     121.132539  126.843396   93.682955  112.089917  \n",
       "1     455.260060  520.178718  601.147425  640.695160  \n",
       "2     186.842949  199.120596  203.736933  246.390543  \n",
       "3     133.477302  142.392257  147.622021  157.887842  \n",
       "4     226.060855  260.403675  283.436860  323.131433  \n",
       "...          ...         ...         ...         ...  \n",
       "3243  135.592074  147.145661  157.466356  169.989886  \n",
       "3244  507.746454  557.249736  565.271463  603.364795  \n",
       "3245  293.809702  341.432573  416.076795  506.863190  \n",
       "3246  213.628613  261.986663  320.610028  389.115239  \n",
       "3247  223.893901  235.857788  252.513716  259.287229  \n",
       "\n",
       "[3248 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#restructuring into the original multiple time series format\n",
    "#aggregating up the total sum of the months predictions\n",
    "df_monthly_forecasts = main_effects_forecasts.groupby([\"meter_id\", \"month_ord\"])[\"meter_reading\"].sum().unstack()\n",
    "\n",
    "#rename ordinal encoded month with its corresponding name\n",
    "df_monthly_forecasts.rename(columns={1:\"Jan\", 2:\"Feb\",3:\"Mar\",4:\"Apr\",5:\"May\",6:\"Jun\",7:\"Jul\",8:\"Aug\",9:\"Sep\",10:\"Oct\",11:\"Nov\",12:\"Dec\"}, inplace=True)\n",
    "#resetting the index \n",
    "df_monthly_forecasts.reset_index(inplace=True)\n",
    "df_monthly_forecasts.index.name = None # removing index column\n",
    "df_monthly_forecasts.columns.name = None # removing columns name\n",
    "\n",
    "display(df_monthly_forecasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving these monthly predictions to be submitted to competition\n",
    "* Saving predictions ready to be submitted so I can get the MAE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_forecasts.to_csv(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_main_effects_monthly_forecasts.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting these monthly forecasts\n",
    "## Renaming months to dates for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "      <th>2018-05</th>\n",
       "      <th>2018-06</th>\n",
       "      <th>2018-07</th>\n",
       "      <th>2018-08</th>\n",
       "      <th>2018-09</th>\n",
       "      <th>2018-10</th>\n",
       "      <th>2018-11</th>\n",
       "      <th>2018-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>140.550585</td>\n",
       "      <td>126.254200</td>\n",
       "      <td>129.486919</td>\n",
       "      <td>109.331424</td>\n",
       "      <td>107.760850</td>\n",
       "      <td>108.498140</td>\n",
       "      <td>113.134209</td>\n",
       "      <td>122.598525</td>\n",
       "      <td>121.132539</td>\n",
       "      <td>126.843396</td>\n",
       "      <td>93.682955</td>\n",
       "      <td>112.089917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>633.924615</td>\n",
       "      <td>611.238636</td>\n",
       "      <td>546.933045</td>\n",
       "      <td>472.594531</td>\n",
       "      <td>458.690497</td>\n",
       "      <td>407.904490</td>\n",
       "      <td>395.598676</td>\n",
       "      <td>416.875115</td>\n",
       "      <td>455.260060</td>\n",
       "      <td>520.178718</td>\n",
       "      <td>601.147425</td>\n",
       "      <td>640.695160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>232.015137</td>\n",
       "      <td>199.593366</td>\n",
       "      <td>211.323644</td>\n",
       "      <td>189.028358</td>\n",
       "      <td>184.301136</td>\n",
       "      <td>178.100952</td>\n",
       "      <td>180.298847</td>\n",
       "      <td>190.635324</td>\n",
       "      <td>186.842949</td>\n",
       "      <td>199.120596</td>\n",
       "      <td>203.736933</td>\n",
       "      <td>246.390543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>180.492360</td>\n",
       "      <td>156.647834</td>\n",
       "      <td>152.640211</td>\n",
       "      <td>133.144262</td>\n",
       "      <td>139.092132</td>\n",
       "      <td>136.542045</td>\n",
       "      <td>134.197360</td>\n",
       "      <td>137.901143</td>\n",
       "      <td>133.477302</td>\n",
       "      <td>142.392257</td>\n",
       "      <td>147.622021</td>\n",
       "      <td>157.887842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>319.757639</td>\n",
       "      <td>281.177082</td>\n",
       "      <td>279.579042</td>\n",
       "      <td>240.198417</td>\n",
       "      <td>228.687678</td>\n",
       "      <td>227.537923</td>\n",
       "      <td>230.776717</td>\n",
       "      <td>229.668158</td>\n",
       "      <td>226.060855</td>\n",
       "      <td>260.403675</td>\n",
       "      <td>283.436860</td>\n",
       "      <td>323.131433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>212.936038</td>\n",
       "      <td>165.048189</td>\n",
       "      <td>156.966087</td>\n",
       "      <td>141.281841</td>\n",
       "      <td>138.390691</td>\n",
       "      <td>135.407719</td>\n",
       "      <td>138.247417</td>\n",
       "      <td>132.720426</td>\n",
       "      <td>135.592074</td>\n",
       "      <td>147.145661</td>\n",
       "      <td>157.466356</td>\n",
       "      <td>169.989886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>636.889283</td>\n",
       "      <td>587.571281</td>\n",
       "      <td>715.958104</td>\n",
       "      <td>685.919098</td>\n",
       "      <td>597.365085</td>\n",
       "      <td>475.169224</td>\n",
       "      <td>467.205432</td>\n",
       "      <td>478.384166</td>\n",
       "      <td>507.746454</td>\n",
       "      <td>557.249736</td>\n",
       "      <td>565.271463</td>\n",
       "      <td>603.364795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>475.484800</td>\n",
       "      <td>402.400621</td>\n",
       "      <td>400.968486</td>\n",
       "      <td>361.098933</td>\n",
       "      <td>339.872479</td>\n",
       "      <td>270.054946</td>\n",
       "      <td>275.860401</td>\n",
       "      <td>281.862637</td>\n",
       "      <td>293.809702</td>\n",
       "      <td>341.432573</td>\n",
       "      <td>416.076795</td>\n",
       "      <td>506.863190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>455.374399</td>\n",
       "      <td>372.407903</td>\n",
       "      <td>349.220337</td>\n",
       "      <td>355.733947</td>\n",
       "      <td>213.915435</td>\n",
       "      <td>194.473441</td>\n",
       "      <td>193.479341</td>\n",
       "      <td>200.056858</td>\n",
       "      <td>213.628613</td>\n",
       "      <td>261.986663</td>\n",
       "      <td>320.610028</td>\n",
       "      <td>389.115239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>264.881644</td>\n",
       "      <td>226.552965</td>\n",
       "      <td>240.217036</td>\n",
       "      <td>215.445147</td>\n",
       "      <td>226.141542</td>\n",
       "      <td>207.719002</td>\n",
       "      <td>215.880305</td>\n",
       "      <td>216.961960</td>\n",
       "      <td>223.893901</td>\n",
       "      <td>235.857788</td>\n",
       "      <td>252.513716</td>\n",
       "      <td>259.287229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id     2018-01     2018-02  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c  140.550585  126.254200   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82  633.924615  611.238636   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734  232.015137  199.593366   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a  180.492360  156.647834   \n",
       "4     0x005958406351bb29580475df698b5f1070096397  319.757639  281.177082   \n",
       "...                                          ...         ...         ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f  212.936038  165.048189   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb  636.889283  587.571281   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5  475.484800  402.400621   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02  455.374399  372.407903   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4  264.881644  226.552965   \n",
       "\n",
       "         2018-03     2018-04     2018-05     2018-06     2018-07     2018-08  \\\n",
       "0     129.486919  109.331424  107.760850  108.498140  113.134209  122.598525   \n",
       "1     546.933045  472.594531  458.690497  407.904490  395.598676  416.875115   \n",
       "2     211.323644  189.028358  184.301136  178.100952  180.298847  190.635324   \n",
       "3     152.640211  133.144262  139.092132  136.542045  134.197360  137.901143   \n",
       "4     279.579042  240.198417  228.687678  227.537923  230.776717  229.668158   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3243  156.966087  141.281841  138.390691  135.407719  138.247417  132.720426   \n",
       "3244  715.958104  685.919098  597.365085  475.169224  467.205432  478.384166   \n",
       "3245  400.968486  361.098933  339.872479  270.054946  275.860401  281.862637   \n",
       "3246  349.220337  355.733947  213.915435  194.473441  193.479341  200.056858   \n",
       "3247  240.217036  215.445147  226.141542  207.719002  215.880305  216.961960   \n",
       "\n",
       "         2018-09     2018-10     2018-11     2018-12  \n",
       "0     121.132539  126.843396   93.682955  112.089917  \n",
       "1     455.260060  520.178718  601.147425  640.695160  \n",
       "2     186.842949  199.120596  203.736933  246.390543  \n",
       "3     133.477302  142.392257  147.622021  157.887842  \n",
       "4     226.060855  260.403675  283.436860  323.131433  \n",
       "...          ...         ...         ...         ...  \n",
       "3243  135.592074  147.145661  157.466356  169.989886  \n",
       "3244  507.746454  557.249736  565.271463  603.364795  \n",
       "3245  293.809702  341.432573  416.076795  506.863190  \n",
       "3246  213.628613  261.986663  320.610028  389.115239  \n",
       "3247  223.893901  235.857788  252.513716  259.287229  \n",
       "\n",
       "[3248 rows x 13 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_monthly_forecasts.rename(columns={\"Jan\":\"2018-01\", \"Feb\":\"2018-02\",\"Mar\":\"2018-03\",\"Apr\":\"2018-04\",\"May\":\"2018-05\",\"Jun\":\"2018-06\",\"Jul\":\"2018-07\",\"Aug\":\"2018-08\",\"Sep\":\"2018-09\",\"Oct\":\"2018-10\",\"Nov\":\"2018-11\",\"Dec\":\"2018-12\"}, inplace=True)\n",
    "df_monthly_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructuring forecasts into daily predictions to plot on top of monthly preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <th>2018-01-02 00:00:00</th>\n",
       "      <th>2018-01-03 00:00:00</th>\n",
       "      <th>2018-01-04 00:00:00</th>\n",
       "      <th>2018-01-05 00:00:00</th>\n",
       "      <th>2018-01-06 00:00:00</th>\n",
       "      <th>2018-01-07 00:00:00</th>\n",
       "      <th>2018-01-08 00:00:00</th>\n",
       "      <th>2018-01-09 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-12-22 00:00:00</th>\n",
       "      <th>2018-12-23 00:00:00</th>\n",
       "      <th>2018-12-24 00:00:00</th>\n",
       "      <th>2018-12-25 00:00:00</th>\n",
       "      <th>2018-12-26 00:00:00</th>\n",
       "      <th>2018-12-27 00:00:00</th>\n",
       "      <th>2018-12-28 00:00:00</th>\n",
       "      <th>2018-12-29 00:00:00</th>\n",
       "      <th>2018-12-30 00:00:00</th>\n",
       "      <th>2018-12-31 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>4.353847</td>\n",
       "      <td>4.501818</td>\n",
       "      <td>4.351720</td>\n",
       "      <td>4.386283</td>\n",
       "      <td>4.211287</td>\n",
       "      <td>4.259761</td>\n",
       "      <td>4.415535</td>\n",
       "      <td>4.729433</td>\n",
       "      <td>4.694657</td>\n",
       "      <td>...</td>\n",
       "      <td>3.965199</td>\n",
       "      <td>3.690685</td>\n",
       "      <td>3.354721</td>\n",
       "      <td>3.472773</td>\n",
       "      <td>3.301716</td>\n",
       "      <td>3.493809</td>\n",
       "      <td>3.720217</td>\n",
       "      <td>3.759964</td>\n",
       "      <td>3.876689</td>\n",
       "      <td>3.443136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>18.180613</td>\n",
       "      <td>17.508603</td>\n",
       "      <td>19.900858</td>\n",
       "      <td>17.889860</td>\n",
       "      <td>17.649567</td>\n",
       "      <td>18.162448</td>\n",
       "      <td>20.620796</td>\n",
       "      <td>19.374866</td>\n",
       "      <td>20.863582</td>\n",
       "      <td>...</td>\n",
       "      <td>21.022116</td>\n",
       "      <td>21.085510</td>\n",
       "      <td>20.604922</td>\n",
       "      <td>18.299270</td>\n",
       "      <td>18.890067</td>\n",
       "      <td>19.470799</td>\n",
       "      <td>21.201166</td>\n",
       "      <td>18.356480</td>\n",
       "      <td>17.862164</td>\n",
       "      <td>16.990427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>7.586026</td>\n",
       "      <td>7.482057</td>\n",
       "      <td>7.539005</td>\n",
       "      <td>7.534735</td>\n",
       "      <td>7.344769</td>\n",
       "      <td>7.831904</td>\n",
       "      <td>7.939284</td>\n",
       "      <td>7.399169</td>\n",
       "      <td>7.480933</td>\n",
       "      <td>...</td>\n",
       "      <td>8.349640</td>\n",
       "      <td>8.207092</td>\n",
       "      <td>8.089813</td>\n",
       "      <td>7.820292</td>\n",
       "      <td>7.956090</td>\n",
       "      <td>8.228444</td>\n",
       "      <td>8.472785</td>\n",
       "      <td>8.527773</td>\n",
       "      <td>8.748534</td>\n",
       "      <td>8.431415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>5.553010</td>\n",
       "      <td>5.401829</td>\n",
       "      <td>5.423814</td>\n",
       "      <td>5.527975</td>\n",
       "      <td>5.648885</td>\n",
       "      <td>6.122810</td>\n",
       "      <td>6.280981</td>\n",
       "      <td>5.492197</td>\n",
       "      <td>5.724267</td>\n",
       "      <td>...</td>\n",
       "      <td>5.315330</td>\n",
       "      <td>5.197326</td>\n",
       "      <td>4.555704</td>\n",
       "      <td>4.858983</td>\n",
       "      <td>4.459111</td>\n",
       "      <td>4.654678</td>\n",
       "      <td>5.164378</td>\n",
       "      <td>5.396200</td>\n",
       "      <td>5.182891</td>\n",
       "      <td>4.918171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>10.392214</td>\n",
       "      <td>10.059121</td>\n",
       "      <td>10.457250</td>\n",
       "      <td>10.256895</td>\n",
       "      <td>10.448037</td>\n",
       "      <td>10.407594</td>\n",
       "      <td>10.445362</td>\n",
       "      <td>10.428155</td>\n",
       "      <td>10.177593</td>\n",
       "      <td>...</td>\n",
       "      <td>11.021410</td>\n",
       "      <td>10.805441</td>\n",
       "      <td>11.128754</td>\n",
       "      <td>10.874190</td>\n",
       "      <td>10.388398</td>\n",
       "      <td>10.688234</td>\n",
       "      <td>10.928356</td>\n",
       "      <td>10.906187</td>\n",
       "      <td>10.740353</td>\n",
       "      <td>10.700820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>6.809315</td>\n",
       "      <td>6.575352</td>\n",
       "      <td>6.294596</td>\n",
       "      <td>6.638904</td>\n",
       "      <td>6.891664</td>\n",
       "      <td>6.890663</td>\n",
       "      <td>6.972688</td>\n",
       "      <td>6.982451</td>\n",
       "      <td>7.171936</td>\n",
       "      <td>...</td>\n",
       "      <td>5.578374</td>\n",
       "      <td>5.470050</td>\n",
       "      <td>5.232342</td>\n",
       "      <td>5.322837</td>\n",
       "      <td>5.294029</td>\n",
       "      <td>5.316758</td>\n",
       "      <td>5.829170</td>\n",
       "      <td>5.884318</td>\n",
       "      <td>5.760542</td>\n",
       "      <td>5.340721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>19.651403</td>\n",
       "      <td>19.804686</td>\n",
       "      <td>19.716493</td>\n",
       "      <td>19.309846</td>\n",
       "      <td>19.482740</td>\n",
       "      <td>19.369375</td>\n",
       "      <td>19.282292</td>\n",
       "      <td>20.414909</td>\n",
       "      <td>20.992571</td>\n",
       "      <td>...</td>\n",
       "      <td>18.408380</td>\n",
       "      <td>18.524724</td>\n",
       "      <td>18.448581</td>\n",
       "      <td>18.625843</td>\n",
       "      <td>17.947400</td>\n",
       "      <td>19.804280</td>\n",
       "      <td>20.893753</td>\n",
       "      <td>19.815281</td>\n",
       "      <td>19.449666</td>\n",
       "      <td>18.829941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>16.761501</td>\n",
       "      <td>15.273817</td>\n",
       "      <td>14.973423</td>\n",
       "      <td>13.618518</td>\n",
       "      <td>14.073222</td>\n",
       "      <td>14.123604</td>\n",
       "      <td>14.753594</td>\n",
       "      <td>16.434244</td>\n",
       "      <td>14.769206</td>\n",
       "      <td>...</td>\n",
       "      <td>14.012255</td>\n",
       "      <td>16.133886</td>\n",
       "      <td>17.777465</td>\n",
       "      <td>15.229708</td>\n",
       "      <td>14.973610</td>\n",
       "      <td>15.517242</td>\n",
       "      <td>16.015067</td>\n",
       "      <td>15.390865</td>\n",
       "      <td>15.948001</td>\n",
       "      <td>17.091049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>13.508463</td>\n",
       "      <td>13.396795</td>\n",
       "      <td>12.896261</td>\n",
       "      <td>13.282461</td>\n",
       "      <td>13.112625</td>\n",
       "      <td>13.636503</td>\n",
       "      <td>13.570401</td>\n",
       "      <td>15.366223</td>\n",
       "      <td>14.956975</td>\n",
       "      <td>...</td>\n",
       "      <td>11.822467</td>\n",
       "      <td>11.983668</td>\n",
       "      <td>12.358573</td>\n",
       "      <td>12.491361</td>\n",
       "      <td>12.336659</td>\n",
       "      <td>13.119906</td>\n",
       "      <td>12.969230</td>\n",
       "      <td>12.647995</td>\n",
       "      <td>11.819372</td>\n",
       "      <td>12.270658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>8.674380</td>\n",
       "      <td>8.608441</td>\n",
       "      <td>8.380156</td>\n",
       "      <td>8.334676</td>\n",
       "      <td>8.338389</td>\n",
       "      <td>8.695296</td>\n",
       "      <td>8.929876</td>\n",
       "      <td>8.270810</td>\n",
       "      <td>8.118026</td>\n",
       "      <td>...</td>\n",
       "      <td>7.920858</td>\n",
       "      <td>8.044422</td>\n",
       "      <td>7.991548</td>\n",
       "      <td>8.267834</td>\n",
       "      <td>8.529942</td>\n",
       "      <td>8.754458</td>\n",
       "      <td>8.892898</td>\n",
       "      <td>8.561983</td>\n",
       "      <td>8.348135</td>\n",
       "      <td>8.611089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id  2018-01-01 00:00:00  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c             4.353847   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82            18.180613   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734             7.586026   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a             5.553010   \n",
       "4     0x005958406351bb29580475df698b5f1070096397            10.392214   \n",
       "...                                          ...                  ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f             6.809315   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb            19.651403   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5            16.761501   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02            13.508463   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4             8.674380   \n",
       "\n",
       "      2018-01-02 00:00:00  2018-01-03 00:00:00  2018-01-04 00:00:00  \\\n",
       "0                4.501818             4.351720             4.386283   \n",
       "1               17.508603            19.900858            17.889860   \n",
       "2                7.482057             7.539005             7.534735   \n",
       "3                5.401829             5.423814             5.527975   \n",
       "4               10.059121            10.457250            10.256895   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             6.575352             6.294596             6.638904   \n",
       "3244            19.804686            19.716493            19.309846   \n",
       "3245            15.273817            14.973423            13.618518   \n",
       "3246            13.396795            12.896261            13.282461   \n",
       "3247             8.608441             8.380156             8.334676   \n",
       "\n",
       "      2018-01-05 00:00:00  2018-01-06 00:00:00  2018-01-07 00:00:00  \\\n",
       "0                4.211287             4.259761             4.415535   \n",
       "1               17.649567            18.162448            20.620796   \n",
       "2                7.344769             7.831904             7.939284   \n",
       "3                5.648885             6.122810             6.280981   \n",
       "4               10.448037            10.407594            10.445362   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             6.891664             6.890663             6.972688   \n",
       "3244            19.482740            19.369375            19.282292   \n",
       "3245            14.073222            14.123604            14.753594   \n",
       "3246            13.112625            13.636503            13.570401   \n",
       "3247             8.338389             8.695296             8.929876   \n",
       "\n",
       "      2018-01-08 00:00:00  2018-01-09 00:00:00  ...  2018-12-22 00:00:00  \\\n",
       "0                4.729433             4.694657  ...             3.965199   \n",
       "1               19.374866            20.863582  ...            21.022116   \n",
       "2                7.399169             7.480933  ...             8.349640   \n",
       "3                5.492197             5.724267  ...             5.315330   \n",
       "4               10.428155            10.177593  ...            11.021410   \n",
       "...                   ...                  ...  ...                  ...   \n",
       "3243             6.982451             7.171936  ...             5.578374   \n",
       "3244            20.414909            20.992571  ...            18.408380   \n",
       "3245            16.434244            14.769206  ...            14.012255   \n",
       "3246            15.366223            14.956975  ...            11.822467   \n",
       "3247             8.270810             8.118026  ...             7.920858   \n",
       "\n",
       "      2018-12-23 00:00:00  2018-12-24 00:00:00  2018-12-25 00:00:00  \\\n",
       "0                3.690685             3.354721             3.472773   \n",
       "1               21.085510            20.604922            18.299270   \n",
       "2                8.207092             8.089813             7.820292   \n",
       "3                5.197326             4.555704             4.858983   \n",
       "4               10.805441            11.128754            10.874190   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             5.470050             5.232342             5.322837   \n",
       "3244            18.524724            18.448581            18.625843   \n",
       "3245            16.133886            17.777465            15.229708   \n",
       "3246            11.983668            12.358573            12.491361   \n",
       "3247             8.044422             7.991548             8.267834   \n",
       "\n",
       "      2018-12-26 00:00:00  2018-12-27 00:00:00  2018-12-28 00:00:00  \\\n",
       "0                3.301716             3.493809             3.720217   \n",
       "1               18.890067            19.470799            21.201166   \n",
       "2                7.956090             8.228444             8.472785   \n",
       "3                4.459111             4.654678             5.164378   \n",
       "4               10.388398            10.688234            10.928356   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             5.294029             5.316758             5.829170   \n",
       "3244            17.947400            19.804280            20.893753   \n",
       "3245            14.973610            15.517242            16.015067   \n",
       "3246            12.336659            13.119906            12.969230   \n",
       "3247             8.529942             8.754458             8.892898   \n",
       "\n",
       "      2018-12-29 00:00:00  2018-12-30 00:00:00  2018-12-31 00:00:00  \n",
       "0                3.759964             3.876689             3.443136  \n",
       "1               18.356480            17.862164            16.990427  \n",
       "2                8.527773             8.748534             8.431415  \n",
       "3                5.396200             5.182891             4.918171  \n",
       "4               10.906187            10.740353            10.700820  \n",
       "...                   ...                  ...                  ...  \n",
       "3243             5.884318             5.760542             5.340721  \n",
       "3244            19.815281            19.449666            18.829941  \n",
       "3245            15.390865            15.948001            17.091049  \n",
       "3246            12.647995            11.819372            12.270658  \n",
       "3247             8.561983             8.348135             8.611089  \n",
       "\n",
       "[3248 rows x 366 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#daily forecasts to plot on top of monthly\n",
    "df_daily_forecasts = main_effects_forecasts.groupby([\"meter_id\",\"date\"])[\"meter_reading\"].sum().unstack()\n",
    "\n",
    "#resetting the index \n",
    "df_daily_forecasts.reset_index(inplace=True)\n",
    "df_daily_forecasts.index.name = None # removing index column\n",
    "df_daily_forecasts.columns.name = None # removing columns name\n",
    "\n",
    "df_daily_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading training data and aggregating into months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d66179acefc4cc1ad27fcee0c3ca91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2017-01-02</th>\n",
       "      <th>2017-01-03</th>\n",
       "      <th>2017-01-04</th>\n",
       "      <th>2017-01-05</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017-01-07</th>\n",
       "      <th>2017-01-08</th>\n",
       "      <th>2017-01-09</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-12-22</th>\n",
       "      <th>2017-12-23</th>\n",
       "      <th>2017-12-24</th>\n",
       "      <th>2017-12-25</th>\n",
       "      <th>2017-12-26</th>\n",
       "      <th>2017-12-27</th>\n",
       "      <th>2017-12-28</th>\n",
       "      <th>2017-12-29</th>\n",
       "      <th>2017-12-30</th>\n",
       "      <th>2017-12-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.030</td>\n",
       "      <td>5.397</td>\n",
       "      <td>5.1075</td>\n",
       "      <td>4.818</td>\n",
       "      <td>3.931</td>\n",
       "      <td>4.2170</td>\n",
       "      <td>4.503</td>\n",
       "      <td>4.8160</td>\n",
       "      <td>5.129</td>\n",
       "      <td>5.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x459c834d1f6cfb5b734b82aa9f5410fa97fb70da</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.101</td>\n",
       "      <td>14.327</td>\n",
       "      <td>14.6315</td>\n",
       "      <td>14.936</td>\n",
       "      <td>16.174</td>\n",
       "      <td>20.3960</td>\n",
       "      <td>24.618</td>\n",
       "      <td>19.8925</td>\n",
       "      <td>15.167</td>\n",
       "      <td>11.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x4a1ed36825360a058cec2bdd409fc2459e1ce54f</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.201</td>\n",
       "      <td>7.320</td>\n",
       "      <td>7.3520</td>\n",
       "      <td>7.384</td>\n",
       "      <td>14.425</td>\n",
       "      <td>16.0650</td>\n",
       "      <td>17.705</td>\n",
       "      <td>13.3355</td>\n",
       "      <td>8.966</td>\n",
       "      <td>4.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x5b76d3c0e0aefc6e0a8d1d031f96388a23263407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.833</td>\n",
       "      <td>12.477</td>\n",
       "      <td>11.7255</td>\n",
       "      <td>10.974</td>\n",
       "      <td>19.646</td>\n",
       "      <td>21.8195</td>\n",
       "      <td>23.993</td>\n",
       "      <td>19.9170</td>\n",
       "      <td>15.841</td>\n",
       "      <td>14.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x943ebe39ef2be6ef807c42c5a647e27112ca5b0f</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>39.440</td>\n",
       "      <td>35.538</td>\n",
       "      <td>21.9445</td>\n",
       "      <td>8.351</td>\n",
       "      <td>9.957</td>\n",
       "      <td>17.9140</td>\n",
       "      <td>25.871</td>\n",
       "      <td>36.0725</td>\n",
       "      <td>46.274</td>\n",
       "      <td>16.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0x7dd7a7b8ee1bec7c44b24f738c752482f6161065</td>\n",
       "      <td>2.317</td>\n",
       "      <td>2.301</td>\n",
       "      <td>2.352</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.229</td>\n",
       "      <td>2.354</td>\n",
       "      <td>2.397</td>\n",
       "      <td>2.397</td>\n",
       "      <td>2.269</td>\n",
       "      <td>...</td>\n",
       "      <td>9.390</td>\n",
       "      <td>9.231</td>\n",
       "      <td>9.2235</td>\n",
       "      <td>9.216</td>\n",
       "      <td>9.336</td>\n",
       "      <td>9.6840</td>\n",
       "      <td>10.032</td>\n",
       "      <td>9.8945</td>\n",
       "      <td>9.757</td>\n",
       "      <td>9.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xfdaf9f857621ec06f2cf801f42a020a322835090</td>\n",
       "      <td>14.437</td>\n",
       "      <td>16.274</td>\n",
       "      <td>7.031</td>\n",
       "      <td>17.018</td>\n",
       "      <td>17.603</td>\n",
       "      <td>15.005</td>\n",
       "      <td>8.987</td>\n",
       "      <td>8.490</td>\n",
       "      <td>10.136</td>\n",
       "      <td>...</td>\n",
       "      <td>4.141</td>\n",
       "      <td>2.828</td>\n",
       "      <td>3.8230</td>\n",
       "      <td>4.818</td>\n",
       "      <td>3.357</td>\n",
       "      <td>8.1315</td>\n",
       "      <td>12.906</td>\n",
       "      <td>8.0140</td>\n",
       "      <td>3.122</td>\n",
       "      <td>3.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xd28f2f001e0cd4d6c121a3cb2e1427207e170e18</td>\n",
       "      <td>7.824</td>\n",
       "      <td>7.517</td>\n",
       "      <td>5.398</td>\n",
       "      <td>6.788</td>\n",
       "      <td>7.360</td>\n",
       "      <td>6.898</td>\n",
       "      <td>7.321</td>\n",
       "      <td>8.042</td>\n",
       "      <td>8.207</td>\n",
       "      <td>...</td>\n",
       "      <td>6.767</td>\n",
       "      <td>5.919</td>\n",
       "      <td>5.9980</td>\n",
       "      <td>6.077</td>\n",
       "      <td>7.761</td>\n",
       "      <td>6.6080</td>\n",
       "      <td>5.455</td>\n",
       "      <td>5.5670</td>\n",
       "      <td>5.679</td>\n",
       "      <td>8.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0x47218b46abb2fcaade487a211911406dc6e13730</td>\n",
       "      <td>23.965</td>\n",
       "      <td>28.689</td>\n",
       "      <td>27.664</td>\n",
       "      <td>29.229</td>\n",
       "      <td>29.548</td>\n",
       "      <td>27.909</td>\n",
       "      <td>26.923</td>\n",
       "      <td>21.277</td>\n",
       "      <td>23.452</td>\n",
       "      <td>...</td>\n",
       "      <td>20.747</td>\n",
       "      <td>19.979</td>\n",
       "      <td>20.1925</td>\n",
       "      <td>20.406</td>\n",
       "      <td>23.668</td>\n",
       "      <td>27.7900</td>\n",
       "      <td>31.912</td>\n",
       "      <td>29.1125</td>\n",
       "      <td>26.313</td>\n",
       "      <td>24.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>11.302</td>\n",
       "      <td>14.178</td>\n",
       "      <td>15.499</td>\n",
       "      <td>11.853</td>\n",
       "      <td>17.431</td>\n",
       "      <td>14.506</td>\n",
       "      <td>12.812</td>\n",
       "      <td>10.472</td>\n",
       "      <td>10.879</td>\n",
       "      <td>...</td>\n",
       "      <td>14.036</td>\n",
       "      <td>15.990</td>\n",
       "      <td>15.5505</td>\n",
       "      <td>15.111</td>\n",
       "      <td>16.506</td>\n",
       "      <td>18.7585</td>\n",
       "      <td>21.011</td>\n",
       "      <td>19.2040</td>\n",
       "      <td>17.397</td>\n",
       "      <td>15.237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id  2017-01-01  2017-01-02  \\\n",
       "0     0xa62b9f23553ff183f61e2bf943aab3d5983d02d7       0.000       0.000   \n",
       "1     0x459c834d1f6cfb5b734b82aa9f5410fa97fb70da       0.000       0.000   \n",
       "2     0x4a1ed36825360a058cec2bdd409fc2459e1ce54f       0.000       0.000   \n",
       "3     0x5b76d3c0e0aefc6e0a8d1d031f96388a23263407       0.000       0.000   \n",
       "4     0x943ebe39ef2be6ef807c42c5a647e27112ca5b0f       0.000       0.000   \n",
       "...                                          ...         ...         ...   \n",
       "3243  0x7dd7a7b8ee1bec7c44b24f738c752482f6161065       2.317       2.301   \n",
       "3244  0xfdaf9f857621ec06f2cf801f42a020a322835090      14.437      16.274   \n",
       "3245  0xd28f2f001e0cd4d6c121a3cb2e1427207e170e18       7.824       7.517   \n",
       "3246  0x47218b46abb2fcaade487a211911406dc6e13730      23.965      28.689   \n",
       "3247  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd      11.302      14.178   \n",
       "\n",
       "      2017-01-03  2017-01-04  2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "0          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "1          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "2          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "3          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "4          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3243       2.352       2.516       2.229       2.354       2.397       2.397   \n",
       "3244       7.031      17.018      17.603      15.005       8.987       8.490   \n",
       "3245       5.398       6.788       7.360       6.898       7.321       8.042   \n",
       "3246      27.664      29.229      29.548      27.909      26.923      21.277   \n",
       "3247      15.499      11.853      17.431      14.506      12.812      10.472   \n",
       "\n",
       "      2017-01-09  ...  2017-12-22  2017-12-23  2017-12-24  2017-12-25  \\\n",
       "0          0.000  ...       4.030       5.397      5.1075       4.818   \n",
       "1          0.000  ...      13.101      14.327     14.6315      14.936   \n",
       "2          0.000  ...      10.201       7.320      7.3520       7.384   \n",
       "3          0.000  ...      14.833      12.477     11.7255      10.974   \n",
       "4          0.000  ...      39.440      35.538     21.9445       8.351   \n",
       "...          ...  ...         ...         ...         ...         ...   \n",
       "3243       2.269  ...       9.390       9.231      9.2235       9.216   \n",
       "3244      10.136  ...       4.141       2.828      3.8230       4.818   \n",
       "3245       8.207  ...       6.767       5.919      5.9980       6.077   \n",
       "3246      23.452  ...      20.747      19.979     20.1925      20.406   \n",
       "3247      10.879  ...      14.036      15.990     15.5505      15.111   \n",
       "\n",
       "      2017-12-26  2017-12-27  2017-12-28  2017-12-29  2017-12-30  2017-12-31  \n",
       "0          3.931      4.2170       4.503      4.8160       5.129       5.395  \n",
       "1         16.174     20.3960      24.618     19.8925      15.167      11.751  \n",
       "2         14.425     16.0650      17.705     13.3355       8.966       4.633  \n",
       "3         19.646     21.8195      23.993     19.9170      15.841      14.452  \n",
       "4          9.957     17.9140      25.871     36.0725      46.274      16.901  \n",
       "...          ...         ...         ...         ...         ...         ...  \n",
       "3243       9.336      9.6840      10.032      9.8945       9.757       9.480  \n",
       "3244       3.357      8.1315      12.906      8.0140       3.122       3.401  \n",
       "3245       7.761      6.6080       5.455      5.5670       5.679       8.148  \n",
       "3246      23.668     27.7900      31.912     29.1125      26.313      24.201  \n",
       "3247      16.506     18.7585      21.011     19.2040      17.397      15.237  \n",
       "\n",
       "[3248 rows x 366 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2017-01</th>\n",
       "      <th>2017-02</th>\n",
       "      <th>2017-03</th>\n",
       "      <th>2017-04</th>\n",
       "      <th>2017-05</th>\n",
       "      <th>2017-06</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.39450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>553.18400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>368.90957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>534.84650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>946.06400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>72.7050</td>\n",
       "      <td>63.245</td>\n",
       "      <td>68.4335</td>\n",
       "      <td>66.6265</td>\n",
       "      <td>69.0480</td>\n",
       "      <td>100.430</td>\n",
       "      <td>177.1735</td>\n",
       "      <td>177.4100</td>\n",
       "      <td>216.7245</td>\n",
       "      <td>279.164500</td>\n",
       "      <td>351.481000</td>\n",
       "      <td>312.08800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>371.4390</td>\n",
       "      <td>269.691</td>\n",
       "      <td>179.3430</td>\n",
       "      <td>141.6590</td>\n",
       "      <td>138.4835</td>\n",
       "      <td>122.910</td>\n",
       "      <td>164.2285</td>\n",
       "      <td>100.9610</td>\n",
       "      <td>118.0520</td>\n",
       "      <td>123.135500</td>\n",
       "      <td>187.140000</td>\n",
       "      <td>186.88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>209.8065</td>\n",
       "      <td>169.858</td>\n",
       "      <td>184.0130</td>\n",
       "      <td>166.7280</td>\n",
       "      <td>134.1760</td>\n",
       "      <td>169.489</td>\n",
       "      <td>157.5775</td>\n",
       "      <td>165.9640</td>\n",
       "      <td>177.0105</td>\n",
       "      <td>185.701833</td>\n",
       "      <td>192.288667</td>\n",
       "      <td>200.61950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>845.6630</td>\n",
       "      <td>608.449</td>\n",
       "      <td>588.7765</td>\n",
       "      <td>503.3050</td>\n",
       "      <td>291.1320</td>\n",
       "      <td>177.605</td>\n",
       "      <td>183.5345</td>\n",
       "      <td>182.0350</td>\n",
       "      <td>244.2255</td>\n",
       "      <td>371.458333</td>\n",
       "      <td>695.878667</td>\n",
       "      <td>858.83950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>428.7345</td>\n",
       "      <td>670.505</td>\n",
       "      <td>462.1050</td>\n",
       "      <td>354.8660</td>\n",
       "      <td>287.9950</td>\n",
       "      <td>200.321</td>\n",
       "      <td>227.0855</td>\n",
       "      <td>231.7585</td>\n",
       "      <td>246.3005</td>\n",
       "      <td>344.210167</td>\n",
       "      <td>516.290333</td>\n",
       "      <td>734.61800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id   2017-01  2017-02   2017-03  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c    0.0000    0.000    0.0000   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82    0.0000    0.000    0.0000   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734    0.0000    0.000    0.0000   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a    0.0000    0.000    0.0000   \n",
       "4     0x005958406351bb29580475df698b5f1070096397    0.0000    0.000    0.0000   \n",
       "...                                          ...       ...      ...       ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f   72.7050   63.245   68.4335   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb  371.4390  269.691  179.3430   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5  209.8065  169.858  184.0130   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02  845.6630  608.449  588.7765   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4  428.7345  670.505  462.1050   \n",
       "\n",
       "       2017-04   2017-05  2017-06   2017-07   2017-08   2017-09     2017-10  \\\n",
       "0       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "1       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "2       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "3       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "4       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "...        ...       ...      ...       ...       ...       ...         ...   \n",
       "3243   66.6265   69.0480  100.430  177.1735  177.4100  216.7245  279.164500   \n",
       "3244  141.6590  138.4835  122.910  164.2285  100.9610  118.0520  123.135500   \n",
       "3245  166.7280  134.1760  169.489  157.5775  165.9640  177.0105  185.701833   \n",
       "3246  503.3050  291.1320  177.605  183.5345  182.0350  244.2255  371.458333   \n",
       "3247  354.8660  287.9950  200.321  227.0855  231.7585  246.3005  344.210167   \n",
       "\n",
       "         2017-11    2017-12  \n",
       "0       0.000000  128.39450  \n",
       "1       0.000000  553.18400  \n",
       "2       0.000000  368.90957  \n",
       "3       0.000000  534.84650  \n",
       "4       0.000000  946.06400  \n",
       "...          ...        ...  \n",
       "3243  351.481000  312.08800  \n",
       "3244  187.140000  186.88400  \n",
       "3245  192.288667  200.61950  \n",
       "3246  695.878667  858.83950  \n",
       "3247  516.290333  734.61800  \n",
       "\n",
       "[3248 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading the training data\n",
    "print(\"training data\")\n",
    "df_train_daily = pd.read_pickle(\"../Data/Preprocessed_Data/consumption_daily_nan_interpolated.pkl\").fillna(0)\n",
    "\n",
    "#aggregating up into months\n",
    "meter_id=df_monthly_forecasts[\"meter_id\"]\n",
    "df_train_monthly = pd.DataFrame(columns=[\"meter_id\"])\n",
    "df_train_monthly[\"meter_id\"] = meter_id\n",
    "\n",
    "\n",
    "#for each month in the range of dates\n",
    "resample_size=\"M\"\n",
    "for new_sample in tqdm(pd.date_range(datetime.datetime(2017, 1, 1), datetime.datetime(2017, 12, 31), freq = resample_size),position=0):\n",
    "\n",
    "    #get this columns name as a string\n",
    "    columnName = str(new_sample.date())[:7]\n",
    "    #get all columns that relate to this new sample\n",
    "    columns = [i for i in df_train_daily.columns.values[1:] if i.startswith(columnName)]\n",
    "\n",
    "    #sum these up into a value for the new sample size\n",
    "    df_train_monthly[columnName] = df_train_daily[columns].sum(axis=1)\n",
    "\n",
    "display(df_train_daily)\n",
    "display(df_train_monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the predictions against the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots = 10\n",
    "for pid in tqdm(range(0,3248)):\n",
    "    if pid>num_plots:\n",
    "        break\n",
    "        \n",
    "    #getting the row corresponding to this meter_id\n",
    "    meter_id = df_daily_forecasts.iloc[pid,0]\n",
    "    this_train_month = df_train_monthly.loc[df_train_monthly['meter_id'] == meter_id].T[1:]\n",
    "    this_preds_month = df_monthly_forecasts.loc[df_train_monthly['meter_id'] == meter_id].T[1:]\n",
    "    \n",
    "    #converting index to datetime for ease of plots key\n",
    "    this_train_month.index=pd.to_datetime(this_train_month.index)\n",
    "    this_preds_month.index=pd.to_datetime(this_preds_month.index)\n",
    "    \n",
    "    #creating figure\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    \n",
    "    #plotting the monthly predictions\n",
    "    plt.title(\"Meter '\"+str(meter_id)+\"' monthly forecasts and historical data\", fontsize=15)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Energy Usage kWh\")\n",
    "    plt.plot(this_train_month, label=\"training monthly energy\", lw=1,color=\"skyblue\", marker=\"x\")\n",
    "    plt.plot(this_preds_month, label=\"forecast monthly energy\", lw=1,color=\"mediumorchid\", marker=\"x\")\n",
    "    \n",
    "    #annotations\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.locator_params(nbins=24)\n",
    "    \n",
    "    #plt.show()\n",
    "    fig.savefig(f\"..\\\\Results\\\\Genetic Algorithm\\\\Plots\\\\forecasts\\\\main_effects\\\\p{population_size}_g{number_of_generations}_forecasts_{pid}_{meter_id}.png\")\n",
    "\n",
    "    fig.clf()\n",
    "    fig.clear()\n",
    "    plt.close()\n",
    "    del fig, this_train_month, this_preds_month\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle_tf",
   "language": "python",
   "name": "mle_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
