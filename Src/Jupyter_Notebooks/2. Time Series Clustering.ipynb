{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Time Series Clustering\n",
    "\n",
    "* Initially thought I would use 1 RNN based model for making predictions\n",
    "    * But in order to do this I would have to onehot encode the meter_id's (as ordinal would apply a linear relation between id's which doesn't exist)\n",
    "        * This would add an extra 3500 features and hence make the solution space sufficiently sparse that it is likely our model would give any sort of reasonable performance\n",
    "        \n",
    "* My next thought was that instead I could create a separate RNN based model for each of the meters\n",
    "    * Issue is the time complexity of doing so: even if each model only takes 1 minute to run (of which it is likely they will take longer) that would be 2.4 days of continuous computation\n",
    "        * And this would have to be repeated for hyperparameter tuning and changes to the model and methodology\n",
    "            * Very impractical especially considering time constraint of the competition\n",
    "            \n",
    "* My plan is to compromise between the 2 by clustering similar time series patterns and having a separate model for making predictions for each of the similar patterns\n",
    "    * May still have problems with the size of the onehot encoded variables\n",
    "    * Will also have problem with missing variables as will soon see\n",
    "    \n",
    "* If this proves impractical will instead consider models which can better handle categorical values such as decision tree based methods\n",
    "    * LGB\n",
    "    * XGBoost\n",
    "    * Etc.\n",
    "    \n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pd display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_energy = pd.read_pickle(\"../Data/Preprocessed_Data/consumption_daily_nan_interpolated.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at how many missing values we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many nans do we have\n",
    "nan_count = df_energy.drop(\"meter_id\", axis=1).isnull().sum(axis = 0)\n",
    "nan_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting number of missing values\n",
    "nan_count.plot(figsize=(9,9), title=\"Missing values per day\", xlabel=\"date\", ylabel=\"number of missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions:\n",
    "* We now know that the exists no single day where all meters have a reading\n",
    "* The best we can get is a minimum of 11 missing values per day for the last 6 days of the year\n",
    "    * This is likely as the battery in the meter has died.\n",
    "* For the last 28 days we only have 21 different meters we are missing values for\n",
    "* Before that it goes up exponentially making it impractical to use any more days than the last 28\n",
    "    \n",
    "* Plan is to:\n",
    "    1. Create new dataframe of just the last 28 days\n",
    "    2. Fill the missing values for the 15 that contain missing to 0\n",
    "    3. Cluster the dataframe\n",
    "    \n",
    "* Questions are:\n",
    "    * 1. just because they have similar patterns in december, are they likely to have similar patterns year round?\n",
    "        * eg is this enough data to make a real conclusion on\n",
    "    * 2. is it a good idea as the predicted values may not be accurate\n",
    "    * 3. May also still have an issue with the onehot encoding if one cluster has too many assigned meters\n",
    "        * so may be forced to use a different model\n",
    "        * could maybe get around this with a keras embedding layer\n",
    "        \n",
    "# 1. Creating new dataframe of just the last 29 days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last 29 days have most reasonable amount of missing values\n",
    "df_energy_last_29 = pd.concat([pd.DataFrame(df_energy[\"meter_id\"]),df_energy.iloc[:,-29:]], axis=1)\n",
    "df_energy_last_29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of missing values\n",
    "df_energy_last_29.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_energy_last_29=df_energy_last_29.fillna(0) # now filling the missing values with 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clustering the dataframe\n",
    "## Getting optimal euclidean K value via elbow\n",
    "\n",
    "* Euclidean distance : not particularly adapted for time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elbow method for getting best value for k\n",
    "# https://www.scikit-yb.org/en/latest/api/cluster/elbow.html\n",
    "if not os.path.exists(f\"../EDA/plots/consumption/clustering/euclidean/\"):\n",
    "    os.makedirs(f\"../EDA/plots/consumption/clustering/euclidean/\")\n",
    "\n",
    "\n",
    "clusterer = TimeSeriesKMeans()\n",
    "visualizer = KElbowVisualizer(clusterer, k=(1,25))\n",
    "\n",
    "visualizer.fit(df_energy_last_29.drop(\"meter_id\", axis=1))\n",
    "plt.title(\"TimeSeries kMeans Elbow\")\n",
    "plt.savefig(\"../EDA/plots/consumption/Clustering/euclidean/_elbow.png\")\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k value (how many clusters)\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering via euclidean kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the euclidean kmeans\n",
    "clusterer = TimeSeriesKMeans(n_clusters=k)\n",
    "clusterer.fit(df_energy_last_29.drop(\"meter_id\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the centroids\n",
    "centroids = clusterer.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting which meters belong to which cluster\n",
    "labels_euc = clusterer.predict(df_energy_last_29.drop(\"meter_id\",axis=1))\n",
    "labels_euc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the labels to the dataframe for ease of plotting\n",
    "df_energy_29_labels = df_energy_last_29\n",
    "df_energy_29_labels[\"labels\"]=labels_euc\n",
    "df_energy_29_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"../EDA/plots/consumption/clustering/euclidean/{k}/\"):\n",
    "    os.makedirs(f\"../EDA/plots/consumption/clustering/euclidean/{k}/\")\n",
    "\n",
    "# plotting the assigned points ontop of the centroids\n",
    "for i in tqdm(np.unique(labels_euc)):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"Euclidean centroid \"+str(i+1)+\" of \"+str(k)+\" assignments\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Energy usage\")\n",
    "    plt.locator_params(axis='x', nbins=10)\n",
    "    for j in tqdm(range(len(df_energy_29_labels.drop(\"meter_id\",axis=1))), leave=False):\n",
    "        if(df_energy_last_29.drop(\"meter_id\",axis=1).iloc[j].labels==i):\n",
    "            plt.plot(df_energy_last_29.drop(\"meter_id\",axis=1).iloc[j].T, color=\"blue\",lw=0.5, label=\"assigned\")\n",
    "    plt.plot(centroids[i], color=\"red\",lw=3, label=\"centroid\",ls=\"dashed\")\n",
    "    plt.savefig(f\"../EDA/plots/consumption/clustering/euclidean/{k}/cluster_{i}\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining based on meter_id to assign labels to the original dataset (with all meter readings)\n",
    "df_energy_labels = pd.merge(df_energy, df_energy_29_labels[{\"meter_id\",\"labels\"}], on=\"meter_id\",how=\"inner\")\n",
    "df_energy_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting all the assigned data on top of each other\n",
    "# last 29 days\n",
    "\n",
    "colours = [\"red\",\"blue\",\"green\",\"magenta\",\"cyan\",\"orange\",\"brown\",\"grey\",\"pink\",\"purple\",\"black\",\"olive\"]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(\"last 29 days clusters\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Energy usage\")\n",
    "plt.locator_params(axis='x', nbins=10)\n",
    "\n",
    "for i in tqdm(np.unique(labels_euc)):\n",
    "\n",
    "    \n",
    "    #plotting the one with no missing nans in december\n",
    "    for j in tqdm(range(len(df_energy_29_labels.drop(\"meter_id\",axis=1).drop(\"labels\",axis=1))), leave=False):\n",
    "        if(df_energy_29_labels.drop(\"meter_id\",axis=1).iloc[j].labels==i):\n",
    "            plt.plot(df_energy_29_labels.drop(\"meter_id\",axis=1).drop(\"labels\",axis=1).fillna(0).iloc[j].T, color=colours[i],lw=0.5)\n",
    "\n",
    "plt.savefig(f\"../EDA/plots/consumption/clustering/euclidean/{k}/clusters_last_29_ts.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting all the assigned data on top of each other\n",
    "# all data\n",
    "\n",
    "colours = [\"red\",\"blue\",\"green\",\"magenta\",\"cyan\",\"orange\",\"brown\",\"grey\",\"pink\",\"purple\",\"black\",\"olive\"]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(\"year long clusters\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Energy usage\")\n",
    "plt.locator_params(axis='x', nbins=10)\n",
    "\n",
    "for i in tqdm(np.unique(labels_euc)):\n",
    "\n",
    "    \n",
    "    #plotting the one with no missing nans in december\n",
    "    for j in tqdm(range(len(df_energy_labels.drop(\"meter_id\",axis=1).drop(\"labels\",axis=1))), leave=False):\n",
    "        if(df_energy_labels.drop(\"meter_id\",axis=1).iloc[j].labels==i):\n",
    "            plt.plot(df_energy_labels.drop(\"meter_id\",axis=1).drop(\"labels\",axis=1).fillna(0).iloc[j].T, color=colours[i],lw=0.5)\n",
    "\n",
    "plt.savefig(f\"../EDA/plots/consumption/clustering/euclidean/{k}/clusters_all_ts.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering the data via dba kmeans\n",
    "\n",
    "* adaption of dtw using averages to be faster and more accurate\n",
    "\n",
    "### Using the elbow method to find the best value for k for dba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elbow method for getting best value for k\n",
    "# https://www.scikit-yb.org/en/latest/api/cluster/elbow.html\n",
    "if not os.path.exists(f\"../EDA/plots/consumption/clustering/dba/\"):\n",
    "    os.makedirs(f\"../EDA/plots/consumption/clustering/dba/\")\n",
    "\n",
    "\n",
    "clusterer = TimeSeriesKMeans(n_init=2, metric=\"dtw\", max_iter_barycenter=10)\n",
    "visualizer = KElbowVisualizer(clusterer, k=(1,25))\n",
    "\n",
    "visualizer.fit(df_energy_last_29.drop(\"meter_id\", axis=1))\n",
    "plt.title(\"DBA kMeans Elbow\")\n",
    "plt.savefig(\"../EDA/plots/consumption/Clustering/dba/_elbow.png\")\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k value (how many clusters)\n",
    "k = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running DBA kMeans to cluster the data using the optimal k elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the dba kmeans\n",
    "clusterer = TimeSeriesKMeans(n_clusters=k, n_init=2, metric=\"dtw\", max_iter_barycenter=10)\n",
    "clusterer.fit(df_energy_last_29.drop(\"meter_id\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the centroids\n",
    "centroids = clusterer.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predicting which meters belong to which cluster\n",
    "labels_dba = clusterer.predict(df_energy_last_29.drop(\"meter_id\",axis=1))\n",
    "labels_dba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the labels to the dataframe for ease of plotting\n",
    "df_energy_29_labels = df_energy_last_29\n",
    "df_energy_29_labels[\"labels\"]=labels_dba\n",
    "df_energy_29_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"../EDA/plots/consumption/clustering/dba/{k}/\"):\n",
    "    os.makedirs(f\"../EDA/plots/consumption/clustering/dba/{k}/\")\n",
    "\n",
    "\n",
    "# plotting the assigned points ontop of the centroids\n",
    "for i in tqdm(np.unique(labels_dba)):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"DBA centroid \"+str(i+1)+\" of \"+str(k)+\" assignments\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Energy usage\")\n",
    "    plt.locator_params(axis='x', nbins=10)\n",
    "    for j in tqdm(range(len(df_energy_29_labels.drop(\"meter_id\",axis=1))), leave=False):\n",
    "        if(df_energy_last_29.drop(\"meter_id\",axis=1).iloc[j].labels==i):\n",
    "            plt.plot(df_energy_last_29.drop(\"meter_id\",axis=1).iloc[j].T, color=\"blue\",lw=0.5, label=\"assigned\")\n",
    "    plt.plot(centroids[i], color=\"red\",lw=3, label=\"centroid\", ls=\"dashed\")\n",
    "    plt.savefig(f\"../EDA/plots/consumption/clustering/dba/{k}/cluster_{i}\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining based on meter_id to assign labels to the original dataset (with all meter readings)\n",
    "df_energy_labels = pd.merge(df_energy, df_energy_29_labels[{\"meter_id\",\"labels\"}], on=\"meter_id\",how=\"inner\")\n",
    "df_energy_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting all the assigned data on top of each other\n",
    "# last 29 days\n",
    "\n",
    "colours = [\"red\",\"blue\",\"green\",\"magenta\",\"cyan\",\"orange\",\"brown\",\"grey\",\"pink\",\"purple\",\"black\",\"olive\"]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(\"last 29 days clusters\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Energy usage\")\n",
    "plt.locator_params(axis='x', nbins=10)\n",
    "\n",
    "for i in tqdm(np.unique(labels_dba)):\n",
    "\n",
    "    \n",
    "    #plotting the one with no missing nans in december\n",
    "    for j in tqdm(range(len(df_energy_29_labels.drop(\"meter_id\",axis=1).drop(\"labels\",axis=1))), leave=False):\n",
    "        if(df_energy_29_labels.drop(\"meter_id\",axis=1).iloc[j].labels==i):\n",
    "            plt.plot(df_energy_29_labels.drop(\"meter_id\",axis=1).drop(\"labels\",axis=1).fillna(0).iloc[j].T, color=colours[i],lw=0.5)\n",
    "\n",
    "plt.savefig(f\"../EDA/plots/consumption/clustering/dba/{k}/clusters_last_29_ts.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting all the assigned data on top of each other\n",
    "# all data\n",
    "\n",
    "colours = [\"red\",\"blue\",\"green\",\"magenta\",\"cyan\",\"orange\",\"brown\",\"grey\",\"pink\",\"purple\",\"black\",\"olive\"]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(\"year long clusters\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Energy usage\")\n",
    "plt.locator_params(axis='x', nbins=10)\n",
    "\n",
    "for i in tqdm(np.unique(labels_dba)):\n",
    "\n",
    "    \n",
    "    #plotting the one with no missing nans in december\n",
    "    for j in tqdm(range(len(df_energy_labels.drop(\"meter_id\",axis=1).drop(\"labels\",axis=1))), leave=False):\n",
    "        if(df_energy_labels.drop(\"meter_id\",axis=1).iloc[j].labels==i):\n",
    "            plt.plot(df_energy_labels.drop(\"meter_id\",axis=1).drop(\"labels\",axis=1).fillna(0).iloc[j].T, color=colours[i],lw=0.5)\n",
    "\n",
    "plt.savefig(f\"../EDA/plots/consumption/clustering/dba/{k}/clusters_all_ts.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering the data via soft dtw kmeans\n",
    "\n",
    "* soft-dtw; slow and less accurate than dba\n",
    "\n",
    "### Finding elbow of soft-dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elbow method for getting best value for k\n",
    "# https://www.scikit-yb.org/en/latest/api/cluster/elbow.html\n",
    "if not os.path.exists(f\"../EDA/plots/consumption/clustering/soft-dtw/\"):\n",
    "    os.makedirs(f\"../EDA/plots/consumption/clustering/soft-dtw/\")\n",
    "\n",
    "clusterer = TimeSeriesKMeans(metric=\"softdtw\", metric_params={\"gamma\":0.01})\n",
    "visualizer = KElbowVisualizer(clusterer, k=(1,25))\n",
    "\n",
    "visualizer.fit(df_energy_last_29.drop(\"meter_id\", axis=1))\n",
    "plt.title(\"soft-dtw kMeans Elbow\")\n",
    "plt.savefig(\"../EDA/plots/consumption/Clustering/soft-dtw/_elbow.png\")\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k value (how many clusters)\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running soft-dtw kmeans on the optimal k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the soft-dtw kmeans\n",
    "clusterer = TimeSeriesKMeans(n_clusters=k, metric=\"softdtw\", metric_params={\"gamma\":0.01})\n",
    "clusterer.fit(df_energy_last_29.drop(\"meter_id\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the centroids\n",
    "centroids = clusterer.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting which meters belong to which cluster\n",
    "labels_dtw = clusterer.predict(df_energy_last_29.drop(\"meter_id\",axis=1))\n",
    "labels_dtw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the labels to the dataframe for ease of plotting\n",
    "df_energy_29_labels = df_energy_last_29\n",
    "df_energy_29_labels[\"labels\"]=labels_dtw\n",
    "df_energy_29_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"../EDA/plots/consumption/clustering/soft-dtw/{k}/\"):\n",
    "    os.makedirs(f\"../EDA/plots/consumption/clustering/soft-dtw/{k}/\")\n",
    "\n",
    "# plotting the assigned points ontop of the centroids\n",
    "for i in tqdm(np.unique(labels_dtw)):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"soft-dtw centroid \"+str(i+1)+\" of \"+str(k)+\" assignments\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Energy usage\")\n",
    "    plt.locator_params(axis='x', nbins=10)\n",
    "    for j in tqdm(range(len(df_energy_29_labels.drop(\"meter_id\",axis=1))), leave=False):\n",
    "        if(df_energy_last_29.drop(\"meter_id\",axis=1).iloc[j].labels==i):\n",
    "            plt.plot(df_energy_last_29.drop(\"meter_id\",axis=1).iloc[j].T, color=\"blue\",lw=0.5, label=\"assigned\")\n",
    "    plt.plot(centroids[i], color=\"red\",lw=3, label=\"centroid\",ls=\"dashed\")\n",
    "    plt.savefig(f\"../EDA/plots/consumption/clustering/soft-dtw/{k}/cluster_{i}\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining based on meter_id to assign labels to the original dataset (with all meter readings)\n",
    "df_energy_labels = pd.merge(df_energy, df_energy_29_labels[{\"meter_id\",\"labels\"}], on=\"meter_id\",how=\"inner\")\n",
    "df_energy_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting all the assigned data on top of each other\n",
    "# last 29 days\n",
    "\n",
    "colours = [\"red\",\"blue\",\"green\",\"magenta\",\"cyan\",\"orange\",\"brown\",\"grey\",\"pink\",\"purple\",\"black\",\"olive\"]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(\"last 29 days clusters\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Energy usage\")\n",
    "plt.locator_params(axis='x', nbins=10)\n",
    "\n",
    "for i in tqdm(np.unique(labels_dtw)):\n",
    "\n",
    "    \n",
    "    #plotting the one with no missing nans in december\n",
    "    for j in tqdm(range(len(df_energy_29_labels.drop(\"meter_id\",axis=1).drop(\"labels\",axis=1))), leave=False):\n",
    "        if(df_energy_29_labels.drop(\"meter_id\",axis=1).iloc[j].labels==i):\n",
    "            plt.plot(df_energy_29_labels.drop(\"meter_id\",axis=1).drop(\"labels\",axis=1).fillna(0).iloc[j].T, color=colours[i],lw=0.5)\n",
    "\n",
    "plt.savefig(f\"../EDA/plots/consumption/clustering/soft-dtw/{k}/clusters_last_29_ts.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting all the assigned data on top of each other\n",
    "# all data\n",
    "\n",
    "colours = [\"red\",\"blue\",\"green\",\"magenta\",\"cyan\",\"orange\",\"brown\",\"grey\",\"pink\",\"purple\",\"black\",\"olive\"]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title(\"year long clusters\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Energy usage\")\n",
    "plt.locator_params(axis='x', nbins=10)\n",
    "\n",
    "for i in tqdm(np.unique(labels_dtw)):\n",
    "\n",
    "    \n",
    "    #plotting the one with no missing nans in december\n",
    "    for j in tqdm(range(len(df_energy_labels.drop(\"meter_id\",axis=1).drop(\"labels\",axis=1))), leave=False):\n",
    "        if(df_energy_labels.drop(\"meter_id\",axis=1).iloc[j].labels==i):\n",
    "            plt.plot(df_energy_labels.drop(\"meter_id\",axis=1).drop(\"labels\",axis=1).fillna(0).iloc[j].T, color=colours[i],lw=0.5)\n",
    "\n",
    "plt.savefig(f\"../EDA/plots/consumption/clustering/soft-dtw/{k}/clusters_all_ts.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Conclusions:\n",
    "\n",
    "* DBA gave the best performance out of the 3 tested time series suited kmeans methods\n",
    "    * Backs up findings from here https://blog.acolyer.org/2016/05/13/dynamic-time-warping-averaging-of-time-series-allows-faster-and-more-accurate-classification/\n",
    "    \n",
    "* Hence will use the DBA found classifications\n",
    "* Will likely use the cluster either to make separate models for each cluster or just as an extra feature for the model to allow it to learn from the clusters\n",
    "\n",
    "# Saving this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO : \n",
    "\n",
    "* Once elbows are finished\n",
    "    * rerun code for the differenet kmeans with the optimal k value for each\n",
    "    \n",
    "* add labels to the entire dataset\n",
    "* simply plot each of the clusters of the one with the best distribution error with all the missing nan ones on top then assign them to the one they best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the labels to the dataframe for ease of plotting\n",
    "df_energy_29_labels = df_energy_last_29\n",
    "df_energy_29_labels[\"labels\"]=labels_dba\n",
    "# joining based on meter_id to assign labels to the original dataset (with all meter readings)\n",
    "df_energy_labels = pd.merge(df_energy, df_energy_29_labels[{\"meter_id\",\"labels\"}], on=\"meter_id\",how=\"inner\")\n",
    "df_energy_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(os.path.exists(f\"../Data/Preprocessed_Data/consumption_clustered.pkl\")==False):\n",
    "        df_energy_labels.to_pickle(f\"../Data/Preprocessed_Data/consumption_clustered.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle_tf",
   "language": "python",
   "name": "mle_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
