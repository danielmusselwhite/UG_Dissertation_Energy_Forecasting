{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Model\n",
    "* RNN was far too slow and hence infeasible given the time limit I am constrained within\n",
    "* So going to use an LGBM\n",
    "* Just comment out the plots when running if not needing to regenerate them\n",
    "\n",
    "# Misc / setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SEED = 96\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>meter_id_8</th>\n",
       "      <th>...</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.9330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.4710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640294</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.7585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640295</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640296</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640297</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.3970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640298</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.2370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640299 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          meter_id  meter_id_0  meter_id_1  \\\n",
       "0       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "1       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "2       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "3       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "4       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "...                                            ...         ...         ...   \n",
       "640294  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "640295  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "640296  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "640297  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "640298  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "\n",
       "        meter_id_2  meter_id_3  meter_id_4  meter_id_5  meter_id_6  \\\n",
       "0                0           0           0           0           0   \n",
       "1                0           0           0           0           0   \n",
       "2                0           0           0           0           0   \n",
       "3                0           0           0           0           0   \n",
       "4                0           0           0           0           0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "640294           1           0           0           1           0   \n",
       "640295           1           0           0           1           0   \n",
       "640296           1           0           0           1           0   \n",
       "640297           1           0           0           1           0   \n",
       "640298           1           0           0           1           0   \n",
       "\n",
       "        meter_id_7  meter_id_8  ...  month_cos  is_weekend  energy_cluster  \\\n",
       "0                0           0  ...        1.0           1               0   \n",
       "1                0           0  ...        1.0           0               0   \n",
       "2                0           0  ...        1.0           0               0   \n",
       "3                0           0  ...        1.0           0               0   \n",
       "4                0           0  ...        1.0           0               0   \n",
       "...            ...         ...  ...        ...         ...             ...   \n",
       "640294           1           1  ...        1.0           0               2   \n",
       "640295           1           1  ...        1.0           0               2   \n",
       "640296           1           1  ...        1.0           0               2   \n",
       "640297           1           1  ...        1.0           1               2   \n",
       "640298           1           1  ...        1.0           1               2   \n",
       "\n",
       "        num_bedrooms   dwelling_type  detached  flat  semi_detached  terraced  \\\n",
       "0                2.0  terraced_house       0.0   0.0            0.0       1.0   \n",
       "1                2.0  terraced_house       0.0   0.0            0.0       1.0   \n",
       "2                2.0  terraced_house       0.0   0.0            0.0       1.0   \n",
       "3                2.0  terraced_house       0.0   0.0            0.0       1.0   \n",
       "4                2.0  terraced_house       0.0   0.0            0.0       1.0   \n",
       "...              ...             ...       ...   ...            ...       ...   \n",
       "640294           3.0  detached_house       1.0   0.0            0.0       0.0   \n",
       "640295           3.0  detached_house       1.0   0.0            0.0       0.0   \n",
       "640296           3.0  detached_house       1.0   0.0            0.0       0.0   \n",
       "640297           3.0  detached_house       1.0   0.0            0.0       0.0   \n",
       "640298           3.0  detached_house       1.0   0.0            0.0       0.0   \n",
       "\n",
       "        meter_reading  \n",
       "0              3.5170  \n",
       "1              2.9330  \n",
       "2              3.0850  \n",
       "3              3.2370  \n",
       "4              4.4710  \n",
       "...               ...  \n",
       "640294        18.7585  \n",
       "640295        21.0110  \n",
       "640296        19.2040  \n",
       "640297        17.3970  \n",
       "640298        15.2370  \n",
       "\n",
       "[640299 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>meter_id_8</th>\n",
       "      <th>...</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185515</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185516</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185517</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185518</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185519</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185520 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           meter_id  meter_id_0  meter_id_1  \\\n",
       "0        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "1        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "2        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "3        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "4        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "...                                             ...         ...         ...   \n",
       "1185515  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185516  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185517  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185518  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185519  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "\n",
       "         meter_id_2  meter_id_3  meter_id_4  meter_id_5  meter_id_6  \\\n",
       "0                 0           0           0           0           0   \n",
       "1                 0           0           0           0           0   \n",
       "2                 0           0           0           0           0   \n",
       "3                 0           0           0           0           0   \n",
       "4                 0           0           0           0           0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "1185515           1           0           0           1           0   \n",
       "1185516           1           0           0           1           0   \n",
       "1185517           1           0           0           1           0   \n",
       "1185518           1           0           0           1           0   \n",
       "1185519           1           0           0           1           0   \n",
       "\n",
       "         meter_id_7  meter_id_8  ...  month_cos  is_weekend  energy_cluster  \\\n",
       "0                 0           0  ...   0.841254           0               0   \n",
       "1                 0           0  ...   0.841254           0               0   \n",
       "2                 0           0  ...   0.841254           0               0   \n",
       "3                 0           0  ...   0.841254           0               0   \n",
       "4                 0           0  ...   0.841254           0               0   \n",
       "...             ...         ...  ...        ...         ...             ...   \n",
       "1185515           1           1  ...   0.841254           0               2   \n",
       "1185516           1           1  ...   0.841254           0               2   \n",
       "1185517           1           1  ...   0.841254           1               2   \n",
       "1185518           1           1  ...   0.841254           1               2   \n",
       "1185519           1           1  ...   0.841254           0               2   \n",
       "\n",
       "         num_bedrooms   dwelling_type  detached  flat  semi_detached  \\\n",
       "0                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "1                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "2                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "3                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "4                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "...               ...             ...       ...   ...            ...   \n",
       "1185515           3.0  detached_house       1.0   0.0            0.0   \n",
       "1185516           3.0  detached_house       1.0   0.0            0.0   \n",
       "1185517           3.0  detached_house       1.0   0.0            0.0   \n",
       "1185518           3.0  detached_house       1.0   0.0            0.0   \n",
       "1185519           3.0  detached_house       1.0   0.0            0.0   \n",
       "\n",
       "         terraced  meter_reading  \n",
       "0             1.0            NaN  \n",
       "1             1.0            NaN  \n",
       "2             1.0            NaN  \n",
       "3             1.0            NaN  \n",
       "4             1.0            NaN  \n",
       "...           ...            ...  \n",
       "1185515       0.0            NaN  \n",
       "1185516       0.0            NaN  \n",
       "1185517       0.0            NaN  \n",
       "1185518       0.0            NaN  \n",
       "1185519       0.0            NaN  \n",
       "\n",
       "[1185520 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_pickle(\"../Data/Prepared_Data/supervised/consumption_all.pkl\")\n",
    "display(df_train)\n",
    "df_preds = pd.read_pickle(\"../Data/Prepared_Data/supervised/consumption_all_preds.pkl\")\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formatting the df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>meter_id_8</th>\n",
       "      <th>...</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.9330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.4710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640294</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.7585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640295</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640296</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640297</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.3970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640298</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.2370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640299 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          meter_id  meter_id_0  meter_id_1  \\\n",
       "0       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "1       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "2       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "3       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "4       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "...                                            ...         ...         ...   \n",
       "640294  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "640295  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "640296  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "640297  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "640298  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "\n",
       "        meter_id_2  meter_id_3  meter_id_4  meter_id_5  meter_id_6  \\\n",
       "0                0           0           0           0           0   \n",
       "1                0           0           0           0           0   \n",
       "2                0           0           0           0           0   \n",
       "3                0           0           0           0           0   \n",
       "4                0           0           0           0           0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "640294           1           0           0           1           0   \n",
       "640295           1           0           0           1           0   \n",
       "640296           1           0           0           1           0   \n",
       "640297           1           0           0           1           0   \n",
       "640298           1           0           0           1           0   \n",
       "\n",
       "        meter_id_7  meter_id_8  ...  month_cos  is_weekend  energy_cluster  \\\n",
       "0                0           0  ...        1.0           1               0   \n",
       "1                0           0  ...        1.0           0               0   \n",
       "2                0           0  ...        1.0           0               0   \n",
       "3                0           0  ...        1.0           0               0   \n",
       "4                0           0  ...        1.0           0               0   \n",
       "...            ...         ...  ...        ...         ...             ...   \n",
       "640294           1           1  ...        1.0           0               2   \n",
       "640295           1           1  ...        1.0           0               2   \n",
       "640296           1           1  ...        1.0           0               2   \n",
       "640297           1           1  ...        1.0           1               2   \n",
       "640298           1           1  ...        1.0           1               2   \n",
       "\n",
       "        num_bedrooms   dwelling_type  detached  flat  semi_detached  terraced  \\\n",
       "0                2.0  terraced_house       0.0   0.0            0.0       1.0   \n",
       "1                2.0  terraced_house       0.0   0.0            0.0       1.0   \n",
       "2                2.0  terraced_house       0.0   0.0            0.0       1.0   \n",
       "3                2.0  terraced_house       0.0   0.0            0.0       1.0   \n",
       "4                2.0  terraced_house       0.0   0.0            0.0       1.0   \n",
       "...              ...             ...       ...   ...            ...       ...   \n",
       "640294           3.0  detached_house       1.0   0.0            0.0       0.0   \n",
       "640295           3.0  detached_house       1.0   0.0            0.0       0.0   \n",
       "640296           3.0  detached_house       1.0   0.0            0.0       0.0   \n",
       "640297           3.0  detached_house       1.0   0.0            0.0       0.0   \n",
       "640298           3.0  detached_house       1.0   0.0            0.0       0.0   \n",
       "\n",
       "        meter_reading  \n",
       "0              3.5170  \n",
       "1              2.9330  \n",
       "2              3.0850  \n",
       "3              3.2370  \n",
       "4              4.4710  \n",
       "...               ...  \n",
       "640294        18.7585  \n",
       "640295        21.0110  \n",
       "640296        19.2040  \n",
       "640297        17.3970  \n",
       "640298        15.2370  \n",
       "\n",
       "[640299 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>meter_id_8</th>\n",
       "      <th>...</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185515</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185516</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185517</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185518</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185519</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185520 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           meter_id  meter_id_0  meter_id_1  \\\n",
       "0        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "1        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "2        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "3        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "4        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7           0           0   \n",
       "...                                             ...         ...         ...   \n",
       "1185515  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185516  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185517  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185518  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "1185519  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd           0           1   \n",
       "\n",
       "         meter_id_2  meter_id_3  meter_id_4  meter_id_5  meter_id_6  \\\n",
       "0                 0           0           0           0           0   \n",
       "1                 0           0           0           0           0   \n",
       "2                 0           0           0           0           0   \n",
       "3                 0           0           0           0           0   \n",
       "4                 0           0           0           0           0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "1185515           1           0           0           1           0   \n",
       "1185516           1           0           0           1           0   \n",
       "1185517           1           0           0           1           0   \n",
       "1185518           1           0           0           1           0   \n",
       "1185519           1           0           0           1           0   \n",
       "\n",
       "         meter_id_7  meter_id_8  ...  month_cos  is_weekend  energy_cluster  \\\n",
       "0                 0           0  ...   0.841254           0               0   \n",
       "1                 0           0  ...   0.841254           0               0   \n",
       "2                 0           0  ...   0.841254           0               0   \n",
       "3                 0           0  ...   0.841254           0               0   \n",
       "4                 0           0  ...   0.841254           0               0   \n",
       "...             ...         ...  ...        ...         ...             ...   \n",
       "1185515           1           1  ...   0.841254           0               2   \n",
       "1185516           1           1  ...   0.841254           0               2   \n",
       "1185517           1           1  ...   0.841254           1               2   \n",
       "1185518           1           1  ...   0.841254           1               2   \n",
       "1185519           1           1  ...   0.841254           0               2   \n",
       "\n",
       "         num_bedrooms   dwelling_type  detached  flat  semi_detached  \\\n",
       "0                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "1                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "2                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "3                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "4                 2.0  terraced_house       0.0   0.0            0.0   \n",
       "...               ...             ...       ...   ...            ...   \n",
       "1185515           3.0  detached_house       1.0   0.0            0.0   \n",
       "1185516           3.0  detached_house       1.0   0.0            0.0   \n",
       "1185517           3.0  detached_house       1.0   0.0            0.0   \n",
       "1185518           3.0  detached_house       1.0   0.0            0.0   \n",
       "1185519           3.0  detached_house       1.0   0.0            0.0   \n",
       "\n",
       "         terraced  meter_reading  \n",
       "0             1.0              0  \n",
       "1             1.0              0  \n",
       "2             1.0              0  \n",
       "3             1.0              0  \n",
       "4             1.0              0  \n",
       "...           ...            ...  \n",
       "1185515       0.0              0  \n",
       "1185516       0.0              0  \n",
       "1185517       0.0              0  \n",
       "1185518       0.0              0  \n",
       "1185519       0.0              0  \n",
       "\n",
       "[1185520 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#replacing nans with 0 so we can aggregate up the OOF predictions\n",
    "df_preds[\"meter_reading\"] = df_preds[\"meter_reading\"].fillna(0) \n",
    "#dropping the \"energy n-k\" columns as they are needed for 3D RNN input not 2D LGBM input\n",
    "# df_preds = df_preds.drop([\"energy n-7\",\"energy n-6\",\"energy n-5\",\"energy n-4\",\"energy n-3\",\"energy n-2\",\"energy n-1\"], axis=1)\n",
    "# df_train = df_train.drop([\"energy n-7\",\"energy n-6\",\"energy n-5\",\"energy n-4\",\"energy n-3\",\"energy n-2\",\"energy n-1\"], axis=1)\n",
    "\n",
    "display(df_train)\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinally encoding the ID's\n",
    "* One hot / binary encoding can actually worsen performance of DT based algorithms\n",
    "* and LGBM supports categorical values; so no need to use the binary encoded meter_id which we planned for the RNN\n",
    "* Hence I will also now encode the ID ordinally and experiment with both to see which gives the best performing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_ord</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>...</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.9330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.4710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640294</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.7585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640295</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640296</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640297</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.3970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640298</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.2370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640299 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          meter_id  meter_id_ord  meter_id_0  \\\n",
       "0       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "1       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "2       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "3       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "4       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "...                                            ...           ...         ...   \n",
       "640294  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "640295  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "640296  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "640297  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "640298  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "\n",
       "        meter_id_1  meter_id_2  meter_id_3  meter_id_4  meter_id_5  \\\n",
       "0                0           0           0           0           0   \n",
       "1                0           0           0           0           0   \n",
       "2                0           0           0           0           0   \n",
       "3                0           0           0           0           0   \n",
       "4                0           0           0           0           0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "640294           1           1           0           0           1   \n",
       "640295           1           1           0           0           1   \n",
       "640296           1           1           0           0           1   \n",
       "640297           1           1           0           0           1   \n",
       "640298           1           1           0           0           1   \n",
       "\n",
       "        meter_id_6  meter_id_7  ...  month_cos  is_weekend  energy_cluster  \\\n",
       "0                0           0  ...        1.0           1               0   \n",
       "1                0           0  ...        1.0           0               0   \n",
       "2                0           0  ...        1.0           0               0   \n",
       "3                0           0  ...        1.0           0               0   \n",
       "4                0           0  ...        1.0           0               0   \n",
       "...            ...         ...  ...        ...         ...             ...   \n",
       "640294           0           1  ...        1.0           0               2   \n",
       "640295           0           1  ...        1.0           0               2   \n",
       "640296           0           1  ...        1.0           0               2   \n",
       "640297           0           1  ...        1.0           1               2   \n",
       "640298           0           1  ...        1.0           1               2   \n",
       "\n",
       "        num_bedrooms   dwelling_type detached  flat  semi_detached  terraced  \\\n",
       "0                2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "1                2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "2                2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "3                2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "4                2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "...              ...             ...      ...   ...            ...       ...   \n",
       "640294           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "640295           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "640296           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "640297           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "640298           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "\n",
       "        meter_reading  \n",
       "0              3.5170  \n",
       "1              2.9330  \n",
       "2              3.0850  \n",
       "3              3.2370  \n",
       "4              4.4710  \n",
       "...               ...  \n",
       "640294        18.7585  \n",
       "640295        21.0110  \n",
       "640296        19.2040  \n",
       "640297        17.3970  \n",
       "640298        15.2370  \n",
       "\n",
       "[640299 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_ord</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>...</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185515</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185516</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185517</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185518</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185519</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185520 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           meter_id  meter_id_ord  meter_id_0  \\\n",
       "0        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "1        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "2        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "3        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "4        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "...                                             ...           ...         ...   \n",
       "1185515  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185516  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185517  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185518  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185519  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "\n",
       "         meter_id_1  meter_id_2  meter_id_3  meter_id_4  meter_id_5  \\\n",
       "0                 0           0           0           0           0   \n",
       "1                 0           0           0           0           0   \n",
       "2                 0           0           0           0           0   \n",
       "3                 0           0           0           0           0   \n",
       "4                 0           0           0           0           0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "1185515           1           1           0           0           1   \n",
       "1185516           1           1           0           0           1   \n",
       "1185517           1           1           0           0           1   \n",
       "1185518           1           1           0           0           1   \n",
       "1185519           1           1           0           0           1   \n",
       "\n",
       "         meter_id_6  meter_id_7  ...  month_cos  is_weekend  energy_cluster  \\\n",
       "0                 0           0  ...   0.841254           0               0   \n",
       "1                 0           0  ...   0.841254           0               0   \n",
       "2                 0           0  ...   0.841254           0               0   \n",
       "3                 0           0  ...   0.841254           0               0   \n",
       "4                 0           0  ...   0.841254           0               0   \n",
       "...             ...         ...  ...        ...         ...             ...   \n",
       "1185515           0           1  ...   0.841254           0               2   \n",
       "1185516           0           1  ...   0.841254           0               2   \n",
       "1185517           0           1  ...   0.841254           1               2   \n",
       "1185518           0           1  ...   0.841254           1               2   \n",
       "1185519           0           1  ...   0.841254           0               2   \n",
       "\n",
       "         num_bedrooms   dwelling_type detached  flat  semi_detached  terraced  \\\n",
       "0                 2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "1                 2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "2                 2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "3                 2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "4                 2.0  terraced_house      0.0   0.0            0.0       1.0   \n",
       "...               ...             ...      ...   ...            ...       ...   \n",
       "1185515           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "1185516           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "1185517           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "1185518           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "1185519           3.0  detached_house      1.0   0.0            0.0       0.0   \n",
       "\n",
       "         meter_reading  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "1185515              0  \n",
       "1185516              0  \n",
       "1185517              0  \n",
       "1185518              0  \n",
       "1185519              0  \n",
       "\n",
       "[1185520 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ordinally encoding id's\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_preds[\"meter_id\"])\n",
    "\n",
    "#ordinally encoding with same encoder so will encode the same\n",
    "df_train.insert(1, \"meter_id_ord\", le.transform(df_train[\"meter_id\"]))\n",
    "df_preds.insert(1, \"meter_id_ord\", le.transform(df_preds[\"meter_id\"]))\n",
    "\n",
    "display(df_train)\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinally encoding the dwelling_type\n",
    "* same reasons for replacing the binary encoded meter_id with ordinal encoding; going to replace one hot encodede dwelling type with ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_ord</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>...</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>dwelling_type_ord</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.9330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.2370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.4710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640294</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.7585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640295</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640296</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640297</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.3970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640298</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.2370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640299 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          meter_id  meter_id_ord  meter_id_0  \\\n",
       "0       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "1       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "2       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "3       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "4       0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "...                                            ...           ...         ...   \n",
       "640294  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "640295  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "640296  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "640297  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "640298  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "\n",
       "        meter_id_1  meter_id_2  meter_id_3  meter_id_4  meter_id_5  \\\n",
       "0                0           0           0           0           0   \n",
       "1                0           0           0           0           0   \n",
       "2                0           0           0           0           0   \n",
       "3                0           0           0           0           0   \n",
       "4                0           0           0           0           0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "640294           1           1           0           0           1   \n",
       "640295           1           1           0           0           1   \n",
       "640296           1           1           0           0           1   \n",
       "640297           1           1           0           0           1   \n",
       "640298           1           1           0           0           1   \n",
       "\n",
       "        meter_id_6  meter_id_7  ...  is_weekend  energy_cluster  num_bedrooms  \\\n",
       "0                0           0  ...           1               0           2.0   \n",
       "1                0           0  ...           0               0           2.0   \n",
       "2                0           0  ...           0               0           2.0   \n",
       "3                0           0  ...           0               0           2.0   \n",
       "4                0           0  ...           0               0           2.0   \n",
       "...            ...         ...  ...         ...             ...           ...   \n",
       "640294           0           1  ...           0               2           3.0   \n",
       "640295           0           1  ...           0               2           3.0   \n",
       "640296           0           1  ...           0               2           3.0   \n",
       "640297           0           1  ...           1               2           3.0   \n",
       "640298           0           1  ...           1               2           3.0   \n",
       "\n",
       "         dwelling_type  dwelling_type_ord detached  flat  semi_detached  \\\n",
       "0       terraced_house                  4      0.0   0.0            0.0   \n",
       "1       terraced_house                  4      0.0   0.0            0.0   \n",
       "2       terraced_house                  4      0.0   0.0            0.0   \n",
       "3       terraced_house                  4      0.0   0.0            0.0   \n",
       "4       terraced_house                  4      0.0   0.0            0.0   \n",
       "...                ...                ...      ...   ...            ...   \n",
       "640294  detached_house                  1      1.0   0.0            0.0   \n",
       "640295  detached_house                  1      1.0   0.0            0.0   \n",
       "640296  detached_house                  1      1.0   0.0            0.0   \n",
       "640297  detached_house                  1      1.0   0.0            0.0   \n",
       "640298  detached_house                  1      1.0   0.0            0.0   \n",
       "\n",
       "        terraced  meter_reading  \n",
       "0            1.0         3.5170  \n",
       "1            1.0         2.9330  \n",
       "2            1.0         3.0850  \n",
       "3            1.0         3.2370  \n",
       "4            1.0         4.4710  \n",
       "...          ...            ...  \n",
       "640294       0.0        18.7585  \n",
       "640295       0.0        21.0110  \n",
       "640296       0.0        19.2040  \n",
       "640297       0.0        17.3970  \n",
       "640298       0.0        15.2370  \n",
       "\n",
       "[640299 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_ord</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>...</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>dwelling_type_ord</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185515</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185516</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185517</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185518</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185519</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185520 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           meter_id  meter_id_ord  meter_id_0  \\\n",
       "0        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "1        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "2        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "3        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "4        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7          2073           0   \n",
       "...                                             ...           ...         ...   \n",
       "1185515  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185516  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185517  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185518  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "1185519  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd          2605           0   \n",
       "\n",
       "         meter_id_1  meter_id_2  meter_id_3  meter_id_4  meter_id_5  \\\n",
       "0                 0           0           0           0           0   \n",
       "1                 0           0           0           0           0   \n",
       "2                 0           0           0           0           0   \n",
       "3                 0           0           0           0           0   \n",
       "4                 0           0           0           0           0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "1185515           1           1           0           0           1   \n",
       "1185516           1           1           0           0           1   \n",
       "1185517           1           1           0           0           1   \n",
       "1185518           1           1           0           0           1   \n",
       "1185519           1           1           0           0           1   \n",
       "\n",
       "         meter_id_6  meter_id_7  ...  is_weekend  energy_cluster  \\\n",
       "0                 0           0  ...           0               0   \n",
       "1                 0           0  ...           0               0   \n",
       "2                 0           0  ...           0               0   \n",
       "3                 0           0  ...           0               0   \n",
       "4                 0           0  ...           0               0   \n",
       "...             ...         ...  ...         ...             ...   \n",
       "1185515           0           1  ...           0               2   \n",
       "1185516           0           1  ...           0               2   \n",
       "1185517           0           1  ...           1               2   \n",
       "1185518           0           1  ...           1               2   \n",
       "1185519           0           1  ...           0               2   \n",
       "\n",
       "         num_bedrooms   dwelling_type  dwelling_type_ord detached  flat  \\\n",
       "0                 2.0  terraced_house                  4      0.0   0.0   \n",
       "1                 2.0  terraced_house                  4      0.0   0.0   \n",
       "2                 2.0  terraced_house                  4      0.0   0.0   \n",
       "3                 2.0  terraced_house                  4      0.0   0.0   \n",
       "4                 2.0  terraced_house                  4      0.0   0.0   \n",
       "...               ...             ...                ...      ...   ...   \n",
       "1185515           3.0  detached_house                  1      1.0   0.0   \n",
       "1185516           3.0  detached_house                  1      1.0   0.0   \n",
       "1185517           3.0  detached_house                  1      1.0   0.0   \n",
       "1185518           3.0  detached_house                  1      1.0   0.0   \n",
       "1185519           3.0  detached_house                  1      1.0   0.0   \n",
       "\n",
       "         semi_detached  terraced  meter_reading  \n",
       "0                  0.0       1.0              0  \n",
       "1                  0.0       1.0              0  \n",
       "2                  0.0       1.0              0  \n",
       "3                  0.0       1.0              0  \n",
       "4                  0.0       1.0              0  \n",
       "...                ...       ...            ...  \n",
       "1185515            0.0       0.0              0  \n",
       "1185516            0.0       0.0              0  \n",
       "1185517            0.0       0.0              0  \n",
       "1185518            0.0       0.0              0  \n",
       "1185519            0.0       0.0              0  \n",
       "\n",
       "[1185520 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ordinally encoding dwelling_type\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_preds[\"dwelling_type\"])\n",
    "\n",
    "#ordinally encoding with same encoder so will encode the same\n",
    "df_train.insert(27, \"dwelling_type_ord\", le.transform(df_train[\"dwelling_type\"]))\n",
    "df_preds.insert(27, \"dwelling_type_ord\", le.transform(df_preds[\"dwelling_type\"]))\n",
    "\n",
    "display(df_train)\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKF-CV for training the LGBM\n",
    "* Using skf on df_train by meter_id with 3 folds\n",
    "    * Meaning for each iteration we use 2/3 of each meters data for training and 1/3 of each meters data for validating\n",
    "* using out of fold predictions, making predictions on each fold and aggregating them together for the final prediction\n",
    "\n",
    "* evaluates the model via OOF predictions made on the held out set on each fold\n",
    "* this score is returned and along with the 3 models\n",
    "* genetic algorithm hyper parameter tuning will then be used to find the LGBM hyper param config with the best val score and this will then be used to make predictions using the model which has the best validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFERENCE the lgbm used inside this function has taken inspiration from the proposed model in the work of Wenlong Wu's : \"Solution to the IEEE-CIS Second Technical Challenge with Machine Learning Modeling\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#function for running the cross fold\n",
    "    #args:\n",
    "        #disp_fold_info = True if we want to print info for each fold\n",
    "        #disp_end_info = True if we want to display evaluation info at the end\n",
    "        #SEED = random seed used for fair repeatability\n",
    "        #num_folds = number of folds in skf (pretty certain going to keep this at 3 )\n",
    "        #df_train = training dataframe\n",
    "        #y_col = the name of the label we want to predict (meter_reading)\n",
    "        #X_cols = the name of the feature columns we are using\n",
    "        #X_cat = the name of these features which are categorical\n",
    "        #params = hyper params for the LGBM model\n",
    "    #returns:\n",
    "        #time_of_execution = how long it took to train the model on all folds; will be used as a point of comparison\n",
    "        #valid_score = MAE calculated using the Out-of-Fold Predictions on the df_train, used for hyper-param tuning\n",
    "        #lgbm_models = array of the different lgbm_models\n",
    "        \n",
    "def run_lgbm_skf_cv(disp_fold_info, disp_end_info, SEED, num_folds, df_train, y_col, X_cols, X_cat, params):\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state = SEED) # defining the SKF algorithm\n",
    "\n",
    "    lgbm_models = []\n",
    "    start_time = time.time()\n",
    "    fold_iter=1\n",
    "    #running the startified kfold, splitting df_train by meter_id, so we use 2/3 of each meters reading for training\n",
    "    for train_index, valid_index in skf.split(df_train, df_train[\"meter_id\"]):\n",
    "\n",
    "        print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Fold {fold_iter}{color.END}\")\n",
    "        \n",
    "        #splitting into the features and labels for the train and valid folds\n",
    "        X_train, X_valid = df_train.loc[train_index, X_cols], df_train.loc[valid_index, X_cols]\n",
    "        y_train, y_valid = df_train.loc[train_index, y_col], df_train.loc[valid_index, y_col]\n",
    "        \n",
    "        if(disp_fold_info):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}X_train{color.END}\")\n",
    "            display(X_train.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}y_train{color.END}\")\n",
    "            display(y_train.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}X_valid{color.END}\")\n",
    "            display(X_valid.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}y_valid{color.END}\")\n",
    "            display(y_valid.head(5))\n",
    "            \n",
    "        print(f\"{color.CYAN}{color.UNDERLINE}Training the LGBM{color.END}\")\n",
    "        #instantiating a lgbm regressor with our params\n",
    "        lgbm_model = lgbm.LGBMRegressor(**params)\n",
    "        #fitting the lgbm model on the 2/3 train and evaluating on the 1/3 valid\n",
    "        #printing details every 1000 iters + stopping if no improvement made in 250 iters\n",
    "        lgbm_model.fit(X_train, y_train,\n",
    "                       eval_set=[(X_valid, y_valid)],\n",
    "                       categorical_feature=X_cat,\n",
    "                       verbose=3333,\n",
    "                       early_stopping_rounds=250)\n",
    "        \n",
    "        #saving the OOF prediction for the held out rows (valid rows from df_train) from the lgbm model with the best performing intrinisic parmams \n",
    "        oof_valid = lgbm_model.predict(X_valid, num_iteration=lgbm_model.best_iteration_) # making prediction on the held out rows, X_valid\n",
    "        df_train.loc[valid_index, \"oof\"] = oof_valid #storing the oof rows \n",
    "        if(disp_fold_info):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}df_train OOF predictions{color.END}\")\n",
    "            display(df_train.loc[valid_index, [\"meter_id\",\"oof\"]].head(5))\n",
    "               \n",
    "        #appending this lgbm\n",
    "        lgbm_models.append(lgbm_model)\n",
    "        if(disp_fold_info):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}lgbm_models size{color.END}: {len(lgbm_models)}\")\n",
    "            \n",
    "        fold_iter+=1\n",
    "        \n",
    "    \n",
    "    #calculating execution time and the MAE on the training set\n",
    "    time_of_execution = time.time() - start_time\n",
    "    valid_score=mean_absolute_error(df_train[y_col], df_train[\"oof\"]) \n",
    "    \n",
    "    if(disp_end_info):\n",
    "        print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}training set OOF preds vs true{color.END}\")\n",
    "        display(df_train[[\"meter_id\",\"date\",\"meter_reading\",\"oof\"]])\n",
    "        print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution for skf-cv:  {color.END}{str(datetime.timedelta(seconds=round(time_of_execution)))}\\n\")\n",
    "        print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set:{color.END} {valid_score}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (time_of_execution, valid_score, lgbm_models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running GA hyper param optim on the LGBM skf-cv function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"meter_reading\" #we want to predict the meter_reading (this will always be the same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the column types and grouping ones together that should be grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'day_of_month': ['day_of_month'],\n",
      " 'day_of_week': ['day_of_week'],\n",
      " 'day_of_year_cyclic': ['day_of_year_sin', 'day_of_year_cos'],\n",
      " 'dwelling_type_onehot': ['detached', 'flat', 'semi_detached', 'terraced'],\n",
      " 'dwelling_type_ord': ['dwelling_type_ord'],\n",
      " 'energy_cluster': ['energy_cluster'],\n",
      " 'is_weekend': ['is_weekend'],\n",
      " 'meter_id_binary': ['meter_id_0',\n",
      "                     'meter_id_1',\n",
      "                     'meter_id_2',\n",
      "                     'meter_id_3',\n",
      "                     'meter_id_4',\n",
      "                     'meter_id_5',\n",
      "                     'meter_id_6',\n",
      "                     'meter_id_7',\n",
      "                     'meter_id_8',\n",
      "                     'meter_id_9',\n",
      "                     'meter_id_10',\n",
      "                     'meter_id_11',\n",
      "                     'meter_id_12'],\n",
      " 'meter_id_ord': ['meter_id_ord'],\n",
      " 'month_cyclic': ['month_sin', 'month_cos'],\n",
      " 'month_ord': ['month_ord'],\n",
      " 'num_bedrooms': ['num_bedrooms']}\n"
     ]
    }
   ],
   "source": [
    "#dictionary to hold all groups of columns which could be chosen\n",
    "#done as if we just pick columns completely random we may get just \"meter_id_3\" from the binary encoded meter_id's\n",
    "#wouldn't make any sense without the other respective binary encoded meter_id columns\n",
    "\n",
    "possible_columns = {}\n",
    "possible_columns[\"meter_id_ord\"] = [\"meter_id_ord\"]\n",
    "possible_columns[\"meter_id_binary\"] = ['meter_id_0', 'meter_id_1', 'meter_id_2',\n",
    "       'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7',\n",
    "       'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12']\n",
    "possible_columns[\"day_of_year_cyclic\"] = [\"day_of_year_sin\",\"day_of_year_cos\"]\n",
    "possible_columns[\"day_of_week\"] = [\"day_of_week\"]\n",
    "possible_columns[\"day_of_month\"] = [\"day_of_month\"]\n",
    "possible_columns[\"month_ord\"] = [\"month_ord\"]\n",
    "possible_columns[\"month_cyclic\"] = [\"month_sin\",\"month_cos\"]\n",
    "possible_columns[\"is_weekend\"] = [\"is_weekend\"]\n",
    "possible_columns[\"energy_cluster\"] = [\"energy_cluster\"]\n",
    "possible_columns[\"num_bedrooms\"] = [\"num_bedrooms\"]\n",
    "possible_columns[\"dwelling_type_ord\"] = [\"dwelling_type_ord\"]\n",
    "possible_columns[\"dwelling_type_onehot\"] = ['detached', 'flat', 'semi_detached', 'terraced']\n",
    "pprint(possible_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting categorical columns\n",
    "\n",
    "all_cat = [\"meter_id_ord\", 'meter_id_0', 'meter_id_1', 'meter_id_2',\n",
    "           'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7',\n",
    "           'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12',\n",
    "           \"day_of_week\", \"day_of_month\", \"month_ord\", \"is_weekend\", \"energy_cluster\",\n",
    "           \"dwelling_type_ord\", \"detached\", \"flat\", \"semi_detached\", \"terraced\"] #all categorical values\n",
    "\n",
    "# setting categorical columns in the dataframe to be categorical\n",
    "#X_cat[0] holds all columns (besides clusters but we aren't using that) \n",
    "for i in all_cat:\n",
    "    df_train[i] = df_train[i].astype('category')\n",
    "    df_preds[i] = df_preds[i].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model parameters for GA\n",
    "* sensible different combinations of params for the model\n",
    "\n",
    "* default values which make sense and the others have place holders as they will be found in GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_fraction': 0.99999,\n",
      " 'bagging_freq': 99999,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.99999,\n",
      " 'lambda_l1': 99999,\n",
      " 'lambda_l2': 99999,\n",
      " 'learning_rate': 0.99999,\n",
      " 'max_depth': 99999,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 99999,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n"
     ]
    }
   ],
   "source": [
    "#default params (including ones we will override and those we won't)\n",
    "params = {\n",
    "    ### won't be tuned ###\n",
    "    'boosting_type': 'gbdt', #gbdt/rf/dart/goss\n",
    "    'metric': 'mae', \n",
    "    'num_threads': -1, # number of threads to run on for speed (auto)\n",
    "    'num_iterations': 10000, #defining the models runs\n",
    "    'seed': SEED, # all runs with same seed for better comparison between different hyper params\n",
    "    'device': 'cpu', #there exists a bug in LGBM library causing occasional crashes when running in gpu https://github.com/microsoft/LightGBM/issues/3679\n",
    "\n",
    "    ### will be tuned (replace these with the best performing) ###\n",
    "    'learning_rate': 0.99999,\n",
    "    'num_leaves': 99999, # limit max numer of leaves in a tree\n",
    "    \"max_depth\":99999, # limit max depth of the tree to prevent overfitting\n",
    "    # fraction to be bagged/sampled every k iterations\n",
    "    'bagging_fraction': 0.99999,\n",
    "    'bagging_freq' : 99999,\n",
    "    'feature_fraction': 0.99999, # fraction of features to use at each tree node\n",
    "    #l1 & l2 regularization to prevent overfitting\n",
    "    \"lambda_l1\": 99999,\n",
    "    \"lambda_l2\": 99999\n",
    "}\n",
    "\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of names of keys for the params we tune in the dic ; will be used in mutation of GA\n",
    "tuned_hyper_names = [\"learning_rate\",\"num_leaves\",\"max_depth\",\"bagging_fraction\",\"bagging_freq\",\"feature_fraction\",\"lambda_l1\",\"lambda_l2\"]\n",
    "whole_number_hyper_names = [\"num_leaves\",\"max_depth\",\"bagging_freq\",\"lambda_l1\",\"lambda_l2\"]\n",
    "fractional_hyper_names = [\"bagging_fraction\",\"feature_fraction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Genetic Algorithm Hyper Param Optimization\n",
    "### creating the initial population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe initial population is\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 0\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.66,\n",
      " 'bagging_freq': 15,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.72,\n",
      " 'lambda_l1': 12,\n",
      " 'lambda_l2': 8,\n",
      " 'learning_rate': 0.092,\n",
      " 'max_depth': 8,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 150,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 1\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.53,\n",
      " 'bagging_freq': 8,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.78,\n",
      " 'lambda_l1': 10,\n",
      " 'lambda_l2': 15,\n",
      " 'learning_rate': 0.051,\n",
      " 'max_depth': 6,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 42,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 2\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'day_of_week', 'month_sin', 'month_cos', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'day_of_week', 'month_cyclic', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.99,\n",
      " 'bagging_freq': 24,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.53,\n",
      " 'lambda_l1': 12,\n",
      " 'lambda_l2': 15,\n",
      " 'learning_rate': 0.034,\n",
      " 'max_depth': 9,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 465,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 3\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.64,\n",
      " 'bagging_freq': 23,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.61,\n",
      " 'lambda_l1': 13,\n",
      " 'lambda_l2': 17,\n",
      " 'learning_rate': 0.082,\n",
      " 'max_depth': 8,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 161,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 4\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.61,\n",
      " 'bagging_freq': 7,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.82,\n",
      " 'lambda_l1': 12,\n",
      " 'lambda_l2': 10,\n",
      " 'learning_rate': 0.097,\n",
      " 'max_depth': 6,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 54,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 5\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'energy_cluster', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'energy_cluster', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.89,\n",
      " 'bagging_freq': 23,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.6,\n",
      " 'lambda_l1': 18,\n",
      " 'lambda_l2': 13,\n",
      " 'learning_rate': 0.047,\n",
      " 'max_depth': 6,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 46,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 6\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_sin', 'day_of_year_cos', 'day_of_month', 'month_ord', 'energy_cluster', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_cyclic', 'day_of_month', 'month_ord', 'energy_cluster', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.77,\n",
      " 'bagging_freq': 7,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.68,\n",
      " 'lambda_l1': 19,\n",
      " 'lambda_l2': 4,\n",
      " 'learning_rate': 0.034,\n",
      " 'max_depth': 6,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 59,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 7\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_week', 'month_ord', 'num_bedrooms', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_binary', 'day_of_week', 'month_ord', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.85,\n",
      " 'bagging_freq': 13,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.72,\n",
      " 'lambda_l1': 16,\n",
      " 'lambda_l2': 16,\n",
      " 'learning_rate': 0.057,\n",
      " 'max_depth': 7,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 88,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 8\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.6,\n",
      " 'bagging_freq': 7,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.71,\n",
      " 'lambda_l1': 19,\n",
      " 'lambda_l2': 13,\n",
      " 'learning_rate': 0.032,\n",
      " 'max_depth': 9,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 378,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 9\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.66,\n",
      " 'bagging_freq': 23,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.64,\n",
      " 'lambda_l1': 10,\n",
      " 'lambda_l2': 8,\n",
      " 'learning_rate': 0.028,\n",
      " 'max_depth': 11,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 1621,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 10\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_week', 'month_ord', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_ord', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.76,\n",
      " 'bagging_freq': 12,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.64,\n",
      " 'lambda_l1': 15,\n",
      " 'lambda_l2': 16,\n",
      " 'learning_rate': 0.058,\n",
      " 'max_depth': 7,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 65,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 11\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_month', 'month_ord', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_month', 'month_ord', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.81,\n",
      " 'bagging_freq': 21,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.7,\n",
      " 'lambda_l1': 14,\n",
      " 'lambda_l2': 16,\n",
      " 'learning_rate': 0.028,\n",
      " 'max_depth': 7,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 122,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 12\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.97,\n",
      " 'bagging_freq': 19,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.64,\n",
      " 'lambda_l1': 14,\n",
      " 'lambda_l2': 19,\n",
      " 'learning_rate': 0.053,\n",
      " 'max_depth': 10,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 792,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 13\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_sin', 'month_cos', 'is_weekend', 'num_bedrooms', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.76,\n",
      " 'bagging_freq': 18,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.6,\n",
      " 'lambda_l1': 6,\n",
      " 'lambda_l2': 6,\n",
      " 'learning_rate': 0.051,\n",
      " 'max_depth': 6,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 42,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 14\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.65,\n",
      " 'bagging_freq': 21,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.84,\n",
      " 'lambda_l1': 8,\n",
      " 'lambda_l2': 15,\n",
      " 'learning_rate': 0.06,\n",
      " 'max_depth': 11,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 1764,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mpopulation member 15\u001b[0m\n",
      "\u001b[1mfeatures\u001b[0m\n",
      " ['meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1mfeature groups\u001b[0m\n",
      " ['meter_id_binary', 'month_ord', 'month_cyclic', 'is_weekend', 'dwelling_type_onehot']\n",
      "\u001b[1mlabels\u001b[0m\n",
      "{'bagging_fraction': 0.52,\n",
      " 'bagging_freq': 9,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.51,\n",
      " 'lambda_l1': 15,\n",
      " 'lambda_l2': 13,\n",
      " 'learning_rate': 0.026,\n",
      " 'max_depth': 8,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 251,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "population = []\n",
    "# loading the description of the best model from RS and the RS main effects to be used as 2 of the original population\n",
    "# rs_best_model = pd.read_pickle(\"../Results/Unclustered Random Search/64_best_model_desc.pkl\")\n",
    "# rs_best_model_features = rs_best_model[\"features\"]\n",
    "# rs_best_model_col_groups = []\n",
    "# for key in possible_columns.keys():\n",
    "#     if(possible_columns[key][0] in rs_best_model_features):\n",
    "#         rs_best_model_col_groups+=[key]\n",
    "# population.append((rs_best_model_features,rs_best_model[\"params\"], rs_best_model_col_groups))\n",
    "\n",
    "# rs_main_effects_model = pd.read_pickle(\"../Results/Unclustered Random Search/64_main_effects_desc.pkl\")\n",
    "# rs_main_effects_features = rs_main_effects_model[\"features\"]\n",
    "# rs_main_effects_col_groups = []\n",
    "# for key in possible_columns.keys():\n",
    "#     if(possible_columns[key][0] in rs_main_effects_features):\n",
    "#         rs_main_effects_col_groups+=[key]\n",
    "# population.append((rs_main_effects_features,rs_best_model[\"params\"], rs_main_effects_col_groups))\n",
    "\n",
    "#filling the rest of the population with random models\n",
    "while (len(population)<population_size):\n",
    "    #firstly randomly picking the features we will use\n",
    "    X_cols = []#this will store the X_cols we use\n",
    "    X_col_groups = []\n",
    "    #generating probability of accepting each column\n",
    "    prob_to_beat = random.randrange(30,100)/100 #between 0.3 and 1\n",
    "    #iterating through each column and randomly decide whether or not to pick it\n",
    "    for key in possible_columns.keys():\n",
    "        #randomly generate a decimal for this column group\n",
    "        this_prob = random.randrange(0,100)/100 #between 0 and 1\n",
    "        #if this is less than the probability to beat then accept it\n",
    "        if(this_prob<=prob_to_beat):\n",
    "            X_col_groups+=[key]\n",
    "            X_cols+=possible_columns[key]\n",
    "    if(len(X_col_groups)<=0):\n",
    "        new_key=random.choice(list(possible_columns.keys()))\n",
    "        X_col_groups=[new_key]\n",
    "        X_cols+=possible_columns[new_key]\n",
    "        print(f\"No columns clipping length to 1 so randomly choosing to use {new_key}\")\n",
    "\n",
    "    #then get LGBM hyper parameters\n",
    "    this_params = params.copy()\n",
    "    this_params[\"learning_rate\"] = random.randrange(10,100)/1000 #between 0.01 and 0.1\n",
    "    this_params[\"max_depth\"] = random.randrange(6,12)\n",
    "    this_params[\"num_leaves\"] = random.randrange(np.round(2**(this_params[\"max_depth\"])*0.5), np.round(2**(this_params[\"max_depth\"])*1)) #picking a random max leaves less than 2^(max_depth) to prevent over fitting (between 50 and 100%)\n",
    "    this_params[\"bagging_fraction\"] = random.randrange(50,100)/100 #between 0.5 and 1\n",
    "    this_params[\"bagging_freq\"] = random.randrange(5,25)\n",
    "    this_params[\"feature_fraction\"] = random.randrange(50,100)/100 #between 0.5 and 1\n",
    "    this_params[\"lambda_l1\"] = random.randrange(4,20)\n",
    "    this_params[\"lambda_l2\"] = random.randrange(4,20)\n",
    "    \n",
    "    #adding this random model to the initial population\n",
    "    population.append((X_cols,this_params,X_col_groups))\n",
    "    \n",
    "#viewing the initial population\n",
    "print(f\"{color.BOLD}The initial population is{color.END}\\n\")\n",
    "for i in range(len(population)):\n",
    "    print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}population member {i}{color.END}\")\n",
    "    print(f\"{color.BOLD}features{color.END}\\n\",population[i][0])\n",
    "    print(f\"{color.BOLD}feature groups{color.END}\\n\",population[i][2])\n",
    "    print(f\"{color.BOLD}labels{color.END}\")\n",
    "    pprint(population[i][1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the genetic algorithm\n",
    "* Selection : Elitism\n",
    "    * pick the best elitism_n models as the parents\n",
    "* Cross Over : Uniform\n",
    "    * for each child pick 2 random parents from the parents found from elitism (each has equal chance of being picked)\n",
    "    * iterate through each column group and hyper parameter and give a 50% chance of it being chosen from each parent\n",
    "* Mutation : \n",
    "    * Column groups : Flip Bit\n",
    "        * Iteratively pick column groups to flip their usage based on the mutation rate\n",
    "            * If all columns are deactive then randomly pick 1 to activate\n",
    "    * Hyper parameters : Gaussian\n",
    "        * Iteratively pick hyper params to +/- up to 25% based on mutation rate\n",
    "        \n",
    "\n",
    "<b> this one doesn't store the lgbm model as my machine was running out of memory due to the GA being more complicated. Instead will just save the description and will have to retrain the best one with that description at the end of the algorithm </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mGenetic Algorithm hyper parameter optimization\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb50d4a9e804a26ae5bbfcdea96f49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9ae4475e75450b9683df5eb291bcb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.092, 'num_leaves': 150, 'max_depth': 8, 'bagging_fraction': 0.66, 'bagging_freq': 15, 'feature_fraction': 0.72, 'lambda_l1': 12, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.72, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02325\n",
      "[6666]\tvalid_0's l1: 1.98386\n",
      "[9999]\tvalid_0's l1: 1.96155\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9873]\tvalid_0's l1: 1.9615\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.72, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02129\n",
      "[6666]\tvalid_0's l1: 1.97945\n",
      "[9999]\tvalid_0's l1: 1.95699\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.95697\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.72, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.03128\n",
      "[6666]\tvalid_0's l1: 1.98864\n",
      "[9999]\tvalid_0's l1: 1.96575\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.96571\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.051, 'num_leaves': 42, 'max_depth': 6, 'bagging_fraction': 0.53, 'bagging_freq': 8, 'feature_fraction': 0.78, 'lambda_l1': 10, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.53, subsample=1.0 will be ignored. Current value: bagging_fraction=0.53\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99026\n",
      "[6666]\tvalid_0's l1: 1.96481\n",
      "[9999]\tvalid_0's l1: 1.95117\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9984]\tvalid_0's l1: 1.95104\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.53, subsample=1.0 will be ignored. Current value: bagging_fraction=0.53\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99641\n",
      "[6666]\tvalid_0's l1: 1.969\n",
      "[9999]\tvalid_0's l1: 1.9559\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.95588\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.53, subsample=1.0 will be ignored. Current value: bagging_fraction=0.53\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99677\n",
      "[6666]\tvalid_0's l1: 1.97127\n",
      "[9999]\tvalid_0's l1: 1.95713\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9929]\tvalid_0's l1: 1.95673\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_cyclic', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.034, 'num_leaves': 465, 'max_depth': 9, 'bagging_fraction': 0.99, 'bagging_freq': 24, 'feature_fraction': 0.53, 'lambda_l1': 12, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.53, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.53\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.99, subsample=1.0 will be ignored. Current value: bagging_fraction=0.99\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.0368\n",
      "[6666]\tvalid_0's l1: 2.00321\n",
      "[9999]\tvalid_0's l1: 1.98913\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9990]\tvalid_0's l1: 1.98912\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.53, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.53\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.99, subsample=1.0 will be ignored. Current value: bagging_fraction=0.99\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.0344\n",
      "[6666]\tvalid_0's l1: 1.99506\n",
      "[9999]\tvalid_0's l1: 1.98195\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9984]\tvalid_0's l1: 1.98192\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.53, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.53\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.99, subsample=1.0 will be ignored. Current value: bagging_fraction=0.99\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.04997\n",
      "[6666]\tvalid_0's l1: 2.01071\n",
      "[9999]\tvalid_0's l1: 1.99688\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.99688\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.082, 'num_leaves': 161, 'max_depth': 8, 'bagging_fraction': 0.64, 'bagging_freq': 23, 'feature_fraction': 0.61, 'lambda_l1': 13, 'lambda_l2': 17}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.61, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.61\n",
      "[LightGBM] [Warning] lambda_l1 is set=13, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.64, subsample=1.0 will be ignored. Current value: bagging_fraction=0.64\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=17, reg_lambda=0.0 will be ignored. Current value: lambda_l2=17\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.10879\n",
      "Early stopping, best iteration is:\n",
      "[5434]\tvalid_0's l1: 2.09961\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.61, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.61\n",
      "[LightGBM] [Warning] lambda_l1 is set=13, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.64, subsample=1.0 will be ignored. Current value: bagging_fraction=0.64\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=17, reg_lambda=0.0 will be ignored. Current value: lambda_l2=17\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.11376\n",
      "Early stopping, best iteration is:\n",
      "[5064]\tvalid_0's l1: 2.10401\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.61, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.61\n",
      "[LightGBM] [Warning] lambda_l1 is set=13, reg_alpha=0.0 will be ignored. Current value: lambda_l1=13\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.64, subsample=1.0 will be ignored. Current value: bagging_fraction=0.64\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=17, reg_lambda=0.0 will be ignored. Current value: lambda_l2=17\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.11819\n",
      "Early stopping, best iteration is:\n",
      "[4470]\tvalid_0's l1: 2.1094\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.097, 'num_leaves': 54, 'max_depth': 6, 'bagging_fraction': 0.61, 'bagging_freq': 7, 'feature_fraction': 0.82, 'lambda_l1': 12, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.82, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.82\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.61, subsample=1.0 will be ignored. Current value: bagging_fraction=0.61\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.58921\n",
      "[6666]\tvalid_0's l1: 2.54632\n",
      "Early stopping, best iteration is:\n",
      "[7074]\tvalid_0's l1: 2.54387\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.82, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.82\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.61, subsample=1.0 will be ignored. Current value: bagging_fraction=0.61\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.60063\n",
      "[6666]\tvalid_0's l1: 2.56138\n",
      "Early stopping, best iteration is:\n",
      "[8096]\tvalid_0's l1: 2.55076\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.82, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.82\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.61, subsample=1.0 will be ignored. Current value: bagging_fraction=0.61\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.58999\n",
      "Early stopping, best iteration is:\n",
      "[5194]\tvalid_0's l1: 2.57354\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'energy_cluster', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.047, 'num_leaves': 46, 'max_depth': 6, 'bagging_fraction': 0.89, 'bagging_freq': 23, 'feature_fraction': 0.6, 'lambda_l1': 18, 'lambda_l2': 13}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=18, reg_alpha=0.0 will be ignored. Current value: lambda_l1=18\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.89, subsample=1.0 will be ignored. Current value: bagging_fraction=0.89\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98524\n",
      "[6666]\tvalid_0's l1: 1.95441\n",
      "[9999]\tvalid_0's l1: 1.93784\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.93783\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=18, reg_alpha=0.0 will be ignored. Current value: lambda_l1=18\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.89, subsample=1.0 will be ignored. Current value: bagging_fraction=0.89\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98587\n",
      "[6666]\tvalid_0's l1: 1.95485\n",
      "[9999]\tvalid_0's l1: 1.93824\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.93824\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=18, reg_alpha=0.0 will be ignored. Current value: lambda_l1=18\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.89, subsample=1.0 will be ignored. Current value: bagging_fraction=0.89\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99048\n",
      "[6666]\tvalid_0's l1: 1.96169\n",
      "[9999]\tvalid_0's l1: 1.94488\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9997]\tvalid_0's l1: 1.94488\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_month', 'month_ord', 'energy_cluster', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.034, 'num_leaves': 59, 'max_depth': 6, 'bagging_fraction': 0.77, 'bagging_freq': 7, 'feature_fraction': 0.68, 'lambda_l1': 19, 'lambda_l2': 4}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.68, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.68\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.77, subsample=1.0 will be ignored. Current value: bagging_fraction=0.77\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=4, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.01106\n",
      "[6666]\tvalid_0's l1: 1.98207\n",
      "[9999]\tvalid_0's l1: 1.96394\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9982]\tvalid_0's l1: 1.96388\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.68, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.68\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.77, subsample=1.0 will be ignored. Current value: bagging_fraction=0.77\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=4, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.0152\n",
      "[6666]\tvalid_0's l1: 1.98587\n",
      "[9999]\tvalid_0's l1: 1.96769\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 1.96769\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.68, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.68\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.77, subsample=1.0 will be ignored. Current value: bagging_fraction=0.77\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=4, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02034\n",
      "[6666]\tvalid_0's l1: 1.99166\n",
      "[9999]\tvalid_0's l1: 1.97393\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9992]\tvalid_0's l1: 1.97391\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_week', 'month_ord', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.057, 'num_leaves': 88, 'max_depth': 7, 'bagging_fraction': 0.85, 'bagging_freq': 13, 'feature_fraction': 0.72, 'lambda_l1': 16, 'lambda_l2': 16}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.72, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 3.09776\n",
      "[6666]\tvalid_0's l1: 2.93204\n",
      "[9999]\tvalid_0's l1: 2.83909\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9996]\tvalid_0's l1: 2.83903\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.72, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 3.1026\n",
      "[6666]\tvalid_0's l1: 2.94344\n",
      "[9999]\tvalid_0's l1: 2.85418\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 2.85413\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.72, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.72\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 3.09745\n",
      "[6666]\tvalid_0's l1: 2.9327\n",
      "[9999]\tvalid_0's l1: 2.84829\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 2.84827\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.032, 'num_leaves': 378, 'max_depth': 9, 'bagging_fraction': 0.6, 'bagging_freq': 7, 'feature_fraction': 0.71, 'lambda_l1': 19, 'lambda_l2': 13}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9535\n",
      "[6666]\tvalid_0's l1: 1.93015\n",
      "[9999]\tvalid_0's l1: 1.91635\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9989]\tvalid_0's l1: 1.9163\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9565\n",
      "[6666]\tvalid_0's l1: 1.93244\n",
      "[9999]\tvalid_0's l1: 1.91995\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 1.91995\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.96115\n",
      "[6666]\tvalid_0's l1: 1.93808\n",
      "[9999]\tvalid_0's l1: 1.92504\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.92504\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1621, 'max_depth': 11, 'bagging_fraction': 0.66, 'bagging_freq': 23, 'feature_fraction': 0.64, 'lambda_l1': 10, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9403\n",
      "[6666]\tvalid_0's l1: 1.92461\n",
      "[9999]\tvalid_0's l1: 1.91448\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 1.91448\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93931\n",
      "[6666]\tvalid_0's l1: 1.9232\n",
      "[9999]\tvalid_0's l1: 1.91327\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9996]\tvalid_0's l1: 1.91327\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94773\n",
      "[6666]\tvalid_0's l1: 1.93317\n",
      "[9999]\tvalid_0's l1: 1.92392\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9911]\tvalid_0's l1: 1.92386\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_ord', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.058, 'num_leaves': 65, 'max_depth': 7, 'bagging_fraction': 0.76, 'bagging_freq': 12, 'feature_fraction': 0.64, 'lambda_l1': 15, 'lambda_l2': 16}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.09741\n",
      "[6666]\tvalid_0's l1: 2.06663\n",
      "[9999]\tvalid_0's l1: 2.05424\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 2.05421\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.08925\n",
      "[6666]\tvalid_0's l1: 2.0612\n",
      "[9999]\tvalid_0's l1: 2.04878\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 2.04877\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.10645\n",
      "[6666]\tvalid_0's l1: 2.07653\n",
      "[9999]\tvalid_0's l1: 2.06388\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9986]\tvalid_0's l1: 2.06374\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_month', 'month_ord', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 122, 'max_depth': 7, 'bagging_fraction': 0.81, 'bagging_freq': 21, 'feature_fraction': 0.7, 'lambda_l1': 14, 'lambda_l2': 16}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.81, subsample=1.0 will be ignored. Current value: bagging_fraction=0.81\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98647\n",
      "[6666]\tvalid_0's l1: 1.96025\n",
      "[9999]\tvalid_0's l1: 1.94617\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9976]\tvalid_0's l1: 1.9461\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.81, subsample=1.0 will be ignored. Current value: bagging_fraction=0.81\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9881\n",
      "[6666]\tvalid_0's l1: 1.96065\n",
      "[9999]\tvalid_0's l1: 1.94712\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9994]\tvalid_0's l1: 1.94709\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.81, subsample=1.0 will be ignored. Current value: bagging_fraction=0.81\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99206\n",
      "[6666]\tvalid_0's l1: 1.96644\n",
      "[9999]\tvalid_0's l1: 1.95252\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.95251\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.053, 'num_leaves': 792, 'max_depth': 10, 'bagging_fraction': 0.97, 'bagging_freq': 19, 'feature_fraction': 0.64, 'lambda_l1': 14, 'lambda_l2': 19}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.88736\n",
      "[6666]\tvalid_0's l1: 1.85964\n",
      "[9999]\tvalid_0's l1: 1.84455\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9991]\tvalid_0's l1: 1.84454\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.88591\n",
      "[6666]\tvalid_0's l1: 1.86194\n",
      "[9999]\tvalid_0's l1: 1.84782\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9998]\tvalid_0's l1: 1.84782\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90189\n",
      "[6666]\tvalid_0's l1: 1.87557\n",
      "[9999]\tvalid_0's l1: 1.86143\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9996]\tvalid_0's l1: 1.86142\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_cyclic', 'is_weekend', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.051, 'num_leaves': 42, 'max_depth': 6, 'bagging_fraction': 0.76, 'bagging_freq': 18, 'feature_fraction': 0.6, 'lambda_l1': 6, 'lambda_l2': 6}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 3.77581\n",
      "[6666]\tvalid_0's l1: 3.65935\n",
      "[9999]\tvalid_0's l1: 3.58547\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 3.58541\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 3.78288\n",
      "[6666]\tvalid_0's l1: 3.65882\n",
      "[9999]\tvalid_0's l1: 3.59173\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 3.59171\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=6, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 3.77402\n",
      "[6666]\tvalid_0's l1: 3.64721\n",
      "[9999]\tvalid_0's l1: 3.58111\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9918]\tvalid_0's l1: 3.58092\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.81392\n",
      "[6666]\tvalid_0's l1: 1.7843\n",
      "[9999]\tvalid_0's l1: 1.77084\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9973]\tvalid_0's l1: 1.77064\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.80763\n",
      "[6666]\tvalid_0's l1: 1.78056\n",
      "[9999]\tvalid_0's l1: 1.76792\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9919]\tvalid_0's l1: 1.76763\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.81725\n",
      "[6666]\tvalid_0's l1: 1.78875\n",
      "[9999]\tvalid_0's l1: 1.77368\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 1.77368\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 0, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'month_ord', 'month_cyclic', 'is_weekend', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.026, 'num_leaves': 251, 'max_depth': 8, 'bagging_fraction': 0.52, 'bagging_freq': 9, 'feature_fraction': 0.51, 'lambda_l1': 15, 'lambda_l2': 13}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.51, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.51\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 3.69601\n",
      "[6666]\tvalid_0's l1: 3.50364\n",
      "[9999]\tvalid_0's l1: 3.38277\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 3.38273\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.51, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.51\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 3.71267\n",
      "[6666]\tvalid_0's l1: 3.51631\n",
      "[9999]\tvalid_0's l1: 3.40042\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 3.40037\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.51, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.51\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 3.71265\n",
      "[6666]\tvalid_0's l1: 3.50936\n",
      "[9999]\tvalid_0's l1: 3.40051\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 3.40047\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.7706509815955915\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.8512619056978388\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.917201382320318\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.9204283711022805\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.053 from 1\n",
      "inherited num_leaves value of 1621 from 2\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 19 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited usage of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 1 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.053 from 1\n",
      "inherited num_leaves value of 378 from 3\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.6 from 3\n",
      "inherited bagging_freq value of 19 from 1\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 13 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited usage of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 2 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 3 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.66 from 2\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 10 from 2\n",
      "inherited lambda_l2 value of 19 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited usage of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 4 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.053 from 1\n",
      "inherited num_leaves value of 378 from 3\n",
      "inherited max_depth value of 9 from 3\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 19 from 1\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 19 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited usage of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 5 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.6 from 3\n",
      "inherited bagging_freq value of 7 from 3\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 19 from 3\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited usage of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 6 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.053 from 1\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 19 from 1\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 19 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 7 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 14 from 1\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited usage of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 8 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1621 from 2\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.66 from 2\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 10 from 2\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 9 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.032 from 3\n",
      "inherited num_leaves value of 378 from 3\n",
      "inherited max_depth value of 9 from 3\n",
      "inherited bagging_fraction value of 0.6 from 3\n",
      "inherited bagging_freq value of 7 from 3\n",
      "inherited feature_fraction value of 0.71 from 3\n",
      "inherited lambda_l1 value of 19 from 3\n",
      "inherited lambda_l2 value of 13 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 10 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.032 from 3\n",
      "inherited num_leaves value of 1621 from 2\n",
      "inherited max_depth value of 9 from 3\n",
      "inherited bagging_fraction value of 0.6 from 3\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.71 from 3\n",
      "inherited lambda_l1 value of 19 from 3\n",
      "inherited lambda_l2 value of 13 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 11 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.032 from 3\n",
      "inherited num_leaves value of 378 from 3\n",
      "inherited max_depth value of 9 from 3\n",
      "inherited bagging_fraction value of 0.66 from 2\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 10 from 2\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 12 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1621 from 2\n",
      "inherited max_depth value of 9 from 3\n",
      "inherited bagging_fraction value of 0.66 from 2\n",
      "inherited bagging_freq value of 7 from 3\n",
      "inherited feature_fraction value of 0.71 from 3\n",
      "inherited lambda_l1 value of 10 from 2\n",
      "inherited lambda_l2 value of 8 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 13 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1621 from 2\n",
      "inherited max_depth value of 9 from 3\n",
      "inherited bagging_fraction value of 0.66 from 2\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.71 from 3\n",
      "inherited lambda_l1 value of 10 from 2\n",
      "inherited lambda_l2 value of 13 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited usage of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 14 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.032 from 3\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 9 from 3\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 19 from 3\n",
      "inherited lambda_l2 value of 13 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited usage of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 15 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.053 from 1\n",
      "inherited num_leaves value of 378 from 3\n",
      "inherited max_depth value of 10 from 1\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 19 from 1\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 19 from 3\n",
      "inherited lambda_l2 value of 13 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited usage of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_year_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_fraction by 23.0% from 0.97 to 1.0\n",
      "Decreased lambda_l1 by 12.0% from 14 to 12\n",
      "\u001b[1m\u001b[92mChild 1\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 20.0% from 378 to 302\n",
      "Increased lambda_l1 by 10.0% from 14 to 15\n",
      "\u001b[1m\u001b[92mChild 2\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased lambda_l2 by 20.0% from 8 to 10\n",
      "\u001b[1m\u001b[92mChild 3\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_freq by 24.0% from 23 to 17\n",
      "Increased lambda_l1 by 20.0% from 10 to 12\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased lambda_l2 by 4.0% from 19 to 20\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased feature_fraction by 9.0% from 0.64 to 0.5824\n",
      "Decreased lambda_l1 by 20.0% from 14 to 11\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 18.0% from 0.032 to 0.03776\n",
      "Decreased bagging_fraction by 8.0% from 0.6 to 0.5519999999999999\n",
      "Decreased lambda_l1 by 0.0% from 19 to 19\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using dwelling_type_ord\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_fraction by 20.0% from 0.66 to 0.792\n",
      "Decreased feature_fraction by 7.000000000000001% from 0.64 to 0.5952\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased lambda_l1 by 11.0% from 10 to 11\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 11.0% from 0.028 to 0.03108\n",
      "Decreased lambda_l1 by 20.0% from 10 to 8\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 9.0% from 1764 to 1923\n",
      "Decreased max_depth by 24.0% from 9 to 7\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using day_of_month\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 20.0% from 0.053 to 0.0424\n",
      "Increased lambda_l1 by 3.0% from 19 to 20\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f75c88c602418d95d6f68ec2052755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.053, 'num_leaves': 1621, 'max_depth': 10, 'bagging_fraction': 1.0, 'bagging_freq': 23, 'feature_fraction': 0.64, 'lambda_l1': 12, 'lambda_l2': 19}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's l1: 2.87421\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's l1: 2.87832\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's l1: 2.88239\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.053, 'num_leaves': 302, 'max_depth': 10, 'bagging_fraction': 0.6, 'bagging_freq': 19, 'feature_fraction': 0.64, 'lambda_l1': 15, 'lambda_l2': 13}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.95657\n",
      "[6666]\tvalid_0's l1: 1.9393\n",
      "Early stopping, best iteration is:\n",
      "[8782]\tvalid_0's l1: 1.93252\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.95354\n",
      "[6666]\tvalid_0's l1: 1.93749\n",
      "[9999]\tvalid_0's l1: 1.92757\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9996]\tvalid_0's l1: 1.92754\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9603\n",
      "[6666]\tvalid_0's l1: 1.9443\n",
      "[9999]\tvalid_0's l1: 1.93661\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9899]\tvalid_0's l1: 1.93655\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.85692\n",
      "[6666]\tvalid_0's l1: 1.8244\n",
      "[9999]\tvalid_0's l1: 1.80403\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.80403\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.86111\n",
      "[6666]\tvalid_0's l1: 1.8287\n",
      "[9999]\tvalid_0's l1: 1.80597\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 1.80597\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.86307\n",
      "[6666]\tvalid_0's l1: 1.8299\n",
      "[9999]\tvalid_0's l1: 1.80905\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.80905\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 10, 'bagging_fraction': 0.66, 'bagging_freq': 17, 'feature_fraction': 0.64, 'lambda_l1': 12, 'lambda_l2': 19}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1310]\tvalid_0's l1: 2.6522\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1429]\tvalid_0's l1: 2.66395\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.65501\n",
      "Early stopping, best iteration is:\n",
      "[4545]\tvalid_0's l1: 2.65195\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.053, 'num_leaves': 378, 'max_depth': 9, 'bagging_fraction': 0.97, 'bagging_freq': 19, 'feature_fraction': 0.64, 'lambda_l1': 14, 'lambda_l2': 19}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1951]\tvalid_0's l1: 1.96893\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2469]\tvalid_0's l1: 1.96897\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2429]\tvalid_0's l1: 1.97755\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.6, 'bagging_freq': 7, 'feature_fraction': 0.84, 'lambda_l1': 19, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02183\n",
      "[6666]\tvalid_0's l1: 1.99323\n",
      "[9999]\tvalid_0's l1: 1.97967\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.97965\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02494\n",
      "[6666]\tvalid_0's l1: 1.99455\n",
      "[9999]\tvalid_0's l1: 1.98119\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9968]\tvalid_0's l1: 1.98108\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Individual 5 failed 1 times\n",
      "Changing feature fraction from 0.84 to 0.35\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Individual 5 failed 2 times\n",
      "Changing feature fraction from 0.35 to 0.16\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Individual 5 failed 3 times\n",
      "Changing feature fraction from 0.16 to 0.16\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Individual 5 failed 4 times\n",
      "Changing feature fraction from 0.16 to 0.72\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Individual 5 failed 5 times\n",
      "Changing feature fraction from 0.72 to 0.93\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Individual 5 failed 6 times\n",
      "Changing feature fraction from 0.93 to 0.63\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Individual 5 failed 7 times\n",
      "Changing feature fraction from 0.63 to 0.77\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Individual 5 failed 8 times\n",
      "Changing feature fraction from 0.77 to 0.23\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.13183\n",
      "[6666]\tvalid_0's l1: 2.09217\n",
      "[9999]\tvalid_0's l1: 2.06708\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9842]\tvalid_0's l1: 2.06678\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.23, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.23\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.13094\n",
      "[6666]\tvalid_0's l1: 2.09406\n",
      "[9999]\tvalid_0's l1: 2.06932\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 2.06927\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.23, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.23\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Individual 5 failed 9 times\n",
      "Changing feature fraction from 0.23 to 0.26\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.13183\n",
      "[6666]\tvalid_0's l1: 2.09217\n",
      "[9999]\tvalid_0's l1: 2.06708\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9842]\tvalid_0's l1: 2.06678\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.26, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.26\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Individual 5 failed 10 times\n",
      "Changing feature fraction from 0.26 to 0.28\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.13183\n",
      "[6666]\tvalid_0's l1: 2.09217\n",
      "[9999]\tvalid_0's l1: 2.06708\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9842]\tvalid_0's l1: 2.06678\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.28, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.28\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Individual 5 failed 11 times\n",
      "Changing feature fraction from 0.28 to 0.78\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.04401\n",
      "[6666]\tvalid_0's l1: 2.00478\n",
      "[9999]\tvalid_0's l1: 1.98286\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.98284\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.04744\n",
      "[6666]\tvalid_0's l1: 2.00567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9999]\tvalid_0's l1: 1.98444\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 1.98444\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.78, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.78\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.05625\n",
      "[6666]\tvalid_0's l1: 2.01335\n",
      "[9999]\tvalid_0's l1: 1.99118\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.99116\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'month_cyclic', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.053, 'num_leaves': 792, 'max_depth': 10, 'bagging_fraction': 0.97, 'bagging_freq': 19, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 20}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99988\n",
      "[6666]\tvalid_0's l1: 1.99215\n",
      "Early stopping, best iteration is:\n",
      "[6461]\tvalid_0's l1: 1.99183\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99972\n",
      "Early stopping, best iteration is:\n",
      "[5073]\tvalid_0's l1: 1.99181\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.01216\n",
      "[6666]\tvalid_0's l1: 2.00283\n",
      "Early stopping, best iteration is:\n",
      "[6517]\tvalid_0's l1: 2.0026\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 23, 'feature_fraction': 0.5824, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5824\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2900]\tvalid_0's l1: 1.93275\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5824\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3079]\tvalid_0's l1: 1.93419\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5824\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2458]\tvalid_0's l1: 1.94273\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1621, 'max_depth': 11, 'bagging_fraction': 0.66, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 10, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's l1: 4.87451\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's l1: 4.86888\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's l1: 4.88007\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.03776, 'num_leaves': 378, 'max_depth': 9, 'bagging_fraction': 0.5519999999999999, 'bagging_freq': 7, 'feature_fraction': 0.71, 'lambda_l1': 19, 'lambda_l2': 13}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5519999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5519999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's l1: 2.95366\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5519999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5519999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's l1: 2.957\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5519999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5519999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's l1: 2.96049\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.032, 'num_leaves': 1621, 'max_depth': 9, 'bagging_fraction': 0.6, 'bagging_freq': 23, 'feature_fraction': 0.71, 'lambda_l1': 19, 'lambda_l2': 13}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02629\n",
      "[6666]\tvalid_0's l1: 2.01444\n",
      "Early stopping, best iteration is:\n",
      "[7531]\tvalid_0's l1: 2.01225\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02743\n",
      "Early stopping, best iteration is:\n",
      "[4467]\tvalid_0's l1: 2.01918\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02913\n",
      "Early stopping, best iteration is:\n",
      "[4757]\tvalid_0's l1: 2.02193\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.032, 'num_leaves': 378, 'max_depth': 9, 'bagging_fraction': 0.792, 'bagging_freq': 23, 'feature_fraction': 0.5952, 'lambda_l1': 10, 'lambda_l2': 8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.792, subsample=1.0 will be ignored. Current value: bagging_fraction=0.792\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97082\n",
      "[6666]\tvalid_0's l1: 1.93797\n",
      "[9999]\tvalid_0's l1: 1.91968\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9998]\tvalid_0's l1: 1.91967\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.792, subsample=1.0 will be ignored. Current value: bagging_fraction=0.792\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9712\n",
      "[6666]\tvalid_0's l1: 1.93791\n",
      "[9999]\tvalid_0's l1: 1.91833\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.91832\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5952, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5952\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.792, subsample=1.0 will be ignored. Current value: bagging_fraction=0.792\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97603\n",
      "[6666]\tvalid_0's l1: 1.94439\n",
      "[9999]\tvalid_0's l1: 1.92591\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.92591\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1621, 'max_depth': 9, 'bagging_fraction': 0.66, 'bagging_freq': 7, 'feature_fraction': 0.71, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.10635\n",
      "[6666]\tvalid_0's l1: 2.08429\n",
      "[9999]\tvalid_0's l1: 2.0761\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9795]\tvalid_0's l1: 2.0758\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.10611\n",
      "[6666]\tvalid_0's l1: 2.08246\n",
      "[9999]\tvalid_0's l1: 2.07445\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9978]\tvalid_0's l1: 2.07442\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.11302\n",
      "[6666]\tvalid_0's l1: 2.09137\n",
      "[9999]\tvalid_0's l1: 2.08304\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9803]\tvalid_0's l1: 2.08291\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.03108, 'num_leaves': 1621, 'max_depth': 9, 'bagging_fraction': 0.66, 'bagging_freq': 23, 'feature_fraction': 0.71, 'lambda_l1': 8, 'lambda_l2': 13}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.95722\n",
      "[6666]\tvalid_0's l1: 1.93396\n",
      "[9999]\tvalid_0's l1: 1.92083\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.9208\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.95873\n",
      "[6666]\tvalid_0's l1: 1.93557\n",
      "[9999]\tvalid_0's l1: 1.92206\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 1.92206\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.71, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.71\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.96569\n",
      "[6666]\tvalid_0's l1: 1.94554\n",
      "[9999]\tvalid_0's l1: 1.93138\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.93136\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.032, 'num_leaves': 1923, 'max_depth': 7, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 19, 'lambda_l2': 13}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.13177\n",
      "[6666]\tvalid_0's l1: 2.10419\n",
      "[9999]\tvalid_0's l1: 2.09154\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9975]\tvalid_0's l1: 2.0913\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.12862\n",
      "[6666]\tvalid_0's l1: 2.10207\n",
      "[9999]\tvalid_0's l1: 2.09014\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9912]\tvalid_0's l1: 2.08978\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=19, reg_alpha=0.0 will be ignored. Current value: lambda_l1=19\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.1352\n",
      "[6666]\tvalid_0's l1: 2.11068\n",
      "[9999]\tvalid_0's l1: 2.09771\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9953]\tvalid_0's l1: 2.09765\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 1, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.0424, 'num_leaves': 378, 'max_depth': 10, 'bagging_fraction': 0.97, 'bagging_freq': 19, 'feature_fraction': 0.64, 'lambda_l1': 20, 'lambda_l2': 13}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.95198\n",
      "[6666]\tvalid_0's l1: 1.94157\n",
      "[9999]\tvalid_0's l1: 1.93563\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9987]\tvalid_0's l1: 1.93563\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94977\n",
      "[6666]\tvalid_0's l1: 1.93846\n",
      "[9999]\tvalid_0's l1: 1.93219\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9898]\tvalid_0's l1: 1.93216\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.95896\n",
      "[6666]\tvalid_0's l1: 1.94899\n",
      "[9999]\tvalid_0's l1: 1.94415\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9990]\tvalid_0's l1: 1.94413\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.7706509815955915\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.8063508512431472\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.8512619056978388\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.917201382320318\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 1621 from 3\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.66 from 3\n",
      "inherited bagging_freq value of 23 from 3\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 10 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 1 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 1764 from 1\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 2 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.053 from 2\n",
      "inherited num_leaves value of 792 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 3 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 4 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 792 from 2\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.97 from 2\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 5 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 1621 from 3\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 0.66 from 3\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited non-use of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 6 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.053 from 2\n",
      "inherited num_leaves value of 1621 from 3\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.66 from 3\n",
      "inherited bagging_freq value of 19 from 2\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 10 from 3\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited usage of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 7 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.97 from 2\n",
      "inherited bagging_freq value of 19 from 2\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 19 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 8 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.053 from 2\n",
      "inherited num_leaves value of 792 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 9 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 792 from 2\n",
      "inherited max_depth value of 10 from 2\n",
      "inherited bagging_fraction value of 0.97 from 2\n",
      "inherited bagging_freq value of 19 from 2\n",
      "inherited feature_fraction value of 0.64 from 3\n",
      "inherited lambda_l1 value of 14 from 2\n",
      "inherited lambda_l2 value of 8 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 10 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 1764 from 1\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 1\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited non-use of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 11 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 12 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 1764 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 1\n",
      "inherited bagging_freq value of 19 from 2\n",
      "inherited feature_fraction value of 0.84 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 19 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited usage of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 13 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 0.66 from 3\n",
      "inherited bagging_freq value of 23 from 3\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited usage of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 14 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 1764 from 1\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 0.66 from 3\n",
      "inherited bagging_freq value of 23 from 3\n",
      "inherited feature_fraction value of 0.84 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited usage of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 15 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 1764 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 1\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 5.0% from 10 to 10\n",
      "Decreased feature_fraction by 24.0% from 0.64 to 0.48640000000000005\n",
      "Increased lambda_l1 by 9.0% from 10 to 11\n",
      "\u001b[1m\u001b[92mChild 1\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 18.0% from 0.028 to 0.02296\n",
      "Increased num_leaves by 22.0% from 1764 to 2152\n",
      "\u001b[1m\u001b[92mChild 2\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using day_of_month\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 24.0% from 0.053 to 0.06572\n",
      "\u001b[1m\u001b[92mChild 3\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 22.0% from 11 to 9\n",
      "Decreased bagging_fraction by 6.0% from 0.65 to 0.611\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using day_of_month\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using day_of_month\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 23.0% from 0.06 to 0.0462\n",
      "Decreased lambda_l2 by 8.0% from 19 to 17\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 15.0% from 0.053 to 0.04505\n",
      "Decreased lambda_l1 by 12.0% from 14 to 12\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 22.0% from 792 to 966\n",
      "Decreased bagging_fraction by 3.0% from 0.97 to 0.9409\n",
      "Increased lambda_l1 by 13.0% from 14 to 16\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using day_of_week\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 24.0% from 0.65 to 0.494\n",
      "Increased feature_fraction by 5.0% from 0.84 to 0.882\n",
      "Increased lambda_l1 by 23.0% from 8 to 10\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 11.0% from 0.06 to 0.053399999999999996\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_freq by 7.000000000000001% from 19 to 20\n",
      "Increased feature_fraction by 22.0% from 0.84 to 1.0\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 22.0% from 0.028 to 0.03416\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_freq by 12.0% from 23 to 20\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355842519c1149a58878cc7d10082028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1621, 'max_depth': 10, 'bagging_fraction': 0.66, 'bagging_freq': 23, 'feature_fraction': 0.48640000000000005, 'lambda_l1': 11, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.48640000000000005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48640000000000005\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.06567\n",
      "Early stopping, best iteration is:\n",
      "[3254]\tvalid_0's l1: 2.06495\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.48640000000000005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48640000000000005\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.06558\n",
      "Early stopping, best iteration is:\n",
      "[3526]\tvalid_0's l1: 2.06418\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.48640000000000005, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.48640000000000005\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1898]\tvalid_0's l1: 2.07553\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.02296, 'num_leaves': 2152, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.06915\n",
      "[6666]\tvalid_0's l1: 2.04752\n",
      "Early stopping, best iteration is:\n",
      "[6561]\tvalid_0's l1: 2.04727\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.06831\n",
      "[6666]\tvalid_0's l1: 2.04501\n",
      "Early stopping, best iteration is:\n",
      "[7063]\tvalid_0's l1: 2.04315\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.07702\n",
      "[6666]\tvalid_0's l1: 2.05737\n",
      "Early stopping, best iteration is:\n",
      "[7896]\tvalid_0's l1: 2.05277\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06572, 'num_leaves': 792, 'max_depth': 10, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.64, 'lambda_l1': 14, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.08449\n",
      "[6666]\tvalid_0's l1: 2.05616\n",
      "Early stopping, best iteration is:\n",
      "[8402]\tvalid_0's l1: 2.04828\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.08384\n",
      "[6666]\tvalid_0's l1: 2.05341\n",
      "Early stopping, best iteration is:\n",
      "[7608]\tvalid_0's l1: 2.04819\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.093\n",
      "[6666]\tvalid_0's l1: 2.06504\n",
      "Early stopping, best iteration is:\n",
      "[7889]\tvalid_0's l1: 2.05813\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1764, 'max_depth': 9, 'bagging_fraction': 0.611, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 14, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.611, subsample=1.0 will be ignored. Current value: bagging_fraction=0.611\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid_0's l1: 2.46192\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.611, subsample=1.0 will be ignored. Current value: bagging_fraction=0.611\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[426]\tvalid_0's l1: 2.46835\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.611, subsample=1.0 will be ignored. Current value: bagging_fraction=0.611\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[399]\tvalid_0's l1: 2.47207\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 23, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.84292\n",
      "[6666]\tvalid_0's l1: 1.8067\n",
      "[9999]\tvalid_0's l1: 1.7873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.7873\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.83748\n",
      "[6666]\tvalid_0's l1: 1.80635\n",
      "[9999]\tvalid_0's l1: 1.78602\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9997]\tvalid_0's l1: 1.78601\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.85099\n",
      "[6666]\tvalid_0's l1: 1.81732\n",
      "[9999]\tvalid_0's l1: 1.7956\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.7956\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1621, 'max_depth': 11, 'bagging_fraction': 0.66, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[289]\tvalid_0's l1: 2.88309\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[334]\tvalid_0's l1: 2.88909\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[302]\tvalid_0's l1: 2.89621\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.053, 'num_leaves': 1621, 'max_depth': 10, 'bagging_fraction': 0.66, 'bagging_freq': 19, 'feature_fraction': 0.64, 'lambda_l1': 10, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.01617\n",
      "[6666]\tvalid_0's l1: 1.99113\n",
      "[9999]\tvalid_0's l1: 1.97745\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.97744\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.0149\n",
      "[6666]\tvalid_0's l1: 1.99069\n",
      "[9999]\tvalid_0's l1: 1.97725\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9822]\tvalid_0's l1: 1.97703\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02153\n",
      "[6666]\tvalid_0's l1: 1.99928\n",
      "[9999]\tvalid_0's l1: 1.98648\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9981]\tvalid_0's l1: 1.98636\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.0462, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 19, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 17}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=17, reg_lambda=0.0 will be ignored. Current value: lambda_l2=17\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98308\n",
      "Early stopping, best iteration is:\n",
      "[5624]\tvalid_0's l1: 1.97196\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=17, reg_lambda=0.0 will be ignored. Current value: lambda_l2=17\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98749\n",
      "Early stopping, best iteration is:\n",
      "[4693]\tvalid_0's l1: 1.97757\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=17, reg_lambda=0.0 will be ignored. Current value: lambda_l2=17\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.00069\n",
      "Early stopping, best iteration is:\n",
      "[4558]\tvalid_0's l1: 1.99321\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.04505, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.64, 'lambda_l1': 12, 'lambda_l2': 15}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.38209\n",
      "Early stopping, best iteration is:\n",
      "[4392]\tvalid_0's l1: 2.36555\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.38067\n",
      "[6666]\tvalid_0's l1: 2.34671\n",
      "Early stopping, best iteration is:\n",
      "[7052]\tvalid_0's l1: 2.34438\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.38177\n",
      "Early stopping, best iteration is:\n",
      "[4391]\tvalid_0's l1: 2.36874\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 966, 'max_depth': 10, 'bagging_fraction': 0.9409, 'bagging_freq': 19, 'feature_fraction': 0.64, 'lambda_l1': 16, 'lambda_l2': 8}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9409, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9409\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97636\n",
      "Early stopping, best iteration is:\n",
      "[3613]\tvalid_0's l1: 1.97579\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9409, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9409\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97437\n",
      "Early stopping, best iteration is:\n",
      "[3497]\tvalid_0's l1: 1.97409\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=16, reg_alpha=0.0 will be ignored. Current value: lambda_l1=16\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9409, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9409\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=8, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2526]\tvalid_0's l1: 1.98422\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.494, 'bagging_freq': 21, 'feature_fraction': 0.882, 'lambda_l1': 10, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.882, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.882\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.494\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[615]\tvalid_0's l1: 3.33248\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.882, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.882\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.494\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[630]\tvalid_0's l1: 3.34034\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.882, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.882\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.494\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[588]\tvalid_0's l1: 3.34923\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.053399999999999996, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92188\n",
      "Early stopping, best iteration is:\n",
      "[3785]\tvalid_0's l1: 1.91813\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.91791\n",
      "Early stopping, best iteration is:\n",
      "[5985]\tvalid_0's l1: 1.90699\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9286\n",
      "Early stopping, best iteration is:\n",
      "[6059]\tvalid_0's l1: 1.9182\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 20, 'feature_fraction': 1.0, 'lambda_l1': 8, 'lambda_l2': 19}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1283]\tvalid_0's l1: 2.5157\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1279]\tvalid_0's l1: 2.57079\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[978]\tvalid_0's l1: 2.55023\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.66, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1656]\tvalid_0's l1: 2.49397\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2030]\tvalid_0's l1: 2.4947\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1656]\tvalid_0's l1: 2.48587\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.03416, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.66, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[969]\tvalid_0's l1: 1.96052\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1120]\tvalid_0's l1: 1.96195\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.66, subsample=1.0 will be ignored. Current value: bagging_fraction=0.66\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1254]\tvalid_0's l1: 1.9695\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 2, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_week', 'is_weekend', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 20, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.84423\n",
      "[6666]\tvalid_0's l1: 2.78976\n",
      "[9999]\tvalid_0's l1: 2.76079\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9978]\tvalid_0's l1: 2.76044\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.85294\n",
      "[6666]\tvalid_0's l1: 2.7956\n",
      "[9999]\tvalid_0's l1: 2.76718\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9981]\tvalid_0's l1: 2.76702\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.85081\n",
      "[6666]\tvalid_0's l1: 2.79769\n",
      "[9999]\tvalid_0's l1: 2.7716\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9981]\tvalid_0's l1: 2.77122\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.7706509815955915\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.7896385599918885\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.8063508512431472\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.8512619056978388\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1764 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 1 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 1764 from 2\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 2 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 3 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1764 from 2\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited non-use of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 4 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.053 from 3\n",
      "inherited num_leaves value of 792 from 3\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 0.97 from 3\n",
      "inherited bagging_freq value of 19 from 3\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 19 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited usage of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 5 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 6 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.053 from 3\n",
      "inherited num_leaves value of 792 from 3\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 7 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1764 from 2\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 8 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 9 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1764 from 2\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 19 from 3\n",
      "inherited feature_fraction value of 0.64 from 3\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 19 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited usage of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 10 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1764 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 11 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 12 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1764 from 2\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.97 from 3\n",
      "inherited bagging_freq value of 19 from 3\n",
      "inherited feature_fraction value of 0.64 from 3\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 13 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 792 from 3\n",
      "inherited max_depth value of 10 from 3\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 19 from 3\n",
      "inherited feature_fraction value of 0.64 from 3\n",
      "inherited lambda_l1 value of 14 from 3\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited non-use of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 14 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 15 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 792 from 3\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.64 from 3\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 19 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited usage of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 1\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 13.0% from 0.65 to 0.5655\n",
      "Decreased bagging_freq by 21.0% from 23 to 18\n",
      "Increased lambda_l1 by 9.0% from 8 to 9\n",
      "\u001b[1m\u001b[92mChild 2\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 3\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 24.0% from 1764 to 2187\n",
      "Decreased max_depth by 12.0% from 11 to 10\n",
      "Decreased feature_fraction by 20.0% from 0.84 to 0.6719999999999999\n",
      "Increased lambda_l1 by 6.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using day_of_month\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 12.0% from 0.97 to 0.8536\n",
      "Decreased feature_fraction by 8.0% from 0.64 to 0.5888\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_freq by 17.0% from 21 to 25\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 1.0% from 0.053 to 0.052469999999999996\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 9.0% from 0.028 to 0.02548\n",
      "Decreased bagging_freq by 6.0% from 21 to 20\n",
      "Decreased lambda_l2 by 6.0% from 15 to 14\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_month\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 3.0% from 0.06 to 0.0618\n",
      "Increased num_leaves by 13.0% from 1764 to 1993\n",
      "Decreased lambda_l1 by 16.0% from 8 to 7\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 9.0% from 1764 to 1605\n",
      "Increased bagging_fraction by 23.0% from 0.65 to 0.7995000000000001\n",
      "Decreased lambda_l2 by 14.000000000000002% from 19 to 16\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 12.0% from 1764 to 1552\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased lambda_l1 by 15.0% from 8 to 9\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 12.0% from 1764 to 1552\n",
      "Decreased bagging_freq by 16.0% from 19 to 16\n",
      "Decreased lambda_l2 by 7.000000000000001% from 10 to 9\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_freq by 13.0% from 19 to 17\n",
      "Decreased lambda_l1 by 19.0% from 14 to 11\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_freq by 3.0% from 21 to 20\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85448daaa2c64d599f16368b26ef6886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[654]\tvalid_0's l1: 2.46378\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[817]\tvalid_0's l1: 2.47004\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[817]\tvalid_0's l1: 2.47381\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.5655, 'bagging_freq': 18, 'feature_fraction': 0.64, 'lambda_l1': 9, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5655\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.03067\n",
      "[6666]\tvalid_0's l1: 2.00778\n",
      "[9999]\tvalid_0's l1: 1.9969\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9773]\tvalid_0's l1: 1.99644\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5655\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02937\n",
      "[6666]\tvalid_0's l1: 2.00698\n",
      "Early stopping, best iteration is:\n",
      "[8504]\tvalid_0's l1: 2.00006\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5655, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5655\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.0367\n",
      "[6666]\tvalid_0's l1: 2.01623\n",
      "[9999]\tvalid_0's l1: 2.00584\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9919]\tvalid_0's l1: 2.0056\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99137\n",
      "Early stopping, best iteration is:\n",
      "[6135]\tvalid_0's l1: 1.97846\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99149\n",
      "Early stopping, best iteration is:\n",
      "[6318]\tvalid_0's l1: 1.97743\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.00382\n",
      "[6666]\tvalid_0's l1: 1.99\n",
      "Early stopping, best iteration is:\n",
      "[6441]\tvalid_0's l1: 1.9894\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 2187, 'max_depth': 10, 'bagging_fraction': 0.97, 'bagging_freq': 23, 'feature_fraction': 0.6719999999999999, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6719999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6719999999999999\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.04922\n",
      "Early stopping, best iteration is:\n",
      "[6408]\tvalid_0's l1: 2.02696\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6719999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6719999999999999\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.06246\n",
      "[6666]\tvalid_0's l1: 2.03527\n",
      "Early stopping, best iteration is:\n",
      "[6425]\tvalid_0's l1: 2.03478\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6719999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6719999999999999\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.06325\n",
      "Early stopping, best iteration is:\n",
      "[6202]\tvalid_0's l1: 2.03553\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.053, 'num_leaves': 792, 'max_depth': 10, 'bagging_fraction': 0.8536, 'bagging_freq': 19, 'feature_fraction': 0.5888, 'lambda_l1': 8, 'lambda_l2': 19}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5888, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5888\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8536\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.88908\n",
      "[6666]\tvalid_0's l1: 1.8458\n",
      "[9999]\tvalid_0's l1: 1.81881\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9997]\tvalid_0's l1: 1.81879\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5888, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5888\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8536\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.88747\n",
      "[6666]\tvalid_0's l1: 1.84407\n",
      "[9999]\tvalid_0's l1: 1.8165\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9997]\tvalid_0's l1: 1.81648\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5888, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5888\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8536\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.89449\n",
      "[6666]\tvalid_0's l1: 1.85094\n",
      "[9999]\tvalid_0's l1: 1.8232\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9998]\tvalid_0's l1: 1.8232\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 25, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.10682\n",
      "Early stopping, best iteration is:\n",
      "[5483]\tvalid_0's l1: 2.09212\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.10918\n",
      "[6666]\tvalid_0's l1: 2.09212\n",
      "Early stopping, best iteration is:\n",
      "[7526]\tvalid_0's l1: 2.08886\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.11404\n",
      "[6666]\tvalid_0's l1: 2.09665\n",
      "Early stopping, best iteration is:\n",
      "[6633]\tvalid_0's l1: 2.09603\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.052469999999999996, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 14, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[460]\tvalid_0's l1: 3.33361\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[897]\tvalid_0's l1: 3.34146\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=14, reg_alpha=0.0 will be ignored. Current value: lambda_l1=14\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[460]\tvalid_0's l1: 3.35157\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.02548, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 20, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 14}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2053]\tvalid_0's l1: 1.96504\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2449]\tvalid_0's l1: 1.96646\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=14, reg_lambda=0.0 will be ignored. Current value: lambda_l2=14\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2429]\tvalid_0's l1: 1.9748\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.0618, 'num_leaves': 1993, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 7, 'lambda_l2': 10}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90022\n",
      "Early stopping, best iteration is:\n",
      "[6009]\tvalid_0's l1: 1.88914\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.89869\n",
      "[6666]\tvalid_0's l1: 1.8886\n",
      "[9999]\tvalid_0's l1: 1.88371\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9916]\tvalid_0's l1: 1.88349\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90461\n",
      "Early stopping, best iteration is:\n",
      "[4350]\tvalid_0's l1: 1.89992\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1605, 'max_depth': 10, 'bagging_fraction': 0.7995000000000001, 'bagging_freq': 19, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 16}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7995000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7995000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.05888\n",
      "[6666]\tvalid_0's l1: 2.00833\n",
      "[9999]\tvalid_0's l1: 1.9792\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.97917\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7995000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7995000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.06545\n",
      "[6666]\tvalid_0's l1: 2.01115\n",
      "[9999]\tvalid_0's l1: 1.97958\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.97956\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7995000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7995000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=16, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.0738\n",
      "[6666]\tvalid_0's l1: 2.01858\n",
      "[9999]\tvalid_0's l1: 1.98844\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9989]\tvalid_0's l1: 1.9884\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1552, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.84517\n",
      "[6666]\tvalid_0's l1: 1.81317\n",
      "[9999]\tvalid_0's l1: 1.79704\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9985]\tvalid_0's l1: 1.797\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.84096\n",
      "[6666]\tvalid_0's l1: 1.80853\n",
      "[9999]\tvalid_0's l1: 1.79107\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9913]\tvalid_0's l1: 1.79095\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.84845\n",
      "[6666]\tvalid_0's l1: 1.81648\n",
      "[9999]\tvalid_0's l1: 1.79879\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.79879\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'energy_cluster', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 21, 'feature_fraction': 0.64, 'lambda_l1': 9, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9415\n",
      "Early stopping, best iteration is:\n",
      "[3084]\tvalid_0's l1: 1.94126\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93606\n",
      "Early stopping, best iteration is:\n",
      "[3183]\tvalid_0's l1: 1.93558\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9455\n",
      "Early stopping, best iteration is:\n",
      "[3234]\tvalid_0's l1: 1.94539\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1552, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 16, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.96241\n",
      "[6666]\tvalid_0's l1: 1.95486\n",
      "Early stopping, best iteration is:\n",
      "[7986]\tvalid_0's l1: 1.95353\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.95778\n",
      "[6666]\tvalid_0's l1: 1.95017\n",
      "Early stopping, best iteration is:\n",
      "[8336]\tvalid_0's l1: 1.94848\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97189\n",
      "[6666]\tvalid_0's l1: 1.96452\n",
      "Early stopping, best iteration is:\n",
      "[8684]\tvalid_0's l1: 1.96271\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 10, 'bagging_fraction': 0.65, 'bagging_freq': 17, 'feature_fraction': 0.64, 'lambda_l1': 11, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1376]\tvalid_0's l1: 2.65589\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2078]\tvalid_0's l1: 2.66115\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=11, reg_alpha=0.0 will be ignored. Current value: lambda_l1=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1376]\tvalid_0's l1: 2.66912\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 20, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[865]\tvalid_0's l1: 2.88437\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[595]\tvalid_0's l1: 2.89127\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[864]\tvalid_0's l1: 2.89798\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 3, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 23, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 19}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02017\n",
      "Early stopping, best iteration is:\n",
      "[5682]\tvalid_0's l1: 2.01134\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.01472\n",
      "Early stopping, best iteration is:\n",
      "[4884]\tvalid_0's l1: 2.0078\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=19, reg_lambda=0.0 will be ignored. Current value: lambda_l2=19\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02629\n",
      "Early stopping, best iteration is:\n",
      "[4839]\tvalid_0's l1: 2.01857\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.7706509815955915\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.7896385599918885\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.7955796378077282\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.8063508512431472\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited non-use of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 1 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited non-use of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 2 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 0.65 from 3\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 3 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited non-use of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited non-use of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 4 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited non-use of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited non-use of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 5 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 3\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 3\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 6 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 23 from 3\n",
      "inherited feature_fraction value of 0.84 from 3\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited non-use of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 7 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 1764 from 3\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 23 from 3\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited non-use of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 8 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 23 from 3\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 9 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited non-use of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 10 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 11 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 23 from 3\n",
      "inherited feature_fraction value of 0.84 from 3\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 12 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited non-use of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited non-use of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 13 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 3\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 3\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 14 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 15 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1764 from 3\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_freq by 23.0% from 21 to 26\n",
      "\u001b[1m\u001b[92mChild 1\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 7.000000000000001% from 0.028 to 0.02604\n",
      "Decreased num_leaves by 18.0% from 1764 to 1446\n",
      "Decreased lambda_l2 by 12.0% from 15 to 13\n",
      "\u001b[1m\u001b[92mChild 2\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using is_weekend\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_fraction by 3.0% from 0.65 to 0.6695\n",
      "Increased bagging_freq by 21.0% from 21 to 25\n",
      "Increased lambda_l2 by 14.000000000000002% from 10 to 11\n",
      "\u001b[1m\u001b[92mChild 3\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_year_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 0.0% from 11 to 11\n",
      "Decreased bagging_freq by 3.0% from 21 to 20\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using month_ord\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 22.0% from 11 to 13\n",
      "Decreased lambda_l2 by 2.0% from 10 to 10\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l1 by 16.0% from 8 to 7\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 8.0% from 11 to 12\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to start using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 22.0% from 1764 to 2152\n",
      "Decreased bagging_fraction by 6.0% from 0.65 to 0.611\n",
      "Decreased feature_fraction by 18.0% from 0.84 to 0.6888\n",
      "Increased lambda_l1 by 4.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased num_leaves by 12.0% from 1552 to 1366\n",
      "Increased max_depth by 17.0% from 11 to 13\n",
      "Decreased bagging_fraction by 24.0% from 0.65 to 0.494\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 19.0% from 0.65 to 0.5265\n",
      "Decreased feature_fraction by 19.0% from 0.84 to 0.6804\n",
      "Decreased lambda_l1 by 24.0% from 8 to 6\n",
      "Decreased lambda_l2 by 22.0% from 15 to 12\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 8.0% from 0.65 to 0.598\n",
      "Increased lambda_l2 by 5.0% from 10 to 10\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l1 by 9.0% from 8 to 7\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 19.0% from 1552 to 1847\n",
      "Increased feature_fraction by 7.000000000000001% from 0.84 to 0.8987999999999999\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 23.0% from 11 to 14\n",
      "Increased bagging_fraction by 18.0% from 0.65 to 0.767\n",
      "Increased lambda_l2 by 15.0% from 10 to 12\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using month_ord\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 5.0% from 0.028 to 0.0266\n",
      "Decreased num_leaves by 11.0% from 1764 to 1570\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec030046a0454442bc161dda47e87dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_month', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1552, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 26, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[274]\tvalid_0's l1: 2.65036\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[249]\tvalid_0's l1: 2.6554\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=26, subsample_freq=0 will be ignored. Current value: bagging_freq=26\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's l1: 2.66119\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_month', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.02604, 'num_leaves': 1446, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 13}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92504\n",
      "[6666]\tvalid_0's l1: 1.91328\n",
      "Early stopping, best iteration is:\n",
      "[8013]\tvalid_0's l1: 1.9092\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.92514\n",
      "[6666]\tvalid_0's l1: 1.91519\n",
      "[9999]\tvalid_0's l1: 1.90677\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9913]\tvalid_0's l1: 1.90652\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=13, reg_lambda=0.0 will be ignored. Current value: lambda_l2=13\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93058\n",
      "[6666]\tvalid_0's l1: 1.91843\n",
      "[9999]\tvalid_0's l1: 1.90996\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.90996\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1552, 'max_depth': 11, 'bagging_fraction': 0.6695, 'bagging_freq': 25, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 11}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6695\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[375]\tvalid_0's l1: 3.41557\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6695\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[700]\tvalid_0's l1: 3.41982\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6695\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=25, subsample_freq=0 will be ignored. Current value: bagging_freq=25\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's l1: 3.42723\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_year_cyclic', 'day_of_week', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1552, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 20, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[228]\tvalid_0's l1: 2.93194\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's l1: 2.93568\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[228]\tvalid_0's l1: 2.93831\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1552, 'max_depth': 13, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.04338\n",
      "[6666]\tvalid_0's l1: 2.02272\n",
      "Early stopping, best iteration is:\n",
      "[7875]\tvalid_0's l1: 2.02011\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.03869\n",
      "Early stopping, best iteration is:\n",
      "[4633]\tvalid_0's l1: 2.02663\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.05077\n",
      "[6666]\tvalid_0's l1: 2.03315\n",
      "Early stopping, best iteration is:\n",
      "[7611]\tvalid_0's l1: 2.02958\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 7, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98939\n",
      "[6666]\tvalid_0's l1: 1.95391\n",
      "[9999]\tvalid_0's l1: 1.93809\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.93809\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98485\n",
      "[6666]\tvalid_0's l1: 1.94572\n",
      "[9999]\tvalid_0's l1: 1.93206\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.93205\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99208\n",
      "[6666]\tvalid_0's l1: 1.95802\n",
      "[9999]\tvalid_0's l1: 1.94295\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9998]\tvalid_0's l1: 1.94295\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1764, 'max_depth': 12, 'bagging_fraction': 0.65, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[459]\tvalid_0's l1: 2.6423\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[346]\tvalid_0's l1: 2.65015\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's l1: 2.65777\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 2152, 'max_depth': 11, 'bagging_fraction': 0.611, 'bagging_freq': 23, 'feature_fraction': 0.6888, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6888, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6888\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.611, subsample=1.0 will be ignored. Current value: bagging_fraction=0.611\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.89909\n",
      "[6666]\tvalid_0's l1: 1.85251\n",
      "[9999]\tvalid_0's l1: 1.82236\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.82235\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6888, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6888\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.611, subsample=1.0 will be ignored. Current value: bagging_fraction=0.611\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90148\n",
      "[6666]\tvalid_0's l1: 1.8522\n",
      "[9999]\tvalid_0's l1: 1.82118\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9997]\tvalid_0's l1: 1.82116\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6888, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6888\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.611, subsample=1.0 will be ignored. Current value: bagging_fraction=0.611\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90468\n",
      "[6666]\tvalid_0's l1: 1.85569\n",
      "[9999]\tvalid_0's l1: 1.82578\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.82578\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1366, 'max_depth': 13, 'bagging_fraction': 0.494, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.494\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.88185\n",
      "[6666]\tvalid_0's l1: 1.84803\n",
      "[9999]\tvalid_0's l1: 1.82528\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.82527\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.494\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.88508\n",
      "[6666]\tvalid_0's l1: 1.84793\n",
      "[9999]\tvalid_0's l1: 1.82668\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.82667\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.494, subsample=1.0 will be ignored. Current value: bagging_fraction=0.494\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.88675\n",
      "[6666]\tvalid_0's l1: 1.85241\n",
      "[9999]\tvalid_0's l1: 1.8285\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.82849\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.5265, 'bagging_freq': 21, 'feature_fraction': 0.6804, 'lambda_l1': 6, 'lambda_l2': 12}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6804, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6804\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5265, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5265\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=12, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.11951\n",
      "[6666]\tvalid_0's l1: 2.08284\n",
      "[9999]\tvalid_0's l1: 2.06433\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9897]\tvalid_0's l1: 2.06321\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6804, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6804\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5265, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5265\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=12, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.11634\n",
      "[6666]\tvalid_0's l1: 2.07868\n",
      "[9999]\tvalid_0's l1: 2.06099\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9915]\tvalid_0's l1: 2.06021\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6804, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6804\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5265, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5265\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=12, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.12771\n",
      "[6666]\tvalid_0's l1: 2.0904\n",
      "Early stopping, best iteration is:\n",
      "[7942]\tvalid_0's l1: 2.08173\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.598, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.598\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[993]\tvalid_0's l1: 2.65586\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.598\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1428]\tvalid_0's l1: 2.66109\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.598\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1431]\tvalid_0's l1: 2.66788\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_year_cyclic', 'day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 7, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's l1: 2.86144\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's l1: 2.86589\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=7, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's l1: 2.87257\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1847, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.8987999999999999, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8987999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8987999999999999\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[646]\tvalid_0's l1: 2.4581\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8987999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8987999999999999\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[642]\tvalid_0's l1: 2.46357\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8987999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8987999999999999\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[628]\tvalid_0's l1: 2.46737\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 14, 'bagging_fraction': 0.767, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 12}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.767, subsample=1.0 will be ignored. Current value: bagging_fraction=0.767\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=12, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93636\n",
      "[6666]\tvalid_0's l1: 1.9262\n",
      "Early stopping, best iteration is:\n",
      "[7037]\tvalid_0's l1: 1.9247\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.767, subsample=1.0 will be ignored. Current value: bagging_fraction=0.767\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=12, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93498\n",
      "[6666]\tvalid_0's l1: 1.92524\n",
      "Early stopping, best iteration is:\n",
      "[6455]\tvalid_0's l1: 1.92486\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.767, subsample=1.0 will be ignored. Current value: bagging_fraction=0.767\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=12, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94464\n",
      "Early stopping, best iteration is:\n",
      "[5127]\tvalid_0's l1: 1.93712\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_ord', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1552, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2013]\tvalid_0's l1: 1.96372\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2398]\tvalid_0's l1: 1.95886\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2839]\tvalid_0's l1: 1.96805\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 4, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['month_ord', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.0266, 'num_leaves': 1570, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[483]\tvalid_0's l1: 4.59967\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[606]\tvalid_0's l1: 4.59851\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[588]\tvalid_0's l1: 4.61339\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.7706509815955915\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.7896385599918885\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.7955796378077282\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.8063508512431472\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 1 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 2 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 1764 from 3\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited non-use of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 3 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 23 from 3\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 4 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 5 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 6 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 7 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 8 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 9 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 10 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 11 parents = 1 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited non-use of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited non-use of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 12 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 13 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 14 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 15 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 2\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited non-use of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited non-use of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 17.0% from 0.06 to 0.0498\n",
      "\u001b[1m\u001b[92mChild 1\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 2.0% from 11 to 11\n",
      "Increased lambda_l1 by 13.0% from 8 to 9\n",
      "\u001b[1m\u001b[92mChild 2\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 4.0% from 1764 to 1835\n",
      "\u001b[1m\u001b[92mChild 3\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using day_of_week\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 10.0% from 11 to 10\n",
      "Increased feature_fraction by 23.0% from 0.64 to 0.7872\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_freq by 15.0% from 23 to 20\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using is_weekend\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 10.0% from 0.028 to 0.0308\n",
      "Decreased lambda_l2 by 7.000000000000001% from 10 to 9\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_freq by 9.0% from 23 to 21\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_freq by 4.0% from 23 to 24\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 2.0% from 11 to 11\n",
      "Increased bagging_fraction by 14.000000000000002% from 0.65 to 0.741\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 10.0% from 11 to 10\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 12.0% from 1552 to 1738\n",
      "Increased bagging_fraction by 18.0% from 0.65 to 0.767\n",
      "Increased feature_fraction by 17.0% from 0.84 to 0.9828\n",
      "Increased lambda_l1 by 16.0% from 8 to 9\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 15.0% from 11 to 13\n",
      "Decreased lambda_l1 by 23.0% from 8 to 6\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased lambda_l1 by 5.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased lambda_l2 by 14.000000000000002% from 10 to 11\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 20.0% from 11 to 9\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece12023446d4b27b32a28a3a3f834e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.0498, 'num_leaves': 1552, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid_0's l1: 3.33431\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid_0's l1: 3.34318\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[420]\tvalid_0's l1: 3.35237\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 9, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[596]\tvalid_0's l1: 3.33424\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[606]\tvalid_0's l1: 3.3418\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[461]\tvalid_0's l1: 3.35181\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1835, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1027]\tvalid_0's l1: 2.654\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1134]\tvalid_0's l1: 2.66023\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1428]\tvalid_0's l1: 2.66558\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 10, 'bagging_fraction': 0.97, 'bagging_freq': 23, 'feature_fraction': 0.7872, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7872\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9364\n",
      "[6666]\tvalid_0's l1: 1.92643\n",
      "[9999]\tvalid_0's l1: 1.92078\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9998]\tvalid_0's l1: 1.92077\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7872\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93151\n",
      "[6666]\tvalid_0's l1: 1.92139\n",
      "[9999]\tvalid_0's l1: 1.91666\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.91666\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7872, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7872\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94478\n",
      "[6666]\tvalid_0's l1: 1.93452\n",
      "[9999]\tvalid_0's l1: 1.92934\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.92933\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 20, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[943]\tvalid_0's l1: 2.6339\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[940]\tvalid_0's l1: 2.64033\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1086]\tvalid_0's l1: 2.64755\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_month', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.0308, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 9}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Individual 5 failed 1 times\n",
      "Changing feature fraction from 0.64 to 0.28\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Individual 5 failed 2 times\n",
      "Changing feature fraction from 0.28 to 0.07\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Individual 5 failed 3 times\n",
      "Changing feature fraction from 0.07 to 0.48\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Individual 5 failed 4 times\n",
      "Changing feature fraction from 0.48 to 0.14\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Individual 5 failed 5 times\n",
      "Changing feature fraction from 0.14 to 0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Individual 5 failed 6 times\n",
      "Changing feature fraction from 0.11 to 0.31\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Individual 5 failed 7 times\n",
      "Changing feature fraction from 0.31 to 0.81\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02102\n",
      "[6666]\tvalid_0's l1: 1.98584\n",
      "[9999]\tvalid_0's l1: 1.96594\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.96592\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.81, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.81\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02123\n",
      "[6666]\tvalid_0's l1: 1.98767\n",
      "[9999]\tvalid_0's l1: 1.96738\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9933]\tvalid_0's l1: 1.96732\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.81, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.81\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02525\n",
      "[6666]\tvalid_0's l1: 1.99026\n",
      "[9999]\tvalid_0's l1: 1.97147\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 1.97147\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1601]\tvalid_0's l1: 1.92582\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1626]\tvalid_0's l1: 1.91834\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1558]\tvalid_0's l1: 1.93055\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'is_weekend', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 24, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[552]\tvalid_0's l1: 4.74257\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[528]\tvalid_0's l1: 4.74142\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[528]\tvalid_0's l1: 4.75871\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'day_of_month', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.741, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.741, subsample=1.0 will be ignored. Current value: bagging_fraction=0.741\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's l1: 2.88375\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.741, subsample=1.0 will be ignored. Current value: bagging_fraction=0.741\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's l1: 2.88896\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.741, subsample=1.0 will be ignored. Current value: bagging_fraction=0.741\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's l1: 2.89271\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1552, 'max_depth': 10, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1429]\tvalid_0's l1: 2.65559\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1038]\tvalid_0's l1: 2.66475\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[819]\tvalid_0's l1: 2.67132\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1738, 'max_depth': 11, 'bagging_fraction': 0.767, 'bagging_freq': 21, 'feature_fraction': 0.9828, 'lambda_l1': 9, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9828\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.767, subsample=1.0 will be ignored. Current value: bagging_fraction=0.767\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1029]\tvalid_0's l1: 2.87448\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9828\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.767, subsample=1.0 will be ignored. Current value: bagging_fraction=0.767\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[674]\tvalid_0's l1: 2.88209\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9828, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9828\n",
      "[LightGBM] [Warning] lambda_l1 is set=9, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.767, subsample=1.0 will be ignored. Current value: bagging_fraction=0.767\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[588]\tvalid_0's l1: 2.88898\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1552, 'max_depth': 13, 'bagging_fraction': 0.65, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 6, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1566]\tvalid_0's l1: 2.68518\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1138]\tvalid_0's l1: 2.6938\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=6, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[897]\tvalid_0's l1: 2.70025\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.62424\n",
      "Early stopping, best iteration is:\n",
      "[4347]\tvalid_0's l1: 2.6233\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2478]\tvalid_0's l1: 2.63315\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1701]\tvalid_0's l1: 2.63927\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_ord', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1552, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 11}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2772]\tvalid_0's l1: 2.00875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.00762\n",
      "Early stopping, best iteration is:\n",
      "[3408]\tvalid_0's l1: 2.00683\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2588]\tvalid_0's l1: 2.01593\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2774]\tvalid_0's l1: 1.98109\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97897\n",
      "Early stopping, best iteration is:\n",
      "[5030]\tvalid_0's l1: 1.9756\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98957\n",
      "Early stopping, best iteration is:\n",
      "[4356]\tvalid_0's l1: 1.98744\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 5, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_month', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1552, 'max_depth': 9, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94413\n",
      "Early stopping, best iteration is:\n",
      "[4624]\tvalid_0's l1: 1.93766\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94429\n",
      "Early stopping, best iteration is:\n",
      "[3426]\tvalid_0's l1: 1.94371\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94784\n",
      "Early stopping, best iteration is:\n",
      "[5378]\tvalid_0's l1: 1.94163\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.7706509815955915\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.7896385599918885\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.7955796378077282\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.8063508512431472\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1552 from 2\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 1 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 1764 from 3\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 2 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited non-use of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 3 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 4 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 5 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 2\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 6 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1764 from 3\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 0.65 from 3\n",
      "inherited bagging_freq value of 21 from 2\n",
      "inherited feature_fraction value of 0.84 from 3\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited non-use of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited non-use of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited non-use of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 7 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 8 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 3\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 23 from 3\n",
      "inherited feature_fraction value of 0.84 from 3\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 9 parents = 3 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited non-use of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 10 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 11 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.64 from 1\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 12 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 3\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 3\n",
      "inherited bagging_freq value of 23 from 3\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 13 parents = 3 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 792 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.97 from 1\n",
      "inherited bagging_freq value of 23 from 3\n",
      "inherited feature_fraction value of 0.84 from 3\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 14 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 1764 from 3\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 3\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 3\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited non-use of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 15 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 3\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited non-use of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 17.0% from 0.65 to 0.5395\n",
      "Increased bagging_freq by 15.0% from 21 to 24\n",
      "Increased lambda_l1 by 24.0% from 8 to 10\n",
      "\u001b[1m\u001b[92mChild 1\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 11.0% from 0.028 to 0.03108\n",
      "Decreased bagging_fraction by 12.0% from 0.97 to 0.8536\n",
      "Decreased feature_fraction by 21.0% from 0.64 to 0.5056\n",
      "Increased lambda_l1 by 24.0% from 8 to 10\n",
      "\u001b[1m\u001b[92mChild 2\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using month_ord\n",
      "Mutated to stop using energy_cluster\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 3.0% from 0.06 to 0.0618\n",
      "\u001b[1m\u001b[92mChild 3\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to stop using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 16.0% from 0.06 to 0.0504\n",
      "Decreased num_leaves by 11.0% from 1764 to 1570\n",
      "Increased bagging_fraction by 5.0% from 0.97 to 1.0\n",
      "Increased feature_fraction by 14.000000000000002% from 0.84 to 0.9576\n",
      "Increased lambda_l2 by 17.0% from 15 to 18\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased feature_fraction by 22.0% from 0.84 to 0.6552\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using month_ord\n",
      "Mutated to start using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased num_leaves by 15.0% from 792 to 911\n",
      "Decreased bagging_fraction by 19.0% from 0.97 to 0.7857\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using day_of_week\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to start using is_weekend\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using day_of_week\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using day_of_week\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 9.0% from 0.06 to 0.054599999999999996\n",
      "Increased max_depth by 19.0% from 11 to 13\n",
      "Decreased bagging_fraction by 21.0% from 0.65 to 0.5135000000000001\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 17.0% from 11 to 9\n",
      "Decreased bagging_fraction by 21.0% from 0.97 to 0.7663\n",
      "Increased feature_fraction by 20.0% from 0.64 to 0.768\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 22.0% from 0.06 to 0.046799999999999994\n",
      "Decreased lambda_l1 by 1.0% from 8 to 8\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased max_depth by 2.0% from 11 to 11\n",
      "Decreased bagging_fraction by 6.0% from 0.97 to 0.9117999999999999\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_ord\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 7.000000000000001% from 0.028 to 0.02996\n",
      "Increased num_leaves by 5.0% from 1764 to 1852\n",
      "Decreased max_depth by 2.0% from 11 to 11\n",
      "Decreased bagging_fraction by 7.000000000000001% from 0.65 to 0.6045\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442313ccb82e49f59d684c20793a0bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_ord', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1552, 'max_depth': 11, 'bagging_fraction': 0.5395, 'bagging_freq': 24, 'feature_fraction': 0.84, 'lambda_l1': 10, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5395\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2091]\tvalid_0's l1: 1.96772\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5395\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2384]\tvalid_0's l1: 1.96382\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5395\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=24, subsample_freq=0 will be ignored. Current value: bagging_freq=24\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1977]\tvalid_0's l1: 1.97608\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.03108, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.8536, 'bagging_freq': 23, 'feature_fraction': 0.5056, 'lambda_l1': 10, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5056, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5056\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8536\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.00861\n",
      "[6666]\tvalid_0's l1: 1.99068\n",
      "Early stopping, best iteration is:\n",
      "[7820]\tvalid_0's l1: 1.98655\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5056, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5056\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8536\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.00738\n",
      "[6666]\tvalid_0's l1: 1.98887\n",
      "[9999]\tvalid_0's l1: 1.98131\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9979]\tvalid_0's l1: 1.98128\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5056, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5056\n",
      "[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8536\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.01415\n",
      "[6666]\tvalid_0's l1: 1.99722\n",
      "[9999]\tvalid_0's l1: 1.99013\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.99013\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.0618, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.04158\n",
      "Early stopping, best iteration is:\n",
      "[3451]\tvalid_0's l1: 2.04024\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.04259\n",
      "Early stopping, best iteration is:\n",
      "[4247]\tvalid_0's l1: 2.03621\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.04999\n",
      "Early stopping, best iteration is:\n",
      "[4353]\tvalid_0's l1: 2.04582\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'month_cyclic', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.0504, 'num_leaves': 1570, 'max_depth': 11, 'bagging_fraction': 1.0, 'bagging_freq': 23, 'feature_fraction': 0.9576, 'lambda_l1': 8, 'lambda_l2': 18}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9576, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9576\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=18, reg_lambda=0.0 will be ignored. Current value: lambda_l2=18\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's l1: 3.00565\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9576, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9576\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=18, reg_lambda=0.0 will be ignored. Current value: lambda_l2=18\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's l1: 3.00793\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9576, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9576\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=18, reg_lambda=0.0 will be ignored. Current value: lambda_l2=18\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's l1: 3.01414\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 21, 'feature_fraction': 0.6552, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6552, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6552\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98107\n",
      "[6666]\tvalid_0's l1: 1.96726\n",
      "Early stopping, best iteration is:\n",
      "[9629]\tvalid_0's l1: 1.96318\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6552, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6552\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9728\n",
      "[6666]\tvalid_0's l1: 1.96077\n",
      "Early stopping, best iteration is:\n",
      "[9673]\tvalid_0's l1: 1.95731\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6552, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6552\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98833\n",
      "[6666]\tvalid_0's l1: 1.97767\n",
      "Early stopping, best iteration is:\n",
      "[9639]\tvalid_0's l1: 1.97377\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 911, 'max_depth': 11, 'bagging_fraction': 0.7857, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7857, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7857\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.83023\n",
      "[6666]\tvalid_0's l1: 1.79575\n",
      "[9999]\tvalid_0's l1: 1.77342\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.77341\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7857, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7857\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.83519\n",
      "[6666]\tvalid_0's l1: 1.79976\n",
      "[9999]\tvalid_0's l1: 1.77753\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 1.77753\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7857, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7857\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.83572\n",
      "[6666]\tvalid_0's l1: 1.80096\n",
      "[9999]\tvalid_0's l1: 1.77887\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9996]\tvalid_0's l1: 1.77886\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'day_of_month', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid_0's l1: 2.87883\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's l1: 2.8822\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's l1: 2.88824\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97888\n",
      "Early stopping, best iteration is:\n",
      "[5544]\tvalid_0's l1: 1.96918\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97762\n",
      "Early stopping, best iteration is:\n",
      "[5758]\tvalid_0's l1: 1.96615\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6311]\tvalid_0's l1: 1.97592\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[987]\tvalid_0's l1: 2.68224\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[896]\tvalid_0's l1: 2.69077\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[897]\tvalid_0's l1: 2.69525\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['is_weekend', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[483]\tvalid_0's l1: 4.77134\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[462]\tvalid_0's l1: 4.76806\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's l1: 4.7863\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.054599999999999996, 'num_leaves': 1764, 'max_depth': 13, 'bagging_fraction': 0.5135000000000001, 'bagging_freq': 21, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5135000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5135000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99838\n",
      "[6666]\tvalid_0's l1: 1.97125\n",
      "Early stopping, best iteration is:\n",
      "[7379]\tvalid_0's l1: 1.96627\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5135000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5135000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.99956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6666]\tvalid_0's l1: 1.96982\n",
      "Early stopping, best iteration is:\n",
      "[8771]\tvalid_0's l1: 1.95882\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5135000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5135000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.00826\n",
      "[6666]\tvalid_0's l1: 1.98065\n",
      "Early stopping, best iteration is:\n",
      "[7901]\tvalid_0's l1: 1.97385\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 9, 'bagging_fraction': 0.7663, 'bagging_freq': 21, 'feature_fraction': 0.768, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.768\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7663\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[609]\tvalid_0's l1: 2.88558\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.768\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7663\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[672]\tvalid_0's l1: 2.89147\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.768, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.768\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7663\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[713]\tvalid_0's l1: 2.89882\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.046799999999999994, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's l1: 2.97138\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's l1: 2.97536\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's l1: 2.98116\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.9117999999999999, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9117999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9117999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2338]\tvalid_0's l1: 1.93417\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9117999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9117999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2847]\tvalid_0's l1: 1.93084\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9117999999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9117999999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2988]\tvalid_0's l1: 1.94639\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1984]\tvalid_0's l1: 1.9757\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2007]\tvalid_0's l1: 1.97638\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1873]\tvalid_0's l1: 1.98618\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 6, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'is_weekend', 'energy_cluster', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.02996, 'num_leaves': 1852, 'max_depth': 11, 'bagging_fraction': 0.6045, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6045\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[992]\tvalid_0's l1: 2.65256\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6045\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[613]\tvalid_0's l1: 2.66082\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6045\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1435]\tvalid_0's l1: 2.66567\n",
      "\u001b[93m\u001b[1mParent 0\u001b[0m has a mae of 1.7706509815955915\n",
      "\u001b[93m\u001b[1mParent 1\u001b[0m has a mae of 1.7766013179965336\n",
      "\u001b[93m\u001b[1mParent 2\u001b[0m has a mae of 1.7896385599918885\n",
      "\u001b[93m\u001b[1mParent 3\u001b[0m has a mae of 1.7955796378077282\n",
      "\u001b[1m\u001b[94mGenerating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 792 from 2\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 3\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited non-use of feature group day_of_week from 3\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited non-use of feature group month_ord from 3\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited non-use of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 1 parents = 2 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 792 from 2\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 2 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 792 from 2\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.97 from 2\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 3 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 1552 from 3\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 3\n",
      "inherited bagging_freq value of 21 from 3\n",
      "inherited feature_fraction value of 0.84 from 1\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited non-use of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited non-use of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 4 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 911 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.97 from 2\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 5 parents = 0 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 911 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 6 parents = 0 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1552 from 3\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited non-use of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 0\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 7 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 0\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 8 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 1552 from 3\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 0.97 from 2\n",
      "inherited bagging_freq value of 21 from 3\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 8 from 2\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited non-use of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited non-use of feature group dwelling_type_ord from 3\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[92mChild 9 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 0\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 1\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 0\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 0\n",
      "inherited usage of feature group energy_cluster from 0\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 10 parents = 2 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 3\n",
      "inherited num_leaves value of 792 from 2\n",
      "inherited max_depth value of 11 from 3\n",
      "inherited bagging_fraction value of 0.97 from 2\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.84 from 3\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 2\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 11 parents = 1 and 0\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 0\n",
      "inherited bagging_fraction value of 0.65 from 0\n",
      "inherited bagging_freq value of 21 from 0\n",
      "inherited feature_fraction value of 0.84 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited usage of feature group day_of_week from 0\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 12 parents = 2 and 1\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 911 from 1\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.7857 from 1\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.84 from 1\n",
      "inherited lambda_l1 value of 8 from 1\n",
      "inherited lambda_l2 value of 10 from 2\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 1\n",
      "inherited non-use of feature group meter_id_binary from 2\n",
      "inherited non-use of feature group day_of_year_cyclic from 2\n",
      "inherited usage of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 2\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 2\n",
      "inherited usage of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 1\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 2\n",
      "\u001b[1m\u001b[92mChild 13 parents = 1 and 3\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 1\n",
      "inherited num_leaves value of 911 from 1\n",
      "inherited max_depth value of 11 from 1\n",
      "inherited bagging_fraction value of 0.7857 from 1\n",
      "inherited bagging_freq value of 23 from 1\n",
      "inherited feature_fraction value of 0.84 from 3\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 1\n",
      "inherited non-use of feature group day_of_year_cyclic from 1\n",
      "inherited non-use of feature group day_of_week from 1\n",
      "inherited non-use of feature group day_of_month from 1\n",
      "inherited usage of feature group month_ord from 1\n",
      "inherited non-use of feature group month_cyclic from 1\n",
      "inherited non-use of feature group is_weekend from 1\n",
      "inherited usage of feature group energy_cluster from 3\n",
      "inherited usage of feature group num_bedrooms from 1\n",
      "inherited non-use of feature group dwelling_type_ord from 1\n",
      "inherited non-use of feature group dwelling_type_onehot from 1\n",
      "\u001b[1m\u001b[92mChild 14 parents = 0 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.06 from 0\n",
      "inherited num_leaves value of 1764 from 0\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.97 from 2\n",
      "inherited bagging_freq value of 23 from 2\n",
      "inherited feature_fraction value of 0.64 from 2\n",
      "inherited lambda_l1 value of 8 from 0\n",
      "inherited lambda_l2 value of 15 from 0\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 2\n",
      "inherited non-use of feature group meter_id_binary from 0\n",
      "inherited non-use of feature group day_of_year_cyclic from 0\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 0\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 0\n",
      "inherited usage of feature group is_weekend from 2\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 0\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 0\n",
      "\u001b[1m\u001b[92mChild 15 parents = 3 and 2\u001b[0m\n",
      "\u001b[1m\u001b[93minherited hyper parameters\u001b[0m\n",
      "inherited learning_rate value of 0.028 from 2\n",
      "inherited num_leaves value of 1552 from 3\n",
      "inherited max_depth value of 11 from 2\n",
      "inherited bagging_fraction value of 0.65 from 3\n",
      "inherited bagging_freq value of 21 from 3\n",
      "inherited feature_fraction value of 0.84 from 3\n",
      "inherited lambda_l1 value of 8 from 3\n",
      "inherited lambda_l2 value of 10 from 3\n",
      "\u001b[1m\u001b[93minherited feature groups\u001b[0m\n",
      "inherited usage of feature group meter_id_ord from 3\n",
      "inherited non-use of feature group meter_id_binary from 3\n",
      "inherited non-use of feature group day_of_year_cyclic from 3\n",
      "inherited usage of feature group day_of_week from 2\n",
      "inherited non-use of feature group day_of_month from 3\n",
      "inherited usage of feature group month_ord from 2\n",
      "inherited non-use of feature group month_cyclic from 3\n",
      "inherited non-use of feature group is_weekend from 3\n",
      "inherited usage of feature group energy_cluster from 2\n",
      "inherited usage of feature group num_bedrooms from 3\n",
      "inherited usage of feature group dwelling_type_ord from 2\n",
      "inherited non-use of feature group dwelling_type_onehot from 3\n",
      "\u001b[1m\u001b[94mMutating the children\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 0\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to start using day_of_week\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased learning_rate by 15.0% from 0.028 to 0.0322\n",
      "Decreased bagging_fraction by 6.0% from 0.65 to 0.611\n",
      "Decreased bagging_freq by 6.0% from 23 to 22\n",
      "Increased lambda_l2 by 7.000000000000001% from 10 to 11\n",
      "\u001b[1m\u001b[92mChild 1\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased lambda_l2 by 2.0% from 10 to 10\n",
      "\u001b[1m\u001b[92mChild 2\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased learning_rate by 16.0% from 0.028 to 0.02352\n",
      "\u001b[1m\u001b[92mChild 3\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to stop using num_bedrooms\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 4\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to stop using month_ord\n",
      "Mutated to stop using num_bedrooms\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "\u001b[1m\u001b[92mChild 5\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 8.0% from 0.65 to 0.598\n",
      "\u001b[1m\u001b[92mChild 6\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using meter_id_ord\n",
      "Mutated to start using is_weekend\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased feature_fraction by 10.0% from 0.84 to 0.9239999999999999\n",
      "\u001b[1m\u001b[92mChild 7\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_year_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 5.0% from 11 to 12\n",
      "Increased bagging_fraction by 8.0% from 0.65 to 0.7020000000000001\n",
      "Decreased feature_fraction by 7.000000000000001% from 0.84 to 0.7812\n",
      "\u001b[1m\u001b[92mChild 8\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to stop using month_ord\n",
      "Mutated to start using month_cyclic\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased feature_fraction by 7.000000000000001% from 0.64 to 0.6848000000000001\n",
      "\u001b[1m\u001b[92mChild 9\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using dwelling_type_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_fraction by 3.0% from 0.65 to 0.6695\n",
      "Increased lambda_l2 by 7.000000000000001% from 10 to 11\n",
      "\u001b[1m\u001b[92mChild 10\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased max_depth by 17.0% from 11 to 13\n",
      "\u001b[1m\u001b[92mChild 11\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using is_weekend\n",
      "Mutated to start using dwelling_type_onehot\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased feature_fraction by 8.0% from 0.84 to 0.9072\n",
      "Increased lambda_l2 by 12.0% from 15 to 17\n",
      "\u001b[1m\u001b[92mChild 12\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 9.0% from 0.7857 to 0.7149869999999999\n",
      "Decreased bagging_freq by 10.0% from 23 to 21\n",
      "Increased feature_fraction by 10.0% from 0.84 to 0.9239999999999999\n",
      "\u001b[1m\u001b[92mChild 13\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to stop using energy_cluster\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased bagging_fraction by 8.0% from 0.7857 to 0.7228439999999999\n",
      "\u001b[1m\u001b[92mChild 14\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using day_of_month\n",
      "Mutated to start using month_cyclic\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Decreased feature_fraction by 18.0% from 0.64 to 0.5248\n",
      "\u001b[1m\u001b[92mChild 15\u001b[0m\n",
      "\u001b[1m\u001b[93mMutating Columns Groups via Bit Flip\u001b[0m\n",
      "Mutated to start using meter_id_binary\n",
      "Mutated to start using day_of_year_cyclic\n",
      "Mutated to stop using month_ord\n",
      "\u001b[1m\u001b[93mMutating hyper parameters via gaussian\u001b[0m\n",
      "Increased bagging_fraction by 6.0% from 0.65 to 0.6890000000000001\n",
      "Increased lambda_l2 by 11.0% from 10 to 11\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72278a1f6bc41b69606fdda77ee376b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 0\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.0322, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.611, 'bagging_freq': 22, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 11}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.611, subsample=1.0 will be ignored. Current value: bagging_fraction=0.611\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93043\n",
      "[6666]\tvalid_0's l1: 1.88458\n",
      "[9999]\tvalid_0's l1: 1.85508\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.85507\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.611, subsample=1.0 will be ignored. Current value: bagging_fraction=0.611\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93597\n",
      "[6666]\tvalid_0's l1: 1.89253\n",
      "[9999]\tvalid_0's l1: 1.86428\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's l1: 1.86428\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.611, subsample=1.0 will be ignored. Current value: bagging_fraction=0.611\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93861\n",
      "[6666]\tvalid_0's l1: 1.89282\n",
      "[9999]\tvalid_0's l1: 1.86334\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9995]\tvalid_0's l1: 1.86333\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 1\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 23, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.00849\n",
      "Early stopping, best iteration is:\n",
      "[5052]\tvalid_0's l1: 1.99628\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.01019\n",
      "[6666]\tvalid_0's l1: 1.99191\n",
      "Early stopping, best iteration is:\n",
      "[6930]\tvalid_0's l1: 1.99014\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.01858\n",
      "[6666]\tvalid_0's l1: 2.00281\n",
      "Early stopping, best iteration is:\n",
      "[7381]\tvalid_0's l1: 1.99972\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 2\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'is_weekend', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.02352, 'num_leaves': 792, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 23, 'feature_fraction': 0.64, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1606]\tvalid_0's l1: 2.6412\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1424]\tvalid_0's l1: 2.64799\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.64, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.64\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1261]\tvalid_0's l1: 2.65462\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 3\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_month', 'month_cyclic', 'energy_cluster']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1552, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1234]\tvalid_0's l1: 1.95592\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1325]\tvalid_0's l1: 1.95928\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1458]\tvalid_0's l1: 1.96685\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 4\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_binary', 'day_of_week', 'is_weekend', 'energy_cluster', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 911, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.67988\n",
      "[6666]\tvalid_0's l1: 2.66856\n",
      "Early stopping, best iteration is:\n",
      "[8236]\tvalid_0's l1: 2.66569\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.68472\n",
      "[6666]\tvalid_0's l1: 2.67355\n",
      "Early stopping, best iteration is:\n",
      "[8257]\tvalid_0's l1: 2.67108\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.6942\n",
      "[6666]\tvalid_0's l1: 2.68367\n",
      "[9999]\tvalid_0's l1: 2.67846\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9982]\tvalid_0's l1: 2.67843\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 5\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 911, 'max_depth': 11, 'bagging_fraction': 0.598, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.598\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's l1: 2.94903\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.598\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's l1: 2.95447\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.598, subsample=1.0 will be ignored. Current value: bagging_fraction=0.598\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's l1: 2.95773\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 6\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1552, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.9239999999999999, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9239999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9239999999999999\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid_0's l1: 2.887\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9239999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9239999999999999\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's l1: 2.89437\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9239999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9239999999999999\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's l1: 2.90091\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_year_cyclic', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1764, 'max_depth': 12, 'bagging_fraction': 0.7020000000000001, 'bagging_freq': 21, 'feature_fraction': 0.7812, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7020000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7020000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.82543\n",
      "[6666]\tvalid_0's l1: 1.78618\n",
      "[9999]\tvalid_0's l1: 1.76484\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9979]\tvalid_0's l1: 1.76478\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7020000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7020000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.81806\n",
      "[6666]\tvalid_0's l1: 1.77848\n",
      "[9999]\tvalid_0's l1: 1.75674\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.75672\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7020000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7020000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.82576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6666]\tvalid_0's l1: 1.78777\n",
      "[9999]\tvalid_0's l1: 1.76479\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.76478\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 8\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'month_cyclic', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1552, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 21, 'feature_fraction': 0.6848000000000001, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6848000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6848000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9605\n",
      "Early stopping, best iteration is:\n",
      "[3590]\tvalid_0's l1: 1.95978\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6848000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6848000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.95963\n",
      "Early stopping, best iteration is:\n",
      "[4179]\tvalid_0's l1: 1.95711\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6848000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6848000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97162\n",
      "Early stopping, best iteration is:\n",
      "[3961]\tvalid_0's l1: 1.97047\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 9\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.6695, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 11}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6695\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9777\n",
      "Early stopping, best iteration is:\n",
      "[3784]\tvalid_0's l1: 1.97568\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6695\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97802\n",
      "Early stopping, best iteration is:\n",
      "[3736]\tvalid_0's l1: 1.97577\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6695\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2840]\tvalid_0's l1: 1.98807\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 10\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 792, 'max_depth': 13, 'bagging_fraction': 0.97, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2093]\tvalid_0's l1: 1.92389\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2011]\tvalid_0's l1: 1.91727\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1947]\tvalid_0's l1: 1.9325\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 11\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'energy_cluster', 'num_bedrooms', 'dwelling_type_onehot']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.65, 'bagging_freq': 21, 'feature_fraction': 0.9072, 'lambda_l1': 8, 'lambda_l2': 17}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9072\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=17, reg_lambda=0.0 will be ignored. Current value: lambda_l2=17\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2774]\tvalid_0's l1: 1.97756\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9072\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=17, reg_lambda=0.0 will be ignored. Current value: lambda_l2=17\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97517\n",
      "Early stopping, best iteration is:\n",
      "[3427]\tvalid_0's l1: 1.97419\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9072\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.65, subsample=1.0 will be ignored. Current value: bagging_fraction=0.65\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=17, reg_lambda=0.0 will be ignored. Current value: lambda_l2=17\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2585]\tvalid_0's l1: 1.9888\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 12\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'month_ord', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 911, 'max_depth': 11, 'bagging_fraction': 0.7149869999999999, 'bagging_freq': 21, 'feature_fraction': 0.9239999999999999, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9239999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9239999999999999\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7149869999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7149869999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97422\n",
      "Early stopping, best iteration is:\n",
      "[4141]\tvalid_0's l1: 1.97197\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9239999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9239999999999999\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7149869999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7149869999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.97466\n",
      "Early stopping, best iteration is:\n",
      "[3422]\tvalid_0's l1: 1.97395\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9239999999999999, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9239999999999999\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7149869999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7149869999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.98693\n",
      "Early stopping, best iteration is:\n",
      "[4347]\tvalid_0's l1: 1.98448\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 13\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'month_ord', 'num_bedrooms']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 911, 'max_depth': 11, 'bagging_fraction': 0.7228439999999999, 'bagging_freq': 23, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 10}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7228439999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7228439999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02447\n",
      "[6666]\tvalid_0's l1: 2.00883\n",
      "Early stopping, best iteration is:\n",
      "[8683]\tvalid_0's l1: 2.00109\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7228439999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7228439999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.02041\n",
      "[6666]\tvalid_0's l1: 2.00446\n",
      "Early stopping, best iteration is:\n",
      "[6442]\tvalid_0's l1: 2.00405\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7228439999999999, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7228439999999999\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 2.03517\n",
      "Early stopping, best iteration is:\n",
      "[6105]\tvalid_0's l1: 2.01801\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 14\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.06, 'num_leaves': 1764, 'max_depth': 11, 'bagging_fraction': 0.97, 'bagging_freq': 23, 'feature_fraction': 0.5248, 'lambda_l1': 8, 'lambda_l2': 15}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5248\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94034\n",
      "Early stopping, best iteration is:\n",
      "[4086]\tvalid_0's l1: 1.9367\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5248\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.93662\n",
      "Early stopping, best iteration is:\n",
      "[3514]\tvalid_0's l1: 1.93511\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5248, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5248\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.97, subsample=1.0 will be ignored. Current value: bagging_fraction=0.97\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=23, subsample_freq=0 will be ignored. Current value: bagging_freq=23\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.94898\n",
      "Early stopping, best iteration is:\n",
      "[3319]\tvalid_0's l1: 1.94884\n",
      "\u001b[1m\u001b[91m\u001b[4mGeneration 7, Individual 15\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mFeature groups\u001b[0m\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper parameters\u001b[0m\n",
      "{'boosting_type': 'gbdt', 'metric': 'mae', 'num_threads': -1, 'num_iterations': 10000, 'seed': 96, 'device': 'cpu', 'learning_rate': 0.028, 'num_leaves': 1552, 'max_depth': 11, 'bagging_fraction': 0.6890000000000001, 'bagging_freq': 21, 'feature_fraction': 0.84, 'lambda_l1': 8, 'lambda_l2': 11}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6890000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6890000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.84165\n",
      "[6666]\tvalid_0's l1: 1.80897\n",
      "[9999]\tvalid_0's l1: 1.79166\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9976]\tvalid_0's l1: 1.79158\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6890000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6890000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.84022\n",
      "[6666]\tvalid_0's l1: 1.80629\n",
      "[9999]\tvalid_0's l1: 1.78946\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9985]\tvalid_0's l1: 1.78944\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.84, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.84\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6890000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6890000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=11, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.84363\n",
      "[6666]\tvalid_0's l1: 1.81204\n",
      "[9999]\tvalid_0's l1: 1.79488\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.79487\n",
      "\u001b[1mThis is the final generation so don't need to generation children\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mGenetic algorithm ran 8 generations with a population of 16 in 2 days, 19:45:37\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mutation_rate = 0.2 # 20% mutation rate\n",
    "gaussian_limit = 25 # increase/decrease by up to 25% (divide by 100 after random.randrange())\n",
    "elitism_n = 4 # pick the 4 best at each generation to be the parents\n",
    "number_of_generations=8 #going to test n hyper parameter configurations\n",
    "\n",
    "num_folds = 3 # 3 fold skf; so we use 2/3 of each meters readings for training at each iteration \n",
    "i=0 #just used to print the index of each skf-cv run\n",
    "all_results = [] # will hold array of all the tuples of results + hyper params\n",
    "\n",
    "print(f\"{color.BOLD}Genetic Algorithm hyper parameter optimization{color.END}\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "#iterate through the generations\n",
    "for g in tqdm(range(number_of_generations)):\n",
    "    ### Training each model in the population ###\n",
    "    generation_results = []\n",
    "    for p in tqdm(range(len(population))):\n",
    "        print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}Generation {g}, Individual {p}{color.END}\")\n",
    "            \n",
    "        \n",
    "        #getting this models columns\n",
    "        X_col_groups = population[p][2]\n",
    "        X_cols = population[p][0]\n",
    "        this_X_cats = list(set(X_cols).intersection(all_cat)) #getting the categorical values for this X\n",
    "        #getting this models hyper parameters\n",
    "        this_params = population[p][1]\n",
    "        \n",
    "        #inspecting\n",
    "        print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Feature groups{color.END}\")\n",
    "        print(X_col_groups)\n",
    "        print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Hyper parameters{color.END}\")\n",
    "        print(this_params)\n",
    "        \n",
    "        #bug in lgbm which occassionally refuses models based on the hypers and the feature fraction value; fixing this by randomising feature fraction if it fails\n",
    "        fail_counter=1\n",
    "        while True:\n",
    "            #try to run this model\n",
    "            try:\n",
    "                #training this model and storing its results (excluding the lgbm model itself as was running out of memory)\n",
    "                this_run = run_lgbm_skf_cv(False, False, SEED, num_folds, df_train.copy(), y_col, X_cols, this_X_cats, this_params)\n",
    "                generation_results.append(((this_run[0],this_run[1]), # MAE and TOE (not this_run[2] (lgbm_models) to stop running out of memory)\n",
    "                                          (X_cols,this_params,X_col_groups))) # models description so we can train and use the best lgbm models without having to store all in memory\n",
    "                break\n",
    "            #if it fails randomise value of feature fraction as it seems the bug that exists in lgbm library that is unpatched is depending on the feature fraction value https://github.com/microsoft/LightGBM/issues/3679\n",
    "            except:\n",
    "                print(f\"Individual {p} failed {fail_counter} times\")\n",
    "                random_new_frac=random.randrange(0,100)/100\n",
    "                print(f\"Changing feature fraction from {this_params['feature_fraction']} to {random_new_frac}\")\n",
    "                this_params[\"feature_fraction\"]=random_new_frac\n",
    "                fail_counter+=1\n",
    "                \n",
    "    #adding this populations results to all_results\n",
    "    all_results = all_results + generation_results\n",
    "    \n",
    "    #if this isn't the last generation then generate children\n",
    "    if(g<number_of_generations-1):\n",
    "        \n",
    "        ### Elitism selection mechanism for parents ### \n",
    "\n",
    "        #sorting all_results (including previous generation populations) instead of just generation_results as we are being greedy to improve efficiency and speed\n",
    "        sorted_generation_results = sorted(all_results, key=lambda tup: tup[0][1]) # sorting the results by the maes\n",
    "        parents = []\n",
    "        #picking the best elitism_n models to be used as the parents\n",
    "        for ne in range(elitism_n):\n",
    "            print(f\"{color.YELLOW}{color.BOLD}Parent {len(parents)}{color.END} has a mae of {sorted_generation_results[0][0][1]}\")\n",
    "            parents.append(sorted_generation_results.pop(0))\n",
    "            \n",
    "        #deleting the previous population; no longer need it now we have parents\n",
    "        del population\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "        ### generating the children from the parents (cross over) ###\n",
    "        print(f\"{color.BOLD}{color.BLUE}Generating the children{color.END}\")\n",
    "        population = []\n",
    "        \n",
    "        #generating the remaining population by combining the parents genes via uniform XO\n",
    "        while (len(population)<population_size):\n",
    "\n",
    "            # randomly picking 2 of the parents to create the children\n",
    "            parent_indexes = list(range(len(parents)))\n",
    "            random.shuffle(parent_indexes)\n",
    "\n",
    "            #picking the first 2 to be the parents\n",
    "            father_index = parent_indexes[0]\n",
    "            mother_index = parent_indexes[1]\n",
    "            father = parents[father_index]\n",
    "            mother = parents[mother_index]\n",
    "\n",
    "            print(f\"{color.BOLD}{color.GREEN}Child {len(population)} parents = {father_index} and {mother_index}{color.END}\")\n",
    "\n",
    "            #iteratively picking the hyperparameters [1][1]\n",
    "            print(f\"{color.BOLD}{color.YELLOW}inherited hyper parameters{color.END}\")\n",
    "            child_params = params.copy()\n",
    "            for key in tuned_hyper_names:\n",
    "                #50% chance of getting from father\n",
    "                if(random.choice([0,1])==0):\n",
    "                    child_params[key]=father[1][1][key]\n",
    "                    print(f\"inherited {key} value of {child_params[key]} from {father_index}\")\n",
    "                #50% chance of getting from mother\n",
    "                else:\n",
    "                    child_params[key]=mother[1][1][key]\n",
    "                    print(f\"inherited {key} value of {child_params[key]} from {mother_index}\")\n",
    "\n",
    "            #iteratively picking X_col_groups [1][2] (will turn this into X_cols [1][0] after mutation)\n",
    "            print(f\"{color.BOLD}{color.YELLOW}inherited feature groups{color.END}\")\n",
    "            child_X_col_groups = []\n",
    "            for key in possible_columns.keys():\n",
    "                #50% chance to pick whether or not to use this column group based on father\n",
    "                if(random.choice([0,1])==0):\n",
    "                    #check if father contains this column group and if it does, add this column group to the child\n",
    "                    if(possible_columns[key][0] in father[1][2]):\n",
    "                        child_X_col_groups = child_X_col_groups + [key]\n",
    "                        print(f\"inherited usage of feature group {key} from {father_index}\")\n",
    "                    else:\n",
    "                        print(f\"inherited non-use of feature group {key} from {father_index}\")\n",
    "                #50% chance to pick whether or not to use this column group based on mother\n",
    "                else:\n",
    "                    #check if mother contains this column group and if it does, add this column group to the child\n",
    "                    if(possible_columns[key][0] in mother[1][2]):\n",
    "                        child_X_col_groups = child_X_col_groups + [key]\n",
    "                        print(f\"inherited usage of feature group {key} from {mother_index}\")\n",
    "                    else:\n",
    "                        print(f\"inherited non-use of feature group {key} from {father_index}\")\n",
    "            #appending the population with this child\n",
    "            #[0] for X_cols currently empty; will fill this after mutating the groups\n",
    "            population.append(([], child_params,child_X_col_groups))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ### applying mutation to the children### \n",
    "        print(f\"{color.BOLD}{color.BLUE}Mutating the children{color.END}\")\n",
    "        #for each child\n",
    "        for child_i in range(population_size):\n",
    "            print(f\"{color.BOLD}{color.GREEN}Child {child_i}{color.END}\")\n",
    "            child = population[child_i] # getting the child\n",
    "\n",
    "            ## mutating the childs column groups via flip bit ##\n",
    "            print(f\"{color.BOLD}{color.YELLOW}Mutating Columns Groups via Bit Flip{color.END}\")\n",
    "            mutated_col_groups = []\n",
    "            mutated_X_cols = []\n",
    "            #iterating through each possible key\n",
    "            for key in possible_columns.keys():\n",
    "                #if we randomly chose to mutate this column...\n",
    "                if(random.random()<mutation_rate):\n",
    "                    #add this column to mutated columns if it doesn't already exist in keys, flipping it's usage\n",
    "                    if(key not in child[2]):\n",
    "                        mutated_col_groups+=[key]\n",
    "                        mutated_X_cols+=possible_columns[key]\n",
    "                        print(f\"Mutated to start using {key}\")\n",
    "                    #else if this column does already exist in keys, don't add it to mutated keys, flipping it's usage\n",
    "                    else:\n",
    "                        print(f\"Mutated to stop using {key}\")\n",
    "                #if we aren't mutating this column...\n",
    "                else:\n",
    "                    #add this column to mutated columns if it already exists in keys\n",
    "                    if(key in child[2]):\n",
    "                        mutated_col_groups+=[key]\n",
    "                        mutated_X_cols+=possible_columns[key]\n",
    "\n",
    "            #if mutated keys is empty after mutation; randomly pick 1 column to keep; clipping it to a length of 1\n",
    "            if(len(mutated_col_groups)<=0):\n",
    "                new_key=random.choice(list(possible_columns.keys()))\n",
    "                mutated_col_groups=[new_key]\n",
    "                mutated_X_cols+=possible_columns[new_key]\n",
    "                print(f\"No columns clipping length to 1 so randomly choosing to use {new_key}\")\n",
    "\n",
    "\n",
    "\n",
    "            ## mutating the childs hyper parameters via gaussian ## \n",
    "            print(f\"{color.BOLD}{color.YELLOW}Mutating hyper parameters via gaussian{color.END}\")\n",
    "            mutated_params = population[child_i][1].copy()\n",
    "            #iterate through each hyper parameter we tuned\n",
    "            for key in tuned_hyper_names:\n",
    "                #if we randomly chose to mutate this hyper...\n",
    "                if(random.random()<mutation_rate):\n",
    "                    #generate the random gaussian percentage\n",
    "                    gaussian_percentage = random.randrange(gaussian_limit)/100\n",
    "                    #50% chance to add\n",
    "                    if(random.choice([0,1])==0):\n",
    "                        mutated_params[key]+=population[child_i][1][key]*gaussian_percentage\n",
    "                        #if this key needs to be a whole number, round it\n",
    "                        if(key in whole_number_hyper_names):\n",
    "                            mutated_params[key] = int(round(mutated_params[key]))\n",
    "                        #clipping fractional keys between 0 and 1\n",
    "                        if(key in fractional_hyper_names):\n",
    "                            mutated_params[key] = float(max(0.01, min(mutated_params[key],1)))\n",
    "                        print(f\"Increased {key} by {gaussian_percentage*100}% from {population[child_i][1][key]} to {mutated_params[key]}\")\n",
    "                    #50% chance to subtract\n",
    "                    else:\n",
    "                        mutated_params[key]-=population[child_i][1][key]*gaussian_percentage\n",
    "                        #if this key needs to be a whole number, round it\n",
    "                        if(key in whole_number_hyper_names):\n",
    "                            mutated_params[key] = int(round(mutated_params[key]))\n",
    "                        #clipping fractional keys between 0 and 1\n",
    "                        if(key in fractional_hyper_names):\n",
    "                            mutated_params[key] = float(max(0.01, min(mutated_params[key],1)))\n",
    "                        print(f\"Decreased {key} by {gaussian_percentage*100}% from {population[child_i][1][key]} to {mutated_params[key]}\")\n",
    "\n",
    "            #overriding X_cols and X_col_groups and params for this child\n",
    "            population[child_i] = (mutated_X_cols, mutated_params,mutated_col_groups)\n",
    "    else:\n",
    "        print(f\"{color.BOLD}This is the final generation so don't need to generation children{color.END}\")\n",
    "        \n",
    "    #deleting generation_results\n",
    "    del generation_results\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"\\n\\n\\n\")\n",
    "time_of_execution = time.time()-start_time\n",
    "print(f\"{color.BOLD}Genetic algorithm ran {number_of_generations} generations with a population of {population_size} in {str(datetime.timedelta(seconds=round(time_of_execution)))}{color.END}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising information from the genetic algorithm results\n",
    "### Box plots of the MAE for the different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8c39e427054378886d1e92bbff83b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_maes = {} #dictionary of each columns maes\n",
    "columnless_mae = {}\n",
    "#iterating through each column and randomly decide whether or not to pick it\n",
    "for key in tqdm(possible_columns.keys()):\n",
    "    column = possible_columns[key][0] # only want to check against one column for the 'in'\n",
    "    \n",
    "    # if this column doesn't yet exist in the dict, create it\n",
    "    if key not in columns_maes:\n",
    "        columns_maes[key]=[]\n",
    "    # if this column doesn't yet exist in the dict, create it\n",
    "    if key not in columnless_mae:\n",
    "        columnless_mae[key]=[]\n",
    "\n",
    "    #iterating through every single models results\n",
    "    for i in range(len(all_results)):\n",
    "        \n",
    "        #if this column was used by the model\n",
    "        if column in all_results[i][1][0]:\n",
    "            # adding this models mae to the dict entry for this column\n",
    "            columns_maes[key].append(all_results[i][0][1])\n",
    "            \n",
    "        #else this column wasn't used by the model\n",
    "        else:\n",
    "            # adding this models mae to the dict entry for this column\n",
    "            columnless_mae[key].append(all_results[i][0][1])\n",
    "\n",
    "# print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}MAEs for each model which contains columns of each type{color.END}\")\n",
    "# pprint(columns_maes)\n",
    "\n",
    "# function for setting the box colour\n",
    "def set_box_color(bp, color_line, color_fill):\n",
    "    plt.setp(bp['whiskers'], color=color_line)\n",
    "    plt.setp(bp['caps'], color=color_line)\n",
    "    plt.setp(bp['medians'], color=color_line)\n",
    "    plt.setp(bp['fliers'], color=color_fill)\n",
    "    plt.setp(bp['boxes'], color=color_fill)\n",
    "    plt.setp(bp['means'], color=color_line)\n",
    "\n",
    "    \n",
    "### plotting a boxplot of these ###\n",
    "# getting the 2 dicts we will plot\n",
    "labels, data_columns = columns_maes.keys(), columns_maes.values()\n",
    "data_columnless = columnless_mae.values()\n",
    "\n",
    "#plotting these 2 dicts next to each other\n",
    "fig = plt.figure(figsize=(25,10))\n",
    "bp_dict_columns = plt.boxplot(data_columns,showmeans=True,positions=np.array(range(len(labels)))*2.0-0.4,patch_artist=True) # getting dictionary returned from boxplot\n",
    "bp_dict_columnless = plt.boxplot(data_columnless,showmeans=True,positions=np.array(range(len(labels)))*2.0+0.4,patch_artist=True) # getting dictionary returned from boxplot\n",
    "\n",
    "#colouring them\n",
    "set_box_color(bp_dict_columns, '#416338','#b0dba4')\n",
    "set_box_color(bp_dict_columnless, '#783d2b','#dbb1a4')\n",
    "\n",
    "#annotating the plot\n",
    "plt.title(\"Box plot of MAEs for the different columns\", fontsize=20)\n",
    "plt.xlabel(\"Column groups\", fontsize=17)\n",
    "plt.ylabel(\"MAE\", fontsize=17)\n",
    "\n",
    "#creating the legend\n",
    "plt.plot([], c='#b0dba4',label=\"MAEs of models that used this column\")\n",
    "plt.plot([], c='#dbb1a4',label=\"MAEs of models that didn't use this column\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "## adding overlayed values to the boxplot\n",
    "\n",
    "# stats for with columns\n",
    "column_means = []\n",
    "column_medians = []\n",
    "column_std = []\n",
    "for key in columns_maes.keys():\n",
    "    column_means.append(np.mean(columns_maes[key]))\n",
    "    column_medians.append(np.median(columns_maes[key]))\n",
    "    column_std.append(np.std(columns_maes[key]))\n",
    "for i, line in enumerate(bp_dict_columns['medians']):\n",
    "    x, y = line.get_xydata()[1]\n",
    "    text = ' μ={:.2f}\\n m={:.2f}\\n σ={:.2f}'.format(column_means[i], column_medians[i], column_std[i])\n",
    "    plt.text(x, y, text, horizontalalignment='center')\n",
    "    \n",
    "# stats for without columns\n",
    "columnless_means = []\n",
    "columnless_medians = []\n",
    "columnless_std = []\n",
    "for key in columnless_mae.keys():\n",
    "    columnless_means.append(np.mean(columnless_mae[key]))\n",
    "    columnless_medians.append(np.median(columnless_mae[key]))\n",
    "    columnless_std.append(np.std(columnless_mae[key]))\n",
    "for i, line in enumerate(bp_dict_columnless['medians']):\n",
    "    x, y = line.get_xydata()[1]\n",
    "    text = ' μ={:.2f}\\n m={:.2f}\\n σ={:.2f}'.format(columnless_means[i], columnless_medians[i], columnless_std[i])\n",
    "    plt.text(x, y, text, horizontalalignment='center')\n",
    "\n",
    "\n",
    "plt.xticks(range(0, len(labels)*2,2), labels)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f\"..\\\\Results\\\\Genetic Algorithm\\\\Plots\\\\p{population_size}_g{number_of_generations}_Box_MAEs.png\")\n",
    "\n",
    "plt.close(fig)\n",
    "del fig\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box and swarm plot to better inspect the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11040"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colourBlindFriendly = False # make graph colourBlindFriendly (pink to blue instead of red to green)\n",
    "\n",
    "#normalizing the std\n",
    "max_std = max(column_std)\n",
    "column_std = [float(i)/max_std for i in column_std]\n",
    "\n",
    "#gradient of green to red based on each columns stats\n",
    "box_grad_palette = {}\n",
    "for i in range(len(column_std)):\n",
    "    box_grad_palette[i] = [column_std[i], 1-column_std[i],1 if colourBlindFriendly else 0] #based on std\n",
    "\n",
    "fig=plt.figure(figsize=(25,10))\n",
    "sns.set(context='notebook', style='white')\n",
    "sns.utils.axlabel(xlabel=\"Column Groups\", ylabel=\"MAE\", fontsize=16)\n",
    "sns.boxplot(data=list(data_columns), width=.18, palette=box_grad_palette)\n",
    "\n",
    "#slightly paler gradient to make it stand out from the box\n",
    "swarm_grad_palette = box_grad_palette.copy()\n",
    "for i in range(len(swarm_grad_palette)):\n",
    "    #fading it to white\n",
    "    #adding to red to make it paler\n",
    "    swarm_grad_palette[i][0] = swarm_grad_palette[i][0]+0.3 if swarm_grad_palette[i][0]+0.3<1 else 1\n",
    "    #adding to green to make it paler\n",
    "    swarm_grad_palette[i][1] = swarm_grad_palette[i][1]+0.3 if swarm_grad_palette[i][1]+0.3<1 else 1\n",
    "    #adding to blue to make it paler\n",
    "    if colourBlindFriendly:\n",
    "        swarm_grad_palette[i][2] = swarm_grad_palette[i][2]+0.3 if swarm_grad_palette[i][2]+0.3<1 else 1\n",
    "\n",
    "\n",
    "sns.swarmplot(data=list(data_columns), size=7, edgecolor=\"black\", linewidth=.6, palette=swarm_grad_palette)\n",
    "\n",
    "plt.xticks(plt.xticks()[0], labels)\n",
    "\n",
    "plt.title(\"Box and Swarm plots of MAEs for the different columns\", fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f\"..\\\\Results\\\\Genetic Algorithm\\\\Plots\\\\p{population_size}_g{number_of_generations}_BoxSwarm_MAEs_GRAD_STD.png\")\n",
    "plt.close(fig)\n",
    "del fig\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Effects Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e3291433534490a8098ebda8d30a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0322</td>\n",
       "      <td>1.860895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate       MAE\n",
       "11         0.0322  1.860895"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.0322])]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAFTCAYAAABmjUu5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAACdWElEQVR4nOzdd3xTZd/H8U+a7sEuZS+BsjcylZbKHmUJskFBULGIC1D0ARw3Q5GhqAwHgiIilA0qUKCyl1DKkCllFiiU7jY5zx9pQtKmbZo2aSi/9/3ybnPOyTlXQpp8c02VoigKQgghhBDCITkVdAGEEEIIIUTWJKwJIYQQQjgwCWtCCCGEEA5MwpoQQgghhAOTsCaEEEII4cAkrAkhhBBCODAJa0I4kPbt2+Pv78/PP/9sdv+oUaPw9/dn3bp1mfZNnz4df39/Nm/enGnfmjVr8Pf3z/K/rVu3WlXeU6dO0bVrV+rVq8fMmTOtOoe5stapUydfzpUXWT3PjiYsLIzz588X2PXbt2/PwoULC+z6QjwJnAu6AEIIUy4uLmzbto1BgwaZbL9//z779+83e5+UlBQ2bdpElSpV+PXXX+natWumY9RqNbt27TJ7/6JFi1pV1kWLFuHs7MzmzZvx8fGx6hyOKjw8nCJFihR0MbJ169YtxowZw7Jly6hevXpBF0cIYSNSsyaEg2nZsiWHDh3i3r17Jtv//PNPGjZsaPY+O3bsICEhgZCQEA4cOMCVK1fMHufr62v2P1dXV6vKGhsbS+3atalUqRLFixe36hyOytfXFzc3t4IuRrZkTnMhngwS1oRwMI0bN6ZUqVL89ddfJtu3bNlitsYMYO3atTRu3JjnnnsODw8PVq1aZdW1L168yIsvvkiTJk1o2rQpr776KlFRUWaPbd++PXv37iU0NBR/f3+ioqJIS0tj8eLFdOzYkfr169OjRw+TZtkFCxYwdOhQQkJCaNKkCV988UWOZXrw4AGTJ0+mRYsWPP3004wePZqLFy8a9icnJ/O///2PwMBA6tWrR8uWLZk8eTKJiYmArlm1U6dOTJ06laZNm/Luu++yZs0aOnfuzK+//kr79u2pV68egwYN4sKFC4bzGjeDTpo0iffee4+PP/6YFi1a0LhxY9566y3i4uIMx//zzz+88MILNGjQgC5duvDbb78ZnhdLmHtutFotCxcupGPHjtSrV49mzZrx+uuvG4J8u3btABg2bBiTJk0C4MaNG4ZztG7dmgkTJnDr1i2z1zxw4AD+/v5cvXrVZHu3bt0M/zYHDhxgyJAhNG7cmHr16hEcHMzu3buzfAwdOnTIdltO5Tt+/DgvvPACjRo1okWLFrzzzjvcv3/foudQiMJKwpoQDkalUtGxY0e2bdtm2Hbv3j0OHTpEp06dMh0fHR1NeHg4nTp1ws3Njfbt27N27VpSU1Nzfe23336bcuXKsXbtWlasWEFMTAzvvfee2WNXr15Ns2bN6NKlC+Hh4ZQtW5YZM2awdOlS3nzzTdavX0+3bt148803TR7LwYMHqVixImvXrqVfv37Zlker1fLyyy9z+/ZtlixZws8//0y5cuUYNGgQMTExAMycOZOdO3cye/Zstm7dyocffsimTZv49ddfDee5fPkycXFxhIaGMmbMGACioqLYsGED8+fPZ9WqVTx48ICPPvooy7KsX78ejUbDypUrmTt3Ljt27GDZsmWArjly5MiRVK9enbVr1zJ+/Hg+++wzy550Ixmfm++//55ly5YxZcoUtm3bxueff86RI0f4+uuvAV1IB10gev/990lISGDo0KG4ubmxcuVKli5dSmpqKsOHDyclJSXT9Z5++mnKly9vEqhPnz7N+fPn6dWrFzdu3GD06NE0bdqU9evXs3r1asqWLcvEiRPNni8nOZVPo9Hwyiuv0KpVKzZu3MiiRYs4efJkvvWHFOJxJX3WhHBAnTt3ZsSIETx48ICiRYvyxx9/0KRJE0qVKpXp2PXr16PVaunYsSOgqxXZuHEjf/31F126dDEcp9FoaNy4cab7Fy9enB07dgBw5coV2rRpQ/ny5XF2dmb27NncuXPHbBlLlCiBi4sL7u7u+Pr6EhcXxy+//MKHH35I586dARg7dixnzpxh0aJFhqCpUql4/fXXcXd3z/F52L9/PydPnuTgwYN4e3sDMG3aNPbv38+qVasYM2YMDRs2pFu3bjRt2hSAChUq8PPPP3Pu3DmTc7366qtUrFgR0NWCpaamMm3aNJ566ikA+vfvn21NX7FixZgyZQpqtZqqVavSunVrjh8/DsCvv/5K8eLFmTZtGmq1mqeeeoo7d+5kG/7MyfjcVK1alZkzZ/Lss88CUL58eZ555hnDYytRogSg63Po4+PDb7/9RmJiIjNmzECtVgMwZ84cWrRowR9//EH37t0zXS84OJiNGzcaQuz69etp1KgRVatW5b///mP8+PG8+OKLqFQqAEaMGMHw4cO5e/cuZcuWzdXj27RpU7bla9u2LTExMZQqVYry5ctToUIFvvrqK6u+eAhRmEhYE8IBNW3alOLFi7N9+3b69OmTbRNoaGgozZo1w9fXF4C2bdtSpEgRfv31V5OwplarCQ0NzXR/J6dHFezjx49n5syZ/Pzzz7Rs2ZKAgAC6detmUZkvXrxIWlpapkDYvHlzQxgEXV8wS4IaQGRkJBqNhmeeecZke3JysqHJMjg4mPDwcGbNmsXly5c5f/48//33HxUqVDAcr1KpTG7rt1WuXNlw28fHJ9tQUKlSJUPA0B+vb76LjIykfv36Jvv14TE3Mj437du359ixY3zxxRdcunSJixcvcuHCBZo1a2b2/pGRkdy7dy/T/sTERJMmXmO9evVi4cKF/Pvvvzz11FNs2rSJsWPHGh5zr169+PHHHzl79ixXrlzh9OnTgC7851ZO5evevTsjR45k+vTpLFiwgDZt2hAYGGi2RlmIJ4mENSEckEqlolOnTmzbto2AgACOHj1qttbn5MmTnDt3DpVKZTLdhUajYf/+/fz3339UqlTJsN04nJgzbNgwunbtys6dO9m7dy//+9//+O6771i3bl2OgxCy6oyv0Whwdn70VmNpUAPdyNhixYqZ7YPn6ekJwPvvv8/27dvp3bs3HTt2ZMKECUyfPt3kWCcnp0zld3JyMikXZN9h39zj1x+vVqvRarWWPahsZHxuFi5cyOLFi+nTpw/PPPOMYeTn9evXzd7fxcWF6tWr8+WXX2bal9Vo3cqVK9OkSRM2btxI69atiYmJMQT0c+fOMXjwYBo2bEirVq3o2rUraWlphjBnibS0tFyVb+LEiQwePJhdu3YRHh7O5MmTWbVqlaHJWYgnkYQ1IRxU586dGTlyJKGhoTz99NOGJi9ja9euxd3dneXLl5uEpatXr/Lqq6+yatUq3n77bYuuFxMTw5dffsno0aN5/vnnef755zlx4gTPP/88Z86coUGDBtnev3Llyri4uHD06FFq1qxp2H7kyBGrp5WoUaOGoXO5PmhqNBrefvttOnToQKtWrVi9ejULFiwwNAOnpaVx9epVypUrZ9U1raEfjKDRaAy1a//880+ez7t48WJCQkIYOXKkYduVK1cMIVPfNKlXo0YNfvvtN4oVK2aYjiUuLo63336bESNG0LJlS7PX6d27N99//z0PHjwgMDDQcN9ff/2VsmXLsmTJEsOxK1euBMwHWxcXF+Lj4022GY9Mzql85cqVY+nSpbz33nsMHjyYwYMHs3nzZiZMmMDdu3cpWbKkZU+cEIWMDDAQwkE1adKEokWL8uWXX5ptAtXPrda9e3fq169PzZo1Df8FBQXRrFmzTAMNoqOjzf4XFxdH0aJF2b17Nx9++CFnzpzhypUrrFmzhiJFilC1atUcy+vu7s7IkSOZO3cuW7du5fLlyyxatIg//vjDJGzkRqtWrWjUqBFvvPEGhw8f5tKlS0yZMoUdO3ZQs2ZNvL298fb2Zvv27fz3339ERkby1ltvcePGDas6wFtr0KBB3Lt3j2nTpnHhwgW2b9/OvHnzgMyBKjfKli1LeHg4Fy5c4N9//2X69OkcO3bM8Ni8vLwAOHv2LDExMfTo0YPixYvzxhtvGGpd33rrLf755x9q1KiR5XW6dOnCtWvXWL9+Pb169TJsL1OmDNeuXePvv//m2rVrrFu3zlDDa+75bdSoEXfv3uWHH34gKiqKn3/+2WTkaE7lK168OFu2bGHq1KlcuHCBCxcusGXLlkI5NYwQuSFhTQgH5eTkRKdOnUhJSck0HQLo5la7f/8+gwcPNnv/ESNGcOfOHbZv3w7oaqTatm1r9r85c+bg5OTEt99+C8DQoUPp2bMn58+fZ+nSpRZPeBsSEsKAAQP49NNPDdN2zJkzx6TvXG6oVCq++uorqlevzquvvkrv3r25fPkyS5cupXr16ri4uDB37lxOnTpF9+7defXVVylatCgvvvgiERERVl3TGqVKlTKMXAwODmbOnDmGSY1dXFysPu/MmTOJjY2ld+/ejBw5kvv37/PWW29x/vx5EhMT8fb2ZujQoXz22WdMmTIFd3d3vv/+e9zd3Rk+fDgDBw4kLS2NH3/8MdtaKR8fH5577jnc3NwMgxlA1yzeoUMHJkyYQM+ePVmxYgXTpk3D09OTkydPZjpPy5Ytef3111m8eDHdunVj3759hISEGPbnVD4fHx8WL17M1atX6d+/P/369SMlJYVFixaZ9K0U4kmjUmRWRSGEyJPz58/z8OFDk8EVmzZtYtKkSRw7dixT3zghhMgN+aoihBB5dOPGDYYNG8bmzZu5fv06Bw8eZP78+XTt2lWCmhAiz6RmTQgh8sHy5cv56aefuH79OsWKFaNLly5MmDCB2NhYw7xzWenatSuffPKJnUoqhHjcSFgTQggb0mg0OS455eXlZXbCYyGEAAlrQgghhBAOzS6dKYYNG8bdu3cNfTemT59Ow4YNDfv1k28mJycbmg4skZSUREREBL6+viYzhwshhBBCOBqNRkN0dDT16tXL1QThNg9riqJw8eJFwsLCzHa0TUpK4r333uOnn36ibNmyjBkzhl27dtGuXbsczx0REZHltAVCCCGEEI5oxYoVWS4bZ47Nw9rFixdRqVSMHj2au3fv0r9/f4YMGWLYf+LECSpXrmxYYLlHjx5s3brVorCmXwtxxYoVlClTxjYPQAghhBAiH9y8eZPBgwcb8oulbB7WYmNjadWqFVOnTiUpKYlhw4ZRtWpV2rRpA8Dt27dNCl26dGnD4sg50Td9lilTJtMizUIIIYQQjii3XbdsHtYaN25smCjS09OTfv36sWvXLkNYMze+IS/LswghhBBCFCY2nxT38OHD7Nu3z3BbURSTvmt+fn7cuXPHcPv27duULl3a1sUSQgghhHgs2DysPXz4kFmzZpGcnExcXBxr1641WeewYcOGXLp0iStXrqDRaNi4caPJ2nRCCCGEEE8ymzeDBgYG8s8//9CrVy+0Wi2DBg2icePGBAcHs2jRIvz8/JgxYwavv/46ycnJtGvXLsfZvoUQQghLpKamEhUVRVJSUkEXRTxh3N3dqVChAi4uLnk+12M9KW5UVBRBQUFs375dBhgIIYTI5NKlS/j4+FCyZEnpDy3sRlEU7t69y8OHD6lataphu7W5RRZyF0IIYxm/vz6+32cFurk8JagJe1OpVJQsWTLfanQlrAkhhN7eqRA24VFAUxTd7b1TC7JUIo8kqImCkJ+vOwlrQggBumCWfB+OznsU2MIm6G4n35caNpFnBw4cYOjQoZm2nzx5kvfff99m19VoNLz00kt069aNAwcO2Ow6ubFgwQL8/f05duyYyfZPPvkEf39/k207d+7E39+fiIgIk+3t27ena9euBAcHG/6bPHmyzcteEOyyNqgQQjg8lQoCvtD9fnSe7j+AJuN126V2RthI/fr1qV+/vs3Of+vWLc6ePUt4eLjNrmGNMmXKsG3bNsNcrFqtlkOHDmU6bs2aNXTq1ImVK1fy8ccfm+xbtGjRE9FnXWrWhBBCzziw6UlQEzZmXOM2dOhQZs2axYABA+jQoQO7du0C4M6dO7z66qv06dOHvn37snfv3kznSUxM5K233qJ79+706NGD0NBQAMaMGcP9+/fp06dPpuuOHDmSESNG0L59e2bOnMnChQvp06cPffr0McyBunv3bvr160evXr0YN24cMTExAGzZsoX+/fvTs2dPOnXqZAhaWT2GjIKCgtixY4fh9pEjR2jUqJHJMffu3WPfvn28++67bN26lbi4OIue0++//56ePXvSq1cvPvzwQ4vu48ikZk0IIfT0TZ/GwiZIYCskli1bxnfffWeTc7/44osMGzYsX86VmprKr7/+yo4dO5g3bx7t2rXjk08+oW/fvgQFBXH79m0GDRpEaGgo3t7ehvstWLCA4sWLs3HjRu7du8fzzz9PrVq1+Prrrxk2bBhr1qzJdK1//vmHTZs2UaxYMVq3bs3EiRNZs2YNkydPZtOmTfTo0YPPP/+cZcuWUbRoUVauXMlnn33GRx99xMqVK/nmm28oUaIEq1evZunSpTRv3jzLx5BR8eLFqVChAidOnKBBgwZs3ryZrl278ssvvxiO2bBhA23atKFChQrUq1ePdevWMXjwYMP+l19+2WRqjGHDhhEcHMy3337Lnj17UKvVTJs2jVu3buHn55cv/z4FQcKaEEKAaR81fdOn/jZIYBN288wzzwBQo0YN7t+/D8DevXu5ePEi8+fPByAtLY2rV69Su3Ztw/3279/Pp59+CkCJEiUICgri4MGDtG/fPstr1axZk7JlywK68NSqVSsAypUrR2xsLP/88w83btwwBFGtVkvRokVxcnLiq6++YseOHVy6dImDBw/i5PSosc7cYzCnS5cubNu2jbp163Ls2DE++OADk/1r1qxh3LhxAHTt2pXly5ebhLWsmkEbN25Mv379CAoKYvDgwY91UAMJa0IIoaNSgVsx0z5q+iZRt2IS1AqBYcOG5Vvtly25ubkBpqMJtVotP/74I8WKFQN0/dBKlSplcr+M06YqioJGo8n2WhknbM24wLhGo6FJkyZ88803ACQnJxMfH098fDx9+/YlODiY5s2b4+/vz4oVK7J9DOY899xzDBw4kLZt29KsWTOTwBcZGcm5c+f45JNP+N///odGo+H27dscO3bM0M8tKwsXLuT48ePs3r2bUaNG8dlnn/H0009nex9HJn3WHhcy95MQttd6qmkNmj6wtZ5akKUSgpYtW/Lzzz8DcP78eXr27EliYmKmY1avXg3o+npt3749zwGlYcOGHD9+nEuXLgG6EDRr1iwuX76Mk5MTY8eOpWXLluzevTvHYGhO8eLFKV++PPPmzaNr164m+9asWUP//v0JCwtjx44d7Nq1i+DgYH799ddsz3nv3j26dOlCzZo1GT9+PG3atOHs2bO5LpsjkZq1x8HeqbqpA/QfIvrmGrdi8iEiRH7LWBMgNWoiHx0+fNikVqhHjx5069Ytx/tNmTKFDz/8kB49egAwa9Ysk/5qAK+99hpTp06lR48eaDQaxo4dS926dYmKirK6vL6+vnz66ae88cYbaLVa/Pz8mD17NkWKFKF27dp06dIFd3d3mjdvzvXr1626RufOnfnqq69MnpeUlBQ2bNjAsmXLTI4dMWIEAwYMMEzRkbHPmoeHBytXruSFF16gX79+eHh4ULZsWXr37m1V2RyFLDfl6LLrRyNTCgghRLZOnz5t0q9LCHvK+PqzNrdIzZqj0zfDKIrp3E+NQySoCSGEEE8A6bP2ONg3LXfbhRBCCFFoSFhzdIoCSTFwbL7p9mPzddsf31ZsIYQQQlhAwpoQQgghhAOTsOboVCpwL67ro2ascYhuu/RZE0IIIQo1CWuPg1b/l7vtQgghhCg0JKw5Ov3UHcfm66bqeFOr+3lsvm679FkTQgghCjWZusPRyRI4QghRaMybN49t27ahUqno168fI0eOzPE+Q4cOZdy4cbRo0cKwLSoqis6dO/PUU08BkJSUhL+/Px9++GGmZajyKuO1tFot8fHx9OrVi5CQkBzu7bgWLFgAwOuvv26yXb+Q/MCBA+1epqxIWHsctJ6qq0HLuASOBDUhhHhsHDx4kP3797N+/XrS0tLo2rUr7dq1o1q1aladr3Tp0qxbtw7QrQM6Z84cQkJCDMtS5Sfja4FubdJOnTrRrVs3Q4grLBwppOlJWHtcyBI4QgjxWHv66adZtmwZzs7O3Lp1C41Gg6enJ1FRUYwaNYrixYvj5ubGokWLeP/994mIiKB8+fLExMTkeG6VSsXrr79OmzZtOHPmDLVq1WLRokVs2bIFjUZD27Zteeedd1CpVCxbtozly5fj4+NDtWrVqFSpEq+//jotW7akbt263Llzh9WrV2da5N1YdHQ0iqLg5eUFkOdrff/995nuHx8fz5tvvsmdO3cA3XJaQUFBfP/996xduxYnJycaNGjA9OnT0Wq1fPrpp+zbtw+VSkXPnj15+eWXOXDgALNnz0ar1VKjRg1mzpyZ43NpXOPWtm1bOnXqxJEjR1Cr1cydO5eKFSty4sQJ/ve//5GUlETx4sWZNm0aFStWtORlYBUJa0IIIZ4I13fFcH1nzsHHGuUCi1OuXfEcj3NxcWH+/Pl89913dO7cGT8/P65du8alS5dYsmQJFSpUYOnSpQBs2bKFy5cv07NnT4vK4OrqSuXKlbl48SK3b98mIiKC1atXo1KpeOedd1i/fj3+/v6sWLGCNWvW4OLiwtChQ6lUqRIAMTExvPzyyybNrXq3b98mODiY5ORkYmJiqF+/Pl9++SVlypRh9+7debpWVvfXarWUL1+eRYsWceHCBVavXk27du349ttv2bNnD2q1mmnTpnHr1i3++usvbty4wfr160lJSWHo0KHUrFkTDw8PLl++zM6dO/Hx8bH0n9MgOjqaVq1a8cEHHzBjxgxWrFjBm2++yZQpU/jmm28oV64ce/bs4YMPPuCHH37I9fktJWHNERg3cZq7LYQQotAICQlh9OjRjB07llWrVtGmTRtKlixpWCvy4MGDDBgwAIAqVaqYLHCeE5VKhbu7O/v27ePEiRP06dMH0PVpK1euHPfu3SMwMNCwCHy3bt2IjY013L9hw4Zmz6tvBtVqtcyYMYOzZ8/SsmVLgDxfK6v79+3blzlz5nDr1i0CAgJ47bXXcHZ2pnHjxvTr14+goCAGDx6Mn58fBw4coHfv3qjVajw8POjRowf79u2jffv2VK1a1aqgpvfMM88AUKNGDQ4fPszly5e5evUqr7zyiuGYuLg4q89vCQlrBW3vVEi+/6gPmn70p1sxXV81IYQQ+aJcO8tqv2zlwoULpKSkULt2bTw8POjYsSNnz56lTZs2uLu7G45TqVRotVrDbWdnyz6qU1JSuHTpEtWrV2f//v0MHz7cMIAhNjYWtVrN6tWrTc6dkXE5zHFycuLdd9+lV69efPfdd4wZMwaNRpOna2V1fy8vL7Zs2cKePXvYuXMn3333HVu2bGHhwoUcP36c3bt3M2rUKD777LNM11EUBY1GY9Fjyombmxug+3dRFAWtVkuFChUMffg0Go2hqdZWZOqOgqQouqB2dN6jaTjCJuhuJ9+XaTmEEKIQiYqKYsqUKaSkpJCSksL27dtp2rRppuNatWrFxo0b0Wq1XLt2jaNHj+Z4bq1Wy4IFC2jYsCGVKlWiZcuWrFu3jvj4eNLS0njttdfYtm0brVq1YteuXcTFxZGSksIff/yBKpctOc7Ozrz77rt88803REdH5/laWd1/+fLlLFiwgC5duvB///d/3Lt3j5iYGLp06ULNmjUZP348bdq0MdTyhYaGotFoSExMZMOGDWabc/NDtWrVePDgAYcPHwbg999/5+2337bJtfSkZq0gpY/qvBebxKiQeSx+fh4lvTCdpkMIIUSh0K5dO/755x969eqFWq2mY8eOdOvWjaioKJPjBg0axL///kuXLl0oX748NWvWNHs+fT8y0IW12rVr8/nnnwPQvn17zpw5Q//+/dFoNDzzzDP07t0blUrFsGHDGDBgAJ6enoZBDbn17LPP0qhRI+bOncsnn3ySp2tlVVb9AIMePXrg7OzMuHHjKFGiBC+88AL9+vXDw8ODsmXL0rt3b9zc3Lh8+TLBwcGkpqbSs2dPOnTowIEDB7J9HN9++y3fffed4fa0adNyfOyurq7MmzePTz75hOTkZLy9vS0auJAXKkV5fKtvoqKiCAoKYvv27Ya2/sfRju3bCXruObaMgs610E18K0FNCCHy7PTp09SuXbugi+EwLl26xK5duxgxYgQAr7zyCs8//zzt27d/rK/lqDK+/qzNLVKzVtAUhdQjXwIQm5S+LWyC1KwJIYTId+XLl+fkyZN0794dlUpF27ZtCQwMfOyvVdhJWCtI6X3UUs+GAvCw3WJ4KkLXZw0ksAkhhMhXrq6uhqbSwnStwk7CWkFKX0oqrUp3YCOxDx/KUlJCCCGEMGHXsDZz5kxiYmKYMWOGyfbQ0FA+++wzSpYsCUBAQAATJkywZ9EKTuuppEatAjbq5p+RpaSEEKLApZFGPPF4440adUEXRzzh7DZ1x759+1i7dq3ZfSdPnmTSpEmsW7eOdevWPTlBLV1a+lwwhskCJagJIYTdJZPMcpZTn/q44kppSuOCC/Wpz3KWk0xyQRdRPKHsEtbu37/PF198wdixY83uP3nyJKGhofTs2ZO3336bBw8e2KNYDiM1NRXAZGZnIYQQ9nOQg5SjHK/wChFEoKCQQgoKChFE8AqvUI5yHOJQQRdVPIHsEtY+/PBDJkyYQJEiRczu9/X15fXXX2fdunWULVuW6dOn26NYDkPCmhBCFJxDHKI97bnHPeIwv2xQHHHc4x6BBFod2KKiovD39+fDDz802X769Gn8/f1Zs2YNgGHutKxs376defPmWVWG/NC3b98sK18cSfv27enUqZPJtrS0NFq2bMmkSZNMtoeEhNCjRw+TbQcOHKBx48YEBweb/Pfnn3/avOwZ2bzP2m+//UbZsmVp1aqV4YWY0VdffWX4fdSoUTz33HO2LpZDSUtLAySsCSGEvSWTTGc6E0+8RcfHE09nOnOd67iR+8lkixUrxp49e9BoNKjVur5wmzdvpkSJEoZj9MsYZSUoKIigoKBcXzs/nD17FhcXF86cOcONGzcoW7ZsgZTDUklJSZw9exZ/f39A1yUr4yoKMTExREZGUqpUKY4cOWKyqkS9evX46aef7Fpmc2xes7Z582b+/vtvgoODmT9/Pjt27ODTTz817H/48KHJSvWKoli8Dlphoa9Ze/jwYQGXRAghniy/8RsppOTqPimksJrVVl3Py8uL2rVrc+jQo9q5v//+m9atWxtu64PFggULmDJlCkOHDqV9+/Z8/fXXAKxZs8ZQM9S+fXtmz55Nt27d6NmzJ2FhYQwbNox27dqxefNmACZNmmRSWWJ8/smTJ9OnTx/atWvH2rVrmThxIp07d+aNN97A3Jz5a9asoU2bNgQFBbFq1SoAzpw5Q/fu3Q3H7Ny501DztmjRInr37k3Pnj2ZNWsWiqIQFRVF586dGThwICNGjCAuLo6QkBAGDBhAYGAg77zzjuHan3/+OR07dmTAgAGMGzfO8DhCQ0Pp3bs3wcHBvPfeeyQnm+9P2LFjR7Zt22a4vXnz5ky1bRs2bKBZs2Z07NiRX3/9NYt/uYJl87D2/fffs3HjRtatW0dISAjt27fnvffeM+z39PRkyZIl/PPPPwAsX76cDh062LpYDkVq1oQQomDMZGaWTZ9ZiSOOGczI+cAsdOnSxRAgTpw4gb+/Py4uLmaPPXv2LEuXLuW3335j0aJFZj8nSpcuzaZNm6hbty6LFi3iu+++Y/bs2SxatCjHspw7d45Vq1Yxe/Zs3nvvPUaPHs3GjRuJjIzk7NmzJsempqayfv16unTpQpcuXVi9ejVpaWnUqlULJycnzp07B8DGjRvp2bMnu3fvJiIigtWrVxMaGsqtW7dYv349oFvdYPbs2fzwww+EhYVRu3Ztfv31V7Zt28bx48c5deoUO3bs4MiRI2zcuJFFixYRGRkJwL///suqVatYuXIl69ato2TJkixdutTs4+vcubOh2TIlJYUzZ87QoEEDk2PWrFljeEzbtm3j/v37hn0RERGZmkFjYmJyfF7zW4FVYb3//vu0b9+eoKAg5s6dy9SpU0lKSqJKlSrMmjWroIpVIKTPmhBC2J8GDac4ZdV9T3EKDRqrpvUIDAxk7ty5aLVatmzZQpcuXQy1YBm1aNECV1dXSpYsSbFixcy2wDz77LMAlCtXjtKlS+Ps7Ey5cuUs+kxp06aN4XhfX1+qV68OgJ+fX6bBfrt27TIcoygKTk5O7Ny5kw4dOhAcHMymTZuoWLEiBw8e5NNPP2Xu3LmcOHGCPn36ALomyXLlytG0aVNKlixpWG6pe/funDhxgh9++IGLFy9y//59EhIS2Lt3L126dMHV1RVXV1dDF6kDBw5w5coV+vfvD+g+Q+vUqWP28fn5+eHt7c2FCxf477//aNOmjcn+06dPc+PGDVq3bo2Liwu1a9cmNDTUsESWozSD2jWs9enTx/CP9sknnxi2N2vWLMtpPZ4EEtaEEML+4ojDBZdcN4MCOONMHHEUpWiu7+vt7U2tWrU4cuQI+/fv56233soyrBkvfK5Sqcw2TRrXypnrRmR8P/3njaX3Nfb7779z48YNw9qecXFxrFy5kg4dOtC9e3eGDx9OrVq1aNu2LW5ubmg0GoYPH87IkSMB3WecWq0mJiYGd3d3w3l/+ukntm3bRv/+/WndujXnzp0zhEGtVpupHBqNhi5dujBlyhQA4uPj0aRPgWVO586d2bp1K1euXGHEiBGcOXPG5DGlpKQYmkbj4+NZuXKlIaw5CrvNsyayZtwMau4PUQghRP7zxptUUnM+0Iw00vDG2+prd+nShc8//5x69erZvJ92sWLFOH/+PAB//fWXVee4c+cOf//9Nxs3bmTHjh3s2LGD0NBQ9u/fz9WrV/Hz86Ns2bIsWrSInj17AtCyZUvWrVtHfHw8aWlpvPbaayb9x/T+/vtvBgwYQM+ePVGpVJw5cwatVkubNm34448/SElJIS4ujrCwMFQqFS1atODPP//k7t27KIrC1KlT+fHHH7Msuz6sXbhwwaQGLiUlhQ0bNvDDDz8YHtP27duJjo7mwIEDVj1PtiJhzQHov+loNBoSExMLuDRCCPFkUKOmLnWtum9d6uZpZYPAwEBOnz5N165drT6HpQYNGsTBgwfp0aMHR48exdfXN9fnWL9+Pe3atcPPz8+wrWLFirRv397QKT84OJh79+7RokULQDf4oWPHjvTv35/u3btTq1Ytevfunencw4cP58svv6R3795MmzaNxo0bExUVRbt27WjWrBm9e/fm5ZdfpnTp0ri5uVGrVi3GjRvH8OHD6datG1qtlpdffjnLsvv5+eHj48Mzzzxjsn3nzp2UL1+ehg0bGrZ5e3vz/PPPs3LlSsB8nzVL+gLmN5XyGFflREVFERQUxPbt2w1t34+jyZMnG5bgunHjBmXKlCngEgkhROFw+vRpateuneX+5SznFV7J1SADb7z5hm8YzOD8KKLIwrFjx7h8+TK9e/cmNTWVAQMG8Omnn1KrVq2CLprFMr7+rM0tUrPmAIz7EEi/NSGEsJ/neR5XXHN1H1dc6Uc/G5VI6FWtWtUwsrRPnz5069btsQpq+enJmtDMQRmHNZlrTQgh7McNN7aylUACLZoY1wsvtrLVqglxRe4UK1Ysyyk5njRSs+YA9AMMQGrWhBDC3prTnJ3spAQlshw04I03JSjBTnbSnOZ2LqF40klYcwDSDCqEEAWrOc25znW+4RvqUQ8VKlxwQYWKetTjG77hOtclqIkCIc2gDkBq1oQQouC54cbg9P9p0BBHHN5452nUpxD5QWrWHEBqaire3rqqdwlrQghR8NSoKUpRCWrCIUhYcwBpaWmUKFECkLAmhBBCCFMS1hyAvmbNxcVFwpoQQhRiW7dupU+fPvTs2ZMePXqwZMkSq87z8OFDXn31VcPtoUOH5lcRTaxatYrAwEBmzpxpsn3o0KE0adKElBTTpbqCg4MzlWXmzJm0bNnS5NioqCjq1auXacLZFStW5Km8a9asYdKkSXk6hyOSPmsOIDU1FRcXF4oUKSJTdwghREFTFFCpsr5tpVu3bjFz5kzWrFlD8eLFiY+PZ+jQoVStWpWgoKBcnevBgwcma1wePHgwz+UzZ+PGjXz00Ue0bds20z4fHx/Cw8MNa4VevHiR27dvU6RIEcMxaWlpbNmyhcaNG7N161bDUlQApUuXZt26dTYpd2EjNWsOIC0tzRDWpGZNCCEK0N6pEDZBF9BA9zNsgm57HsXExJCamkpSUhIAXl5ezJgxg+rVq+suvXevocZtzJgxxMXFERcXR0hICAMGDCAwMJB33nkHRVH4+OOPuX37Nq+99hoff/wxAM8//zwAu3fvpl+/fvTq1Ytx48YRExMD6JZ/euONN+jUqRN37941Kdvvv/9O9+7d6dGjB5MmTSI+Pp4vv/ySkydPMm3aNHbt2pXp8XTs2NFkrc/NmzcbFkTX27VrFxUrVqRXr16GZalyY9myZUyfPt1we+bMmXz//ffcunWLl156if79+xMYGMhnn32W6b7t27cnKioKgAMHDhhq/K5cucLIkSPp3bs3AwcOJDIyEoANGzYQHBxMnz59CAkJITk5OdfltRUJaw4gNTUVZ2dnCWtCCFGQFAWS78PReY8CW9gE3e3k+48CnJVq1apFUFAQzz33HP369WP27NlotVoqV65MSkoKb7/9NjNnzmTDhg34+/uzdu1awsLCqF27Nr/++ivbtm3j+PHjnDp1iilTplC6dGm++uorpkyZAsBvv/3GvXv3+Pzzz1m6dCmhoaG0bdvWJMg8++yzbNu2jZIlSxq2nT17lm+++YaffvqJDRs24OHhwZdffsm4ceOoV68eH3/8Me3atcv0eJ555hkOHjxomH4qLCyMwMBAk2PWrFlD586dadeuHadPnzYsKA9w+/btTM2gZ8+eNbl/t27d+Ouvv9BoNCiKwrZt2+jWrRsbN26ke/furFq1ivXr1/Pzzz9z7949i/4dJk6cyDvvvMPatWv56KOPmDBhAgBz587lu+++Y82aNVStWpWLFy9adD57kGZQB6CvWZM+a0IIUYBUKgj4Qvf70Xm6/wCajNdtz4em0GnTpvHqq68SHh5OeHg4/fv357PPPqNs2bL4+fkZ1pF88803Dfc5ceIEP/zwAxcvXuT+/fskJCRQrFgxs+f/559/uHHjBsOGDQNAq9VStGhRw37jRcv1Dh06RGBgIMWLFwdgwIABTJ48OcfH4ubmRtOmTdm7dy9ly5alYsWKuLu7G/bfu3eP8PBwPvroI9zd3QkMDGTlypWGcGlJM2jJkiWpXbs2Bw4cwMXFhSpVqlC6dGleeukl9u/fz9KlS/n3339JTU0lMTExxzLHx8cTERFh8vgSEhKIiYkhMDCQgQMHEhQURKdOnbJdU9beJKw5gNTUVFxdXXF3d+fWrVsFXRwhhHhy6QObPqhBvgW1sLAwEhIS6Nq1K3379qVv376sWrWK1atXm4Qz0A0giI+P588//2Tbtm3079+f1q1bc+7cOZRsavg0Gg1NmjThm2++ASA5OZn4+EfLaLm5ZV4mS6vVmtxWFMVk/s/sdO7cmW3btuHn50fXrl1N9q1fvx5FUejXT7eOalJSEqmpqbz99tsWnVuvZ8+ebN68GRcXF0OftxkzZnD16lW6d+/Oc889x969e80+L/pt+sej1WpxdXU1CYk3b96kWLFiTJkyhTNnzrBr1y7eeecdxo0bR3BwcK7KaivSDOoApBlUCCEchL7p05hxH7Y8cHd35/PPPzf0o1IUhfPnz1O7dm2qVq3KvXv3DM2ES5Ys4ZdffuHvv/9mwIAB9OzZE5VKxZkzZ9BqtTg7O5sEKrVaTVpaGg0bNuT48eNcunQJgIULFzJr1qxsy/X000+zY8cO7t+/D+hGgLZo0cKix/Tss89y4MABdu/ezbPPPmuy7/fff2fGjBns2LGDHTt2EB4eTtGiRdm8ebNF59YLCgri0KFDhIeH06FDBwD+/vtvXnrpJbp06cKNGze4detWptBZvHhxw/O5fft2QDcookqVKoaw9vfffzN48GDS0tLo2LEjxYsXZ8yYMQQHB3P69OlcldOWpGbNAcgAAyGEcADGfdT0TZ/625DnGraWLVsybtw4xo4da+jn9cwzz/Daa6/h6urK7Nmzeffdd0lNTaVSpUrMmjWLEydOMHXqVL777ju8vLxo3LgxUVFRNGvWjHLlyjF06FB++ukngoKCCA4OZs2aNXz66ae88cYbaLVa/Pz8mD17drblqlWrFmPGjGHo0KGkpqZSt25dpk2bZtFjcnV1pUmTJoBprV1ERAQxMTGGcAXg5OTE8OHDWblyJU8//bShz5qx5s2bG5pJ9dzd3Q3ThHh5eQEwZswY3n33XYoUKULJkiWpV6+eIQTrhYSE8NFHH/Hll1+ajGadPXs2U6dOZcmSJbi4uPDFF1/g4uJCSEgII0eOxN3dnSJFimSarqQgqZTs6lMdXFRUFEFBQWzfvp0KFSoUdHGs1rBhQ6pWrUqNGjVYuHChSZW1EEII650+fTp3fY/2TtUNJtAHM32AcysGrafappCi0Mr4+rM2t0jNmgMwrllLSEggLS0NZ2f5pxFCCLtrPdV0XjV9H7Z86LMmhLWkz5oDMJ4UF5CJcYUQoiBlDGYS1EQBk7DmAIwHGICsDyqEEEKIRySsOQB9M6iPjw8gYU0IIfLTY9w1WzzG8vN1J2HNAUjNmhBC2Ia7uzt3796VwCbsSlEU7t69azJJcF5IL3YHYDzAACSsCSFEfqlQoQJRUVFER0cXdFHEE8bd3T3fZqqQsOYAZICBEELYhouLC1WrVi3oYgiRJ9IM6gCkGVQIIYQQWZGw5gCkGVQIIYQQWZGwVsAURTHUrHl7ewMS1oQQQgjxiIS1AqZfeNbFxQUnJye8vb0lrAkhhBDCQMJaAdMv5uvi4gIgi7kLIYQQwoTdwtrMmTOZNGlSpu3Xr19n8ODBdO7cmVdeeeWJW8RcH9b0a4FKWBNCCCGEMbuEtX379rF27Vqz+6ZNm8agQYPYunUr9erVY+HChfYoksNIS0sDTGvWZOoOIYQQQujZPKzdv3+fL774grFjx2bal5qayqFDh+jUqRMAffr0YevWrbYukkORmjUhhBBCZMfmYe3DDz9kwoQJhmkpjMXExODt7W0IKr6+vty6dcvWRXIo5mrWJKwJIYQQQs+mYe23336jbNmytGrVyux+c2u1qVQqWxbJ4cgAAyGEEEJkx6bLTW3evJno6GiCg4N58OABCQkJfPrpp7z33nsAlChRgri4ODQaDWq1mujoaEqXLm3LIjmcjM2gPj4+EtaEEEIIYWDTsPb9998bfl+zZg0HDx40BDXQ1SY1a9aMzZs306NHD0JDQ3n22WdtWSSHk1UzqKIoT1wtoxBCCCEyK5B51t5//322b98OwP/93/+xatUqunbtyuHDh3njjTcKokgFxtwAA61WS0JCQkEWSwghhBAOwqY1a8b69OlDnz59APjkk08M28uXL89PP/1kr2I4HHM1a6BbcsrLy6vAyiWEEEIIxyArGBQwczVrgMy1JoQQQghAwlqBMzcaFGQxdyGEEELoSFgrYNk1gwohhBBCSFgrYFk1g0pYE0IIIQRIWCtwGWvWfHx8AAlrQgghhNCRsFbApGZNCCGEENmRsFbAZICBEEIIIbIjYa2AZWwGdXNzw9XVVabuEEIIIQQgYa3AZWwGBVnMXQghhBCPSFgrYBlr1kDCmhBCCCEekbBWwKRmTQghhBDZkbBWwMzVrPn4+EhYE0IIIQQgYa3AZRwNClKzJoQQQohHJKwVMGkGFUIIIUR2JKwVsKwGGMjUHUIIIYQACWsFTmrWhBBCCJEdCWsFLKuatcTEREOQE0IIIcSTS8JaAUtNTUWtVqNSqQzb9EtOSVOoEEIIISSsFbDU1FSTJlDQTd0Bsj6oEEIIISSsFbi0tDSTJlCQxdyFEEII8YiEtQJmrmZNwpoQQggh9CSsFbDsatakz5oQQgghJKwVMKlZE0IIIUR2JKwVsNTUVOmzJoQQQogsSVgrYDLAQDg0Rcn+thBCCJuTsFbAzDWDenl5ARLWRAHbOxXCJjwKaIqiu713akGWSgghnjgS1gqYuZo1JycnfHx8JKyJgqMokHwfjs57FNjCJuhuJ9+XGjYhhLAj55wPEbZkrmYNZH1QUcBUKgj4Qvf70Xm6/wCajNdtN1pxQwghhG1JzVoBMzfAAHRhTabuEAXKOLDpSVATQgi7k7BWwMw1g4LUrAkHoG/6NGbch00IIYRdSFgrYNIMKhyScR+1JuPhTa3up3EfNiGEEHZhlz5r8+bNY9u2bahUKvr168fIkSNN9n/55Zf8/vvvhikr+vfvz+DBg+1RtAKXlpaGu7t7pu1FihTh+vXrBVAiIdA1dboVM+2jpm8SdSsmTaFCCGFHNg9rBw8eZP/+/axfv560tDS6du1Ku3btqFatmuGYiIgI5syZQ+PGjW1dHIeTmpqKt7d3pu0yGlQUuNZTdTVo+mCmD2wS1IQQwq5s3gz69NNPs2zZMpydnbl79y4ajQZPT0+TYyIiIli8eDE9evRg+vTpJCcn27pYDiO7AQYS1kSByxjMJKgJIYTd2aXPmouLC/Pnz6dbt260atUKPz8/w774+Hhq167NxIkTWbt2LbGxsSxcuNAexXIIOQ0wUKRvkBBCCPFEs9sAg5CQEPbt28eNGzdYtWqVYbuXlxeLFy+mcuXKODs78+KLL7Jr1y57FavAZTfAQFEU4uPjC6BUQgghhHAUNg9rFy5c4PTp0wB4eHjQsWNHzp49a9h//fp1Vq9ebbitKIrZ8FJYZVezBshca0IIIcQTLtuwdvHixWzvHBoamuMFoqKimDJlCikpKaSkpLB9+3aaNm1q2O/u7s7s2bO5evUqiqKwYsUKOnToYFnpC4HsatbAaH1QWVBbCCGEeCJlG9b69etncnvgwIEmt6dPn57jBdq1a0e7du3o1asXffv2pXHjxnTr1o3Ro0dz8uRJSpQowfTp03nllVfo3LkziqJkmtqjMMtugAGkhzVZUFsIIYR4YmXb3pixc/uFCxey3Z+VkJAQQkJCTLYtXrzY8HunTp3o1KmTRed67BlPhUDWzaA+Pj4AxD54AOr7j9ZmDPjCdLLSDOcTQgghROGSbVhT5RACctovMtg7FZLvP5qrSlFITXyAc/SRTIcaatYePoResqC2EEII8aSS5absRVF0Qc14uZ6wCaSlJOOiSsvUB82kGVQW1BZCCCGeWBLW7EUfuJqM5+Kf8xjU1Inkg/NIVdQ4VwnKFLxMwposqC2EEEI8sbJtBk1OTmb8+PGG2wkJCSa3U1JSbFeywig9sO36Zh6/HIPpnSBVAy6urpkO1fdZexgba9pHzbjPGkgNm7Bexv6Oeen/mJ/nEkIIYSLbsPbKK6+Y3K5Ro0a2t0UO0mvIktIe3dRoNLiYmbrDzc0NNzc3XZ+1f0PBoxQ8+7nuA/DZz+H0Ct32wLn2fASisDDTf5KwCbpF2ltPLbhzCSGEyCTbsDZu3Lgs92k0GrZt25bvBSq09B9gR+eR5PcMsIdU/yHAcpyv/gnKVLNNobEPHoB7cYi+AiuawZAjup+Jd8C3Ami14CSt2SIXjPtPQt5GGOfnuYQQQpiV66UC7ty5w8qVK1m5ciVxcXF07drVFuUqfFQqXU1Dk/EkJZcG9pDa+C1gOS7unmY/0Hx8fHQ1a0OOwPKmEH0cvlDrdvo20m2XoCZyy2jAyu1d83hv0jzmBoN3KytGGBuda84X8+iyZR61/ZDRykIIkY8s/qQ/duwYb731FoGBgfz999+EhISwZ88eW5at8Gk9FQK+ICk5GYDUNF17qPNTXcwerl/MHScnXTAzJkFN5EV6yFofCUsPwp6LWB+uVCqiqr/FWxvg52Pp2ySoCSFEvsn20z4lJYXff/+dPn368Nprr1GmTBk8PT358ssv6d+/v6ETvMgFlYqkpCRAt3oBYHZSXDAKa1qtrmbN2PKmuu1CWCO9WT7ipu7mmWisH2GsKOxbMhaAxNT0bTJaWQgh8k22Ya1du3Zs3ryZl156ibCwMN55550sg4WwnD6s6UfTZrVwvSGs6ZtAfRvBBI3uZ/RxCWzCOkb9JyPiKwJwVqlnOgdgLs+1L2wzAIl1XtE1gVpzLiGEEGZlG9aqVq3KpUuXOHHiBFeuXLFXmQq93NSsPXz4ENyKmvZRG3JEd9utqDSFitwz6j8ZcU33heFMbEldyHIrlvs+a27F2HenDACJSUmG+QRzfS4hhBBmZTvA4Oeff+bChQusWrWKoUOHUqVKFeLj40lISKBkyZL2KmOhk5iYCOSiGXTAv6ajPvWBTYKasFbrqUTfvs2tW/NQq9WcOXMGAnZaFa6Sm07m6Pn/Aemvbf2gAwlqQgiRL3L8tH/qqaeYPHkyu3fvZvDgwdSrV4/u3bvz2muvsWXLFnuUsdDJWLOWYzMoZA5mEtREHkWcOgVAYGAgt27d4v6DB1ad59ixY4Ymff0XEQlqQgiRfyz+xHd1daVHjx789NNPhIaGUqlSJT766CNblq3QsrQZ1MfHh6SkJFkpQthEREQEAP369QPg7NmzVp1n3759AFSuXJmEhIT8KZwQQggDq6pnqlatysSJE9m1a1d+l+eJkJuaNUDXb02IfBYREUGJEiUICAgA0DWFWmHfvn1UrlyZatWqPapZE0IIkW+y7bMWFBSU4wm2b9+eb4V5UmQcDZpdnzXQLeYufQRFfouIiKBevXpUq1YNZ2fnPNWstW3bltjY2EfN9kIIIfJNtmEtLi6OtLQ0OnbsSPv27WXajnySm9GggHwAinynKAoREREMHToUFxcXqlevblXNWlRUFFFRUbRs2ZI9e/ZIzZoQQthAtmHt77//Zs+ePWzYsIGPPvqIgIAAevbsSbNmzexVvkJJmkFFQYuKiiI2NpZ69eoBUKtWLavC2v79+wFo1aoVhw8flrAmhBA2kG1Yc3Z2JjAwkMDAQOLj4/nzzz/5+uuvuXr1Kl27dqVnz55Uq1bNXmUtNKRmTRQ0/eAC47C2adMm0tLSsvzyYM6+fftwd3enUaNGeHh4SFgTQggbsHiAgZeXF7169WLp0qV88cUX/PXXX3Tr1s2WZSu0cluzJmFN5Dd9WKtbty4A/v7+pKamcunSpVydZ9++fTRt2hRXV1cJa0IIYSMWh7UHDx7w22+/MXz4cIYNG0bNmjVZuHChLctWaFk6wEC/9qqENZHfIiIiKF++PMWLFwd0NWuQuxGhycnJHDlyhFatWgHg6ekpU3cIIYQNZNvekZCQwPbt29m4cSMHDx6kefPm9OnTh6+//hpPT097lbHQkWZQUdD0I0H1/P39Ad1caz169LDoHMePHyclJYWWLVsC4OHhQWpqKhqNBrVanf+FFkKIJ1S2Ya1Nmza4u7vTqVMnvv32W0qUKAHA9evXDcdUr17dtiUshCxtBvXy8kKlUklYE/lKo9EQGRnJa6+9ZthWvHhxSpcunauaNf1kuPqaNQ8PD0C3ioG3t3c+llgIIZ5s2Ya1xMREEhMTWblyJb/++iugG/Kvp1KpOH36tG1LWMhoNBpDSMupZs3JyQkfHx8JayJfXbhwgaSkJJOaNcj9iNB9+/ZRqVIlypUrB0hYE0IIW8k2rFk7o7nIWnJysuH3nGrWQNcUKlN3iPyUcSSoXq1atVizZo3F59m3bx+tW7c23DYOa0IIIfKPrAZuZ/omUMh5gAFkWMxdiHwQERGBSqWidu3aJtv9/f25c+cOd+7cyfEc165d4+rVq4YmUJCwJoQQtiJhzc6Mw1pOzaAgYU3kv4iICKpVq4aXl5fJdv2IUEuWndJPhqsfXAAS1oQQwlYkrNmZubCWXTOo9FkT+S0iIoL69etn2p6bsLZv3z7c3Nxo3LixYZt+hLhM3yGEEPlLwpqdSc2aKEjJycmcO3cuU381gMqVK+Pm5mZRX1XjyXD1pGZNCCFsQ8KaneW2Zk3CmshPZ8+eRaPRmA1rarWaGjVq5BjWUlJSTCbD1ZOwJoQQtmGXsDZv3jy6du1Kt27d+P777zPtP336NH379qVTp068//77pKWl2aNYBcL4g0wGGAh7y2okqF6tWrVMm0GNpurRO378OMnJyRLWhBDCTmwe1g4ePMj+/ftZv349v//+Oz/99BMXL140Oeadd97hgw8+YNu2bSiKwqpVq2xdrAJjTc3aw4cPTea3E8JaERERuLi4UKNGjcw7906llvt/XLhwQfdFQlEgbALsnWpymH4yXOPBBSBhTQghbMXmYe3pp59m2bJlODs7c/fuXTQajclSVdeuXSMpKYlGjRoB0KdPH7Zu3WrrYhUYa8KaoijEx8fbvGzCwWUM7FYE+IiICPz9/U36mhnOlXwff81BNBoNF86f1wW1o/Mg+b7Jtfbt20fFihUpX768ySkkrAkhhG3YpRnUxcWF+fPn061bN1q1aoWfn59h3+3bt/H19TXc9vX15datW/YoVoHIGNacnZ1RqVRZHi/rgwpAV7sVNuFRaMqi1isnGdcENVCpIOALard7AYBTM+rqglqT8RDwhW5/un379mVqAgUJa0IIYSt2G2AQEhLCvn37uHHjhkkzp7nmvezCy+POXFjLjoQ1M/Khhumxkl7rxdF5jwJbFrVe2Xn48CGXLl3Ksr8aKhX1hn+PqxoOXU3fliGoXb9+nf/++89sWCs0U3c8aa8vIYTDs3lYu3DhgmH9UA8PDzp27GjSgdnPz89kxvTo6GhKly5t62IVmIxhLbvBBaCbZw0g9sED0x1P6gdIPtUwPVbSa71oMp7NK+Zx7C2nLGu9shMZGQlkPbgARcFt3yQal4f9/6VvM36uMT8Zrp6rqysqlerxrll7El9fQgiHZ/OwFhUVxZQpU0hJSSElJYXt27fTtGlTw/7y5cvj5ubGkSNHAAgNDeXZZ5+1dbEKTMblpiyuWdszUz5AjGqYlJ1voGi1VtUwPZbSA9vroTA7LH1bLoIa5DAS1Ki2rkWzRhy+6Ulaw9dNa/PQNYG6urqaTIb7qIgqPDw8Ht+wlk81mEIIkd9sHtbatWtHu3bt6NWrF3379qVx48Z069aN0aNHc/LkSQA+++wz/ve//9GlSxcSExMZNmyYrYtVYHJbs1ZEX7MWsVY+QIxqmHqMm8+QZmqrapgeS+n/7g8SIVWTvi1DrVdOIiIi8PT0pGrVqpl3qlTgVgyajKdl33dISEggouRI3XPrVszw3Oonw3VzczN7jcc6rBm9vjg6D+ZYV4MphBD5LftqnXwSEhJCSEiIybbFixcbfq9VqxarV6+2R1EKXK7DWtGiAMT6ddB9cBydp9vxpH6AqFTcqj2JzWfm4aSC2d2hXGF/HowC+sNUNalVu0OTKo9eCxY+/oiICOrWrYuTUxbf0VpPBUWhxaVLABw4eJBGLz86d0pKCocPH+a1117L8hqPdViDR4FN/9zCk/l3JoRwKLKCgZ1ZO8DgYdmupjue+ezJ/ABRFNbPHoKigEYLPxwm1zVMj530Wq/keq+RkqrRTRqtrwEyqvXKSZYjQTNcq2rVqvj6+ur6pxmdO6vJcI099mFNUWDHeNNtO8YX7teXEMLhSVizM6sHGPz5jumOL31gUeV8L59DS69hCt28naplixAYGMiS40XQHp5X+ANb66k8bPJ/ALqwpq8Baj3VorvfuXOHmzdv5hzW0PU9a9GiBQcOHDDZnt3gAj2zYe1x+XdRFPi2IhxfAI1ehze1up/HF+i2Py6PQwhR6EhYs7PcDjBwdXLC3RliE9JA7Q7jU3U/NUkQdx0K8dJcmahUPEzz4K8LanoNeJHRo0dz6UYsO1S9c1XD9Lh6GBcH8Gg5tlw83lOnTgHZjATNoGXLlpw+fZr79+8btu3bt48KFSpQoUKFLO/nqblHQtSxx3MwjH6AAUDUbt3tqN26209a/1AhhEORsGZnua1ZQ63Gx92J2GR0AW2ei+4ngLsvqNW2K6wD2nq/CSmpGnr17k3v3r0pUaIESw67WlzD9DjTz7WnX/kiN3JaEzSjFi1aAHDo0CHDtqwmwzVQFDxcIPHef/YdDJNf86KpVFD/Jd3vd/6BL9S6n6DbXsi/DAghHJeENTvLdVgDihTxITbJzI5az+djyR4PoaGhlCpVitatW+Pu7s7QoUNZu3atyVx9hdXDhw8Bo5q1XIiIiKB48eKULVvWouObN2+OSqUyNH3euHGDK1euZB/WVCo8yjUg0aW0/UZT5ue8aCoVBM6FxqaDoWgcotsuYU0IUUAkrNlZbgcYoFJRpHRVYpMz/FOp3eHZz5+oD5CUlBQ2bdpEjx49DM/bqFGjSElJ4aeffirg0tleXsLayZMnqVevnsWrgxQtWpTatWsb+q3pF2/PNqyR3mfNuZTpRlsFNVvMi6YocHWX6baru6QJVAhRoCSs2Vmua9Y0GorERxCbpM2wPQkWlQWNxvz9CqFdu3bx4MEDevXqZdhWr149WrZsyeLFi80uXVaY6JtBcxvWFEWxbCRoBi1atGD//v0oisL+/fuznAzXmIeHB4kxUaYbbTX4w2hetFOb5/HgkzzW5Gm18FOTR02fenf+0W3Xas3fTwghbEzCmp3ldoABTk4UcVN4mGxmX1oyZDVnViEUGhqKp6cnHTp0MNk+atQoTp8+baj9Kaz0NWu57bN27do1Hjx4kOuw1rJlS+7evcvFixfZt28fTZo0yXIyXEDXZy3mOIlxsbrA9Kb20QSzNgxsiS0+5el51q/sYHwuktKb0xuH6MqvbxJNuvNE1WILIRzLk/NJ7yCMwxpgYZ+1Yro+axk/QErWsUEJHZNWq2XdunV06tQJDw8Pk30DBgzA29vbZKLlwsjaZtDcDi7Q0w8y2LNnD4cPH86xCRSVCg9PTxK1ro8CkxXzweWKonBo0XASUuHC3fRt1gZDlQrqjzLto6bvw1Z/lIQ1IUSBscsKBuKRpKQkk7mocgxrKhVF/KoSG5lg+gEC4F78ifkAOXLkCNeuXaN3796Z9nl7ezNw4EBWrFjB3LlzKZq+6kNhY20zqLVhrW7dunh5efHtt9+SlJSUc1gDPJ9qT0LKsUevS31gs1WftbAJ7NmmW/0kyrstNGma65UdTKSv4mBSfhlcIIQoYFKzZmeJiYm4u7sbbufYDAr41GhPbKI28wfgEzBdhV5oaChqtZpu3bqZ3T969GgSEhL45Zdf7Fwy+7G2GTQiIoJy5cpRokSJXN3P2dmZZs2aGUaEWhLWPDw8SE1NRWPcl9JWQSd9ZYfwe7rJoaOiovKnJi/j/SSoCSEKmIQ1O9PXrOlZ1Ax6/xDJyckk65tQFQV2vfl4TDSaT9auXUu7du2yDBzNmjWjQYMGLFmyxM4ls5+8NIPmtlZNT79aQfny5bOdDFdP/9q215JTmhYfsPdMDKDrm6dVlCfui4wQovCTsGZnGcNajjVrikIRV90otIdbx9tvolEHcvbsWU6fPm0yCjQjlUrF6NGjOXLkCMeOHbNf4ezImmZQjUZDZGSk1WFN32/Nklo1sH9Yi4iIIDY2llatWpGamkp0dLTUhAkhCh0Ja3aWlJRk0gxqUZ+1piMAiD24yD4TjTqYdevWARAcHJztcYMHD8bd3b3Q1q5ZU7N26dIlEhMTrQ5rrVq1wsXFhYCAAIuOt3dYCw8PB+CFF14A0ptChRCikJGwZmdWNYOmd5g3mb7jCQlqoOuv1qRJEypVqpTtccWLF6dfv36sWLGChIQEO5XOfqzps2bt4AK9MmXKEBkZyZgxYyw63t5hbc+ePVSoUIHWrVsDEtaEEIWThDU7y1izZskAgyI+PgCmS07Zat4qB3Pjxg3279+fbROosVGjRvHgwQNWr15t24IVAGuaQfVhrU4d66d5qV69ukWvU7BvWFMUhT179tC2bVsqVqwISFgTQhROEtbsKC0tDY1Gk7uaNUWhyL+6Zr3YCj3tM9GoA9mwYQOKolgc1p599llq1KhRKOdcs6YZ9OTJk1SrVg0vLy9bFcuEp6cngF1qNq9cucL169d55pln8PX1xcXFJX/CWn4tDC+EEPlEwpod6SfEzdUAA5UKn8SLAMRW6q9r+mw3B3wbwe3jhb4pNDQ0lGrVqlncjKdSqRg1ahTh4eGcPn3axqWzL2vCWl5GglrDnjVr+v5qbdu2xcnJiXLlynHt2rW8nTQ/F4YXQoh8ImHNjvRhLVcDDBSFIq66D+fYw0sffXhEH4e0pJy/9T/GtQSxsbFs376dXr16WbwAOcDw4cNxdnZm6dKlNiyd/embQTUajUXroCYnJ3Pu3LlCHdaKFi1K3bp1AahQoULeatZssTC8EELkAwlruZHH4GNVzRpQ5OFJAGL/3akbDXpsvm7HraPZ3/ExryXYunUrKSkpFjeB6vn5+REcHMyPP/5IcrK5RVUfP2lpaSQlJRnW5rSkdu3cuXOkpaUV2rC2Z88eWrdujVqtBvIhrOknm270ui6g6UdeN3r9iRrQI4RwPBLWLJUPwcdcWMuxZk2jwctVi0oFsZlyhxaMZ4o3VghqCUJDQ/H19TWM9MuNUaNGcefOHdavX2+DktmfvglUPymwJWFNP7igfv36titYBvYKa3fv3iUyMpK2bdsatunDmiW1jllaFQjX9phuu7ZHt10IIQqIhDVL5FPwsSqsqdWo/JpSxC3D1B0ApZtAeq1CJum1BKkNxvHL0nmkzn685mdLSUlh06ZN9OzZ01BzkhsdOnSgUqVKhWaggb4JtHjx4oBl03dERETg7OxMzZo1bVo2Y/YKa3v37gXgmWeeMWyrUKECiYmJxMTEWHdSrRaSH+i6GBiLPq7brtVad14hhMgjCWuW0DePNBnPw73zWDLACe3h3Acfc33WLFnBgNgrFHHPMHUHQOyV7IOiSsVnh8oyaAX8eS5922MQ1ADCwsKIjY3NdROonlqt5sUXX+TPP//k0qVL+Vu4AqCvWdOHNUtr1vz9/XF1dbVp2YzZK6yFh4fj6upK8+bNDdv0y2FZ3RSqUkH5Z8zvK//MY/F3I4QonCSsWSo9sK05CaN/g/BL5Dr4WFWzBqBAETczYS2HCr2oq1f5+KP/A+Dq/fSNj8l0H2vXrsXLy4ugoCCrz/Hiiy+iUqn47rvv8rFkBcPaZlB79lcD+03dER4eTrNmzUy++ORLWPMooeujZqzR67rtEtaEEAVEwpql0ps+b8fpbu66SK6Dj1UDDLRaSLqDj7uZPmtJd7JumlEU3hn+HJq0NJycVFyrPeWxmZ9Nq9Wybt06OnfubPJc5VbFihXp3Lkz33//fa4XP3c0+mZQS8NafHw8Fy9etHtYc3V1RaVS2bRmLTExkUOHDpn0V4N8CGsALT8032et5YfWn1MIIfJIwpoljPqoRXs3BSDsdoVcBx+rpu5Qq8HJ2XzNmpNzln3Wdu3ezcqd53h34NP4+ZXh2vXrhqZc3Io5dC3BoUOHuHHjhtVNoMZGjx7NtWvX2Lp1a94LVoAyNoPm1GctMjISsH6ZKWupVCo8PDxsGtYOHTpEampqprBWpkwZnJycrA9rWi0sb6rro+bbCCZodD+jj+u2S581IUQBkbBmCZVKF3CajOeOh25k3d7Td0iu91qugo/VzaClG5nvs1a6kdnD09LSCAkJoVKlSkz6egfly5fXTRaq73vXeqpF5S0ooaGhqNVqunXrludzde/eHT8/v8d+cffcNoPmdU3QvLB1WNNPhtumTRuT7c7OzpQtW9b6sObkBG5FdQFtyBHd7SFHdLfdiupuCyFEAZB3H0u1ngoBXxB95w6gC14HPfrnKvhYNcAAAJUurGm9dMtNNQ4xbDfn22+/5cSJE3z++ed4enk9Cmvg0DVqeqGhoQQEBBhqkfLCxcWFESNGsHHjRm7cuJEPpSsYuW0GPXnyJB4eHlStWtXmZcvIHmGtbt26hufCWJ7nWhsQ9iiowaPANiDM+nMKIRyfg08gL2EtN1QqoqOjadq0KSqVil27d+fq7lbVrKlU4OxOkWK+PExRP6od820Ezu6ZwtedO3f44IMPaN++PX379gUwDWsO7syZM5w5cyZfmkD1XnrpJTQaDT/88EO+ndPecjsaNCIigjp16lg17Ule2TKsaTQa9u7dm6kJVK98+fJ5Xx80Yw2a1KgJUbg9BhPIy7tQLt25c4eaNWvSoEEDwsLCcnVf/QdYrgYYKIquGVSJ5uHDWLQaDex6U9ePpnSjTOn//fffJzY2lvnz5xuWaCpfvjwxMTF2mVU+r9atWwdAcHBwvp2zRo0aBAQEsGTJErSPab+jhw8f4ubmZnjt5NRnrSBGgurZMqydOnWKBw8eZBnWKlSo8Nh8MRFCOACjeVTvrhtLakqKQ04gL2Etl6Kjo/H19SUgIIC9e/fmajkjqwYYpNekFXnqGRQF4mc4Zzm57dGjR1m8eDHjxo0zrJcIUK5cOQCuX79ucVkLSmhoKE2bNqVixYr5et5Ro0Zx8eLFXAdsRxEbG0uRIkUM4T67mrW7d+9y48aNAgtrnp6eNpu6Y88e3UjN7MJabGysodlYCCGylf4Ze7HMCJ4auIi5fdwccgJ5u4S1L7/8km7dutGtWzdmzZpldn9gYCDBwcEEBwezYsUKexQr15KTk4mNjaVUqVIEBAQYphCwlNUDDFQqfBoNBoym78jwIlIUhddff51SpUoxdepUk7uXL18ewOFrHG7cuMH+/fvztQlUr2/fvhQvXvyxXdHg4cOH+Pj4GF4v2YW1U6dOAfZdZsqYLWvWwsPDqVChApUrVza7Xz99h6O/1oUQjiM1LY2B8yNRqaB/w/SNDhTUwA5hbe/evYSHh7N27VpCQ0M5deoUf/75p8kxERERzJkzh3Xr1rFu3ToGDx5s62JZ5e7duwD4+voalrnZtWuXxfdPSkpCrVabNH1aNMBAUSgSFQoYjQjNMGXI8uXL2bt3LzNmzKBYsWImd39cwpp+Hc/evXvn+7nd3d0ZMmQIa9as4U76IJHHiT6sWVKzVpAjQcF2YU1RFPbs2UPbtm0NTfwZ5ctcaw7e0VgIkb8+/OADDh48yOJ+UFk/bsnB5iO1eVjz9fVl0qRJuLq64uLiwlNPPZWpOS4iIoLFixfTo0cPpk+fnqumRXuKjo4GdI+pZMmSue63lpSUhLu7u8kHTY41a+kdHYvc0M0TFttnX6bJbWNjY3n33Xdp3rw5I0aMyHSKxyWshYaGUr16derUqWOT848aNYqUlBSWL19uk/PbUsZm0Oz6rEVERFCsWDFD87e92Sqs/ffff1y7di3LJlDIh7D2GHQ0FkLkn+1//cXMWTMZ3QL6jRyvm3HBASeQt3lYq1GjBo0aNQLg8uXLbN68mXbt2hn2x8fHU7t2bSZOnMjatWuJjY1l4cKFti6WVfQ1MqVKlQIgICCAv//+m5SUFIvurw9rxnKsWVOp4PZxipSpDkDsw4fQbo5uNOjt46BS8dFHH3Hz5k0WLFiAk5mRa0WKFMHLy8uhw9qDBw/Yvn07vXr1yrLWJK8aNGjA008/zeLFi1Ec5A/QUrmtWatXr57Nnsec2Cqs6edXyy6s6QOqVWHNqKOx4U3aATsaCyHyR3R0NEOHDaNW5VLM/b9XHzV9OuAE8nYbYPDvv//y4osvMnHiRKpUqWLY7uXlxeLFi6lcuTLOzs68+OKLuWpatCfjmjUg1/3WrK5ZS0uiSOJ5AGIfPNB9gEQfh7Qkzpw+zdy5cxk5ciQtWrQwewqVSkX58uUdeoDBli1bSE1NtUl/NWOjR48mMjKS/fv32/Q6+c3SPmuKohToSFCwXVjbs2cPRYoUyfaxubm5Ubp0aevCmkoFrumT4h6dB3OcdD99G+m2O8ibthAi7xRFYeTIkdy7d49fQv/Cs/OXj/7GHXACebuEtSNHjjBixAjeeuutTP2Rrl+/zurVqw23FUWxcKJY+9OHNX3NWm77rVkV1gDKtqBIeoXcw9XPw7H5AChlnuaNCRPw9PTkf//7X7anKFeunEPXrIWGhlK6dGlatmxp0+sMGDDA8AXhcWJpM+iNGzeIiYkplGEtPDycNm3a5Dh3nNUT4yoKpDzQfREyFn1ct11q1oQoNBYsWMCmTZuYPXs2DRs2zPxlzMG+nNk8rN24cYPXXnuNzz77zOzyQe7u7syePZurV6+iKAorVqygQ4cOti6WVe7cuYNKpaJkyZKALrTVr1/f4n5rSUlJmRYmt6gZNHAuRZq/DBgNMGgcwvqH7dm2bRtTp07Fz88v29M48sS4ycnJbN68mZ49e9p8ElcfHx8GDhzIr7/++lhN72BpM+jJkyeBghtcALqwlt9Td9y7d49Tp05l2wSqZ3VYU6kedTEw5ttIt93B3ryFENY5fvw477zzDt27d2fcuHEFXRyL2DysLV26lOTkZGbMmGGYmuOXX35h9OjRnDx5khIlSjB9+nReeeUVOnfubKiadETR0dGUKFHCJFDkpt+a1TVrgI+n7jj91B2JyWlMePNN6tSpY9GLTd8M6oh9tXbu3MnDhw9t3gSqN3r0aBISEvjll1/scr280mg0xMfHW9QMqh8JajzPnr15enqSmpqKRqPJt3Pu3bsXyL6/ml6eatb0E04biz6u2+6AfztCiNyJj49n4MCBlCxZku+//77A+vbmls3bG6dMmcKUKVMybR84cKDh906dOtGpUydbF8Uqilbhv813Ubs54XzHk0p+VUz2BwQEsGDBAg4fPkzr1q2zPZdVAwwUBXa+gcvJr3B3flSz9vn8hVy6BH/9+adFga98+fKkpKRw584dQ587RxEaGoqXlxdBQUF2uV7z5s2pX78+S5YsYcyYMXa5Zl7ExcUBWFSzFhERQZkyZQxN9QVBX3ucmJiIt7d3vpwzPDwcFxcXmjdvnuOxFSpU4N69eyQkJODp6Wn5RYz7rBkHNumzJkSh8cYbb3D27Fn++uuvAn2fzC1ZwSAHmiQtVzbd4fTi6/RgBDPr/sCu0Wc49H8XiVx0jVqpTXm6zDPs/+MQWk3237ytrlm7cQCAIt4exNZ8mf/KjeTT7dC3eXGLA46jTt+h1WpZt24dXbp0yRRkbUWlUjF69GgOHz7M8ePH7XLNvNCvC2pJn7WCHlwApmEtv+zZs4dmzZpl6kZgjtWvdeM+a02MhvBLnzUhCoVVq1axZMkSJk2aRPv27Qu6OLkiYS0Hzp5qnvnKn7Zf1eTb/2awV7OVUo29UbRw+0As135/yMfPLKR+ZBA7hkSyd8K/HJ99hX9/vsn1sBjun0sgNU5XC2IurFnUZ61qZ2gcQpFS5Yl9+JC318ahqNR8PmmYxd/2HTWsHTx4kJs3b9qtCVRv8ODBuLm5sWTJErte1xr6sJZTzZpWq+XUqVMFtnKBXn6HNf2Ia/2AnpxYPdeaSqUbqm+8zIwDDuEXQuTe5cuXefnll2nRogXTpk0r6OLkmmMOu3QwKicVHr6uhF/+ixINPKn7agXDvpSHaXz89gyOhZ1k9pQvSLqRSsL1FO4cjUMxqmlz8VHzctn3SHNPJG4PBFTswo24qzilqFEUJft289ZTdasYFAknLCyMGzduMPX//o/KfaZa/BgcdX3Q0NBQnJ2d6dq1q12vW6JECfr168fy5cuZNWtW7prL8ouimAaAjLfT6QdC5NRn7dKlSyQmJha6mrXDhw+TmppqUX81yOOSU+l/a5mG8EtQE+KxlZaWxuDBg1EUhV9++cXivuKORMKahbRardn+Xq4+zjTsWJuPFn3Ae9XfoNXQVrrjNQqJt1NIuJ5M/HXdz4jQFCqoqhG/y4n3WurWSL0wNZ4rHqfx8HPF3dcFD19XPEq74F7aFQ9f3TYXTzWoVBQpUoSjR49SpUoV3p04MVflL1u2LCqVyuFq1kJDQwkMDKR48eJ2v/aoUaNYsWIFv//+O0OHDrXvxfdO1U20qg8C+glY3YplmtvHXDOoubBW0MtM6eV3WNNPhptTn1A9fS2y1asYOPgQfiFE7kyfPp29e/fy888/U7Vq1YIujlUkrFnowYMHaDQasx0Sn332WUA331qrVrqw5qRW4VXWDa+ybvg21R3XYfrbdO3alddfCaFnYG/KelVgyRc/oI53JfFWCgk3Urh7Ig5tsmnfGGcvNR6lXRhQYiy1Gj5Nt/6deXA0maSSWtxLuOBWwhkn5+xbtF1cXChdurRDhbUzZ85w9uxZQkJCCuT67dq1o3r16ixevNi+Yc14pnzQBTb9TPlNxmeqYTPXDGquz5o+rNlquS5L6cNafk3fER4eTp06dQxT5uTEy8uL4sWL5219UCFEoRAWFsbHH3/MiBEjTAY2Pm4krFko4+oFxnx9falbty5hYWFMmjQpy3Po+6w5uaq4EnuBK7EXKNexqEmtkqIopD7UkBidSlJ0Com3039Gp1KxaFUq+dfA5bgrJ48bfRCpwLWoM+4ldcFN99NF97OkC+4lnHEr5uJwc62tXbsWgJ49exbI9VUqFaNGjWLSpEmcPXsWf39/e11YF9CA77+ZR6Vf5xFUA9O+UkaMm0FzqlmrWrVqvo3AtJa+STk/atY0Gg1///03AwYMyNX9rJ6+QwhRaNy9e5chQ4ZQvXp1FixYUNDFyRMJaxbKuHpBRgEBAfzwww+kpqZm2R5uyQADlUqFaxFnXIs4U/Qp05FvjakMQFqChqR7qSTdSSX5XipJd9NIvptK0r1UEm+mEBMZT1q8NtP1p1f7lvup9zg89SKuxVxwK+6MWzFnXIs641pMd03dT3WONXX5ITQ0lObNmxv6GBWE4cOHM2XKFJYsWcLs2bPtd2GVisjSoxn12zyaVYAD48myb5RxM2h2fdYcYSQo5G8z6KlTp3jw4IHFgwv08hrWIiMjWbJkCTNnznws+7cI8aRTFIVRo0Zx+/Zt9u/fX+BfYvNKwpqF9Iu4ZzVHWUBAAF999RVHjhwxu2SSoihm51mz5oPA2VONt6ca7wpZT3WRlqQh+V4aSXdTSb6bSvL9NLb+/gd3bt+jprY6sRcSSb6fmqnJ1XANLzWuRdW4FnHGxUeNi48zrt5qw++6n2pcvNW4+jjj7K3GSW15355r165x8OBBPvnkk1w//vxUpkwZevTowY8//sgnn3yCq6urfS6sKEx+uSdaBQ5Hwf1EKBY2wWxgs6QZNCUlhTNnztCjRw/7lD8b+RnWLFm83ZwKFSpw9OhRq66p1WoZOXIkBw8epG3btvTp08eq81h0LY2CkqqgTdOiTVV0/6Wl/5eqoKRqDb8b9qVvA+OXigqMxkRgtNmw3eiYTMca3UlldB/TY1Umt41Pp7tOhnPkcB1UZsqafozpeY2vozIpW8brGO6f4byqDPvNl9/4EFUWz0H213n0XJtex+TSKnBydcLZw+mxmZD1cfTNN98QGhrKnDlzaNKkSUEXJ88krFkou2ZQMO23Zi6spaamotVqrV7BILec3dU4l1PjVc7NsO3OyYt8uPxD3v3jZdzcdNvTkjSk3E8jJVb/M42UB+n/3U8j5aGGxJspPDifSOpDDUpa1nNNOXs6PQpyXmrUHro3JGcPNc6eTqg91Om3nfhr5x7qlmxMt5bBJN5OST9WjZOz/d+8Ro8ezdq1a1m/fj39+vWz/QUVhfAF/Vm/9yJdnq7MloNX2EV3go37sBm9RmJjY3F2djb8m0HmmrVz586RlpZW6GrWwsPDKV++PJUrV87V/SpUqMCtW7dISUkxCeCKoqBo0IWjFH0IMgpKqQqbN2xG+c+VZyt1JGzpflqWCDQKS+n3S1PQpqQHqYy3jUNVqoJiFL60GYIZMnXbE0ulRvcluIg688/01hUXH7XRT/u0eBQGJ0+eZMKECXTu3Jnx48cXdHHyhYQ1C+lr1rJqBi1dujR16tQhLCyMiWZGaiYl6ZYeyFiz5uRkvz8+/Si569evG0bEOLurcS6jxrNMzvdXFAVNspbUWA2pcRpSH+rCnO533e1U/e14DUl3UklL1KBJ1JKWpDX5YCpHPb5ov4zb3yjc5pxhu5OLShfs3HUBz9nDOOTpfqo9db+r3VQ4OTvh5KJC5aLCyVmFk4sKJxcn3e+u+m26Y/T7Vc4qk8DcsWNHKlasyOLFi+0S1hTgnUX7KVfSi5+3HqNc+fJsv1WF4D7m5/N6+PAhRYoUMZTZ2dk5U1hzlJGgYBTWEhINtUDaNNPQYvjdeJ8+NBkFG/fzJXmlzTtc+j06UxBSzNU4pd9uerszSzs15u/X/8VJUZuEspwCki+1+OSZrw23Ty00089TRfrry8nodWb6WlO7OeHipdumMuw3/5rUvS4zbNO/XvWvZ+P7G32pUQz/h8ljUxRMJvJVMh6j6Lcb38lou8mxivlzmLnOo/NmvJ7y6G6ZrqOYHms4LyYbTOYlzngd/Q3jf+IM51DMXAcl8znMXUd3XqP7Z1lWxezzZHwdTbJW934ZqyElVve++fBykuH9MyvOHk7pQS5DsPPJ8DN9v7Pnk1d7l5iYyMCBAylWrBg//PCDXT9jbUnCmoWio6Px9PTMdj6ugIAAli1bZrbfmnFY0//xuLi42PUPyXhiXGuGL6tUKl24c1fjUTp391W0uqCXlqgl5tZ9OrTryJABwxg55EVdmEvQPgp2ibrf9duS76YSn/hovzY179URJh+eLiq+fGYVt+/cZPcbkbh7uRk+eFXOKtQu5j80VU4qVE4YmkNUToBTetOISr9P97zp9ul+P3b8GMXimxMybhgJJ2BM+ze4d+Qe1/tNhzRgd4zREwe+MZXoVLUX13bGgAKdq/amdEwVov66h6JVQAsxe5Lp6z8crwuluXwpGkWbXoukBbS6n/pjFUX3u6JF98GkBUWj6P4z+l2r0dVCmdxOM9quD1pG+xSNbtvmvkdx3uHC9h2Refp3GlhlDChwYdVtXUAyCS1OupCeIai7uDvhkqbiQuRZqviVx7e8n2mQyvT7o9uLln7L6rW/sWjpIkqWLsFznYIYNmIokz+YjJOLCrVL+jVz0eQvRG5oNQppcboQl/JQQ2qsruUj1fj2wzSSY1J5eCWR1FhNlu+JT2Lt3VtvvcWpU6fYtm0bfn5+BV2cfCNhzULR0dE5rqkZEBDAwoULOXr0KC1atDDZZ65mLcfVC/JZQa5ioHJSpdeMqQnb9henoo/z7MCv8GtRNNfn0qbqAp0mJb2ZyaQ2Rmu+tiVjH6AU0/u4PoDDG/bh/cCTGqVqoE1VSI3XPKoFMlPro2ita8Zyx483m0+HSDgVeY2unoPAE059Zf7fpTVdaV2tK5Ff6/aHNPoQ7sDpRY8mOK5OU6o3aMrFX+6Yv2h6mFQ5qQyh0XBblR5enVSo1ICTLoyonNOPUT+67eShwkWtQqW/7awy3e+sQqNomD1nFu0C2tGu/bO67epHtZr6miGVUS2RYbtRjVPohrWMeeVldv+9mwaNG6BSY/GXm8jIBD797B3qj/+F9i9Y1l8lIiKCqUsmM3r0aJ7u3giAJu0b8NVP83lvxkRcjZqhhbAVJ7VKN+irqGWfD8YtHvpaOpOf+Vl7ZxL0HK/2bu3atXz99de88847dOzYsaCLk68krFnozp07OS762q5dO0DXby2rsObh4WFSs2ZPjrLkVGhoKH5+fpmeI0s5uTjh6pL/3/6m7Z7Ad39+zpUlV1Cr1RbfT9EqhqYgXW1VenOLFkMNF4ru9+U//cTEdyfx3dKldHiuI4pWISIigl69ejFnzhyz05gMHTaMxMQEfv/9d1BB/Qb16dunD9M+mm4IXM2bN6dBw/p8/+P3utdX+nbj2j17URSFH1/6kgq9ijKid1+rz7P7cBgqD6jfpF6ua7Jyu+SUoii8/vrrFC1alI8//tiwfezYsaxZs4bff/+dQYMG5aoMQtiDaYuHZQOksqy9e2j88/Gqvbt69SovvfQSzZo1M/kbLiwkrFnIkpq10qVLU7t2bcLCwnj33XdN9mXVDGpPxYoVw93dvUDDWnJyMps3b2bgwIG5CkT2MGrUKPr168fWrVvp1q2bxfdTOelHr2UfKOLj45ny6XvUalqDHgO7GV4HTX0bkeQazx/7t/DCy89nul/Ug8sUL17c8EYcq4nhofIA9xIuhvOe/Pcf+g3pg7NHwT+nKpUKDw+PPA8wCA8Pp3Xr1la9TooUKYK3t7fFYe23334jLCyMr7/+2mTy3aCgIKpXr87XX38tYU0UGo5Re6cPcLpg5+HnimdZNzzLuuJZ1hVnd8v/7jUaDUOGDCE1NZVffvnFfqP67UjCmoWio6OpVatWjscFBATw008/kZaWZtLM6QjNoCqVqsAnxt2xYwdxcXF2X7jdEj169KB06dIsWbIkV2HNUl988QU3b97k999/N6npUqvVBAYG8tdff5ldJzY2NpZKlSoZbmccYHD69GkURXGIwQV6eQ1rMTExRERE8MILL1h9jgoVKlj0Wo+Pj+ett96icePGjB492mSfk5MTY8aM4Z133nGYeeyEsDeb195dSiQ5xnTQlGtxZ7zKGge49J9+rjhlaFn59NNP2b17N8uWLaN69er59rgdiYQ1C5lbF9ScgIAAvv76a44ePcrTTz9t2O4INWugawotyMXcQ0ND8fb2JigoqMDKkBVXV1dGjBjB559/zo0bNyhbtmy+nTs6OppZs2bRq1cvs2tcBgUFsWbNGs6fP0+NGjVM9j18+BAfHx/DbWdnZ5N51hxpJKheXsPa33//DeR+fjVjlk6M++mnnxIVFcXKlSvN1uKNGDGC999/n2+//faxnwVdCHvJbe2dJllLws0UEm4kk3BD9zP+Rgq3D8WSGmtUS6cCD18XQ3i7mXiNDV//wdjBrzFk8BAbPZqCJ2HNAomJicTHx1sU1oz7rWUV1vTsXbMGurB24MABu18XdJONrlu3jq5du5rMGeZIXnrpJWbNmsWPP/6Y7dJhufXxxx+TkJDA//73P7P7n3vuOQC2b99uNqwVKVLEcDtjzVpERATu7u5Uq1Yt38qbV3kNa+Hh4bi4uJj8DeVWhQoV+Ouvv7I95vz583z22WcMGTKENm3amD2mVKlSPP/88yxbtowZM2bg5eVldZmEEOap3ZzwqeyOT+XMk72nxmtMQlzCjRTibyQTczYebZIHn7T9GlJg+5BIPP10zaieZVzxLPeoVs6tuLPDDISwhoQ1C+Q0x5oxPz8/atWqRVhYGO+8845huyPVrF27ds1sc5ut7d+/n1u3bjlkE6hezZo1adeuHUuWLOHdd9/Nlzl6Ll68yNdff81LL72UZVN6jRo1qFChAtu3b2fs2LGG7YqiZKpZc3FxyRTW6tSp41B9APMjrDVr1swwZ5s1KlSowI0bNzJ1STA2YcIEXF1dmTVrVrbnGjt2LCtWrGDlypW89NJLVpdJCJF7Ll5qilb3pGj1R1NnKYpC//79Cduym/U/baZS0arpYU4X6O7+E2cyKELt5mQ2xHmWdcXVx/GjkOOX0AHktHpBRgEBAaxYscLkQ8KRwlpycjL37t0z6UhtD6Ghobi4uNC1a1e7Xje3Ro0axdChQ9m1axeBgYF5Pt+UKVNwdnbm//7v/7I8RqVSERQUxMaNG9FqtYaQGB8fj6IoOTaDOlqzsoeHBwkJCVbdNykpiUOHDuV55vEKFSqg0Wi4deuWYSS0sU2bNrFx40Zmz56dY5N3mzZtqFevHt98842ENSEcwNKlS1m9ejUzZ86kVe+mmfYrWoWku6kmtXEJN5KJvZzE7YOxupH76Zy91HiV04W3KsGl8K6Y9VKOBeXxnv3OTnJaxD2jgIAAHj58yLFjxwzbHKUZtFy5coD9p+9QFIW1a9cSGBhI0aK5n1vNnvr27UuxYsVYvHhxns915MgRfvnlF958803Dc5+VoKAg7t69yz///GPYZryIu55xM2hMTAzXrl1zqP5qAJ6enlbXrB0+fJiUlJQ89VeD7KfvSE5O5o033sDf35+QkJAcz6VSqRg7diyHDx/m8OHDeSqXECJvTp8+TUhICM899xxvv/222WNUTio8fF0p2cCbip1K4j+iLI0nV6Ht/Jq0X16X1nNr0GhiJWoOK0OZ1kVRuzlx/2w8cVeT7fxoLCNhzQI5LeKekXG/NT1HqlkD+4e106dPc/78eYduAtXz8PBgyJAh/P7779y9e9fq8yiKwsSJEylZsmSmqVzM0deObd++3bAtNjYWIMtmUEccXAB5awbds2cPQJZ9yCyVXVibM2cO58+fZ/78+RYP8x8yZAienp588803eSqXEMJ6SUlJvPDCC3h7e7Ns2TKruqo4OavwKueGb9MiVO5eitqjy9H0w6q0XeBPmdaOWZkgYc0CuW0GLVOmDP7+/oSFhRm2OUrNmvH6oPYUGhoKYHbSV0c0evRoUlJSWL58udXn+PPPP9m+fTsffPCBSc1YVsqVK0etWrVMwpq+Zi1jM2hhDmvh4eHUqVMnz830WYW1qKgoPv74Y3r37p2rWc6LFi3KoEGD+OWXX7h//36eyiaEsM67777LiRMn+OGHH/J1xL6jk7BmgTt37qBWqylWrJjF9wkICGDPnj2GD1VHqVkrqGbQ0NBQnn76abN9hxxRgwYNaN68OUuWLDFd6NpCWq2WiRMnUrVqVZMBAzkJCgpi9+7dpKSkAFk3g+r7rEVERFC0aFFDMHEU1oY1rVbL33//necmUIASJUrg7u6eKay9/fbbaLVa5syZk+tzjh07loSEhDyFePEEy/heYsV7y5Nsw4YNLFiwgDfeeMPh+z7nNwlrFoiOjqZkyZK5qm4NCAggNjaW48ePA4/CmvGUFQUR1lxdXfH19c0+rOXzG0pUVBSHDh16LJpAjY0ePZqIiAirpjr55ZdfOH78OJ988kmupikJCgoiISHBcE1zzaAZa9bq1avncEPSrQ1rp06d4sGDB/kS1lQqVaa51sLCwvj111+ZOHEiVapUMX/HbF7/TZs2pXnz5nzzzTdWhXjxBNs7FcImPHo9KYru9t6pBVmqx8b169cZOXIkjRo1YsaMGQVdHLuTsGYBS5aayihjv7WkpCRcXFxQq9WGD9ZcNYPmY4DKdhUDG7yhrF+/HuCxC2svvPACXl5euR5okJyczJQpU2jSpAkDBgzI1X0DAgJwcnIyNIWaawbV91lTFMVhZ9W3NqyFh4cDeZsM15hxWEtLS+P111+nSpUqTJw40fwdLHj9jx07llOnThkm7hUiR4oCyffh6LxHr6+wCbrbyfelhi0H+uWkEhMTWblypcPO02lLEtYsYMki7hmVLVuWmjVrGvqtJSUlGfqr5boZdO9U2DHe9ANkx3irA1S5cuXMhzUbvaGEhoZSs2ZNi5brciQ+Pj688MILrFy50lDDZYmFCxdy+fJlZs6cmevOr8WLF6dp06bZhjV9zdrNmze5d++ew4Y1a6bu2LNnD+XKlcu61iuXypcvbwhrCxcuJCIigjlz5pifv83C1/+AAQMoWrSoDDQQmWg0GuLi4rh9+zaXL1/m9OnTHDlyhD3h4fyR0oXQhO78snQe619y4vwf89A0fB0CvgAHqxl3NLNmzWLnzp0sWLAAf3//gi5OgZB51iwQHR1t1QdiQEAAK1euRKPRmIQ1PYtq1hQFTiyB+PRw1X6eLqgdXwBe5aHV/+X6D718+fIcOnQo8w6VSvfGAboPqKPzdL83GW/1G8r9+/fZuXMnb775psM11Vli1KhRLF26lJUrV/Lyyy/nePyDBw/4+OOP6dChg2FVgtwKCgris88+Iy4uzhASzfVZc9TBBaCbuiM1NRWNRpOryXrDw8N55pln8u21UiG9FvnWrVt8+OGHdOjQIesaXgtf/15eXgwbNoxvv/2WuXPn5vqLnLAvRVFISkoiMTGRhIQEw8+sfs/Lfn1fU0u5z11MrVp7qFOnDnXr1jX8rFatmkNNcl2Q9u/fzwcffMCAAQMYOXJkQRenwEhYy4mimNasKYrFoSUgIIBFixZx/PhxEhMTratZUxTw9NWFteMLdP/pefrmqjx65cuXJzo6muTk5MzVyfoPLP0HFeTpm9/mzZtJS0ujd+/eVt2/oLVo0YJ69eqxZMkSi8LazJkzuXfvHjNnzrT6mkFBQcyYMYM9e/bw8OFDnJyc8PR8NHO3vmZNH9bq1q1r9bVsRV9zlZiYiLe3t0X3+e+//7h69Wq+NYGydyoVEg+SmprK6NGjiY+PZ/7gMqj2TYPWU83fx8LX/5gxY1iwYAHff/+9bqWSjH+HVvxdWsye17Kh1NRUuwSoxMREq/oXqtVqPD098fT0xMPDw+T34sWLU758ecP2jPsz/u7h4YGnhweekQvxuPAL9xPh9C04pdQhMs6P8PBwfv75Z8O13dzc8Pf3NwQ4fYh76qmnCmQWgYLy4MEDBg0aRMWKFfnmm28eyy/8+eXJ+Ve3xt6paBLucffuXV2fNX2ziFuxrN/sjRj3W0tKSsrU9GLRH52TEww5Aj81gTuPJkulVEPddivmmNGPyLx58yaVK1c23al/jMbCJlgd2NauXUuZMmXytMZjQVKpVIwaNYo33niDf/75h4YNG2Z57LVr15g7dy6DBw+mcePGVl+zTZs2uLm58ddff5GWloa3t7fJm5S+z1pERAR+fn657k9pD9aEtXztr5bepFnhYRigG0X2dv8m1LrzE1Qan3XAsfD1X7duXZ599lm+/fZb3moVh1Pqg0fH5PJ9Ilf2TtU1ydroWlqtlqSkJJsHqISEBJMl03Iju2BUsmTJrMNSTmEqw7Z8HQCm/3d6+At01tXUttQ3sTcZDwGbeBgXx+nTp4mMjCQyMpJTp06xb98+fvnlF8NpXF1d8ff3N6mJq1OnDtWrVy+QAWu2pCgKY8eO5b///mPPnj25mo2hMJKwlpX0N/t7fy9AUcC3VKlH/VeaZPNmb6RcuXLUqFGDsLAw1Gq19X3W9k3LenubLPZlw3hiXJOwZtxHR9/0o78NuQ5sSUlJbNmyhSFDhuTLGpsFZejQoUycOJElS5awYMGCLI+bOnUqGo2Gjz76KE/X8/DwoHXr1mzfvp3GjRtnmqPNuGbNEZtAAUNNYFxcnMVhMjw8HB8fH+rXr5/3AqTXkFU4ewt+WEkZH/igwdHsm/Rz+fofO3YsgwYNYvu+E3RwCn10TC7fJyyW/p6kOTyPf/+7R2yt10jYO5uEU7+TWLErCeeXkZgetKwNUPpR67nl6uqaZfDx9fXNc3DS/2489dFjRaXSBWrj15++yd2tGKhU+Pj48PTTT2f6YhsXF8eZM2cMAS4yMpKDBw/y66+/Go5xcXGhZs2amWriqlevbvGkz47mxx9/ZOXKlXz88ce0atWqoItT4CSsZSX9j+nefzHAMkodHA+p5Lr/VkBAAKtWreLpp5+2LqxptXB+nWmtGjy63er/cl27luUqBioV3D4Ovo2g3Rzd7XZz4Oou3fZcvklu376d+Pj4x24UaEYlSpSgT58+LF++nFmzZpntnB4ZGcl3331HSEgIVatWzfM1g4KCmDJlCsWKFTMZXAC6sJacnMypU6cYNWpUnq9lC/pOwP/884/Fz8eePXto3bp1/vXVUamoOfAbKk1eyec9oIg72f/t5vL136dPH0qVKsU3+53oMG58vvXzzEir1XLy5EnCwsLYufMyu7a7cT/uJ+Ano6M2p/9n/HBUhqCTMQz5+Pjg5+eXL7VQHh4eT1TTnNVaTzUN7/rAlsNrxNvbm2bNmtGsWTOT7fHx8Zw9e9YQ4E6dOsWRI0f47bffDM2+zs7O1KxZ0yTA1alTh5o1azp0iDt37hzjxo0jICCASZMmFXRxHIJd/sK+/PJLtmzZAuiaBjMuvXP69GmmTJlCXFwczZo1Y9q0aY7xx69SUX3wUqb+vIxutdO35fINOCAggMWLF3P48OFMNQYWP8Z7kbnbnoMsJ8ZVFCjdSPeBs+tN3WPd9SZEH7eqliA0NBQfH598WQy9oI0ePZpffvmF33//nSFDhmTaP3nyZLy9vXn//ffz5Xr6sBYeHk7TpqaLFLu4uBAVFYVWq3XMmjVFoVmzZri5uREeHk6v4OAcXzcxMTFERETwwgsv5Gs5ihz9P65MMdqWXZO+okBaku71HjYBAufqfkYfhzItMr3+3dzcePHFF/n888+5Pv8K5fKpn6eiKERGRrJz50527tzJrl27DMueVatWjb79B9M2/jtKe4OHC3gO34enl1emMOXq6vp41kIVZhn/PfLw7+Pl5UWTJk1o0qSJyfbExMRMNXH//PMPa9asQavVrV6uVqupUaNGpoENNWvWLPBpMZKTk3nhhRdwc3Nj+fLlMtAinc0T0d69ewkPD2ft2rWG/j9//vknHTp0MBzzzjvv8PHHH9OoUSPee+89Vq1axaBBg2xdtJwpCuo9b/N/xivS5LL/lr7fWkxMjPXNoFn1jbVyap6SJUvi5ubGNTNrJuZpNKjRh5lGo2H9+vV07dq1wP/480NAQADVq1dn8eLFmcJaeHg469ev55NPPsm3kYHNmjWjSJEixMbGPmoGTX9+nZ2dDW+6DhfW9k6FpBjcAufSvHlzXT+0nW+Ae/Fs+1Tt3bsXyL/51fLcpH9svu6/HLz88svMmjWLpR/04wPjcR65eJ9QFIVz584ZwllYWBi3b98GoFKlSnTv3p3AwEACAwOpVLFi+uMwOkHiSmgh0z8IHQ8PDxo3bpyp32xiYiLnzp0zqYmLiIggNDTUJMQ99dRTJgGuTp06+Pv7Z5rNwFbee+89jh07xrp16x6bFW/sweZhzdfXl0mTJhmqXJ966imTdSmvXbtGUlISjRo1AnRNC/Pnzy/4sJZP/bfKly9P9erVOX/+/KMXu1EVdY5UKlBSsyhjqlVv0CqgXEkPrh3bAMrsRzv0HZWtGQ2a/iFN4FxQqdi/bx+3b9+mVx3rOhE7GpVKxUsvvcTkyZM5d+4cNWvWBHQftO+++y7lypXjjTfeyLfrOR/8mHZ1S7JhX6yuGdSoI7nx68ahRoIqClzaCjd1qy+0bdOGzz6bTcKBA3hWamF+mpn0ABoeHo6LiwvNMzT1WM2CPkJmxV7N1fanqlWjU/PKLFqzn8mDXsc5aF6O7xOKonDhwgWTcHbjxg1A937RsWNHQzirUqXKo9qxfO5TKp4sHh4eNGzYMNMgqaSkJM6dO2dSExcZGcn69evRaDQAODk58dRTT2Ua2FCrVi3zcxZaaevWrcyZM4dx48Y9NutI24vNw1qNGjUMv1++fJnNmzezcuVKw7bbt2+bdED29fXl1q1bti5Wzqx9s89o71QCarpx/nz6Iu6Kops6AAtr1nKatyclBXJTc5UeqsqX8OT65XO6Wg+AGwd0H7KNQwzbHiaBjzs51xIYf0grCrSfR+iC8biooUuZS4/t1AIZjRgxgilTprBkyRJmzZoFwLp169i3bx+LFy82mV4jT9I7kgeVvsQG0ifENfqQdk5vFqhSpUqm/mz5ztppIo7Np200zNDAgf8gsJKZY4xGNuqbez0Pvp9/oyhz20dIUSDlgfl9KQ/MP3aVirF9WtJ78hU2xwfRM4v3icuXLxvC2c6dOw0T9fr5+RmCWWBgINWrV8+66TK/3pOEMOLu7k6DBg1o0KCByfbk5GT+/fdfkwB36tQpNm3aZBjJq1KpqFatWqaBDbVq1bL8/TD97+rmzZsMHz6c+vXrM3v27Jzv94SxW8ewf//9lzFjxmRak8/c/DcO08/Cyg6hBukfugHFTrGE9LAWNgEilgLgYknNWk6BLjfDtfUztB+bT/lSNTjyb1HTpp5Gr5OQlMqvP37N1//4cejsLf5ZPIgGlnxzL9sCbh7gv50LuLB6AWu3Q/vqUNRdq/tQtmLUqqMpU6YMPXr04Mcff+Tjjz/GycmJyZMnU6tWLUaMGJF/F0p/nT136S6sW06RC8t0zV5NxkO7Obhs0vX5rFevnm2DsDXTRKS/DgBaV9HdLfwSBD7fwvQ4o9UCklLSOHjwICG96uX/KMrc9BFSFFC7Q1p85n1q9yxX8Oj+9nLKLdjDN99+S8/0/nlXn3qTnWFh7Fw8krCwMC5fvgzovowGBAQYwpm/v3/u3u/y+p4khIXc3NyoV69epq4WKSkp/PvvvyYBLjIyki1btpCaqmsFUqlUVK1aNVNNXO3atfHy8np0svT3GO2znzN8+HAePnzIzhkdcT86I/+nvXnM2SWsHTlyhJCQEN577z26detmss/Pz487d+4YbkdHR1O6dGl7FMsyeekQmv5G2i76Ifz8He7ndB+6qvovAUtxtiRo5TQXUVoaWDqqx+ibePn181h/G+7GQ0kvOBcN32xU88PSxcQ8hKpVdd+Kjqqfo0ET3+y/uaefN3TdekYsusyD9NH/b3evoOucXbFdoaldGz16NKGhoWzYsIG7d+9y5swZQteuzf8BMSoVdUb8SKdZy2mrH0zpWhR2vYmzWleTWq9uXdvN52W89BJYNiWF/vX1XxjcPUFxT6hXBsKjvDMHCqPX4t+/ziMlBdp65jC1hq05OWVfs5bFqGtnZ2dGjx7N9OnTGTlyJHv27OHChQuAbiRxu3btePPNNwkMDKRu3bp5/zKaj53UhcgtV1dX6tatm6kLRmpqKufPnzcJcKdOnWLbtm2GEAe6FoE6depQt04d6jj9Q92kP/lzxUH++GMf377Znjr3lkNyPk97UwjYPKzduHGD1157jS+++MLsXCnly5fHzc2NI0eO0LRpU0JDQ3n22WdtXSz7Uamo8PwSBs74jnbV0je1mQ4stawZNKcQkNuQkP4h2b76PL7YA9X+B43Kwe6L4KyeT5++/Xh1zBhatW2Lh4cHFy5ehGGfQzYjclJTU5k0cSJz5l+mWQXdFAnhl6BnpShds2oh+ubfyWc/FXy9WbBgAefOnaNNmzb0LLIT9h7P38CkKKh2vcnW0UbbLqyH6OM4X2sOQD31cTi6Lf/n8wLTJjZLB5soCvzSCu6eMGxqWwV+OhpH2vKWOA898OjcQNS1a8xYncriJVDUHZ6pRsG+VjQaUDTm9yka3f4s/t5GjRrF7NmzWbt2Le3atWPcuHEEBgZSv379x3qOQSEs5eLiQu3atalduzZ9+/Y1bE9LS+PChQsmAS4yMpK//vrLaHmuffStD6PL7ijYL2wOzOZhbenSpSQnJzNjxgzDthdeeIEdO3YQEhJC/fr1+eyzz5gyZQrx8fHUqVOHYcOG2bpY9pPedPTzYKNtf38IGA0wyO6DNjk5+/MnJ0NuOngqCux8g2514MSb8ME2iLxfjI9G1mJUxf2UKbkFos6B8xEqVarE+fP/kraiMWq34qgG7Mp0uqtXrzJgwAD27dvHuDbwWQ9wUsH1B1CuKFYv/u6QFAV1WiwvNopj+p+652L15Laojs3P38CUXUdy30Y439at61ovaZtt39j0gc3SwSaKArH/mWxqWxW+3gcnz1yksVYLu98i6oETM/5KYfHixWg1abzYHCa3hxKe5Gm1jDxTqdANvzH3mlVlW6YKFSpw/fp1vL29ZaoBIYw4Ozvj7++Pv78/ffr0MWxPS0vj4sWLRJ46xZUf+zCiWfqfmAQ1s2we1qZMmcKUKVMybR84cKDh91q1arF69WpbF8X+zH3o/twKlXGftZz6AeVnzZr+Wsfmg6cf9creYu3bDXUT7JZKhDvoahCij3NveVWin7pLxMFfcW4Gx3xhmLYuE50m8zzP44Yb27ZtY/DgwSQnJ7NyXHUGVDmvm1A0+jiVS6Rf89xvhhGij7308PLizVg++ut7gutC65Tf8j8wZdeR3LUoFYodp6Qn+Pti2ze23C49plKBTyVIuGnYpG/C3XPVi9KrX2bGgu9YdFCNVlHxYudaTG4QQZXnHGhko8oJFK357dlRFIoWLWpyu1C85oWwEWdnZ2rWqEHNawvhGaMdBfmFzYFJ/bwtZfzQBV0H7HQuLi6PPqCS75uvhcrpBZvbPnT68oy5rmui1K+EcOcfaBzCwXF/ccJXTYno/xgcH8/NW7qg1mQIRDhF8gqvUFZTlpc+eIkuXbpQrlw5jhw5woAXBhmCGk3GwwSN7nbCTd3EuoWlhk2lovILSwkbC0ueT99mizeW1lNNz6tS6WbTT3nAi83h8vvg7oLu9WOL5zbjF403tbqfR+dlfU2VCqp1gUavGzZVKg4Vi8HsDf9RbfB3fLPfieHDR/Lvv//y7eS+j4KaPpA2GV9wIxvVaijbCl3tmjGVbntWNWZ7p5o+J/rnbu9U25VViMedNe8xTzAHWCagkMs4eitwLqp7CcASnHe/CVqyr5lRq0HlYn6uNZVLtn3JcixP4FyT0aCHAgfTXtWe+CEalC/gqZJwJx6a9MQQ6+NuxsEg+G7nd/R4sQcrF6zUDdGumT7as2K7R49lyBFdUCtM0wqkv8E8+5TRNlt9E8w4ZcauN+HoPJyajcfb1jVR1k4T0er/Hk0Hk65jTfjxMIxsDu/9cp4q+uWnqkx1rJGNGg3EnCZzM6ii267RZP57s2YghhBCpqLJJQlr9pBhFFzpPt/yYYcl9KiTvi27DyitFpycQWMmrDk56/bnNrAZT8Ng5EjYs8Q/m8zRFbrb1dKbMn9eAIPeB3YDA4EHwPfw94i/UWN07TbTTD+cnJwKV3V2QU5KWhBvbNbMU6ZvZk+fZoTlTZnf6zgzukEpL+DyPKiSocYw4+MsKE5OkJrFQuapSeZHg1ozEEMIoSNT0VhMmkHtLX2U37ROPOrXlVOVryb9A8StJLyRpvtpvN2KMmSsfj7dpBNjjyZz61toHA03PGF/G93hzv/CuAGgCoKSrsABYASkkMJqMvQ1dKQP3/yWVWCyV9OduabRgC9sOx9Rbv49VapHC6E/+7lhXVnPoqUoVfPZx6OJo1T6dASNQ3TNMo1DTLebYxzY9OQDRwjLFObPjHwkNWv2ZE3NjFqt67SdEgev3NLdfuUWfO0Hrt65r1UDs6Gjf0AULwG9/oVjpWBXRfhgL3wOvLwW7sfBC42g4ccwOX2OxDjimMEMBjM462sVNgX9TdCR39gUBUo30r2ed7+lmxdO34/Rr7Gupg0ct4lDpYKqnXX9SvWDYgLn6va5F8+5RtGYdJIWQuQjCWv2ZG1TVr0REH/nUTOMkxP4vwBeeVg03Ch0aNBwShXJhACYEIiuH51K919pb7ifCAv7QNJr8GYgJv2vT3EKDRrT5tDCzpEDU0HSv54VxXS6D+O59hw9wJgL49mNZpb1OoUQdiBhzd6s6QekX3dTrdZ9cOx8A058BWWyWBzbUun3iyMOF1xIUaVPUJieCScEwN4R4OMG9cqCKkNQA3DGmTjiKEpRhCB93Vuz21tPfTyCS26bfqWTtBDCxiSsFYRc18yk9+85Nt90LU+zk3fmnjfepJJhAIMCX4RBqyqPNn0RpgtwxoEtjTS88c6XcojHnKJAUkyG1yi6241DCu/IyIJuGhdCFHoywOBxcPd07rbnkho1dTHqQJ0e1N44CnObgOpN3c83juq2G2fEutR9sppAhTBHmsaFEDYkYc3RabWgzWIxd22abn8+mMjERzVkKrjvpgtoEwJ0tycE6G7fd8NQs+aNN5OYlC/XF4WASqXriK8fQanXOCT7DvqOJuNIVUcduSqEeGJIWHN0KhUUq2F+X7Ea+fYB+DzP44qr4fa01hmaPNMD27TWj+7jiiv96Jcv1xeFRKv/y912R7N3qq5PqPFqBDvfkNUIhBAFSsKao1OpQO1mfp/aLd/CmhtubGUrXngZXTtjWR796oUXW9mKG1mUTTx5Mk6Kq18+5th8x55bTU8/mOfY/EeBbecbutuXtjp++YUQhZYMMHgcZBXI8rlZqTnN2clOOtOZFFKIIy7TMd5444orW9lKc5rn6/XFY64wjIws20I38jrjYB6jNX2FEMLeJKw5Oq0W7p40v+/uSeuWm8pGc5pzneusZjUzmMEpTuGMM2mkUZe6TGIS/egnNWrCvMd5ZKTxJLjGQa1xSPZzrQkhhI1JM6ijc3ICVXqmbjhO17TUcJzutsrZ/HqFeeSGG4MZzElOkkoq0USTSionOclgBktQE9mTkZFCCJGvpGbN0alU0OxNSLgLQfN1t4PSv/V7lrT5B6EatUx4K54Mxn3UjOlvS+2aEKKASFh7HJhrWtIHNyFE/rlxQPdT3/SpD2/67UIIUQAkrD0upGlJCNuydiF3IYSwMQlrQgihl9uF3IUQwg5kgIEQQhiTWmwhhIORsCaEEEII4cAkrAkhhBBCODAJa0IIIYQQDkzCmhBCCCGEA5OwJoQQQgjhwB7rqTs0Gg0AN2/eLOCSCCGEEEJkT59X9PnFUo91WIuOjgZg8ODBBVwSIYQQQgjLREdHU7lyZYuPVymKotiwPDaVlJREREQEvr6+qNXqgi6OEEIIIUSWNBoN0dHR1KtXD3d3d4vv91iHNSGEEEKIwk4GGAghhBBCODAJa0IIIYQQDkzCmhBCCCGEA5OwJoQQQgjhwCSsCSGEEEI4MAlrQgghhBAOTMKaEEIIIYQDe+zC2oYNG+jatSsdOnRgxYoVmfafPn2avn370qlTJ95//33S0tIAOHLkCH379iU4OJjhw4dz7do1exfdZqx9Tg4fPkyfPn3o0aMHY8eO5cGDB/Yuuk1Y+3zoRUZGUq9ePXsV1y6sfU5CQ0Np27YtwcHBBAcH88UXX9i76DZh7fNx+/ZtXn75ZXr16sULL7xAVFSUvYtuM9Y8J3fv3jW8NoKDg2nfvj2NGzcugNLnP2tfI1FRUQwePJjg4GCGDh0qnzXAiRMn6Nu3Lz169GDMmDGG1Ycedzk9H3oTJ05kzZo1htvXr19n8ODBdO7cmVdeeYX4+PicL6Y8Rm7evKkEBgYqMTExSnx8vNKjRw/l33//NTmmW7duyrFjxxRFUZTJkycrK1asUBRFUQIDA5XTp08riqIov/32mzJ27Fi7lt1W8vKcPPfcc4ZjZ8+erXz++ed2Lbst5OX5UBRFSUhIUAYMGKDUrFnTnsW2qbw8J9OnT1c2bNhg7yLbVF6ej+HDhys///yzoiiK8vPPPyvjx4+3Z9FtJq9/N4qiKBqNRhkyZIiyfv16exXbZvLyfLz99tuG35ctW6a89dZbdi27rVj7nGi1WqVdu3bKvn37FEVRlE2bNiljxoyxd/HznSXPx82bN5UxY8YoDRo0UH7//XfD9pdfflnZuHGjoiiK8uWXXyqzZs3K8XqPVc3a3r17admyJcWKFcPT05NOnTqxdetWw/5r166RlPT/7d17TFP3+8Dxd2kB7wJbYXOJk+mGyZKBDKkKcyoKeCnghcC8zFuZDB0KatRFl2gyp1vmNqNpZGrcpm6ZU8ELc6ZTGU6ZOC942SSrzkgQ0IizsKoFz+8PYzO+gpeWtsDvef1Fz2nP5/k855zm6edwzuc2YWFhAIwZM4Z9+/Zx9+5dZs+eTe/evQEICQnh6tWrnuhCs3M0JwD5+fn06tULm81GZWUlXbp08UQXmpUz+QBYsWIFU6ZMcXPUruVMTs6cOUNubi4JCQnMmzevTYy+OpqPGzdu8Oeff5KamgrA2LFjmTNnjgd60PycPW8Atm/fTvv27dHr9e4M3SWcyce9e/eoqakBwGq1PtWUQi2Zozmprq7m9u3b9OvXD4DBgwdz+PBh7t6964luNJvH5QPuj7zFxMQwfPhw+zKbzUZxcTFxcXFA4+dSY1pVsVZVVYVWq7W/DgwMpLKyssn1Wq2WyspKfHx8SExMBO6fSGvWrGHo0KHuC9yFHM0JgLe3NxcuXODNN9/kt99+Y+TIke4L3EWcycfPP//M7du3iY+Pd1/AbuBMTrRaLe+99x55eXk8//zzLFu2zH2Bu4ij+bhy5QrdunVj+fLlJCQkkJmZibe3t1tjdxVnjhG4P9+h0Whk7ty57gnYxZzJx+zZs9m0aRNvvPEGGzduJC0tzX2Bu5CjOfH396dDhw4cPnwYgL1792Kz2aiurnZf8C7wuHwAGAwGkpOTGyyrrq6mU6dOaDQa4OFzqSmtqlhTGpnGVKVSPfH6u3fvMm/ePOrq6pgxY4ZrgnQzZ3MSEhLCkSNHyMjIICsryzVBupGj+bh27RpGo5ElS5a4ND5PcOYYWbt2LaGhoahUKgwGA7/88ovrAnUTR/NRV1fH+fPnGTBgALt27SImJoaFCxe6NFZ3cfZ7pLCwkODgYEJCQlwToJs5k48FCxawbNkyCgsLWbp0KbNmzWr0/a2NozlRqVSsXr2adevWkZSUhMViwc/Pr9X/0HlcPpr7c62qWAsKCuL69ev211VVVQQGBja5/tq1a/b1tbW1GAwG6urqMBqNrf5AecDRnNy5cweTyWRfnpCQwIULF9wTtAs5mo9Dhw5x8+ZN+z8GAyQmJtovZ7RmjubEYrGwadMm+3JFUey/BlszR/Oh1Wrp2LEjgwcPBmDUqFGUlJS4L3AXcua7FcBkMjFixAj3BOsGjubjxo0bXLx40X7lJi4ujmvXrrX6USRw7hjRaDR888035ObmMnr0aO7du4efn5/bYneFx+WjKQEBAdTU1FBfXw88fC41pVUVawMGDODo0aPcuHEDq9XK/v37GThwoH39Cy+8gK+vL7///jtw/062B+vnz5/Piy++yBdffIGPj49H4ncFR3Oi0WhYunQpZ8+eBeDHH38kPDzcI31oTo7mIzk5GZPJRF5eHnl5eQDk5eXRqVMnj/SjOTmakw4dOrB+/XpOnz4NwObNmxk2bJhH+tCcHM1H9+7dCQoKoqCgAICDBw/y6quveqQPzc2Z71aAU6dOERER4fa4XcXRfPj7++Pr68vx48eB+08h6NixIwEBAR7pR3Ny5hh5//337T9sNm7cSHx8PF5erar8eMjj8tEUb29vIiIiyM/PBx4+l5rk+L0QnrFr1y5l5MiRSmxsrJKTk6MoiqIYDAalpKREURRF+eOPP5SxY8cq8fHxSnZ2tnLnzh3l3LlzyiuvvKKMGDFCSUhIUBISEhSDweDJbjQrR3KiKIpSXFysjB49WklISFDS0tKUq1eveqwPzcnRfPxXW7obVFGcO0aSkpKU+Ph4JT09Xbl165bH+tCcHM2H2WxWJk6cqIwcOVJJSUlRLl265KkuNDtnzpvXXntNuX37tkfidhVH83H69Gll3LhxyqhRo5SUlBTl3LlzHutDc3MmJ0lJSUpcXJySmZmpWCwWj/WhOT0uHw8sWLCgwd2gZWVlysSJE5Xhw4cr06ZNU27evPnYtlSK0gYupgshhBBCtFGtexxSCCGEEKKNk2JNCCGEEKIFk2JNCCGEEKIFk2JNCCGEEKIFk2JNCCEccOXKFU+HIIT4f0KKNSHEEysrKyMkJITa2lq3ttunTx/MZrNb23yUzZs388knn7itvR07djBmzBi3tSeEaFla/+PIhRBt3smTJz0dQgNt4Yn0QojWQ0bWhBAOu3DhApMmTSIiIgK9Xm9/uj/A+fPnmTJlCtHR0YSGhjJt2jT79CwLFy4kKyuLwYMHo9frOXr0KHq9no8++ojIyEgGDhzIl19+ad9WSEgIpaWllJWVERERQU5ODlFRUfTv35/ly5fb3/fXX3+RmppKeHg4kyZNYvHixU80f+eOHTsYP348ycnJ6HQ6Ll++zNGjR0lNTaVfv36Eh4eTmZmJ1Wrlp59+Yt26dZhMJsaNGwdAeXk56enp6HQ6YmNj2b59e6PtzJ07l5UrV9pf19bWEhYWhtlsprq6mrlz5zJkyBBCQ0PR6/X2p8H/b6z/HWWrra0lJCSEsrKyx+6T3bt3ExsbS9++fRk7dqx9cm0hRMsmxZoQwiE1NTVMnz6d+Ph4ioqKWLx4MfPnz+fSpUsAzJ49m5iYGAoLCzl06BAWi4XNmzfbP19cXMx3333H1q1b8fLyorS0lK5du3LkyBGWLFnCqlWrqKioeKhdi8VCWVkZBw8exGg0snXrVk6ePInNZuPdd98lKiqKoqIi0tPTyc3NfeL+nDhxguzsbEwmE1qtllmzZpGWlkZRURH5+fmcPXuWPXv2EBcXx4wZMxg6dCg//PAD9fX1pKen8/LLL1NYWMjq1av57LPPKCoqeqiNxMRE9u3bZ5/M2WQy0bNnT3r27Gm/rJqfn09xcTGvv/46n3766dPskkfuE6vVyqJFi1i1ahXFxcWMHz+eJUuWtIlJxoVo66RYE0I4pKCggICAACZMmIBGo0Gn0xETE8POnTsB2LBhAxMmTMBqtVJZWYm/vz+VlZX2z+t0OoKCgujcuTMAarWatLQ0NBoNw4YNo0OHDk3+E39aWho+Pj6EhYXx0ksvcfnyZU6dOsWtW7fIyMjAx8eHqKgoYmNjn7g/Wq2W/v3707lzZ3x9fdm5cycxMTFYLBaqqqrw8/NrEP8DZ86c4erVq2RlZeHj40Pv3r1JTU1l27ZtD703KioKm83GiRMnANizZw+JiYkAZGVlsXTpUtRqNeXl5XTp0qXR9h7lcfvE19eX77//npMnT5KYmMiBAwdQqVRP1YYQwv3kf9aEEA4pLy/HbDY3mMC7vr7ePtl7SUkJaWlp9st0//zzT4MJrbVabYPtde7cGW9vb/trjUbDvXv3Gm37v9t58L6qqioCAwNRq9X2dd26dbNfen2c/8ajVqs5cOAAX331FXD/MqzVam10FKq8vJyamhoiIyMb5KGxSd7VajV6vZ78/HyCg4M5duwYK1asAKCqqooPP/wQs9lMcHAwfn5+Tz3q9ah90r59e77++muMRiMGgwGNRsP06dN55513nqoNIYT7SbEmhHCIVqslLCyMLVu22JdVVFTg6+tLRUUFCxYsYOvWrYSGhgKwaNGiBsVHc4/oPPfcc1RVVVFfX28v2CoqKtBonv5r7sSJE6xdu5Zt27bRo0cPAN5+++1G3xsYGEhQUBCHDh2yL7t+/XqThVZiYiIGg4FevXrRr18/nnnmGQCys7NJSUlhy5YtqFQqcnNzKS0tfejzXl5e2Gw2++ubN2/a/37UPqmpqaG2tpY1a9ZQV1fHkSNHmDlzJpGRkYSFhT1hZoQQniCXQYUQDhk0aBAXL15kz5491NfXYzabSU5OxmQyUVtbi6IotGvXDkVRKCgoYN++fQ2KjOYWFhaGv78/RqMRm81GcXEx+/fvd2hbNTU1eHl50a5dO+rr68nNzeX48ePU1dUB4OPjQ01NDQChoaG0a9eO9evXY7PZqKioYOrUqQ0Kpv/q3bs3AQEBrFu3zn4J9EGb7du3R6VSYTab7dv7X8HBwfz999+YzWbu3LlDTk6OvfB91D75999/MRgMFBYWotFoCAwMRKVS0bVrV4dyJIRwHynWhBAO8fPzY/369Xz77bfodDqmTp3KW2+9RXJyMj179iQjI4PJkyej0+kwGo2kpqZy8eJFl8WjVqv5/PPPOXjwIJGRkaxduxadTtfg0uqTio6OJj4+Hr1ez4ABA9i9ezejR4+2P+tt0KBBlJaWEhcXh7e3Nzk5ORw7dozo6GjGjBmDTqdj5syZTW4/KSkJi8XCkCFD7MuWLVvGhg0bCA8PZ9asWSQlJVFdXf3QY0JCQ0OZOHEikydPJiYmhh49etgLrkftk8DAQD7++GOWL19Onz59yMjI4IMPPiA4OPip8yOEcC+VIrcCCSHaAKvVytmzZ+nbt6992Zw5c+jevTvZ2dkejEwIIZwjI2tCiDZBrVYzY8YM+3PFSkpKKCgoIDo62sORCSGEc2RkTQjRZvz666+sXLmSK1eu8Oyzz2IwGEhJSSEzM5PCwsJGP9OtWzf27t3r5kiFEOLJSbEmhBBCCNGCyWVQIYQQQogWTIo1IYQQQogWTIo1IYQQQogWTIo1IYQQQogWTIo1IYQQQogWTIo1IYQQQogW7P8A1bDoxSX2tSwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1366.0</td>\n",
       "      <td>1.826808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_leaves       MAE\n",
       "16      1366.0  1.826808"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.0322]), array([1366.])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.928892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth       MAE\n",
       "8       14.0  1.928892"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.0322]), array([1366.]), array([14.])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.702</td>\n",
       "      <td>1.76209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bagging_fraction      MAE\n",
       "18             0.702  1.76209"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.0322]), array([1366.]), array([14.]), array([0.702])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bagging_freq</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.860895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bagging_freq       MAE\n",
       "12          22.0  1.860895"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.0322]), array([1366.]), array([14.]), array([0.702]), array([22.])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.7812</td>\n",
       "      <td>1.76209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_fraction      MAE\n",
       "22            0.7812  1.76209"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.0322]), array([1366.]), array([14.]), array([0.702]), array([22.]), array([0.7812])]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAFTCAYAAAB4RHsKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAACdrUlEQVR4nOzdZ3xTZR/H4W+a7kWh0LKHzLLLKqusKnuDICIIiqCMMhRERGQoW7YgKAgoyt5TH5bMFhkCMmWXWVoKdKZN8rxIkzZ00Jmk7f/yg23OSc6506xf7qnQarVahBBCCCGEWVmZuwBCCCGEEEJCmRBCCCGERZBQJoQQQghhASSUCSGEEEJYAAllQgghhBAWQEKZEEIIIYQFkFAmhAm1aNGCihUr8ttvvyW7f8CAAVSsWJFt27Yl2Td58mQqVqzI7t27k+zbvHkzFStWTPHf3r17M1Tef//9l7Zt21K1alVmzJiRoWMkZ9myZfj4+ODt7c2FCxcyfby4uDhWrlyZ+YJlga1bt9K4cWOqV6/On3/+mS3nOHToEP/99x8AQUFBVKxYkb///jtbzpVZAQEBVKxYkUePHpm7KEJYPGtzF0CIvMbGxoZ9+/bx7rvvGm0PCwvj5MmTyd5GpVKxa9cuSpcuzbp162jbtm2S6yiVSg4fPpzs7fPly5ehsi5btgxra2t2796Ni4tLho7xqoiICObMmcPHH3/M22+/jYeHR6aPuXv3bqZNm0a/fv0yX8BMmjFjBs2aNWPo0KEUKFAgy4//+PFjBg0axOrVqylXrhxFihTh6NGjuLm5Zfm5hBCmJTVlQphY/fr1OXXqFKGhoUbb//zzT2rUqJHsbQ4cOEBkZCT+/v4EBARw586dZK9XqFChZP/Z2tpmqKwvXrzAy8uLkiVLkj9//gwd41Xh4eFotVrq169PsWLFsLGxyfQxLWkO7BcvXlCnTh2KFSuGg4NDlh//1fuqVCopVKhQlvwdhRDmJaFMCBPz9vamYMGC/O9//zPavmfPnmRrwAC2bNmCt7c3b775Jg4ODqxfvz5D57558yYffPABtWrVonbt2gwePJigoKBkr9uiRQuOHz/O1q1bqVixIkFBQcTFxfHjjz/SsmVLqlWrRocOHYyaUxcuXEifPn3w9/enVq1azJ071+iYAQEBNGnSBID333+fPn36APDw4UPDbRo2bMjIkSN5/Pix4XZhYWF88cUXNG7cmCpVqtC4cWNmzJiBRqMhICCAMWPGAFCxYkU2b97M5s2bqVy5stG5X91WsWJF5s+fT5MmTWjSpAnBwcE8f/6cL774Ah8fH+rVq8dHH33EzZs30/S31TcjxsXFMW7cOFq0aJHiea5cucJHH31EnTp1qFq1Kq1atWLr1q2GY2m1WlauXEnLli2pUaMGnTp1MtSCNm3aFIC+ffsyduzYJM2XaXmMPvzwQ77//ntDM+vAgQON/t6JjR071vA46Z0/f56KFSty+/ZtNBoNixcvpmXLllStWpU6deowbNiwJF869Fq0aMHixYtT3fa///2Pjh07Uq1aNVq3bs3y5cvRaDSG/cuWLcPPz8/wt1uzZk2qj40QOYWEMiFMTKFQ0LJlS/bt22fYFhoayqlTp2jVqlWS6wcHB3P06FFatWqFnZ0dLVq0YMuWLcTGxqb73J999hlFixZly5YtrFmzhmfPnjFu3Lhkr7tx40bq1KlDmzZtOHr0KEWKFGH69OksX76cUaNGsX37dtq1a8eoUaOM7ktgYCAlSpRgy5YtdO/e3eiY3t7ebNmyBdCFg4ULFxIZGUmfPn2ws7Nj7dq1LF++nNjYWN5//31UKhUAn3/+OTdu3GDJkiXs3buXTz75hJ9//pkDBw7g7e3NhAkTADh69GiKwTY5GzZsYOnSpSxatAh3d3cGDhzIkydP+Omnn/jtt98oWrQo7777Ls+ePXvtsfTNiEqlknHjxrFx48Zkz+Pk5MQHH3yAh4cH69evZ9u2bdStW5fx48fz9OlTAH788UcWLFjA4MGD2bFjB61bt2bIkCFcv37d6O/35ZdfJilHWh6jgIAArl69ys8//8yKFSu4dOkSCxYsSPZ+de7cmb///tsotO3YsQNvb29Kly7Nzz//zOrVqxk/fjz79u3ju+++4/Tp0yxZsiRtD8IrDh8+zGeffUbfvn3ZtWsXo0ePZvXq1YbQduDAAZYvX84333zDvn37GDBgAFOmTOHUqVMZOp8QlkT6lAlhBq1bt6Zfv348f/6cfPny8ccff1CrVi0KFiyY5Lrbt29Ho9HQsmVLANq1a8fOnTv53//+R5s2bQzXU6vVeHt7J7l9/vz5OXDgAAB37tyhUaNGFCtWDGtra2bNmmUIAq8qUKAANjY22NvbU6hQIcLDw/n999+ZMGECrVu3BuDjjz/mypUrLFu2zBAoFQoFw4YNw97ePskxbW1tDf2s8uXLh5ubGxs2bCAqKorp06ejVCoBmDNnDj4+Pvzxxx+0b98eX19ffHx8KF++PAC9e/fmp59+4urVq7z55ps4OzsDuubb9OjSpQteXl4AHD9+nAsXLhAYGGg43qRJkzh58iTr169n0KBBqR5L34wI4OLiYtSfLPF5QkJC6NevH3369DE0bw4aNIgNGzZw+/Zt3N3dWb16Nf3796dz584AfPLJJ8TFxREZGYmnp6fh7+fi4sLz588N50nrY6TVapk6darhfrZt25Zjx44le798fHwoUqQIu3fvpn///qjVanbv3s2wYcMAKFOmDDNmzDDUgBYrVgxfX1+uXbv22r9/cn744Qd69eplCPQlS5YkIiKCr776isGDB3P37l1sbGwoWrQoxYoV4+2336Z48eK88cYbGTqfEJZEQpkQZlC7dm3y58/P/v376dq1a6pNl1u3bqVOnTqGD/zGjRvj6urKunXrjEKZUqk0agLTs7JKqBAfPnw4M2bM4LfffqN+/fo0a9aMdu3apanMN2/eJC4uLknwq1u3riH0gS4YJRfIUnLp0iVCQ0OpU6eO0faoqChu3LgBQK9evdi/f78huFy9epVHjx4ZNWllRIkSJYzKoVar8fX1NbpOTEyMoRxZcR53d3feffddtm7dyuXLl7l9+zZXrlwBdMH62bNnBAcHU716daNj6ENQaqMY0/oYFSxY0BDIQBciU6p5VSgUdOzYkZ07d9K/f39OnDjBixcvDM/XFi1acPbsWebOncutW7e4efMmN27cSPJ4ptXly5e5cOECa9euNWzTaDRER0dz//59OnbsyMaNG2nZsiUVKlSgcePGtG/fHnd39wydTwhLIqFMCDNQKBS0atWKffv20axZM86cOZOk/xXAhQsXuHbtGgqFwqg/lFqt5uTJk9y9e5eSJUsatpcqVSrV8/bt25e2bdty8OBBjh8/zrRp01ixYgXbtm177WAAOzu7ZLer1WqsrRPeStITyEA3GrVcuXIsWrQoyT4XFxc0Gg0DBw7k1q1bdOjQgU6dOlG9enXef//9dJ1HrVYn2Zb4PtnY2ODm5pZsfz1HR8d0nSu18zx+/Jh33nkHT09PmjdvTrNmzfDw8KBbt26GcmTFeRJ79TFK7rFObbBE586dWbJkCbdv32bnzp20aNECV1dXABYvXsyPP/5I165d8fX1NYwMffDgQZrLHRcXZ/jdxsaGAQMG0KFDhyTX8/T0xNbWlu3bt3P69GmOHj3K4cOHWbFiBdOmTaNr165pPqcQlkj6lAlhJq1btzZ0pK9Xr16y0yds2bIFe3t7NmzYwNatWw3/Fi9ejFarTVeH/2fPnjFlyhTi4uJ4++23mTt3LitXruTmzZuGmprUlCpVChsbG86cOWO0/fTp05QrVy7N5XhV+fLlCQoKws3NjVKlSlGqVCnc3d2ZNm0a165d49KlSxw9epSFCxcycuRI2rVrR/78+QkODjYECYVCYXRMGxsb1Go1UVFRhm23b99+bTnCwsIM97VUqVIUL16cefPmZWl/pV27dhEREcGaNWsYNGgQLVq0MPRZ02q1uLi4UKhQoSTzt/Xp04effvopyX1NLLseo9KlS+Pt7c2uXbv43//+Z2hWBV3/N39/f7766ivefvttqlSpwp07d1IMeTY2NoSHhxsuh4eHExISYrhcrlw5bt++bXgMSpUqxbVr1wxfWnbv3s3vv/9O3bp1GTlyJFu3bqVJkybs2bMnw/dPCEshoUwIM6lVqxb58uVj0aJFyTZd6ucma9++PdWqVaNChQqGf35+ftSpUydJh//g4OBk/4WHh5MvXz7++usvJkyYwJUrV7hz5w6bN2/G1dWVMmXKvLa89vb29O/fn3nz5rF3715u377NsmXL+OOPP+jfv3+G/w4dOnQgf/78jBgxwlAz+Omnn/LPP/9Qvnx5ChUqhLW1NXv27CEoKIizZ88yePBgVCqVYSCAk5MToKtZjIiIoGbNmigUChYsWEBQUBC7d+82dJBPSYMGDahZsyYjRozg77//5tatW4wfP54DBw5QoUKFDN+/VxUuXJjw8HD27dvH/fv32b9/P19//TWA4f4MGDCAlStXsmvXLu7evcvixYv5559/aNq0qeG+Xr16NckAhOx6jEDXL2758uXY2toaNfHqBzjcuHGD69evM3nyZM6ePWu4L6+qWbMmu3bt4uzZs1y/fp2xY8ca+hKCrv/crl27WLZsGbdv3+bQoUNMmDABe3t7bG1tUalUzJgxg+3bt3P//n1OnDjBpUuXUpxORoicRJovhTATKysrWrVqxbp163jrrbeS7D9w4ABhYWH07t072dv369ePoUOHsn//fkDXRNW4ceNkr9u7d28mTJjA0qVLmT59On369EGlUlGtWjWWL1+e5olh/f39sbKyYurUqTx79oyyZcsyZ84co75t6WVvb8/PP//M9OnTef/991EoFNSsWZNVq1YZ+glNnTqVhQsXsmrVKjw9PWnTpg2enp6G2iT9FBa9evXi008/pX///kyaNImlS5fy66+/Urt2bcaMGZPiSFPQ1bZ9//33zJgxwxD6vLy8WL58eaZqmV7Vpk0bLly4wDfffENkZCQlS5Zk8ODBLFu2jAsXLtCkSRP69u1LdHQ0s2bNIjQ0lPLly/PDDz8YBjr06dOH2bNnExAQwBdffGF0/Ox4jPTl/vbbb2nfvr1RU+iMGTOYPHkyXbp0wdXVlXr16vHpp5/yww8/GNVU6o0aNYoJEybQr18/XFxc+OCDD4xqzpo0acLMmTNZtmwZCxYsoECBAnTu3JmRI0cCuqbUkJAQFi5cyMOHD3F3d6dr1658/PHHmbp/QlgChdaSZl0UQgghhMijpPlSCCGEEMICSPOlEEKkQceOHbl3716K+z08PIwmaBVCiPSS5kshhEiDBw8epLqKglKppHjx4iYskRAit5FQJoQQQghhAUzSfNm3b19CQkIMI3YmT55sNHxZP4llTEwMbdq0MYyyeZ3o6GguXrxIoUKFjIZUCyGEEEJYGrVaTXBwMFWrVk12ou1sD2VarZabN29y6NAho2HUetHR0YwbN45ffvmFIkWKMGjQIA4fPkzTpk1fe+yLFy+mOF2AEEIIIYQlWrNmTbJLkWV7KLt58yYKhYKPPvqIkJAQevTowXvvvWfYf/78eUqVKmVYG65Dhw7s3bs3TaFMvxbgmjVrKFy4cPbcASGEEEKILPDo0SN69+5tyC+vyvZQ9uLFCxo0aMDEiROJjo6mb9++lClThkaNGgHw5MkTo8J5eHjw+PHjNB1b32RZuHBh6WArhBBCiBwhpS5X2R7KvL298fb2BnSL+nbv3p3Dhw8bQlly4wxSW9tNCCGEECI3yvbJY//++29OnDhhuKzVao36lnl6evL06VPD5SdPnuDh4ZHdxRJCCCGEsCjZHspevnzJzJkziYmJITw8nC1bthit81ejRg1u3brFnTt3UKvV7Ny5kyZNmmR3sYQQQgghLEq2N182b96cf/75h86dO6PRaHj33Xfx9vamU6dOLFu2DE9PT6ZPn86wYcOIiYmhadOmtG7dOruLJYQQIg+IjY0lKCiI6OhocxdF5DH29vYUL14cGxubNN8mR08eGxQUhJ+fH/v375eO/kIIIZK4desWLi4uuLu7S39lYTJarZaQkBBevnxJmTJlDNtfl1tkQXIhhBCW49V6gkzWG0RHR0sgEyanUChwd3dPdw2thDIhhBCW4fhEODQyIYhptbrLxydm6rASyIQ5ZOR5J6FMCCGE+Wm1EBMGZ+YnBLNDI3WXY8IyXWNmCQICAujTp0+S7RcuXODLL7/MtvOq1Wo+/PBD2rVrR0BAQLadJz0WLlxIxYoVOXv2rNH2b7/9looVKxptO3jwIBUrVuTixYtG21u0aEHbtm3p1KmT4d8XX3yR7WXPTiZZ+1IIIYRIlUIBzebqfj8zX/cPoNZw3fZcXNtVrVo1qlWrlm3Hf/z4MVevXuXo0aPZdo6MKFy4MPv27TPMZarRaDh16lSS623evJlWrVqxdu1avvnmG6N9y5Yty1V9yqWmTAghhGVIHMz0cnkgA+MatD59+jBz5kx69uzJW2+9xeHDhwF4+vQpgwcPpmvXrnTr1o3jx48nOU5UVBSffvop7du3p0OHDmzduhWAQYMGERYWRteuXZOct3///vTr148WLVowY8YMFi9eTNeuXenatathDtG//vqL7t2707lzZ4YOHcqzZ88A2LNnDz169KBjx460atXKEKhSug+v8vPz48CBA4bLp0+fpmbNmkbXCQ0N5cSJE4wZM4a9e/cSHh6epr/pzz//TMeOHencuTMTJkxI020sgdSUCSGEsAz6JsvEDo3MsmC2evVqVqxYkenjJOeDDz6gb9++WXKs2NhY1q1bx4EDB5g/fz5Nmzbl22+/pVu3bvj5+fHkyRPeffddtm7dirOzs+F2CxcuJH/+/OzcuZPQ0FDefvttKlWqxJIlS+jbty+bN29Ocq5//vmHXbt24ebmRsOGDfn888/ZvHkzX3zxBbt27aJDhw589913rF69mnz58rF27Vpmz57NlClTWLt2LT/88AMFChRg48aNLF++nLp166Z4H16VP39+ihcvzvnz56levTq7d++mbdu2/P7774br7Nixg0aNGlG8eHGqVq3Ktm3b6N27t2H/wIEDjaac6Nu3L506dWLp0qUcOXIEpVLJpEmTePz4MZ6enlny+GQnCWVCCCHML3EfMn2Tpf4y5IkaMz1fX18AypcvT1hYGADHjx/n5s2bLFiwAIC4uDju3buHl5eX4XYnT55k6tSpABQoUAA/Pz8CAwNp0aJFiueqUKECRYoUAXQhqUGDBgAULVqUFy9e8M8///Dw4UND4NRoNOTLlw8rKyu+//57Dhw4wK1btwgMDMTKKqHxLbn7kJw2bdqwb98+qlSpwtmzZ/nqq6+M9m/evJmhQ4cC0LZtW3799VejUJZS86W3tzfdu3fHz8+P3r1754hABhLKhBBCWAKFAuzcjPuQ6Zsy7dyyJJD17ds3y2qzspOdnR1gPHpPo9GwatUq3NzcAF0/sYIFCxrd7tVpR7VaLWq1OtVzvTqx6asLZavVamrVqsUPP/wAQExMDBEREURERNCtWzc6depE3bp1qVixImvWrEn1PiTnzTffpFevXjRu3Jg6deoYBbtLly5x7do1vv32W6ZNm4ZarebJkyecPXvW0A8tJYsXL+bcuXP89ddfDBgwgNmzZ1OvXr1Ub2MJpE+ZEEIIy9BwIjSdkxDAFArd5YYTzVkqi1C/fn1+++03AP777z86duxIVFRUkuts3LgR0PXF2r9/f6aDSI0aNTh37hy3bt0CdGFn5syZ3L59GysrKz7++GPq16/PX3/99doAmJz8+fNTrFgx5s+fT9u2bY32bd68mR49enDo0CEOHDjA4cOH6dSpE+vWrUv1mKGhobRp04YKFSowfPhwGjVqxNWrV9NdNnOQmjIhhBCW4fhE3fQX+poyrRYOj9LVlOWSYPb3338b1fJ06NCBdu3avfZ248ePZ8KECXTo0AGAmTNnGvUnAxgyZAgTJ06kQ4cOqNVqPv74Y6pUqUJQUFCGy1uoUCGmTp3KiBEj0Gg0eHp6MmvWLFxdXfHy8qJNmzbY29tTt25dHjx4kKFztG7dmu+//97o76JSqdixYwerV682um6/fv3o2bOnYeqLV/uUOTg4sHbtWt555x26d++Og4MDRYoUoUuXLhkqm6nJMktCCCHML7U+ZZmYFuPy5ctG/a6EMKVXn3+vyy1SUyaEuWi1xh8yr14WIi/Jw/OUCaEnfcqEMIdsWk5GiBwtj85TJoSehDIhTC0PLCcjRIakNE+ZvCZEHiHNl0KYmjTTCJGUzFMmhNSUCWEW0kwjhLGU5imrNTzL5ikTwtJJTZkQ5pDNy8kIkSM1nGg84EUfzOQ1IfIIqSkTwtRebaYZpdH9TNzHTIi86tUAJoFM5CFSUyaEqZlgORkhhGWaP38++/btQ6FQ0L17d/r37//a2/Tp04ehQ4fi4+Nj2BYUFETr1q0pW7YsANHR0VSsWJEJEyYkWX4ps149l0ajISIigs6dO+Pv75+l5zKlhQsXAjBs2DCj7foF0Xv16mXyMkkoE8IcpJlGiDwnMDCQkydPsn37duLi4mjbti1NmzbljTfeyNDxPDw82LZtG6Bb53LOnDn4+/sblmPKSonPBbq1N1u1akW7du0MYS23MEcY05NQJoS5SDONEHlKvXr1WL16NdbW1jx+/Bi1Wo2joyNBQUEMGDCA/PnzY2dnx7Jly/jyyy+5ePEixYoV49mzZ689tkKhYNiwYTRq1IgrV65QqVIlli1bxp49e1Cr1TRu3JjRo0ejUChYvXo1v/76Ky4uLrzxxhuULFmSYcOGUb9+fapUqcLTp0/ZuHFjksXKEwsODkar1eLk5ASQ6XP9/PPPSW4fERHBqFGjePr0KaBbRsrPz4+ff/6ZLVu2YGVlRfXq1Zk8eTIajYapU6dy4sQJFAoFHTt2ZODAgQQEBDBr1iw0Gg3ly5dnxowZr/1bJq5Ba9y4Ma1ateL06dMolUrmzZtHiRIlOH/+PNOmTSM6Opr8+fMzadIkSpQokZanQaoklAkhhMgTHhx+xoODrw84GVG0eX6KNs3/2uvZ2NiwYMECVqxYQevWrfH09OT+/fvcunWLn376ieLFi7N8+XIA9uzZw+3bt+nYsWOaymBra0upUqW4efMmT5484eLFi2zcuBGFQsHo0aPZvn07FStWZM2aNWzevBkbGxv69OlDyZIlAXj27BkDBw40aibVe/LkCZ06dSImJoZnz55RrVo1Fi1aROHChfnrr78yda6Ubq/RaChWrBjLli3jxo0bbNy4kaZNm7J06VKOHDmCUqlk0qRJPH78mP/97388fPiQ7du3o1Kp6NOnDxUqVMDBwYHbt29z8OBBXFxc0vpwGgQHB9OgQQO++uorpk+fzpo1axg1ahTjx4/nhx9+oGjRohw5coSvvvqKlStXpvv4r5JQJoQQwnLkgeXH/P39+eijj/j4449Zv349jRo1wt3d3bAWYmBgID179gSgdOnSRgt1v45CocDe3p4TJ05w/vx5unbtCuj6nBUtWpTQ0FCaN29uWMy8Xbt2vHjxwnD7GjVqJHtcffOlRqNh+vTpXL16lfr16wNk+lwp3b5bt27MmTOHx48f06xZM4YMGYK1tTXe3t50794dPz8/evfujaenJwEBAXTp0gWlUomDgwMdOnTgxIkTtGjRgjJlymQokOn5+voCUL58ef7++29u377NvXv3+OSTTwzXCQ8Pz/DxE5NQJoQQwjIcn6hb1ULfv1I/UtnOTdcPM5OKNk1bbVZ2uXHjBiqVCi8vLxwcHGjZsiVXr16lUaNG2NvbG66nUCjQaDSGy9bWafuoVqlU3Lp1i3LlynHy5Enef/99w0CCFy9eoFQq2bhxo9GxX5W4HMmxsrJizJgxdO7cmRUrVjBo0CDUanWmzpXS7Z2cnNizZw9Hjhzh4MGDrFixgj179rB48WLOnTvHX3/9xYABA5g9e3aS82i1WtRqdZru0+vY2dkBusdFq9Wi0WgoXry4oY+dWq02NLFmlkyJIYQQwvzywPJjQUFBjB8/HpVKhUqlYv/+/dSuXTvJ9Ro0aMDOnTvRaDTcv3+fM2fOvPbYGo2GhQsXUqNGDUqWLEn9+vXZtm0bERERxMXFMWTIEPbt20eDBg04fPgw4eHhqFQq/vjjDxTprIm0trZmzJgx/PDDDwQHB2f6XCnd/tdff2XhwoW0adOGr7/+mtDQUJ49e0abNm2oUKECw4cPp1GjRoZau61bt6JWq4mKimLHjh3JNsNmhTfeeIPnz5/z999/A7Bp0yY+++yzLDm21JQJIYQwvzyw/FjTpk35559/6Ny5M0qlkpYtW9KuXTuCgoKMrvfuu+9y/fp12rRpQ7FixahQoUKyx9P38wJdKPPy8uK7774DoEWLFly5coUePXqgVqvx9fWlS5cuKBQK+vbtS8+ePXF0dDQMLkivJk2aULNmTebNm8e3336bqXOlVFZ9R/8OHTpgbW3N0KFDKVCgAO+88w7du3fHwcGBIkWK0KVLF+zs7Lh9+zadOnUiNjaWjh078tZbbxEQEJDq/Vi6dCkrVqwwXJ40adJr77utrS3z58/n22+/JSYmBmdn5zQNIEgLhVabc79+BAUF4efnx/79+w1t8UIIIXIwrRbmJGrEGaXJVCC7fPkyXl5eWVCw3OHWrVscPnyYfv36AfDJJ5/w9ttv06JFixx9Lkv16vPvdblFasqEEEJYBll+LNsVK1aMCxcu0L59exQKBY0bN6Z58+Y5/ly5hYQyIYQQ5vfq8mPN5iZcBglmWcTW1tbQxJmbzpVbSCgTQghhfrL8mBCmDWUzZszg2bNnTJ8+3Wj71q1bmT17Nu7u7gA0a9aMkSNHJncIIYQQuZUFLT8WRxwRROCMM0qUJj+/yJtMNiXGiRMn2LJlS7L7Lly4wNixY9m2bRvbtm2TQCaEEHmVGZcfiyGGX/mValTDFls88MAGG6pRjV/5lRhiTFYWkTeZJJSFhYUxd+5cPv7442T3X7hwga1bt9KxY0c+++wznj9/bopiCSGEEAAEEkhRivIJn3CRi2jRokKFFi0XucgnfEJRinKKU+YuqsjFTBLKJkyYwMiRI3F1dU12f6FChRg2bBjbtm2jSJEiTJ482RTFEkIIITjFKVrQglBCCSf55XLCCSeUUJrTPMPBLCgoiIoVKzJhwgSj7ZcvX6ZixYps3rwZwDD3WEr279/P/PnzM1SGrNCtW7cUK1ksSYsWLWjVqpXRtri4OOrXr8/YsWONtvv7+9OhQwejbQEBAXh7e9OpUyejf3/++We2lTnb+5Rt2LCBIkWK0KBBA8MT7lXff/+94fcBAwbw5ptvZnexhBBCCGKIoTWtiSAiTdePIILWtOYBD7Aj/ZOuurm5ceTIEdRqNUqlrq/a7t27KVCggOE6+uV7UuLn54efn1+6z50Vrl69io2NDVeuXOHhw4cUKVLELOVIq+joaK5evUrFihUBXVeqV1cVePbsGZcuXaJgwYKcPn3aaJWFqlWr8ssvv5isvNleU7Z7926OHTtGp06dWLBgAQcOHGDq1KmG/S9fvjRaWV2r1aZ5nS8hhBAiMzawARWqdN1GhYqNbMzQ+ZycnPDy8uLUqYTatmPHjtGwYUPDZX2AWLhwIePHj6dPnz60aNGCJUuWALB582ZDTU+LFi2YNWsW7dq1o2PHjhw6dIi+ffvStGlTdu/eDcDYsWONKkUSH/+LL76ga9euNG3alC1btvD555/TunVrRowYQXJzy2/evJlGjRrh5+fH+vXrAbhy5Qrt27c3XOfgwYOGmrRly5bRpUsXOnbsyMyZM9FqtQQFBdG6dWt69epFv379CA8Px9/fn549e9K8eXNGjx5tOPd3331Hy5Yt6dmzJ0OHDjXcj61bt9KlSxc6derEuHHjiIlJvr9fy5Yt2bdvn+Hy7t27k9Se7dixgzp16tCyZUvWrVuXwiNnGtkeyn7++Wd27tzJtm3b8Pf3p0WLFowbN86w39HRkZ9++ol//vkHgF9//ZW33noru4slhBBCMIMZKTZZpiSccKYz/fVXTEGbNm0MQeH8+fNUrFgRGxubZK979epVli9fzoYNG1i2bBkvXrxIch0PDw927dpFlSpVWLZsGStWrGDWrFksW7bstWW5du0a69evZ9asWYwbN46PPvqInTt3cunSJa5evWp03djYWLZv306bNm1o06YNGzduJC4ujkqVKmFlZcW1a9cA2LlzJx07duSvv/7i4sWLbNy4ka1bt/L48WO2b98O6Gb7nzVrFitXruTQoUN4eXmxbt069u3bx7lz5/j33385cOAAp0+fZufOnSxbtoxLly4BcP36ddavX8/atWvZtm0b7u7uLF++PNn717p1a0Nzo0ql4sqVK1SvXt3oOps3bzbcp3379hEWFmbYd/HixSTNl8+ePXvt3zWjzFYl9eWXX9KiRQv8/PyYN28eEydOJDo6mtKlSzNz5kxzFUsIIUQeoUbNv/ybodv+y7+oUWdouozmzZszb948NBoNe/bsoU2bNoZarVf5+Phga2uLu7s7bm5uvHz5Msl1mjRpAkDRokXx8PDA2tqaokWLJhvgXtWoUSPD9QsVKkS5cuUA8PT0TDLo7vDhw4braLVarKysOHjwIG+99RadOnVi165dlChRgsDAQKZOncq8efM4f/48Xbt2BXRNiUWLFqV27dq4u7sblhlq374958+fZ+XKldy8eZOwsDAiIyM5fvw4bdq0wdbWFltbW0PXpoCAAO7cuUOPHj0AXVisXLlysvfP09MTZ2dnbty4wd27d2nUqJHR/suXL/Pw4UMaNmyIjY0NXl5ebN261bA0lKmbL00ayrp27Wp4cL799lvD9jp16qQ4XYYQQgiRHcIJxwabdDdfAlhjTTjh5CNfum/r7OxMpUqVOH36NCdPnuTTTz9NMZQlXsBboVAk26SYuJYtue4/iW8XGxubrtsmtmnTJh4+fGhYuzI8PJy1a9fy1ltv0b59e95//30qVapE48aNsbOzQ61W8/7779O/f38AXrx4gVKp5NmzZ9jb2xuO+8svv7Bv3z569OhBw4YNuXbtmiH0aTSaJOVQq9W0adOG8ePHAxAREYFarU6x3K1bt2bv3r3cuXOHfv36ceXKFaP7pFKpDE2aERERrF271hDKTM1k85QJIYQQlsQZZ2KJff0VkxFHHM44Z/jcbdq04bvvvqNq1arZ3o/azc2N//77D4D//e9/GTrG06dPOXbsGDt37uTAgQMcOHCArVu3cvLkSe7du4enpydFihRh2bJldOzYEYD69euzbds2IiIiiIuLY8iQIUb9u/SOHTtGz5496dixIwqFgitXrqDRaGjUqBF//PEHKpWK8PBwDh06hEKhwMfHhz///JOQkBC0Wi0TJ05k1apVKZZdH8pu3LhhVKOmUqnYsWMHK1euNNyn/fv3ExwcTEBAQIb+TpkloUwIIUSepERJFapk6LZVqJKpmf6bN2/O5cuXadu2bYaPkVbvvvsugYGBdOjQgTNnzlCoUKF0H2P79u00bdoUT09Pw7YSJUrQokULQ+f4Tp06ERoaio+PD6AbhNCyZUt69OhB+/btqVSpEl26dEly7Pfff59FixbRpUsXJk2ahLe3N0FBQTRt2pQ6derQpUsXBg4ciIeHB3Z2dlSqVImhQ4fy/vvv065dOzQaDQMHDkyx7J6enri4uODr62u0/eDBgxQrVowaNWoYtjk7O/P222+zdu1aIPk+ZWnpq5dRCm1ydaE5RFBQEH5+fuzfv9/QNi2EEELoXb58GS8vrxT3/8qvfMIn6ers74wzP/ADvemdFUUUKTh79iy3b9+mS5cuxMbG0rNnT6ZOnUqlSpXMXbQ0e/X597rcIjVlQggh8qy3eRtbbNN1G1ts6U73bCqR0CtTpoxhJGfXrl1p165djgpkGSETggkhhMiz7LBjL3tpTvM0TSDrhBN72ZuhiWNF+ri5uaU41UVuJTVlQggh8rS61OUgBylAgRQ77zvjTAEKcJCD1KWuiUso8goJZUIIIfK8utTlAQ/4gR+oSlUUKLDBBgUKqlKVH/iBBzyQQCaylTRfCiGEEOiaMnvH/6dGTTjhOOOcqVGWQqSHhDIhhBDiFUqUGZoYVojMkOZLIYQQQggLIKFMCCGEMJG9e/fStWtXOnbsSIcOHfjpp58ydJyXL18yePBgw+U+ffpkVRGNrF+/nubNmzNjxgyj7X369KFWrVqoVMZLVHXq1ClJWWbMmEH9+vWNrhsUFETVqlWTTMy6Zs2aTJV38+bNjB07NlPHMCdpvhRCCCES02pBoUj5cgY9fvyYGTNmsHnzZvLnz09ERAR9+vShTJky+Pn5petYz58/N1rDMTAwMNPlS87OnTuZMmUKjRs3TrLPxcWFo0ePGtbCvHnzJk+ePMHV1dVwnbi4OPbs2YO3tzd79+41LMEE4OHhwbZt27Kl3DmV1JQJIYQQescnwqGRuiAGup+HRuq2Z9KzZ8+IjY0lOjoaACcnJ6ZPn065cuV0pz5+3FCDNmjQIMLDwwkPD8ff35+ePXvSvHlzRo8ejVar5ZtvvuHJkycMGTKEb775BoC3334bgL/++ovu3bvTuXNnhg4dyrNnzwDdskcjRoygVatWhISEGJVt06ZNtG/fng4dOjB27FgiIiJYtGgRFy5cYNKkSRw+fDjJ/WnZsqXRWpa7d+82LOytd/jwYUqUKEHnzp0NyzGlx+rVq5k8ebLh8owZM/j55595/PgxH374IT169KB58+bMnj07yW1btGhBUFAQAAEBAYYavDt37tC/f3+6dOlCr169uHTpEgA7duygU6dOdO3aFX9/f2JiYtJd3sySUCaEEEKALoDFhMGZ+QnB7NBI3eWYsISglkGVKlXCz8+PN998k+7duzNr1iw0Gg2lSpVCpVLx2WefMWPGDHbs2EHFihXZsmULhw4dwsvLi3Xr1rFv3z7OnTvHv//+y/jx4/Hw8OD7779n/PjxAGzYsIHQ0FC+++47li9fztatW2ncuLFRYGnSpAn79u3D3d3dsO3q1av88MMP/PLLL+zYsQMHBwcWLVrE0KFDqVq1Kt988w1NmzZNcn98fX0JDAwkNla3qPuhQ4do3ry50XU2b95M69atadq0KZcvXzYsjA7w5MmTJM2XV69eNbp9u3bt+N///odarUar1bJv3z7atWvHzp07ad++PevXr2f79u389ttvhIaGpulx+Pzzzxk9ejRbtmxhypQpjBw5EoB58+axYsUKNm/eTJkyZbh582aajpeVpPlSCCGEAF0TZbO5ut/PzNf9A6g1XLc9C5owJ02axODBgzl69ChHjx6lR48ezJ49myJFiuDp6WlYJ3HUqFGG25w/f56VK1dy8+ZNwsLCiIyMxM3NLdnj//PPPzx8+JC+ffsCoNFoyJcvYRRp4sW39U6dOkXz5s3Jnz8/AD179uSLL7547X2xs7Ojdu3aHD9+nCJFilCiRAns7e0N+0NDQzl69ChTpkzB3t6e5s2bs3btWkOITEvzpbu7O15eXgQEBGBjY0Pp0qXx8PDgww8/5OTJkyxfvpzr168TGxtLVFTUa8scERHBxYsXje5fZGQkz549o3nz5vTq1Qs/Pz9atWqV6pqp2UVCmRBCCKGnD2b6QAZZFsgOHTpEZGQkbdu2pVu3bnTr1o3169ezceNGoxAGuo78ERER/Pnnn+zbt48ePXrQsGFDrl27hjaVGju1Wk2tWrX44YcfAIiJiSEiImH5KDu7pMtDaTQao8tarZa4uLg03afWrVuzb98+PD09adu2rdG+7du3o9Vq6d5dt05odHQ0sbGxfPbZZ2k6tl7Hjh3ZvXs3NjY2hj5p06dP5969e7Rv354333yT48ePJ/t30W/T3x+NRoOtra1RGHz06BFubm6MHz+eK1eucPjwYUaPHs3QoUPp1KlTusqaWdJ8KYQQQujpmywTS9zHLBPs7e357rvvDP2ctFot//33H15eXpQpU4bQ0FBD895PP/3E77//zrFjx+jZsycdO3ZEoVBw5coVNBoN1tbWRsFJqVQSFxdHjRo1OHfuHLdu3QJg8eLFzJw5M9Vy1atXjwMHDhAWFgboRlz6+Pik6T41adKEgIAA/vrrL5o0aWK0b9OmTUyfPp0DBw5w4MABjh49Sr58+di9e3eajq3n5+fHqVOnOHr0KG+99RYAx44d48MPP6RNmzY8fPiQx48fJwmX+fPnN/w99+/fD+gGJ5QuXdoQyo4dO0bv3r2Ji4ujZcuW5M+fn0GDBtGpUycuX76crnJmBakpE0IIIcC4D5m+yVJ/GTJdY1a/fn2GDh3Kxx9/bOiH5evry5AhQ7C1tWXWrFmMGTOG2NhYSpYsycyZMzl//jwTJ05kxYoVODk54e3tTVBQEHXq1KFo0aL06dOHX375BT8/Pzp16sTmzZuZOnUqI0aMQKPR4OnpyaxZs1ItV6VKlRg0aBB9+vQhNjaWKlWqMGnSpDTdJ1tbW2rVqgUY18JdvHiRZ8+eGUIUgJWVFe+//z5r166lXr16hj5lidWtW9fQvKlnb29vmH7DyckJgEGDBjFmzBhcXV1xd3enatWqhrCr5+/vz5QpU1i0aJHR6NFZs2YxceJEfvrpJ2xsbJg7dy42Njb4+/vTv39/7O3tcXV1TTINiCkotKnVg1q4oKAg/Pz82L9/P8WLFzd3cYQQQliYy5cvp69v0PGJuk79+gCmD2p2btBwYvYUUuRarz7/XpdbpKZMCCGE0Gs40XheMn0fsyzoUybE60ifMiGEECKxVwOYBDJhIhLKhBBCCCEsgIQyIYQQuVoO7jotcrCMPO8klAkhhMi17O3tCQkJkWAmTEqr1RISEmI0mW5aSEd/IYQQuVbx4sUJCgoiODjY3EUReYy9vX26Z4aQUCaEECLXsrGxoUyZMuYuhhBpIs2XQgghhBAWQEKZEEIIIYQFkFAmhBBCCGEBJJQJIYQQQlgACWVCCCGEEBbAZKFsxowZjB07Nsn2Bw8e0Lt3b1q3bs0nn3xCRESEqYokhBBCCGExTBLKTpw4wZYtW5LdN2nSJN5991327t1L1apVWbx4sSmKJIQQQghhUbI9lIWFhTF37lw+/vjjJPtiY2M5deoUrVq1AqBr167s3bs3u4skhBBCCGFxsj2UTZgwgZEjR+Lq6ppk37Nnz3B2dsbaWjeHbaFChXj8+HF2F0kIIYQQwuJkayjbsGEDRYoUoUGDBsnuT24tMoVCkZ1FEkIIIYSwSNm6zNLu3bsJDg6mU6dOPH/+nMjISKZOncq4ceMAKFCgAOHh4ajVapRKJcHBwXh4eGRnkYQQQgghLFK2hrKff/7Z8PvmzZsJDAw0BDLQrUlWp04ddu/eTYcOHdi6dStNmjTJziIJIYQQQlgks8xT9uWXX7J//34Avv76a9avX0/btm35+++/GTFihDmKJIQQQghhVgptch27coigoCD8/PzYv38/xYsXN3dxhBBCCCFS9LrcIjP6CyGEEEJYAAllQgghhBAWQEKZEEIIIYQFkFAmhBBCCGEBJJQJIYQQQlgACWVCCCGEEBZAQpkQQgghhAWQUCaEEEIIYQEklAkhhBBCWAAJZUIIIYQQFkBCmRBCCCGEBZBQJoQQQghhASSUCSGEEEJYAAllQgghhBAWQEKZEEIIIYQFkFAmhBBCCGEBJJQJIYQQQlgACWVCCCGEEBZAQpkQQgghhAWQUCaEEEIIYQEklAkhhBBCWAAJZUIIIYQQFkBCmRBCCCGEBZBQJoQQQghhASSUidxNq039shBCCGEhJJSJ3Ov4RDg0MiGIabW6y8cnmrNUQgghRLIklIncSauFmDA4Mz8hmB0aqbscEyY1ZkIIISyOtbkLIES2UCig2Vzd72fm6/4B1Bqu265QmK9sQgghRDKkpkzkXomDmZ4EMiGEEBZKQpnIvfRNlokl7mMmhBBCWBAJZSJ3StyHrNZwGKXR/Uzcx0wIIYSwICbpUzZ//nz27duHQqGge/fu9O/f32j/okWL2LRpE66urgD06NGD3r17m6JoIrdSKMDOzbgPmb4p085NmjCFEEJYnGwPZYGBgZw8eZLt27cTFxdH27Ztadq0KW+88YbhOhcvXmTOnDl4e3tnd3FEXtJwoq5GTB/A9MFMApkQQggLlO3Nl/Xq1WP16tVYW1sTEhKCWq3G0dHR6DoXL17kxx9/pEOHDkyePJmYmJjsLpbIK14NYBLIhBBCWCiT9CmzsbFhwYIFtGvXjgYNGuDp6WnYFxERgZeXF59//jlbtmzhxYsXLF682BTFEkIIIYSwGCbr6O/v78+JEyd4+PAh69evN2x3cnLixx9/pFSpUlhbW/PBBx9w+PBhUxVLCCGEEMIiZHsou3HjBpcvXwbAwcGBli1bcvXqVcP+Bw8esHHjRsNlrVaLtbXMaSuEEEKIvCXVUHbz5s1Ub7x169bXniAoKIjx48ejUqlQqVTs37+f2rVrG/bb29sza9Ys7t27h1arZc2aNbz11ltpK70QQojc5dXpamT6GpGHpBrKunfvbnS5V69eRpcnT5782hM0bdqUpk2b0rlzZ7p164a3tzft2rXjo48+4sKFCxQoUIDJkyfzySef0Lp1a7RabZIpM4QQQuQBxycazyOon2/w+ERzlkoIk0m1nVD7yjeUGzdupLo/Jf7+/vj7+xtt+/HHHw2/t2rVilatWqXpWLlK4ukakrsshBB5hVYLMWEJ69Q2m2s8AbS8P4o8INVQpnjNC+B1+0Uqjk/UvQHp583SfyO0c9PNryWEEHlJ4gmez8xPCGeJJ4AWIpeTZZbMIfE3Qn1Vvf4bYUyY9KEQQuRNiYOZngQykYdIKDMH/RtPreFMnz2f7R9aJVTRyxuQECKv0n9BTUzWqhV5SKrNlzExMQwfPtxwOTIy0uiySqXKvpLldvHBbEHn+dQtAR2rIIFMCJF3JW4x0H9B1V8Gy3p/lP7AIpukGso++eQTo8vly5dP9bJIh/g3oEgV3AqN33ZopGW98QghhKkoFHBxJSjtwXe27rLvbPhnqW5783lmLmA86Q8sslGqoWzo0KEp7lOr1ezbty/LC5QnJPpGGBlnxe1wJ7Te/VFY4jdCIYQwBbUalDageg7LisCgR7qf6miwdY7frzRvGWWEqMhm6Z46/+nTp6xdu5a1a9cSHh5O27Zts6NcuZtCAXZuxFYfSmzcImJfviS0+le4x2+XF7UQIs9RKnVBbGlhiHoK8+I/nhwK6rabO5CB0UCEh4fm89eK+fSsifQHFlkmzaHs7Nmz/Prrr/zxxx9UrVoVf39/2rRpk51ly90aTiTq+XNgEQC379zBXV7UQoi8TB/M5iX6aLKUQKanUKBtOoc+g+az/zo0KAUl5b1bZJFUR1+qVCo2bdpE165dGTJkCIULF8bR0ZFFixbRo0cPXFxcTFXOXCkyKsrw++3bt+VFLYTI29RqXU1ZYksL67ZbCq2WdV+3Y/913cUjt5ARoiLLpBrKmjZtyu7du/nwww85dOgQo0ePxsbGxlRly/UiIyMNv9+6dcuMJRFCCDPTB7Kop7omyxFxup9RTy0nmGm1vNg1mFEL9lKrvAeurq4ceVnVeM5JITIh1VBWpkwZbt26xfnz57lz546pypRnJA5lt2/fNl9BhBDC3JRKsHYy7kM26JHusrWTZTRhKhR8/ctZHr2EJb9sp1GjRhy5odH1KZP+wCILpNqn7LfffuPGjRusX7+ePn36ULp0aSIiIoiMjMTd3d1UZcy1pKZMCCESGXjbeJSlPphZQiAD/vnnHxZu+puBHw2kno8Pvr6+7Nmzh5Bqh3EvWNDcxRO5wGtn9C9btixffPEFf/31F71796Zq1aq0b9+eIUOGsGfPHlOUMdeKiu9T5ubmJjVlQggBSQOYhQQyjUbD4MGDyZ8/P1OnTQPA19cXgKPHjpmzaCIXSfMyS7a2tnTo0IFffvmFrVu3UrJkSaZMmZKdZcv19DVllStX5vbt22ilP4IQQlikVatWcfz4cWbOnEmBAgUAqFOnDra2thw5csTMpRO5RYbWvixTpgyff/45hw8fzury5CmJQ1lkZCTBwcFmLpEQQohXhYaGMmbMGBo1asT7779v2G5vb0+9evUklIksk2qfMj8/v9ceYP/+/VlWmLxGH8qqVKkC6Dr7e3h4mLNIQgghXjFu3DiePXvG4sWLsbIyrsvw9fVl1qxZRERE4OTkZKYSitwi1VAWHh5OXFwcLVu2pEWLFjIdRhZLXFMGus7+9erVM2eRhBBCJBIQEMCyZcsYMWIE1atXT7Lf19eXadOmcfLkyTRVZAiRmlSbL48dO8bs2bOJiYlhypQpHDhwAGdnZ5o1a2b4JzLu1VAmnf2FEMJyqNVqBg8eTJEiRZg4cWKy12nYsCEKhUKaMEWWSLWmzNramubNm9O8eXMiIiL4888/WbJkCffu3aNt27Z07NiRN954w1RlzXX0oczT0xN3d3cJZUIIYUF++OEHzpw5w9q1a3F1dU32Ovny5aNGjRoSykSWSHNHfycnJzp37szy5cuZO3cu//vf/2jXrl12li3Xi4yMxNraGhsbG0qXLi1zlQkhhIV4/PgxX375JW+++SY9evRI9bq+vr6cPHmS2NhYE5VO5FZpDmXPnz9nw4YNvP/++/Tt25cKFSqwePHi7CxbrhcZGYmjoyOgG9EqNWVCCGEZRo8eTWRkJIsWLULxmpn6fX19iYyM5OzZsyYqncitUm2+jIyMZP/+/ezcuZPAwEDq1q1L165dWbJkiSFMiIxLHMpKly7Njh070Gg0SUb3CCGEMJ3Dhw/zyy+/8OWXX1KxYsXXXl8/ieyRI0dksJbIlFRDWaNGjbC3t6dVq1YsXbrUMGHegwcPDNcpV65c9pYwF3u1piwmJobHjx9TpEgRM5dMCCHyptjYWAYPHkzp0qUZN25cmm5TuHBhypUrx5EjR/j000+zuYQiN0s1lEVFRREVFcXatWtZt24dgNGs8wqFgsuXL2dvCXOxV2vKQDcCU0KZEEKYx7x587h06RLbt29PV4uQr68v27dvl9YOkSmphrIrV66Yqhx5UnKh7NatWzRo0MCMpRJCiLzp3r17TJo0iY4dO9KhQ4d03dbX15eff/6ZK1euGKY5EiK9JM6bUUo1ZUIIIUxv5MiRaDQa5s+fn+7bJu5XJkRGSSgzo8ShzNHREQ8PD5kWQwghzGDv3r1s2rSJ8ePHG74kp0fZsmUpXLiwhDKRKRLKzChxKAOZFkMIIcwhOjqaoUOHUqFChQx31FcoFPj6+kooE5kiocyMXg1lMoGsEEKY3owZM7hx4wbff/89dnZ2GT6Or68vd+/e5e7du1lYOpGXSCgzo+RC2d27d1Gr1WYslRBC5B03btxg2rRp9OzZkzfffDNTx5J+ZSKzTBLK5s+fT9u2bWnXrh0///xzkv2XL1+mW7dutGrVii+//JK4uDhTFMvskmu+jI2N5eHDh2YslRBC5A1arZZhw4Zha2vLnDlzMn28atWq4erqKqEssUTTaCV7WRjJ9lAWGBjIyZMn2b59O5s2beKXX37h5s2bRtcZPXo0X331Ffv27UOr1bJ+/frsLpbZabXaZGvKAGnCFEIIE9i6dSt79uxh8uTJFC1aNNPHUyqVNGrUSEKZ3vGJcGhkQhDTanWXj080Z6ksWraHsnr16rF69Wqsra0JCQlBrVYbBZH79+8THR1NzZo1AejatSt79+7N7mKZnUqlQqPR4ODgYNhWpkwZQKbFEELkYSaqWYmIiGD48OFUr16doUOHZtlxfX19uXTpEiEhIVl2zBxJq4WYMDgzn5e7h/DyxQtdIDszX7ddasySZZLmSxsbGxYsWEC7du1o0KABnp6ehn1PnjyhUKFChsuFChXi8ePHpiiWWUVGRgIYBdSSJUsCUlMmhMijTFizMmXKFO7du8fixYuxtk51HvV00fcrO3r0aJYdM0dSKKDZXF5U/Bjv95dQuGA+PvpiPqed34Fmc3X7RRIm6+jv7+/PiRMnePjwoVHzpDaZtKzIAw9WVFQUYBzK7O3tKVq0qNSUibxL+p/kXYlqVgzBLJtqVi5dusR3331H//79adSoUZYdF6Bu3brY2dlJEyagBT7+7Tm3n0GnqvDbGajz8Vrq1qvH8uXLiYiIMHcRLU62h7IbN24Y1sd0cHCgZcuWXL161bDf09OTp0+fGi4HBwfj4eGR3cUyu+RqykDXr0xCmciTpP9J3qZQgG0+KFhDF8TmWOl+Fqyh255FX9a1Wi2DBw/GxcWFGTNmZMkxE7Ozs6NevXoSyoBVK1fy+++/M7El/NYbHkyARf7NiI6OZsCAARQtWpRhw4Zx8eJFcxfVYmR7KAsKCmL8+PGoVCpUKhX79++ndu3ahv3FihXDzs6O06dPA7qOl02aNMnuYpldaqFMmi9FnmPCWhJhobRauL0Pnv5jvP3pP7rtWfQc+O233zh8+DDTpk0z6jqTlXx9fTlz5kyergm6euUKQwYPpFlZ+OLTYTBKQ75GwxlS8hDn57fg6JEjdOzYkR9//JFq1arh6+vLmjVriI6ONnfRzSrbQ1nTpk1p2rQpnTt3plu3bnh7e9OuXTs++ugjLly4AMDs2bOZNm0abdq0ISoqir59+2Z3scwupVBWpkwZ7t27l2emBRECMPQ/odZw41qSWsOl/0leUsQnfdvTKSwsjE8//ZR69eoxYMCALDlmcnx9fYmLi+PkyZPZdg5LFhMTwzu9euFgZ8OvUz9E6Tff6DWusM9Po8aN+eWXXwgKCmL27Nk8evSI9957j+LFizN69GiuX79u7rthFlnXuzEV/v7++Pv7G2378ccfDb9XqlSJjRs3mqIoFiO1mjK1Wk1QUFCG1l8TIsfSv2mfSbQYtAQykYUmTJhAcHAwu3btQqlUZtt5GjZsiJWVFUeOHMHPzy/bzmOpPv/8c86dO8f27dsp1r59wmtY/xpP9JouWLAgn376KSNHjuTgwYP88MMPzJs3j9mzZ/Pmm2/y8ccf07FjR2xsbMx0b0xLZvQ3k9RqykCmxRB5kL7JMrHEfcxyExnQkJRCAXZukL+q8fb8VXXbMxnOz5w5w/fff88nn3xi1IUmO7i6ulKjRg3z9yszw/Ns586dzJ8/n2HDhtGhQ4ekj1sKj6OVlRV+fn5s2LCBu3fv8s0333Dt2jW6d+9OyZIl+eqrr/LE8lUSyswktZoykFCWJ8gHc4LEfchqDYdRmoSmzNwWzGRAQ/K0Wvh7Djx7pdP3s4u67Zl4Dmg0GgYPHkzBggX55ptvMlnQtGncuDEnT54kNjbWJOdLwgzPswcPHtC/f39q1KjBzJkzM3ycIkWK8OWXX3Lz5k127txJnTp1+PbbbylTpgwdOnRg165dxssR5qL3UgllZpJSKCtRogQKhUI6++d28sFsTF9LkrgPmb6PWRbUklgMGdCQMrUa4uI7xivtYXis7ifotmdiTeDly5cTEBDA7NmzcXNzy3xZ08DX15fIyEjOnDljkvMZMcPzTK1W89577xEZGcnatWuxt7fP9DGVSiXt2rVjx44d3Lp1i3HjxvH333/Tvn173njjDb799lse7fgsV72XSigzk5RCma2tLcWLF5eastxMPpiT13CicX8TfTBrODHpdXPqN+P4+/Rv/vdo+fF8TvjLgAYDpRIcC+t+V0fDfBvdT9Btz2AfsKdPnzJ27FiaNGnCe++9l0WFfT2zLk5uhoEzM2bM4ODBgyxcuJBKlSpl+fFLlSrFlClTuHv3Lhs3bqRChQqMHz+eEl3m8vaI+eyf0w2NWp3j30sllJlJSqEMZFqMXE9GGqYsLf1Pcngt4/YdO6g/fCt/XoON5+M35vXHXa/i2+nbngZjx47lxYsXLF682KQTkxcuXJhy5cqZr1+Z/n0msWx6np04cYIJEybQs2dP+vfvn+XHT8zGxoZu3brx559/cu3aNUaMGMnB2/a8+dkWBje2zvHvpRLKzEQfyhKvfalXpkwZqSnL7Uz4hpmr5OBaRq1Wy7fffkvnzp2pWNSRsu5wSb+iXG7rN5cRCgU0+S6hyVJPaa/bnoHXxvHjx1m+fDkjR46kSpUqWVTQtPP19eXo0aNoNBqTn9tUA2fCwsLo1asXJUqUYOnSpSYNvuXLl2fW7NkEPQplaCNYehIOXCdHv5dKKDOTyMhI7Ozskh2WXbp0ae7fv49KpTJDyYRJ5KWRhlkph9YyRkRE8M477zB+/Hh6tajAkf5PqFejApejS+XeAQ3ppVbDsiIJTZaG7dHx29PXpywuLo7BgwdTvHhxJkyYkIUFTTtfX19CQ0MNq9qYjIkGzmi1WgYNGkRQUBC///47+fLly5LjprMQ2J/8gpntoVxBGLgRovYNy7GvJQllZhIZGZls0yXoQplGo+HevXsmLpUwibw00jA75LBaxrt379K4cWM2bNjAjBkz+HVSTxx8hlO52XvcuXOH8DpTct+AhoywsoLYFGZzj43W7U+H77//nn/++Yd58+bh7OycBQVMP7MtTm6igTMrVqxg/fr1fPPNN9SvXz9Ljpkuid5LHXyGs3Tt/7gRApNnfZ9j30tNMnmsSCq1UJZ4rrKyZcuasljCFFJ6wwT5YE6LlGoZLTCYHTlyhG7duhETE8POnTtp27atbodWi1foZgCuXrtGbQssu1kUrAKPAsDbH5rPg4Mj4OwC3fZ0ePjwIV999RWtW7ema9eu2VLUtChbtiyFCxfmyJEjDBo0yLQnbzhR91pJZeLWzLh8+TLDhg3Dz8+PMWPGZMkx0+2V99IWCgX9+vVj1upV9Ho/huo58DUlocxMXldTBkhn/9wsm98wc61XaxmbzU24DBb1N/zxxx8ZMmQIZcqUYdu2bcYj0hQKKleuDMClS5eyfTLTHEGhgDKtdUsqNZ+nu9x8nm6fff50Pa6ffvopKpWKhQsXmrSP06sUCgW+vr7m7eyf2uUMio6O5p133sHJyYlffvkFq3TWYmapV95LZ8+eza5duxiw6DQnequzdeWG7CDNl2aSWigrXrw4SqVSOvvndtn0hpmr5YD5zGJjYxk6dCgDBw7Ez8+PgICAZKcIKFeuHNbW1qbvb2TJ0jMtSgoOHDjA77//ztixYylXrly2FDM9fH19uXv3bq6ajX706NGcP3+eVatWUaRIEXMXx+h17+7uzvz58zl16hSLFi0yY6EyRkKZmURGRiY78hLA2tqaEiVKSE2ZEMnJgg/u7PL06VNatmzJ999/z2effcbOnTtTnKzUxsaG8uXLSyhL7PhEODzKeLqTw6PSPN2JSqViyJAhvPHGG3z++efZVsz0MOt8Zdlg+/btLFq0iJEjRyY0x1uYd955hzZt2vDll19y584dcxcnXSSUmUlqNWWga8KUmjIhUmCBtYwXLlygbt26nDhxgtWrVzNr1qzXNp14eXlx6dIlE5XQwmXBdCdz5szhypUrLFq0KMUvvaZWrVo1XF1dc0UoCwoKon///nh7ezNt2jRzFydFCoWCJUuWADB48GC0qTx3tFotqhdxvLgZRfDfL4iNyPjKEVlB+pSZSWRkJPnz509xf5kyZdi3b58JS5R7LViwgBYtWlC1atXXX1mIDNiyZQt9+vQhX758/PXXX9SrVy9Nt6tcuTLbtm0jJiYGOzu7bC6lhUs84OXM/IR+gmmc7uTOnTtMnjyZLl260KZNm2wubNoplUoaNWqU40OZfhmlmJgY1q5da/HP11KlSvHNN98w5tPP2bB8C34+LYl+Ghv/T5Xo91g0sQmhrWK/wpRsW9Bs5ZZQZiZpqSl78OAB0dHRWbKGWF6lUqkYPnw4AwcOZOnSpeYujshlNBoNU6ZMYeLEidSrV48tW7ZQtGjRNN/ey8sLtVrN9evX5UsDJAQzfSCDNA/eGD58OAqFgnnz5mVf+TLI19eXPXv2EBISgru7u7mLkyFTp07l8OHDrFy5kgoVKpi7OAZx0WqiHscS9VhFVLBx2PJ+2opd3d6EP+DMH7cNt7HNb41DQRtcStlTqLYL9oVssS9og338NnOSUGYmrwtl+mkx7t69a1EvgJzm2bNnAJw9e9bMJRG5TXh4OP369WPTpk307duXpUuXpvsLlH4E5uXLlyWUQYanO9m5cyfbtm1j+vTplCxZMpsLmX6J5yvr1KmTmUuTfseOHWPixIn07t2bvn37mvTcWq0W1fM4oh6piHys0oWvxwm/q54bNzda2SlwKKgLWS6lXQmLC2HSdxPwblydCbPGY1/AGisby+25JaHMTKKiol5bUwa6aTEklGVcaGgooOvvExcXh7W1POVF5t2+fZtOnTpx8eJF5syZw4gRIzI09ULFihVRKBTSrwwyPN1JVFQU/v7+eHl5MXLkyCT7LUHdunWxs7PjyJEjOS6UPXv2jHfffZcyZcpk2/qhmjgNUcGxxoHrUfzvT1RoYhL1CVOAvbsNDp62FKztiqOnLQ76fx422DgrXyljMWoFeTF9+hRa9mtGixYtsrz8WUk+ocwkrTVl0tk/c/ShLDo6mmvXrhlqJoTIqEOHDtG9e3fUajW7d++mVatWGT6Wg4MDZcqUkRGYoAtc17eCQ8GEtS6bfAeX1+i26+cse8W0adO4desWBw8exNbW1pQlTjM7Ozvq1auX4/qVabVaPvroIx48eMDx48dxdXXN8LHiItWG2q3I+MAV9UT3e/TTWEiUu6xsFfEhy5YC1ZxxKGybEL4K2aS7pmvChAls2LCBQYMGcf78eYsZBJIcCWVmoNVqXxvKihQpgo2NjYSyTNKHMtA1YVpUKEs8eWxyl4XFWbJkCf7+/pQrV47t27dTvnz5TB9TRmDG02hAHQNRT2FNHXjvtO5n1FNwtNbtf2WS0uvXrzNjxgx69+5Ns2bNzFPuNPL19WXmzJlERETg5ORk7uKkybJly9i0aRMzZ86kbt26r72+VqMlKjiWiPsxRD6IIeJ+DBHxP2NfGDcz2rgocSxsi1tFRxya2BrVeNnlt87SGjkHBweWLl3Km2++yZQpU5g6dWqWHTurSSgzg+ho3fpuqYUypVJJyZIlZa6yTEocys6dO0fv3r3NWJpEjk+EqFBoMV8XxLRaODAcHApYxHxbwphKpcLf35+lS5fSrl071qxZk2WLL1euXJn//e9/0ryuUEB0iO734HMwN9F0ItEhSb6waLVahg4dir29PbNnzzZdOTPI19eXqVOncvLkSfz8/MxdnNf6999/GTFiBC1btuTTTz812hcXrSbygUoXuuKDV+T9GCIfqYxGMtq4KHEqZodHHVcci+gCl2NhXQ2YtaNpZ9r38/PTLcE0axbvvPMO1atXN+n50yoPvwOYT2RkJJB6KANdE6bUlGWOPpSVLVuWc+fOmbcwelotnP8JIu7rLreYrwtk5xaCUzFo8LXUmFmQJ0+e0L17d44cOcLYsWP55ptvsnTpFi8vL2JiYrh161aW1LzlWGo1aOKS36eJ0+1PFFo3btzIH3/8wYIFCyhcuLCJCplxDRs2xMrKiiNHjlh8KIuKiqJnz56ULvgG34/7kaA/nhGZqNYrJjThcVJYoQtbRe1w93bBqagdTsXscCxqi62LZUUMwxJMAwZw4sQJi1yCybL+YnlEWkNZ6dKl2b59uymKlGuFhISgVCpp2rQp27ZtQ6vVmnUtPEAXyrTxVfnnFur+GfappRnTgpw7d45OnTrx5MkTfvvtN3r16pXl50g8AjNPhzIrKyhQFUIvJN1XoKpR0+XLly8ZOXIk3t7efPLJJyYsZMa5urpSo0YNi+tXplZpiHyk0oWu+OB1+cR1plZYgYO1I7e+fwG8wNrBCsdidhSo6oxTsYTg5ehpa9GjGRPTL8H07rvvsmjRIoYPH27uIiUhocwM0lNT9uTJk9f2PxMpCw0NJX/+/NSqVYsVK1Zw//59ihcvbt5CKRRQ4W3jMKZX4W0JZBZiw4YN9OvXjwIFCnD06NFsWzRcvy7mpUuX6NixY7acI8eIfJSm7ZMmTeL+/fts3LgxRzX5+vr68tNPPxEbG4uNjY3JzqvVaol9oTbq46VvcowKNu5kr3GM5b/71/AoX4BWPd/EqagtTsXssHXL2n5e5vLOO+/wyy+/8OWXX9K5c2dKlSpl7iIZyTnP5lwkPTVloJup2svLK7uLlSuFhoZSoEABatasCehqPiwilDWfB/cOQ8j5hO3u1XXbc8EbX06m0Wj4+uuv+eabb2jYsCGbNm3K1uaxfPnyUaxYMRmBCRDz8rXbL1y4wLx58/joo4+oX7++iQqWNXx9fVmwYAFnzpzBx8cny4+v1WqJeRZHRFAM4feiibgXQ3hQNBH3VcQlWj7IylaBU1E7XMs5UqSpnSF4hcQ9wbtuTcqVK8exJccsdjRrZuiXYKpSpQqDBw9m586dFhU2JZSZQXpD2a1btySUZZA+lFWvXh2FQsHZs2dp3769eQul1cLBEcaBDHSXD45I6PwvTO7ly5f06dOHbdu28eGHH/L999+bZDkZGYGJbnQlsSnsjAWNBq1CweDBg3Fzc7PotRdTknhx8syEMt2EqmoigqIJv2ccwOIiNIbr2bgocS5hR+FG+XAqquv35VTMDnt3GxRWxu8xcXFx9Gn+HnFxcfz++++5MpDp6ZdgGjlyJOvWreOdd94xd5EMJJSZQXqaL0HmKsuM0NBQPD09cXFxoVy5cpbR2V+rhWsbkt93bYPUlpnJjRs36NSpE1euXGHBggUMHTrUZN+gvby8+Pnnny2jz6O5WFmlvOi4VgtWVqxevZqjR4/y008/5cjlijw9PSlfvjxHjhzhs88+S9NtVC/iCA+KIeJeogAWFEPsy4SaL2snJc4l7Sjc0A2nEnY4F7fDuYQ9tvnS/hH/zTffcPToUX799VfKlSuX7vuW0wwbNozffvuN4cOH07JlSwoUKGDuIgESyswiraHM09MTOzs7mRYjE0JDQw21jDVr1uT06dNmLhG6wKWIH/VTc5jx6EuFUgKZGezfv58ePXqg1WrZt2+fyUfHVa5cmfDwcIKCgihRooRJz20xrKygWGMIvgiqhKlssC0Ahary7PlzRo8eTYMGDejfv7/5yplJvr6+bN26FY1Gg1WiwQtxUWoigmJ4eTe+1uteNOF3Y1A9TxjpaO1ohVMJezzqueJcwg6n4vY4l8h8f6/Dhw8zZcoU+vbtaznTBmUzpVLJjz/+SO3atRk9ejTLly83d5EACWVmkdZQZmVlRenSpaWmLBMSLwDs7e3Nhg0beP78eZbNMZUhCgVUH2A8T1mL+KVkHApIKDMhrVbLwoULGTVqFJUqVWLbtm2ULVvW5OXQf3G4dOlSzgtlWTUJslYLnt5w/6+kyyx5evPluHGEhITwxx9/GIWZnKZxQ18ObPyL0+sv4aYpSPhdXQCLDk5ourWyU+Bcwp6CtZxxLqELXk4l7LN8UlXQvUe+9957lC1blkWLFmXpsS1djRo1+Oyzz5gxYwbv9e5N88RLMJlpFLyEMjNIaygDJJRlQmxsLC9evDBUS+s7+//zzz80adLEjCVDN0Fs4he9PphJIDOZmJgYhgwZwvLly+nUqRO//PILLi4uZilL4mkxMrNsk8kdnwgxYQnrUurXr7RzS/8kyAqF7nb6QKZQ6H4Cf9+M5IelP+Hv7294HVs6rVZLTEgsL+/GEH432vCv+P06LGu1hbDN8Fz5FMeiduQr70hxPzucStrjXMIeh0JJ+3xlVxk//PBDHj9+zIkTJ8z2/Denr7/+mo2/LmNg366cv/YAB0fHzD2PM0lCmRmkN5T9/fff2V2kXCksLAwgSSg7d+6c+UMZJA1gEshM5vHjx3Tt2pXjx48zfvx4Jk2aZNbal0KFCuHu7p6zOvtrtbpAdmY+EVGxRNSegMelaQkLimekpiGZLytq39l8MqYBnp6eTJo0KavvRZaIjVQTcTfaOIDdM+50b+9ug3NJ3QSrY2eMokhVDxaunoOVtfmed0uWLGHbtm3MmTMn26Z8sXQO9vYsHdmMNz/bwpSPmjL118CEGtqMPo8zQUKZGehDWVoWRS1TpgwhISG8fPkyT36LyQz9bP76UFakSBE8PT05e/asOYslzOz06dN07tyZ0NBQ1q9fz9tvv23uIgG62rIcNS1Gopqs/iPms+H8YuoUhw5v1qdji/epAWToo+yVD8Aff/qJv//+m99++8283Q4AjVpL5MMYXZPjnWhe3tEFsOinCU2P1g5WOJe0p3BDN5xL2uFcSlf7ZeOUMHu89bY4dhzdzPfW88xwL3QuXLjAqFGjaNOmjUVOomoyCgV+ozbR788qzFr7N+8UtqJ6UYxrbE3IJKFs0aJF7NmzB4CmTZsyZsyYJPs3bdpkWIG+R48eubqzoT6U2dvbv/a6+mkxbt++TbVq1bKzWLnOq6EMdLVlFjECU5jF77//zgcffICHhwfHjh2zqKYwLy8vNm7cmLNGYCoUaJvO4dCN+dQsCjZKmLgqgK9X1qJEiRK0b9+ejh070rx58wxNLfLkyRO++OILmjdvbvJpC1Qv4nShKz54vbyjG/WoX9tRoQTHona4VXTE+S17QwCzd7d57ePn6+vLhg0buHPnjlkmL42MjKRnz57kz5+flStX5ug+ellCoWD2r3+xv3whDt5AF8rMEMjABKHs+PHjHD16lC1btqBQKBgwYAB//vknb731luE6Fy9eZM6cOXh7e2d3cSxCZGQkDg4OaXohJJ4WQ0JZ+qQUyubMmYNKpcrV8/AIY2q1mvHjxzN9+nR8fX3ZuHEjHh4e5i6WkcqVKxMaGkpwcLDFlS1FWi131g0gOAImt4KPG8KTMgPYFVaf7Tt2sGrVKpYsWYKTkxOtWrWiQ4cOtGvXjkKFCqV6TP2H4ZgxY4iIiOD777/PtqCqidUQcV836jH8TowhgKnCEkY92rpZ41LKngKtnXEuZYdLSXucitlleHmhxPOVmSOUjRw5kitXrvDHH3/knOdadtJqcb/wDdc+Bzt9Kjo0MnfWlBUqVIixY8caPgDLli3LgwcPjK5z8eJFfvzxR+7du0fdunX5/PPPTTJho7mkZ9mkxBPIivTRh7LE8xl5e3sTGxvLpUuXLKqWRGSf58+f07t3b3bt2sWgQYNYsGCBRQbyxCMwc8QHZXxn6IDdPwNQb9zf8OIXPM7Mp38tR/pv3kx0TAwHDx5k+/bt7Nixg82bN6NQKGjQoAEdO3akQ4cOeHl5JQSu4xMh+hk0n8eRo0dZtWoVX/Sqg9ezdcDETBZXN9t94mbH8DvRRDyIMSxFa2WjwKm4HQVrOuNc0h7nUva4lEzffF9pUa1aNVxdXTl69Cjvvfdelh77dTZs2MCyZcsYO3Ysb775pknPbZH0nfrPzMfe55VRv2DyYJbtoSzxAru3b99m9+7drF271rAtIiICLy8vPv/8c4oVK8bYsWNZvHgxI0eOzO6imU16QlmhQoVwdHSUEZgZEBISAiStKQNdZ38JZbnf9evX6dixI//99x+LFy+26MWrE4/AbNasmXkLkxbxoyUDY7yxt79MterVwVrXxww7N1AosLe3p02bNrRp04bFixdz9uxZduzYwfbt2xk7dixjx46lbNmydOjQgQ7t2+MbtBubp6eIjVMz+NPDlPRw4cuqf8MtJTT4Os0fjuoYTfw8X9G8jK/9Cr8TTWx4woSr9gVtcC5pT6E6rrp+XyXtcCxih5Uy+z+AlUoljRo1Ml6c3AQdyu/cucNHH32Ej48PkydPztZz5RipjPrVP49NyWQd/a9fv86gQYP4/PPPDbU/AE5OTvz444+Gyx988AHjxo2TUBZPoVDItBgZFBoaikKhMOocXK5cORwdHaVfWR7wxx9/0LNnT5RKJX/++afFB51ixYrh4uKSs0ZgNpxI4Of7qVWrVsIC2ynULCgUCmrVqkWtWrX4+uuvuX//Pjt37mT79u0sWbKEefPmkc9RSZsK4GT7PRcvwtZ+4GQHRitmJ6LVaokOjjX0/XoZH74iH6kMN1HaWeFc0g6P+q64xNd+OZc07nhvcscn4lvsOXv2XNLNpVigQLZPwRAXF8e7776LVqvl999/N+mC6BYvuSmKcmufMtCNdvL392fcuHG0a9fOaN+DBw84fvw43bt3B3QvMmvr3D0oND2hDHRNmNJ8mX6hoaHkz5/fqO+eUqmkRo0aMgIzF9NqtcydO5fRo0dTpUoVtm3bZuibackUCgVeXl45agRmXFwcp0+fZtCgQQkb0/hBVqxYMQYNGsSgQYOIiIjgzz/+YMey8ew8eokn4dDeCzpWib9ykfrERaoJv5fQ9+tl/NQT6qiEaSccCtviUtKewo3dcImv/XLwsDXJnF9pFj+ViK/dcQCOHjlCp3yHsn0KhkmTJnH8+HF+//33HPF6MDkLmaIo29PPw4cPGTJkCHPnzqVBgwZJ9tvb2zNr1ix8fHwoXrw4a9asMRoEkBulN5SVKVOG48ePZ2OJcif9YuSvqlmzJmvWrMlZo9xEmkRHR/Pxxx+zatUqunbtyqpVq3B2djZ3sdLMy8uLP/74w9zFSLN///2XqKgo6tWrl6njODk50blLFzp36oR6VW3OnAmjkH15btyvQHhcXV7erE/0D1cM17d20k07UbSpG84l7XEpZY9TCTus7c1Y+5VW8bUwdVVx2C39niPzutCpA9k6BcPBgwf59ttv+eCDDyxq8W2RVLaHsuXLlxMTE8P06dMN29555x0OHDiAv78/1apVY/LkyXzyySfExsZSq1atHL2uWVpERUWl64OidOnShIWFERYWhpubW/YVLJdJLZQtWbKE27dvyzfGXOThw4d06dKFgIAAJk6cyFdffZXjhvpXrlyZVatW5ZjXekBAAECGQ5nqeVxCp/u70bz89zoRT39Eo7UnDFAQh6PDbfIVu0xxv4Y4l3bApaQddmmYdsKiKRTYtVxIneLfc+JO/LZsCmRPnz7lvffeo0KFCixYsCDLjy+yVraHsvHjxzN+/Pgk23v16mX4vVWrVjlraZFMioyMTNfoqsTTYkjn9LQLDQ2lYMGCSbbrp145e/ashLJc4tSpU3Tu3Jnnz5+zadMmunbtau4iZYh+BObly5eTbVmwNIGBgbi7u/PGG2+kej21SkNEUMJ0E/oQpnqe0PHeNp81zjZPKO65GxfH6zg7XsPJ4QZKKxV41oMuJ3PPqhfxI/58SsLi46CKA9tsmoJhwIABPH36lF27duHk5JSlxxZZL3d33rJQGelTBhLK0iskJIQKFSok2V61alWsrKw4d+5cjv3wFgl+/fVXBgwYQJEiRThx4kSOns8v8QjMnBLK6tWrZ6i10mq0RAXHGkY7ht/Vdb6PfJjQ8d7KRoFTCTsKersYTzvhqoTf+sGjAPD2h+Zb4OAIOLsg94QxMJqCoX6ztsz5azfn871DnWyYguHYsWNs27aN6dOny2dHDiGhzAwyGsqks3/6pNR86eDgQKVKlWQEZg6nVqsZO3Yss2fPplmzZmzYsCHZmtGcpHTp0tjZ2eWIzv7PHj5H+diBTs16cWnp/fj1HmNQRyfqeO+pm3bCs0G++I739jgWTqXjfZnWUMQHms/TBZPm83Tb7fPnnmCWaAoGnzdGwuTSBMQ1ok4tzyyfgmHWrFkUKFCAoUOHZtkxRfaSUJYGz/+LxN7dBrv8WTOEOL2hrECBAri4uMi0GOmgVqsJCwtLNpSBrgnz8OHDJi7VK14dZWXihW9zukmTJjF79mzDQKLcMMRfqVRSqVIli5oWwzDn173Ei23HoAqLY2bT5fAIHr98gXNJO4o203W8dy5pj3MJO6wd0tnxPrmpCfQBLTeJv58l0K3JezIggCFDVmfp/bxy5Qrbt29n/Pjx0myZg0goe43YCDWnvrqJVg3OJewoUMMZ9+rO5PdyQmmXsU7E6Q1l+rnKpKYs7cLCwgBSDGX6EZhPnz41T+3K8YkQE5bQVKFv0sjGeYpyk6CgIGbNmkWvXr1YtGiRuYuTpby8vAwd6E1JrdIQ+SBGF77u6dZ5DL8XQ9STRE2Ptgkz3v994yQL18xh+5HNFCnnmXUd7y1kaoJsp1CgAHx8fHSPdxbfz++++w47OzupJcthJJS9ho2TkvozyxF8+iWhF8K5tzeUuztDUFgryF/JkQLVnXGv4YxLKfs0zYWjVquJiYlJVygDXWd/CWVpl9y6l4np+1f8888/+Pn5mapYOvHzFBkt46Ff1iMb5ynKTcaPH49Wq2Xq1KnmLkqW8/LyYt26den+8pZWmlgNEQ9UiYKX7mfiCVcVSnAsYodrGXuKNHXTrfVYwg5Hz4Smx4lvryPU8RFFyxfO8jLmJT4+PmzdulU3iWyiJeEy49GjR6xevZoPPvggZyzZJQwklKWBcwl7nEvYU6ZzIdQxGp5djiDkfDih58P577fH/PfbY2xclbhXc9aFtOrO2Lsn35QSFRUFkO4329KlS3Pw4EGZWyuNklv3MjF9KDt79qzpQ1niZTzOzE8IZ9k4T1Fucu7cOVavXs1nn31mtDpIblG5cmW0Wi1Xr141jBTOCE2chsiHKsLvxRARFB3/M4bIhzFo47t9Kax04cu5pD2FG+XDqbiu2dGxiC1W1qm3BAQGBuaIwQiWrn79+oDu79mmTZssOeaCBQuIjY3l008/zZLjCdORUJZOSjsrCtZ0oWBNFwBinsUSciGc0H/CCTkfwaNjzwFwKmaHew1dSMtf2dEwqWFkZCSQsVD28uVLQkNDs+zbVG72upqyggULUrx4cfN19tcHM30gAwlkaaDVavnss8/Inz8/48aNM3dxskXihcnTEso0cVqiHqsM/b4i7kUTrg9f+hknFOBY2Ban4nZ4+LjiVNwO5xL2OBW1xcom/d0wHj16xN27dxkxYkS6byuM1alTBysrKwICArIklL18+ZIlS5bQtWtXypUrlwUlFKYkoSyT7PLbULRJfoo2yY9WqyX8boyhFi3oz1Du7g5BoVTgVtEB9+rOxBR6iZVCmaHmS9BNiyGh7PWSW4z8VTVr1jRfKNP3IUssm+Ypyk327t3L/v37mT9/fo6YXDUjypcvj1KpTDIC09DnKyiGiPu6Wq+I+zFEPlShVevbHcHBwwan4vYUquMSX8tvh2NRO5S2WTeR7qlTp4CMTxorEjg7O1O1alVOnjyZJcf76aefCAsLY/To0VlyPGFaEsqykEKhwKWUbsmP0h0KolZpCLsSSej5cELOh/Pf2icAbOp0FNvTcMstmPxeTri+Yf/ab6uJp8WoXbt2dt+VHO91NWWgG4G5Z88eoqKicHBwMFXRjOYpMjRZ6i+DBLMUxMXFMXr0aMqVK8fHH39s7uJkC61WC1FWtKrRAe1lB66uekjEgxgi78cQFRybsC63vuarmB2F6rjgVCy+5quYXYYHIKVHYGAgSqUyU82rIoGPjw8bN25Eo9FkahWK2NhY5s6dS5MmTfDx8cnCEgpTkVCWjZS2VrjH9zErj25Jkb+3nWfH/F20K9iF/357DIDCWoFrGXvyVXAkX3lH8lVwwP6VZUQSTyArXk8fylKrTalZsyZqtZqLFy9St25dE5UMo3mKDAFM38csi+cpyk1WrlzJv//+y8aNG7G1tTV3cTJFE6ch6kkskQ9iiHgQX/N1P4aI+yriItSMKDsFgKA/Q3EqaodrOUeKNLHFqbg9TsXtcCxsm6U1X+kVGBhItWrVsmUgQl7k4+PDjz/+yPXr16lYsWKGj7Nu3Tru3bvHkiVLsrB0wpQklJmQbT5r4kqHs/DMN3Sa2Qzfuk0JuxJJ2LVInl+LJOiPUO7u0jW72ea3xi0+oOUr74jrG664ublJKEuj0NBQ3NzcUCpTnidJ39n/3Llzpg1lkPx8TFJDlqLw8HC++uorGjZsmGNWYYgNVxP1REXkIxVRj3X/IuN/RockqvUCbN2scSpmR+GG+XAqZsv6P35nzvKZ3Ar+Dzt7O/PdiWRoNBoCAwPp0aOHuYuSa+g7+wcEBGQ4lGm1WmbNmkXlypWzbMCAMD0JZSaWuKO/ras1HvVc8ajnCug67IbfjTaEtOfXo3gS+ALQjZKa47uap/cf8vCvMPJVcMDB01ZGYqYgLQMiypQpg6urK2fPnjVRqV6RV+ZjygKzZ8/m0aNHbNmyxWKe81qNlujQWKIeJYStqMcqXQ3YI12NV2K2+ZQ4eNriVskRx8K2OHjY4ljUDqeidtg4G395KPKsAA/nB3Hj5g3D0kuW4r///iMsLEyax7JQpUqVcHFx4eTJk/Tt2zdDx/jjjz84f/48P//8c6aaQIV5SSgzsdRGX1pZK3B9wwHXNxygtS5QqF7EGQLavU03qaT15uKiIABsXJS4vuGASxn7+J8OOHjYWMyHljmltMRSYgqFwryd/UWaPHz4kFmzZvH2228bahRMRR2j0dVwPVERFV/jZfg9OBZtXEJ1l0IJ9oVscfS0pXCjfLrQVdgWB09bHDxs0jW7feIRmJYWygIDAwHp5J+VlEol9erVy9SkwbNmzaJo0aK8++67WVgyYWoSykwsvVNi2LpaU6iOK4XquLL41CF+XPojDy494fn1KJ5fj+TlrWju7HhqGPpu7WSFYxG7hA8ED1scCtvi6GGDXQGbNE1wmxuEhIS8NpSBrglz+fLlqNXqVJs6hflMmDCB2NhYpk2bluXH1mq1xL5Q62q6HiUNX6pncUbXt3awwqGwLc6l7PGo64pDfOhy9LTFzt0GK2XWvL4qVaqEQqGwyDUwAwMDcXJyMgRHkTV8fHyYOXNmhiYNPnPmDPv372fmzJk5vr9lXiehzMQyOk8Z6JrbwiPDiXJ4SfE3PSj+pi50qFUawu/F8PJWFC9vRRP5KIYXNyJ5cvK5YZJI0A0ocPCw0X2IeMR/g4//QHHwsEVpn3uqvENDQylbtuxrr+ft7U1ERAT//fdfpjrYiuxx4cIFVqxYwfDhw9P0eCZHE6cl+ml836740BUZ38wY9VhltIA2gJ27NY6ethSs4az7QuOZ8FqxcVaapCba0dGRUqVKWdQamHqBgYHUqVNHvsRkMR8fH+Li4jhz5gyNGzdO121nzZqFi4sLAwcOzKbSCVORUGZimQlliUdgJl46Q2lrRb6yDuQrazytgyZOS3RIbEJfF31H4ycqnl+JJC7K+MPINp+1oVbNIdEHkYOHLXb5rXNUs2hami/BuLO/hDLLM2bMGFxdXRk/fnyq14uNVCc8x/XhK/736KfGneqtbBS6GmRPWwpUcUqoTfa0xb6QjVlHNSZWuXJli6spU6lUnD17luHDh5u7KLmOvo9eQEBAukLZrVu3WL9+PZ9++in58uXLruIJE5FQZmKZrSkD3YswLf05rKwVOMbXhL1Kq9XqRofpawwexRAZX3Pw7HIkD48+N/4gs034INPXrDkU1vWVcfAw7/D8V2k0Gp49e5amUFa5cmVsbGw4d+4cPXv2NEHpRFr9+eef7N27l9mzvsNB40zY1UiiQ2KJCY0l+mks0fE/ox6riH1p3KnexkWJY2Fb3Co64uBr3JRv52adI5rxvby8OHDggEU1rf/zzz+oVCrpT5YNPD09KV26dLonkZ07dy5KpVKCci4hoczEIiMjsbKyylC7f6lSpYCsmatMoVBg62KNrYs1+ZJZiUMTqyEqODahxiHRyLJnFyNQx7zS5FPA2lCrlri5x9HTFhtX0zT56D1//hytVpumlQ9sbW2pUqWK+UZg5mFarZa4CDUxoXHEPIsl5llc/D9d4Lp7OIJ1nQ6R/5Q7RwOvGd3Wyk6BvbsN9u42ePi4JoxmjP9p7WgZISYzKleuTHR0NLdv385w021W03fyl5GX2aN+/focO3YszdcPCQlh+fLl9O7dm2LFimVjyYSpSCgzMX0nzoyEFBcXF9zd3bl161Y2lMyYlY0VTvHD9V9l1DnaENZ0wS30QjgPDxt3jlbaWxlGoBlq2vS1bR42r134OL3SMpt/YjVr1mTPnj1ZWoa0UKlUnD59mqioKFq0aGHy82cHrVaLOlqD6nkcqudqVM/jiAmLQ/UiDlVYnOFyTGgsqrA4NLHaJMewdrQiShFB8PMnePq480bdQtgVsDGEMDt3G6wdrXJUc3pG6DvSX7582aJCWeHChSlevLi5i5Ir+fj4sHbtWh48eEDRokVfe/3FixcTGRnJZ599ZoLSCVOQUGZiUVFRmZoFu0yZMmafQFahUGCbzxrbfNa4VUh6X9Qqja6G7YluDid9YIt8qCLkXLjxB7EC7N0T+rA5etjgUNjOEOAy0rE6I6Fs5cqVPHr0iMKFC6frXOkRHh7OiRMnOHLkCEeOHCEgIICoqCgA1qxZY5FD2bUaLbERamJf6v/FoYr/GftCjeplHKoX6vgQpvunUSUNWgA2zkps81ljl9+a/JUcsc1vg11+a+wMP3W/x6ijKV++PMWLF+fzmSdzffhKSeJpMdq3b2/m0ugEBgZSr169PPuYZLfE/cq6dOmS6nWjoqJYuHAh7dq1o0qVKqYonjABCWUmlpHhzomVLl2a8+fPZ2GJsp7S1grn4vY4F7dPsk+r1aIKizOuZXusIvJJLE9Pv0T1/JVaNgcrbF2U2LhYY+OixMY50e9Oun/WTlZYOymxcVRi7aQk5FEoChRpDmX69fvOnj2bpTNhP3nyhKNHj3LkyBGOHj3K2bNnUavVWFlZUbNmTT766CN8fX1ZtGgRH3zwAeXKlcvSvjqaOC3qaDVxURrUURriojWoo+IvR2vit6uJi9Togle4mrgItdHvcZGaFI+vsFZg66p7POzcrHEqaoetqxJbN2tDaDf8c7XGyjptH+Tzps7jwYMHrF27Nk9/+Lu5uVGkSBGL6ez//Plzrly5wnvvvWfuouRa3t7e2NjYpCmUrVq1iuDgYMaMGWOi0glTkFBmYpkNZWXKlGHHjh2ZXrjWXBQKRXzNiA35Kzkl2a+O1hhq1qIe60bOqV7EERuuq6mJfBBD7Et1kpGjiSkpxp7u54hYbMVfq69gba9EaW+F0k6BlZ0VSlsrlHZWWNkqUNpZ4U5p3qn0IQ/+eM5dRQgKACtdWVEACt3vCv2fO9E+hYL4/2kJfhrMpcuXuHT5Ev9e+pegoHtotFpsbKypWrE27wzrS9Vq1ahcpTJOzo6gUKBQQJ1pDRnyyVC+7j+V72bOIX++AmhUWjRxGjSxWt2/OC0alQZNnBZtom1qVcqBK/HEpqmxslHoQq2TEmtnJXb5bXAubqfb5vxKEI7/3dZV9zfN6tAUEhLCjBkz6NixI76+vll67JyocuXKFjMtxqlTpwCZNDY72dvbU7Nmzdd29ler1cyePZt69erJ6ySXkVBmYllRUxYTE8Pjx48pUqRIFpbMMijtrXAuaY9zyaS1bIlp4rTERepqdfQ1OvrancP/O8Ifu/5kxJBR2GJLXJQGTYwGdYyG2BdqolWxhsvqGC3qGA0fVBsB9+HqioeZKn8BytKYsjQu3QFKv7Lzvu7flb1PktxuRIXJuqusiuQ+kckeW6EEK2srrGwUKGwUWFkrdAHT3gprBytsXWyxdrBC6aDE2t4KpYNuu9JeGb/dKn57/OX421nZWE64nzp1KuHh4UydOtXcRbEIXl5erFq1Cq1Wa/ZaQ30nf5OvE5vH1K9fnxUrVhAXF4e1dfIf0Vu3buXGjRvMmDHD7M8LkbUklJlYVoQy0E2LkRtDWVpZWSuwddU1i73qxol/WP3v9yz/aF6Kb2qJaY9NpMcXa7kW7MCpgFOg0aI9NgFs86Gt/SlotMTEqLhw/gKnTp3i71N/c+bMWcJfhKNQKCjsWZjatetQy7sWtWrVotwbZVEorNBqAa02YQJfjTZ+m64ZF40Wra5eDisbBcdPHMV/lD9+b/kxb9FclLZWhhBmZaPIEdM4ZMadO3dYtGgR/fr1kz4y8SpXrszLly+5f/++2TvXBwYGUrFiRdzc3LL3RFqt8Tqwr17O5Xx8fFi4cCH//vsvNWrUSLJfq9Uyc+ZMypUrR+fOnU1fQJGtJJSZWGRkZJr7OiVHP1fZ7du3adiwYVYVK1cJDQ0lX758aQpkaLUoVGFUd7zKpqsQQyQuZyfw4tx8Tth05sihiRw5epTAwECio6MBqFixIr5tffH11f0rXbp0+r+tHp8IMWHQbK7uA0erpd3DPVx6tyRjFi+heNXCTJgwId33PSebMGECVlZWTJw40dxFsRiJR2CaM5RptVoCAgJ46623svdEybwuODQS7Nyg4cTsPbeFSNzZP7lQduTIEQIDA1myZInFzF8nso6EstfJ4m9tkZGRmXpz1c9VZoppMXKqtM7mD+gey2ZzqXn8Jtp9OxjQJB//PYVzDxVoNFtRKnfg7e3NJ598gq+vL40bN6ZQoUKZK6BWq/vgOTNfd7nZXN0Hz5n5fNbNn4vhRfn666+pXLky3bt3z9y5MltOE9VYnD9/nl9++YXRn31GiRIlTHLOnCDxCMxsD0SpuH//Po8ePcre/mSpvC6oNTzPPBfKli2Lu7s7AQEByS6bNHPmTAoVKsT7779vhtKJ7CahLDXZ8K0ts82Xjo6OeHp6mn1aDEuWrlAGoFBQ94Ol2H69gx2XoH5JGP/leBr7+tKgQQOcnZ2ztoDxQRCtVveBo/8Q8vZH0XweSxvGcP36dfr27UvZsmUNo0NNysQ1Fl988QX5nO0Y2/hFwodvHqwleZWHhwcFChQw+whMfX+ybA1l+tcFGL8uag1PeB7mAQqFAh8fn2Q7+//777/s2rWLyZMn4+DgkMytRU5nOT18LU3ib22HRiZ8QJyZr9uuTdvItldlNpSBrl+ZhLKUhYSEpC+UabUUvjKD+xMgbAoc+AQmNX/BW2++mfWBTO/EpBS329vbs3nzZgoWLEjHjh159OhR9pQhJdn03E/JoUOH2L17N+N61SH/9aUmOWdOoVAo8PLyMvsIzICAAGxtbZNtTstSCgU0+c54W5Pv8kwg06tfvz6XL1/m+fPnRttnz56No6MjgwcPNlPJRHaTUJaS+G9tWm9/fvtpPmc/tUJ7en6mv7VFRkZm+htOmTJlpPkyFemqKUv04V/Qdzi2YzS6xzhxIMlqWi3c2gtnFxhvP7tAt12rpXDhwmzbto3Q0FC6dOli6M+W5eVI7rK+xqLWcG7+OZ+9A60SmpCyuMZCq9Xy+eefU7x4cYbO3Zfwt5+TfefMaSxhYfLAwEBq1qyJnV3SFT6y1NqmsPSVCZyXFtZtz0N8fHzQarWGaUhA14S8Zs0aPvzwwzQtISdyJgllqVEoeO49kU82Q6254DUTJh7Kx5WrVzN8yKyqKbt79y5qtfr1V86DQkND0/6mpVDomscSf/jHBxLs3LInDGi1EJdCyIqLNoQjb29vVq9ezcmTJxk4cKBuxGZWOT7ROHTqw+nxibrL8X+HOYeh3XK4+oRsCUebN28mMDBQ1xzj6AhN5xhfoemcPB3IQNev7OnTpwQHB5vl/Gq1mr///jv75ydTqyH0EkQ9BYeCMCJO9zPqqW57Hnq/0/+tAwICDNvmz5+PWq1m5MiR5iqWMAEJZanRanE7N4kbX8DS7lDUFSZPmYyXlxc1a9Zk+vTp6aqxio2NJS4uLktCWWxsLA8ePMjUcXIjjUaT/j5lDScaBw59MMuufkxWVlCuE7hXN97uXl23PdGkwN26dWPy5Mn88ssvzJo1K2vOn5bmyfhtYdGg0cLEP8jymsO4uDjGjRtH5cqV6du3Lxz7Gn6tbXylX2vrtudhlStXBjBbbdmVK1cIDw/P/lCmVEJ+L1Da64LYPGvdT6V9/Pa8M9LQzc2NSpUqGfqVPX/+nB9++IEePXoYRuCL3MkkoWzRokW0a9eOdu3aMXPmzCT7L1++TLdu3WjVqhVffvklcXFxyRzFxF5p1hq4XsOBH4dz/yuYP7Qpjo6OfPHFF7zxxhs0aNCA+fPnvzYkRUbqJgXNbChLPC2GMPby5Us0Gk36px15tTbGFLUzr+abFPLO+PHj6dmzJ2PHjmXHjh2ZP69CgabJd5yw68H4b+fze59XmubB8Nx/af8GAGvPwfmdWduku2LFCq5du8a0adNQKhRwYzsEn4NCNWGkWvcz+JxuuyblFRxyu8TTYpiDSTr5g+559eImqF+pRVZH67bnsX6FPj4+BAQEoNVqWbZsGS9fvmT06NHmLpbIZtkeyo4fP87Ro0fZsmULW7du5d9//+XPP/80us7o0aP56quv2LdvH1qtlvXr12d3sV4vhWatIs2G49+rGcePH+fWrVvMmDGD6OhoRowYQfHixWnevDlLly7l6dOnSQ4ZGREBJAplGXyT0U8gmySUpdRHKA9J72LkZqHRQMA0CH1lDdPQ87rtrwQQhULBihUrqFWrFu+++y4XLlzI0Gnj4uI4dOgQw4YNo0TJkjQctp5v98O7a6DVj3CrlL/ueZ7ouf/SrhRVqlQhX758TAh4I8uadCMiIpg4cSKNGjWiQ4cOutrBsh0TgthcZUJAK9vRqPYwrylRogTOzs7Gnf1N+NoODAwkX758lC9fPntPpNWCXQrdDuzc89z7WX0fH4KDg7l27Rrz5s3Dz8+PWrVqmbtYIptl+ztdoUKFGDt2LLa2ttjY2FC2bFmjGqX79+8THR1NzZo1AejatSt79+7N7mKlzWuatUqXLs2YMWM4e/Ysly9f5uuvv+bhw4d8/PHHFC5cmDZt2rBq1SrdCJrjE4k8MA6ID2Wv9uFJh2TnKntdH6E8IiQkBMgBoUwbm/w+bWyytUKOjo5s27YNFxcXOnbsSPCTV5ZqSuEDS6VSsXfvXj766COKFi1K8+bN+emnn6hXrx6/fNGKkMmwqAucuANVq1Rk7pw5ur6KDSdC0zm8fPmSEiVK8Omnn7Lt2E1O2bTL5J3XmT9/Pg8fPjReJqbRJHjvtPEV3zut256HKU5MolIxx4SaMlO9tuOfUwEBAdStWxcrU9Qeh6YwyjSl7bnV8Yn4KI8AMHz4cB48eMCYli7pf8zli3qOk+2hrHz58obAdfv2bXbv3k3TpgkjaZ48eWI0GWehQoV4/Phxdhcr7dLYrFWpUiW+/vprLl++zLlz5xg9ejRXrlyhX79+eHp60vXzX1n32yoAHB0cMjXc387OjqJFiybUlCXqI3R77Yfc+O8/XuwarGuSymPTCeSImrLXPR4p7C9WrBhbt27l4YN7dHvTG1VMTML1E31IR0VFsW3bNvr27Yunpydt2rRh7dq1tGjRgvXr1xP85Alb/Evxnvs+CjQezpBNGv5d2Z9mpeMY9emnNGjQgPOrP4HDowgPD8fFxYXh/v64u9rz1dBe6bsvyXj69CkzZsygU6dONGrUyPhYh0cZX/nwqOTPkVc+bOJf25Wdn3Dp7AnTTRUS/yUvKjKS8+fP41OvXvYHQa0WtCl0XdHG5d7H+FXxj3m1sN9xsLNm37591ChbkLestqbvMZcv6jmSySaPvX79OoMGDeLzzz83NL8ByY4oy8kLrCoUCmrUqEGNGjWYOnUqgYGB/P7776xfv54t8WtdO+3rAV5kfLi/Vkvp0qWNaspiG83kiyVH+G7Dz8DPANjaKClYaAOFCh2iUKFCFCxYkEKFCiX5XX/Z3d09xy/boQ9lhtGXlriOnpUVKB1BnczC40rHVJvq6tWty4rRb9L7230M7lqbH3ecR3F4FOEn5rMrug2b5/dk165dREREkD9/fjp16kS3bt146623sLdPtMj7K03zJXsuZ6eHC+uO3sd/0V/U/uA0nzfT8OyxIy4NGuB65mvGNolm9M4bHDl8GN+mTdM/uWv8396w6Pi33xrvSzx7e+LZ3MH4dZKXluJRKMA2H15vFGH16Ye8mGqFqz26Zl3bfNk3Ojj+S97Ziw9Qq9XUc7gAZ3aYYGZ9Bcl3rsy5nwnpFt8iYw3UKTqfI7dgtM9TFLXT8XkhqyPkWCYJZadPn8bf359x48bRrp1x84enp6dR/6vg4GA8PDxMUaxsp5+Z2cfHh++++44jf/3FiVktaFYu/goZCWTxH0hlypTh2LFjoNUStGEAPb/5k+MX7jGwPjQsBcEREOw1iqchIQQHBxMcHMytW7d4+vRpkgkJE5e3QIECyQa2lMKc0Qd9VspgmDKqKbPUD2+FAqwckg9lVg6p30+Fgnen7OHf2z5MXXMK28ZK7r+AfdeUxMTuwcPDg969e9OtWzeaN2+OjY1N8sdpONH4b6pQoGg+j3daKHhrSAijRo3i29WrgUhc/vsZzsDgjtX57vB5vhz2LofP3UNxeFTa3+TjH4vbpYfz/fff079fPyo/+RGeu+nKktLUJGDcjy2vfdhotaB6TmVn3Te6y4/BpxS6/nYlmmbL/dUC98t9yuW/77B65QYA6sbugEYZ/BKZVhoNKY52Qavbn8O/NKZZ/PO/c9X5vIiBHjVI399eVkfIsbI9lD18+JAhQ4Ywd+5cGjRokGR/sWLFsLOz4/Tp09SuXZutW7fSpEmT7C6WySmtrGjGNpr5Jdp4aGT6XiCJPpBKU5e19+6xe3pn3v92O1FqG377shW98u9LuH4tFTT7KcnxVSoVT58+Ncx9FBwcbPS7/vK1a9c4duwYISEhKc6J5uTklGrt26u/58uX7/U1oRkNU1qtIZTld3OD6GcJE7Ra0oe3RgOxIcnviw3R7U+tY7tCwZRVJ7j0jzVLTkDxfDDo48F0696dRo0apb22M4WmeXd3d1atWkXvd99l3IDWNCqt2+344Vm+vODHsIWHODJUSZOypO1NPtHzdsK0fbpFx1uR9LFoOFE3F1XiPpxNvjP+IM5rHzYKBTSdQ5nje4Gr3AuLD2WFaibM4ZbBLzBqtZrbt29z+fJlLl26ZPTz5cuXhus1KAVFXMn+v6/1az6OXrc/N4l/zxvVFEbpe/uk9/NC/1rRv0Ygd75Gcplsf5YvX76cmJgYpk+fbtj2zjvvcODAAfz9/alWrRqzZ89m/PjxREREJMxZlJukp2kmNYk+kMoEzEethnbjtlO1jDsbJrShUsivaTq+ra0tRYsWpWjRomkqvkajISwsLMXwpv/9yZMn/PvvvwQHBxMVFZXssWxsbChYsGDKtW8FC1Iw6AKFHmymUGgE7h0XY3109OvDVHyQCw1R4OLiklBDVNjH8j68XzcJplqd+geQVovVX5+y7j24GgxVPMGqjhX4+mbd/dJqaWm7h5YjEm07PIoPpu7gi2UurD6NLpSl5W8Z/7zdcuQ/fv3fLsY0g+L3ViR9LNY1g5jnus79Vla6cLqmDtjlg56HkhwvT3zYxPezKxCjm7A6VP+yCj6n629nmw9Uz1P9AqNSqfjvv/+SBK+rV68arRRRpEgRvLy8eP/99/GqVInKqoN4Pd+Eh36lsfSGgvSKTWHwS+L9trbZc25LklWfF/rjJJbdj6HItGwPZePHj2f8+PFJtvfqldBhuFKlSmzcuDG7i2I+aW2aSeuxms2l5nbdC7RfHfj+0B0c/5kFMVlw/GRYWVlRoEABChQoQMWKFdN0m8jIyBTDW+Lfz549S3BwMM+ePUvmKD9R0Okn/hoMXm1SCVOJamJCL3vpmi4PjdTVknn7w6OEWbEt4g3pdTVZqe1P9IZtW2841TL6hp2aVD4UHO8dpktV2HheN2rTPo1v8kuXLWPwpD3UKwHj9LXFiW+n0egCWfA53YSx753W/dRPi5G49jAvfdjE9ykrULI6cJ6QiPjthWqCjasukMU/9pH1vuXqmo+4dPh3Livqcmn2eS5fvsx///1nNPdj6dKl8fLy4s0338TLy4vKlSvj5eWFm5ub7gqGx38TNM1EKMjIfc3M/twiKz4vsirYCZPLQ/XBZpZMH56MdvLn0EhqF4fgSVDQCQj8MuFFm9njZxFHR0dKlSplmL7jdWJjYwkJCUkIbE+eELzuHb7eB31/hxPfzsI6pfuS6E3r3g/zKRCH7s3H2z/pdS3hw1upBBtniA1Pus/GOfVQlpUBPz3naDoH7h2G4HO816Mzv3y+lV0xben2mjd5rVbLpEmTmDRpEm19SrO+422c9MsnJn4srKyMg9jc+L9BoZoJNWe6A+atD5v4PmUOz8/jYGdNaOXhUCtOd39LNIWmc3geHkOrfvMJvDffMNBOqTxDuXIv8PLyomvXrobwVbFiRZycnFI/pymeYymdNzP7c5PMfl6Y6zEUmSahzJTSOL1Gil75QCqY3AdSZo5vRjY2NhQuXJjChQsn3M9G4OkMb/8C0wY14avlx1O+TwoFq+96c+A/GP9mou1nF1jmh3cBL3h8Kvntr5NVAT8959BP7lqiKS0az8JzTgnW/GNHt2HDU3yTj4uLY8iQISxbtox+rbxY1uIyNnVTeSz0wWxuolCaOJDp72te+rBJdH8LFNxI6LNnun6ioNtuZcWSiyUJuAtftADvYlB5zAXKV6iAbWaa+kzxHHuVlRWgBJJr3lfmvQmEM/t5YY7HUGSahLKcJC98IL0SPLuPmkuv+5WYvOok7ev3xvujNcnez3NnzzJo4Ic0KwtfvxW/8WGArrbM0v5WWi28vJv8vpd309ZRO7Nv2Gnx6jEbTQKtFmuFgl69erF48WKe/fSQ/MnMCRcVFUWvXr3Ytm0b48aN45u21igS931K7rHQaJJf+/LVYJbXPmzi76+7+0Hd5MiJ7m90VBTzZn3DWxVgatv46wf/BFXmpnbEtDHFcywxrRaUtqBOpj+q0jbvzFOWlUz9GIpMy2NfPXIBUy+ebWrJBM9F649T0M2RvjP2E6NSJbnJs9BQurVrjruDmrUzBmA9WqO7feK+ZPpjW8LfSqGA2PjpMGoOg1Ea3U/QbbfkN874svXu3RuVSsXGTZuSXCU0NJS33nqL7du3s2DBAr799lsUjSal/rzVB7Lk1r78tXbSVQ7y2oeNQjddjX50sb5T/+rx7Xn8LJLPB3bRPY9qDTdeaD6neXXdy9dtFyKXkVCWE+X2D6RXgmcBd3eWr17PxZtPmDhxotFVNRoNffr25V7wSzZ80wPPrssSPvBrDQf7/MZ/H0v5W9m6pm+7halduzYVK1ZkzZo1Rtvv3buHr68vp06dYt26dQwbNixhZ2rPWysr3SjLxH3I3jutu2yXL+81XSWjQIEChmXEANQaDbPWn6NORQ9ajNxo/Lw3d21wRlhZ6fpUJsfGWZ4DIk+QZ7mwTK98oLRt144BAwYwc+ZMThw/btj+zTffsGvXLubNX0iDIWtzTg1ihW66n+cWwhwr3c/E2y2cQqGg97vvcvjwYe7e1TXF/nvxIg0bNiQoKIi9e/fy9ttvp++gPQ8ZN1Xqg1ni6TDyMHd394SaMmDz5s38FxTK51MWodD/zSz9ef86+i8lr9Yg55AvK0JkloQykWN89913lPBw4f2e7YgID2fPnj1MnDiRPm9V4pMaj3NODaJCAc3nJR0d6u2v226p5U7s+ER6l70FwO+//86xo0dp3KAOcVFh/PXXXzRv3jxjx321NkRqRwz0zZdh2jDitHHMmDGD8uXL06VrV+Mr5oTnT0pciut+Jv5ylXi7ELmcvOOJHMPVxYWfR/txPSiMDzvWpnfv3lR/w50fml/RdSLPaX1ocuqi2vHzwr3xaCUNKhdh/vz5vOnXDA+HGE4sfJsa1aubu4S5Sgwx/MqvrHRfiUqlwiPCA5sDNpw+fRrf0b7EKVNYxDunUSigdCsoWEM3anqOle5nwRq67Tk5bAqRRhLKRM6hUNB85Eb8u9Zk3cFraKOfsentpzjWT2ViWUuk1cKa+glNlnrnFuq2W3o4S9R36b2KD3n48CHVPdUcWzaQ0u8szzmPQw4QSCBFKconfMLjAo8BiA2NhelAYVjXZx1FKcopkpleJafRauHCcnj6j/H2p//otlv660KILCChTOQsCgXTVh/l/TqwsS+ULUjOCmRgPCVG4pGGkDAlhqWLD2Yf+sDKnnDgYyjY6Yec9ThYuFOcogUtCCWUcMJBP/PIn8D/gJEQYR9BKKE0p3nOD2ZaLWhSqPXTxOWM14UQmSShTOQsWi2OgV+y8h3wKx+/LacN/7eyguoDE6Z8mKtMmAqi+sCc0Y8qfj45O2t4vy66Wfpz2uNgwWKIoTWtiSAiYaM+lH0NuAIDE3ZFEEFrWhNDjAlLKYTIajng3V+IeK8usZOT52VqNEk3sjCx907rtlu63PQ4WKgNbEBFwpx8Xx+HMTfiL9wHPoa5Z3Xb9VSo2EgOXkNY8f/27j0oqvL/A/h75WaId4GkH2GNYgo5IjdBRPECDuyKSmZ5KaUc/I6ahhdgSPE6gpqZmoXM6KjZH0pqIqZ5n/JeeRnJxFFJDBEQE5frsnx+fxCbCLoquLss75d/6HnO4eyH89ldP/s8z55HAbR9wrJsbV3YC0vNAosyajqetKJBU7wvkwhwPLp22/HoplHQmFMeTFQSkqqHLAFAgHblwIysf3faAAu8gZm/V7fj36eMGmokItEI0TYiR5/naycyM1xmiZoWc1hixxwW1TaHPJgoLbTIQMZ/DQrg04FAZQVgbQFM8gAS/gJW96luxyOXPAMZ0EILCzxlUXtTJQJce0JP37VUYNCXfH6R2WNRRk1PU7kf2ZOYyxqmTT0PJkoNNaxgVWv4EgpgTjDw23TgLYfqpk8HolZBBgCWsIQaarRFWwNF24gUCkDxhMEbRQs+v6hZ4PAlkTGY+xqm9MLsYAcNNLUbBfjiGNDn/wBb6+qmL45BN3RZoxKVsMMTlipqClo7V//t8Un1XMWaGyzXtBOZOfaUERkLe5qoHhawgBvccBmXqxv+Lchm/v7fkGXNNlC7x8wNbk1z6BKofv6/MQzo7PvfyhZBq6v3Pb6GLZGZYlFGRGRiYhCD/+F/1ZP9FcA/NrXnkH06sPq4f2ygK8jsYIdYxBoj3MZT31zFprL0GFEjYFFGRGRiRmM0ZmCGbnuhP6qHKmtqE0XdOWXWsMY7eMdgMb407EGmZoxzyoiITIwNbLAf+9EKrf5rfLw2eWS7FVphP/bDBjYGiY+IXg4WZUREJsgb3jiKo+iADk+cvG8HO3RABxzFUXjD28ARElFjY1FGRGSivOGNHOTgG3wDd7hDAQWsYAUFFHCHO77BN8hBDgsyIjPBOWVERCbMBjYY9+8fLbRQQw072DXdb1kS0ROxKCMiaiIsYNE0bwxLRM+Ew5dEREREJqBJ95RptVoAQG5urpEjISIiInq6mnqlpn55XJMuyvLz8wEA48aNM3IkRERERM8mPz8fLi4uddoVIiL1HN8klJWV4fLly7C3t4eFBSe9EhERkenSarXIz8+Hu7s7WrZsWWd/ky7KiIiIiMwFJ/oTERERmQAWZUREREQmgEUZERERkQlgUUZERERkAliUEREREZkAFmVEREREJoBFWSNIS0tDaGgohg4dim3bttXZv27dOgQFBSE8PBzh4eH1HkONQ18ubty4gQkTJmD48OH46KOP8ODBAyNEaf6elocrV67oXgvh4eHo378/lEqlkSI1f/peExkZGYiIiMDw4cMRFRWFoqIiI0TZPOjLxfHjx6FSqaBSqTBr1iwUFxcbIcrmQa1WQ6lU4vbt23X2XblyBREREQgJCUF8fDwqKysNF5hQg+Tm5kpQUJDcv39fiouLRaVSybVr12odExUVJb///ruRImw+9OWiqqpKgoOD5fjx4yIismLFClm+fLmxwjVbz/KaqFFSUiJhYWFy7tw5A0fZPDxLLt5//305duyYiIgsW7ZMVq1aZYxQzZ6+XDx48ED69u2ra9uwYYMsXrzYWOGatQsXLohSqRQ3NzfJzs6usz8sLEzOnz8vIiJxcXGybds2g8XGnrIGOnnyJPr27Yt27drB1tYWISEh2L9/f61jLl++jJSUFKhUKixatAjl5eVGita86ctFRkYGbG1tERgYCACYMmUKl+h6CZ7lNVEjOTkZ3t7e8PLyMnCUzcOz5KKqqkrXI1NaWlrvXcap4fTlIisrC05OTujatSsAICgoCIcOHTJWuGZt+/btSEhIgIODQ519f//9N8rKytC7d28AwKhRo574/vUysChroLy8PNjb2+u2HRwccPfuXd12cXExevTogZiYGOzatQtFRUVYv369MUI1e/pycevWLXTq1AkxMTFQqVRISEiAra2tMUI1a/ryUKOoqAjbt2/HtGnTDBles/IsuYiNjUV8fDwCAgJw8uRJvPfee4YOs1nQl4suXbogNzcXf/75JwDgxx9/REFBgcHjbA6WLl36xA+Cj+fJ3t6+3vevl4VFWQNJPatUKRQK3b9btWqFlJQUuLi4wNLSEpGRkTh+/LghQ2w29OWisrISZ8+exfjx45GWlgZnZ2ckJiYaMsRmQV8eaqSlpWHIkCHo2LGjIcJqlvTloqysDPHx8di8eTN++eUXjB07FjExMYYMsdnQl4s2bdogKSkJ8+bNQ0REBBwcHGBlZWXIEAnP/v71srAoayBHR8dan2by8vJqdYnm5OQgNTVVty0isLS0NGiMzYW+XNjb28PFxQVvv/02AECpVOLSpUsGj9Pc6ctDjUOHDiE0NNSQoTU7+nKRmZkJGxsb9OrVCwAwZswYnD171uBxNgf6cqHVavHqq69ix44d+P777+Hu7g5nZ2djhNqsPZ6n/Pz8et+/XhYWZQ3k7++PU6dOobCwEKWlpfjpp590c5YAoGXLllixYgWys7MhIti2bRuGDh1qxIjNl75ceHh4oLCwUDc8cOTIEbi5uRkrXLOlLw9A9YeTjIwMeHh4GCnK5kFfLlxcXJCbm4sbN24AAA4fPqz70EKNS18uFAoFIiMjcffuXYgINm7cyA8tRvDaa6/BxsYGv/32GwBg9+7ddd6/XiqDfaXAjO3Zs0fCwsIkODhYNmzYICIiH3/8sVy6dElERPbv36/bHxsbK+Xl5cYM16zpy8WFCxckIiJCQkNDJTIyUgoKCowZrtnSl4eCggLx9/c3ZojNhr5cHDt2TFQqlSiVSvnwww/l1q1bxgzXrOnLxdGjR0WpVEpwcLAkJCRIRUWFMcM1e0FBQbpvXz6ahytXrkhERIQMGzZMoqOjDfp/tkKkngFUIiIiIjIoDl8SERERmQAWZUREREQmgEUZERERkQlgUUZERERkAliUEREREZkAFmVE9NJUVlYiNzfX2GE0mtzcXFRWVho7DCIyUyzKiKiO9evXw9PTE/369YNGo3nh80RHRxtlUeXGiv9RBQUFGDZsGMrLywEA8+fPxxdffNEo526o7t27IzMz09hhEFEDcb0fIqpj586diIuLwzvvvNOg89y/f7+RIno+jRX/o8rKylBaWqrbXrRoUaOdm4gIYE8ZET0mJCQEt2/fxqJFi3SFx3fffYfg4GD4+vpi6tSpyM/P1x2/ZcsWqFQqeHp6wt/fH2vXrgUALF26FL/++isSExORmJiIM2fOwNfXt9Zj+fr64syZMwCqe3sWLlwIb29vJCcnQ6vVYt26dRg0aBD8/PwQFxcHtVr93PGvXbsWUVFRCA0NRWBgINRqNdLT0zFq1Cj4+PjAx8cH8+fP1y1EfOfOHUyZMgV9+vRB//79sWnTJgBAREQEACAgIAB//PEHYmNjkZSUBKC6F23WrFnw9fXFgAEDsHz5clRUVAAAYmNjsWTJEowdOxYeHh4YNWoUMjIy6sR94sQJ9OvXD1qtVtcWExODFStWPPU6P+7xXrNPPvlEd2xZWRmWLFmC/v37IyAgAElJSbo4c3Jy8MEHH8DLywtDhgzB8uXL612cmYheIoOtHUBETUZQUJAcOXJERET27dsnAwYMkMzMTCkrK5Nly5bJuHHjRETk3Llz4ufnJzdv3tRtd+/eXbKyskREZPz48bJ161YRETl9+rT4+PjUehwfHx85ffq0iIi4urpKXFyclJeXy8OHDyUlJUWGDx8uOTk58vDhQ5k5c6bMnTv3ueNfs2aN9OrVS65evSpFRUWSnZ0tvXv3losXL4qIyLVr18TDw0NOnjwpIiKjR4+Wzz77TEpKSiQrK0v8/f3l559/luzsbHF1dRW1Wi0iIjExMZKYmCgiImPGjJHo6Gh5+PCh5ObmSkREhKxYsUJ3nJeXl1y5ckVKS0tl5syZEhkZWSdmrVYrAQEBujhKS0vFw8NDMjMz9V5nV1dXuXr1ap1/i4hMnz5d1qxZIyIiCxYskEmTJklhYaHcu3dPxo8fL19++aWIiMyePVsWL14sWq1W7ty5I4GBgXLixIlnut5E1DjYU0ZET5WamoqJEyeiW7dusLGxQXR0NC5evIibN2/Czc0NO3fuRJcuXVBQUACNRoOWLVsiLy/vhR4rLCwM1tbWsLOzQ2pqKqZNm4bOnTvDzs4Os2fPxp49e3Rzup5Hjx494OrqitatW8PBwQFpaWno1asX7t+/j3/++Qdt27bF3bt3kZ2djYsXL2Lu3Ll45ZVX4OLigs2bN6Nnz55PPPetW7dw/vx5xMfHw87ODo6OjpgxYwZ27dqlO2bQoEF466230LJlS4SGhiIrK6vOeVq0aAGVSoX09HQAwJEjR+Di4oJu3bo1ynUWEezcuROzZ89G+/bt0aFDB0yfPh3bt28HANjY2ODcuXM4cOAAbG1tcfToUfj7+z/z+Ymo4TinjIie6s6dO1i9ejXWrVuna1MoFMjJyYGTkxPWr1+PAwcOoGPHjnB3dwcAVFVVvdBjderUqdbjzp07FxYWFro2S0tL5OTk4I033niu89rb29c6x44dO5CamgpbW1v07NkTGo0GVVVVuHfvHmxtbdG6dWvd8V27dgUAlJSU1Hvump/p0KGDrs3JyUlXPAGotc/S0vKJw4IjRozAhAkTkJCQgL179yI8PBxAdcHW0OtcWFiIsrIyTJgwAQqFAkB1oabRaFBeXo74+HisWbMGq1atwqxZsxAYGIglS5bUygkRvVwsyojoqezt7REZGVlr0vz169fh7OyMjRs3IjMzE4cOHULr1q2h0Wiwb9++es9jYWFR65uQGo0GxcXFtY6pKRZqHnfx4sXw8/PTHZ+dnY3XX3/9uX+HR8+bnp6Offv2Yffu3bpibfDgwQAAR0dHlJSU4OHDh7rCbO/evWjTpg3efPPNes/t5OSEkpISFBYW6oqv27dvo127drCysnquOF1dXdG5c2ccPHgQJ0+exMKFCwEAmzZteubr3KJFi1rXuebLFjXx7N69G87OzgCqC82CggLY2NjgwoULmDx5MmJiYnDr1i1dkcYvNBAZDocvieipRo4ciU2bNuGvv/5CVVUVtm7dinfffRelpaVQq9WwsrKClZUViouLkZSUBI1Go7uXl7W1tW5yvrOzM0pLS3Hq1ClotVqkpKQ89Z5fI0aMwFdffYW8vDxoNBqsXr0akydPbvDkc7VaDUtLS1hbW6OiogIpKSm4ffs2Kisr0blzZ3h5eeHzzz9HeXk5srKykJiYqDu+5ucf5ejoCD8/PyxduhTFxcW4e/cu1qxZA5VK9ULxjRgxAsuXL4eXl5euaNR3nR/VpUsXHD58GCKCEydO4MKFCwCqi2KVSoWVK1eiqKgIJSUlmD9/PmJjYwEAX3/9NVauXIny8nJ07NgRFhYWaN++/Qv9DkT0YliUEdFThYeHY/To0Zg8eTK8vLzwww8/IDk5GW3btsWkSZNgaWkJPz8/hISEoKKiAn369MH169cBAEqlEsnJyZg3bx4cHR0xZ84cxMXFwd/fH2q1+qlztaKiouDp6YkxY8agb9++uHTpEpKTk2Fp2bAO/pEjR6Jbt24ICgrCwIEDcfnyZQwdOlQX86pVq5Cfn4/AwEBMnDgRU6dOhb+/P+zt7TFgwACEhITg9OnTtc65cuVKVFVVYfDgwQgPD4enpyfmzJnzQvEplUrk5+frhi4B6L3Oj5o3bx4OHjwIT09PfPvtt1Aqlbp98fHxaN++PcLCwjBgwACo1WrdvdYWLFiAvLw8BAQEYODAgXBwcEBUVNQL/Q5E9GIU0tCPnURERETUYOwpIyIiIjIBnOhPRE3Kli1bnrq8UXp6OpycnAwYERFR4+DwJREREZEJ4PAlERERkQlgUUZERERkAliUEREREZkAFmVEREREJoBFGREREZEJYFFGREREZAL+Hw00gy4ROffUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda_l1</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.937306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lambda_l1       MAE\n",
       "13       20.0  1.937306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.0322]), array([1366.]), array([14.]), array([0.702]), array([22.]), array([0.7812]), array([20.])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda_l2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.961573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lambda_l2       MAE\n",
       "3        9.0  1.961573"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.0322]), array([1366.]), array([14.]), array([0.702]), array([22.]), array([0.7812]), array([20.]), array([9.])]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#array of the hyperparameters we tuned\n",
    "arr_hypers = [\"learning_rate\",\"num_leaves\",\"max_depth\",\"bagging_fraction\",\"bagging_freq\",\"feature_fraction\",\"lambda_l1\",\"lambda_l2\"]\n",
    "arr_best_hypers = []\n",
    "#iterate through each of these hypers\n",
    "for hyper in tqdm(arr_hypers):\n",
    "\n",
    "    df_max_depth = pd.DataFrame(columns = [hyper,\"MAE\"])\n",
    "\n",
    "    #iterating through each column and randomly decide whether or not to pick it\n",
    "    #iterating through every single models results\n",
    "    for i in range(len(all_results)):\n",
    "        # adding this models mae to the dict entry for this column\n",
    "        df_max_depth.loc[i] = [all_results[i][1][1][hyper],all_results[i][0][1]]\n",
    "\n",
    "    #sort in ascending order by the params values\n",
    "    df_all = df_max_depth.sort_values(by=[hyper])\n",
    "    # display(df_all)\n",
    "\n",
    "    #grouping together by value and calculating mean\n",
    "    grouped_df = df_all.groupby(hyper)\n",
    "    mean_df = grouped_df.mean().reset_index()\n",
    "    #display(mean_df)\n",
    "    \n",
    "    # the minimum point\n",
    "    df_min = mean_df[mean_df['MAE']==mean_df['MAE'].min()]\n",
    "    arr_best_hypers.append(df_min[hyper].values)\n",
    "    display(df_min)\n",
    "\n",
    "    #plotting the stats for this param \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    print(arr_best_hypers)\n",
    "    \n",
    "    plt.scatter(df_min[hyper], df_min.MAE, label=\"Minimum Average MAE\", color=\"lime\", marker=\"o\",s=200)\n",
    "    plt.plot(mean_df[hyper], mean_df.MAE, label=\"Line of mean MAEs\", color=\"black\") # line of means\n",
    "    plt.scatter(df_all[hyper], df_all.MAE, label=\"Scatter of MAE values\", color=\"darkorange\", marker=\"x\") # scatter of values\n",
    "    plt.plot(np.unique(df_all[hyper]), \n",
    "             np.poly1d(np.polyfit(df_all[hyper], df_all.MAE, 3))\n",
    "             (np.unique(df_all[hyper])), label=\"3rd Degr Regressor Line\", color=\"mediumorchid\") # line of best fit from a simple regressor\n",
    "\n",
    "    plt.title(f\"MAEs for {hyper} values\", fontsize=15)\n",
    "    plt.xlabel(f\"{hyper} values\", fontsize=13)\n",
    "    plt.ylabel(\"MAE\", fontsize=13)\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(f\"..\\\\Results\\\\Genetic Algorithm\\\\Plots\\\\p{population_size}_g{number_of_generations}_scatter_{hyper}.png\")\n",
    "    plt.close(fig)\n",
    "    del fig\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspecting stats on all models TOE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m\u001b[92m\u001b[4mmin time of execution = \u001b[0m0:00:34\n",
      "\u001b[1m\u001b[92m\u001b[4mmax time of execution = \u001b[0m2:05:11\n",
      "\u001b[1m\u001b[92m\u001b[4mmean time of execution = \u001b[0m0:30:54\n",
      "\n",
      "\u001b[1m\u001b[92m\u001b[4mmin MAE = \u001b[0m1.7620903897052624\n",
      "\u001b[1m\u001b[92m\u001b[4mmax MAE= \u001b[0m4.874488996625159\n",
      "\u001b[1m\u001b[92m\u001b[4mmean MAE = \u001b[0m2.3435214547070236\n"
     ]
    }
   ],
   "source": [
    "#inspecting the min/max/mean of time of execution of the models we tested in genetic algorithm\n",
    "all_toes = []\n",
    "all_maes = [] \n",
    "\n",
    "for i in range(len(all_results)):\n",
    "    #getting the results for this model\n",
    "    all_toes.append(all_results[i][0][0])\n",
    "    all_maes.append(all_results[i][0][1])\n",
    "    \n",
    "print()\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}min time of execution = {color.END}{str(datetime.timedelta(seconds=round(min(all_toes))))}\")\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}max time of execution = {color.END}{str(datetime.timedelta(seconds=round(max(all_toes))))}\")\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}mean time of execution = {color.END}{str(datetime.timedelta(seconds=round(np.mean(all_toes))))}\")\n",
    "print()\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}min MAE = {color.END}{min(all_maes)}\")\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}max MAE= {color.END}{max(all_maes)}\")\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}mean MAE = {color.END}{np.mean(all_maes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the results of the hyper parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:47:26\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9613953222789904\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:25:35\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9545496564525262\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:33:22\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9893042071070084\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:15:24\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.104339142211311\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 2:05:11\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.556059624900032\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:19:24\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.940315728516418\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:17:54\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.968497160805084\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:18:03\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.847143408360674\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:29:19\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9204283711022805\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:09:18\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.917201382320318\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:26:50\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.055569770316942\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:34:57\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9485668795630773\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:57:58\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8512619056978388\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:24:18\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 3.5860109784659673\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:21:26\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7706509815955915\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 0 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:33:53\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 3.394523048051363\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:43\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.8783065284208966\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:49:57\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9322025170494497\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:55:58\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8063508512431472\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:07:17\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6560313302932026\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:07:51\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9718196458001347\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:07:24\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9861449291769009\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:31:39\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.995413931519118\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:16:09\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.936556651248347\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:27\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 4.874488996625159\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:24\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.957050447763349\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:27:09\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.017782856139977\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:00:46\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9213007071718882\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:52:22\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.0777106766063187\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:49:12\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9247416043691927\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:31:17\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.0929108519124098\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 1 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:45:40\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9373062517111963\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:17:53\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.068219447869392\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:37:22\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.047734005990894\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:32:28\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.0515308843140136\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:54\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.4674489974021103\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:36:51\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7896385599918885\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:45\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.889463123946761\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:53:02\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9802795799608104\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:34:28\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9809126990063726\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:57:58\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.359556421410664\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:17:58\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9780352146407938\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:54\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 3.3406849533151974\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:34:29\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9144410541767063\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:20:02\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.5455730165075514\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:32:44\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.491511721609332\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:08:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.963989065516599\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 2 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:46:00\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.7662300553885766\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:06:34\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.4692114814343293\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:48:07\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.000701447477092\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:28:49\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.981763034349137\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:07:00\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.0324198030697493\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:07:29\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8194922981046873\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:36:27\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.0923375711392547\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:45\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 3.3422097389795744\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:13:50\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9687656944185952\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:53:30\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.89084878946267\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:10:50\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.982375015961693\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:18:04\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7955796378077282\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:15:44\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9407434011182054\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:47:59\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9549085292011277\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:08:20\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6620558970647967\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:50\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.8912054564125738\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 3 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:41:13\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.0125712599823804\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:59\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.655653136295402\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:12:41\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9085588108861464\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:01\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 3.4208724057470525\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:21\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.935310580822101\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:36:47\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.025439690733623\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:10:14\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9376935069266776\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:58\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6500745911545334\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:20:40\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8230964460566401\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:22:02\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8268075737495748\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:39:24\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.068382619494793\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:07:17\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6616113743707577\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.866632021729269\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:06:58\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.4630112723547284\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:37:35\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.928892004539765\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:14:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.963542350384091\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 4 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:04:18\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 4.603857093453268\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:47\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 3.34329049054489\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:44\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 3.3426172661506524\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:53\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6599391239872543\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:50:42\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9222558611812945\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:04:02\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.64059406441122\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:07:16\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.968236634573859\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:11:37\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.924906133803524\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:14\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 4.747563636074709\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:07\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.888474411104032\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:04:13\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6638845914902554\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:04:09\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.881850634832775\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:54\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6930748726637357\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:12:26\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6319080776095642\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:17:54\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.0105028403320206\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:24:29\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9813779668160731\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 5 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:20:27\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9409982884239452\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:16:34\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9692072233712665\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:52:37\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9859850805544454\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:21:52\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.040760233400258\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:34\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 3.0092388749065946\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:38:55\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9647530921800713\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:10:57\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7766013179965336\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:07:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.8830927687172165\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:39:00\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9704162199542794\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:05:02\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6894197775824344\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:00:34\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 4.7752323541128785\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:37:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9663137631031344\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:50\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.8919550998636545\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:30\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.975965533887288\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:21:26\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9371346026683423\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:14:49\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9794185869909895\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 6 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:03:38\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6596835480379633\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 0 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:58:23\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8608947144460055\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 1 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:33:02\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9953799527503173\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 2 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:08:03\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.6479383450744525\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 3 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:07:18\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.960682812240893\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 4 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:01:47\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.671733116339281\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 5 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:01:17\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.953746339206569\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 6 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:02:19\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.8940933453371636\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 7 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:34:43\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7620903897052624\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 8 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:39:15\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9624522565277074\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 9 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:23:42\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9798385693137246\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 10 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:15:12\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.924552977294378\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 11 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:16:19\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9801834640526044\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 12 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:23:53\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.976798350915892\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 13 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:33:48\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 2.0077177474335537\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 14 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 0:28:00\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.9402164840790943\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mgeneration 7 individual 15 \u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:\u001b[0m 1:24:57\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.791964685929182\n",
      "\n",
      "best model is at generation 7 individual 7 with a MAE of 1.7620903897052624\n"
     ]
    }
   ],
   "source": [
    "best_index = 0\n",
    "best_mae = 999999\n",
    "\n",
    "for i in range(len(all_results)):\n",
    "    #getting the results for this model\n",
    "    LGBM_TOE = all_results[i][0][0]\n",
    "    LGBM_MAE = all_results[i][0][1]\n",
    "    #displaying the results\n",
    "    print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}generation {int(i/population_size)} individual {i%population_size} {color.END}\")\n",
    "    print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution for skf-cv:{color.END} {str(datetime.timedelta(seconds=round(LGBM_TOE)))}\")\n",
    "    print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set:{color.END} {LGBM_MAE}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    #keeping track of the best performing model\n",
    "    if(LGBM_MAE<best_mae):\n",
    "        best_mae=LGBM_MAE\n",
    "        best_index = i\n",
    "print(\"best model is at generation\",int(best_index/population_size),\"individual\",best_index%population_size,\"with a MAE of\",best_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model based on the best models \n",
    "* Done this as no longer storing the models in memory as was running out\n",
    "* So instead just storing the configuration\n",
    "* Then this is used to retrain a model with that configuration\n",
    "    * Should fix the problem of running out of memory whilst running the GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no longer need all results only the best one\n",
    "best_results = all_results[best_index]\n",
    "del all_results\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7020000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7020000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.82543\n",
      "[6666]\tvalid_0's l1: 1.78618\n",
      "[9999]\tvalid_0's l1: 1.76484\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9979]\tvalid_0's l1: 1.76478\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7020000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7020000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.81806\n",
      "[6666]\tvalid_0's l1: 1.77848\n",
      "[9999]\tvalid_0's l1: 1.75674\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.75672\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812\n",
      "[LightGBM] [Warning] lambda_l1 is set=8, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7020000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7020000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10\n",
      "[LightGBM] [Warning] bagging_freq is set=21, subsample_freq=0 will be ignored. Current value: bagging_freq=21\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.82576\n",
      "[6666]\tvalid_0's l1: 1.78777\n",
      "[9999]\tvalid_0's l1: 1.76479\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's l1: 1.76478\n"
     ]
    }
   ],
   "source": [
    "best_X_cols = best_results[1][0]\n",
    "best_X_cats = list(set(best_X_cols).intersection(all_cat)) #getting the categorical values for this X\n",
    "best_params = best_results[1][1]\n",
    "best_run = run_lgbm_skf_cv(False, False, SEED, num_folds, df_train.copy(), y_col, best_X_cols, best_X_cats, best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions based on the best performing model and displaying it's information\n",
    "BEST_LGBM_MODELS = best_run[2] #getting the lgbm_models from the best index\n",
    "BEST_LGBM_FORECASTS = df_preds.copy()\n",
    "start_time = time.time() \n",
    "\n",
    "#calculating the average preds by summing the weighted preds for each folds model\n",
    "for i in range(len(BEST_LGBM_MODELS)):\n",
    "    pred_forecasts = BEST_LGBM_MODELS[i].predict(BEST_LGBM_FORECASTS[best_results[1][0]], num_iteration=BEST_LGBM_MODELS[i].best_iteration_) #predicting the unkown df_preds\n",
    "    BEST_LGBM_FORECASTS[y_col] += pred_forecasts / num_folds #weighting the predictions for BEST_LGBM_FORECASTS for this fold and adding to df_preds y column \n",
    "BEST_LGBM_FORECASTS[\"meter_reading\"] = BEST_LGBM_FORECASTS.meter_reading.clip(lower=0) #clip meter_reading so no predictions lower than 0\n",
    "execution_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting information on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mbest model came from generation 7 individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mEvaluation and results\u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for skf-cv:  \u001b[0m1:34:43\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mTime of execution for predictions: \u001b[0m1:17:40\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mTotal time of execution: \u001b[0m2:52:23\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7620903897052624\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mpreds set with the next years forecasts for each meter\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>date</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5.997642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>5.341159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>5.207851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>5.505288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>5.566343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185515</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>22.509967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185516</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>20.247730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185517</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2018-12-29</td>\n",
       "      <td>18.736898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185518</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>16.819715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185519</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>16.438936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185520 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           meter_id       date  meter_reading\n",
       "0        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7 2018-01-01       5.997642\n",
       "1        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7 2018-01-02       5.341159\n",
       "2        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7 2018-01-03       5.207851\n",
       "3        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7 2018-01-04       5.505288\n",
       "4        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7 2018-01-05       5.566343\n",
       "...                                             ...        ...            ...\n",
       "1185515  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd 2018-12-27      22.509967\n",
       "1185516  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd 2018-12-28      20.247730\n",
       "1185517  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd 2018-12-29      18.736898\n",
       "1185518  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd 2018-12-30      16.819715\n",
       "1185519  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd 2018-12-31      16.438936\n",
       "\n",
       "[1185520 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94m\u001b[4mHyper-parameters\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mX_cols:\u001b[0m\n",
      "\n",
      "['meter_id_ord',\n",
      " 'day_of_year_sin',\n",
      " 'day_of_year_cos',\n",
      " 'day_of_week',\n",
      " 'month_ord',\n",
      " 'is_weekend',\n",
      " 'energy_cluster',\n",
      " 'num_bedrooms',\n",
      " 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[96m\u001b[4mmodel params:  \u001b[0m\n",
      "{'bagging_fraction': 0.7020000000000001,\n",
      " 'bagging_freq': 21,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.7812,\n",
      " 'lambda_l1': 8,\n",
      " 'lambda_l2': 10,\n",
      " 'learning_rate': 0.06,\n",
      " 'max_depth': 12,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 1764,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n"
     ]
    }
   ],
   "source": [
    "#printing the forecasts and other evaluation info\n",
    "print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}best model came from generation {int(best_index/population_size)} individual {best_index%population_size}{color.END}\")\n",
    "#displaying the results\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Evaluation and results{color.END}\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution for skf-cv:  {color.END}{str(datetime.timedelta(seconds=round(best_results[0][0])))}\\n\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution for predictions: {color.END}{str(datetime.timedelta(seconds=round(execution_time)))}\\n\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Total time of execution: {color.END}{str(datetime.timedelta(seconds=round(best_results[0][0]+execution_time)))}\\n\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set:{color.END} {best_results[0][1]}\\n\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}preds set with the next years forecasts for each meter{color.END}\")\n",
    "display(BEST_LGBM_FORECASTS[[\"meter_id\",\"date\",\"meter_reading\"]])\n",
    "#displaying the hyperparameters\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Hyper-parameters{color.END}\")\n",
    "print(f\"\\n{color.BOLD}{color.CYAN}{color.UNDERLINE}X_cols:{color.END}\\n\")\n",
    "pprint(best_results[1][0])\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}model params:  {color.END}\")\n",
    "pprint(best_results[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the description of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_LGBM_FORECASTS.to_pickle(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_best_model_daily_forecasts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE': 1.7620903897052624,\n",
      " 'features': ['meter_id_ord',\n",
      "              'day_of_year_sin',\n",
      "              'day_of_year_cos',\n",
      "              'day_of_week',\n",
      "              'month_ord',\n",
      "              'is_weekend',\n",
      "              'energy_cluster',\n",
      "              'num_bedrooms',\n",
      "              'dwelling_type_ord'],\n",
      " 'params': {'bagging_fraction': 0.7020000000000001,\n",
      "            'bagging_freq': 21,\n",
      "            'boosting_type': 'gbdt',\n",
      "            'device': 'cpu',\n",
      "            'feature_fraction': 0.7812,\n",
      "            'lambda_l1': 8,\n",
      "            'lambda_l2': 10,\n",
      "            'learning_rate': 0.06,\n",
      "            'max_depth': 12,\n",
      "            'metric': 'mae',\n",
      "            'num_iterations': 10000,\n",
      "            'num_leaves': 1764,\n",
      "            'num_threads': -1,\n",
      "            'seed': 96},\n",
      " 'time_of_execution_preds': '1:17:40',\n",
      " 'time_of_execution_skf-cv': '1:34:43',\n",
      " 'time_of_execution_total': '2:52:23'}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "desc_disc = {\n",
    "    \"time_of_execution_skf-cv\":str(datetime.timedelta(seconds=round(best_results[0][0]))),\n",
    "    \"time_of_execution_preds\":str(datetime.timedelta(seconds=round(execution_time))),\n",
    "    \"time_of_execution_total\":str(datetime.timedelta(seconds=round(best_results[0][0]+execution_time))),\n",
    "    \"MAE\":best_results[0][1],\n",
    "    \"features\":best_results[1][0],\n",
    "    \"params\":best_results[1][1]\n",
    "}\n",
    "\n",
    "with open(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_best_model_desc.pkl\", 'wb') as handle:\n",
    "    pickle.dump(desc_disc, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "pprint(desc_disc)\n",
    "    \n",
    "# verifying it saved correctly and can be loaded back\n",
    "with open(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_best_model_desc.pkl\", 'rb') as handle:\n",
    "    desc_disc_loaded = pickle.load(handle)\n",
    "print(desc_disc == desc_disc_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting into monthly forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>139.575618</td>\n",
       "      <td>123.876521</td>\n",
       "      <td>138.361733</td>\n",
       "      <td>110.934399</td>\n",
       "      <td>120.531687</td>\n",
       "      <td>112.008203</td>\n",
       "      <td>110.226784</td>\n",
       "      <td>121.813996</td>\n",
       "      <td>120.473575</td>\n",
       "      <td>127.570597</td>\n",
       "      <td>102.373577</td>\n",
       "      <td>114.495704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>664.593476</td>\n",
       "      <td>637.335456</td>\n",
       "      <td>619.233330</td>\n",
       "      <td>509.289712</td>\n",
       "      <td>490.237883</td>\n",
       "      <td>437.166070</td>\n",
       "      <td>396.295499</td>\n",
       "      <td>430.125935</td>\n",
       "      <td>483.971543</td>\n",
       "      <td>540.740062</td>\n",
       "      <td>612.775874</td>\n",
       "      <td>640.356772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>287.738951</td>\n",
       "      <td>227.035148</td>\n",
       "      <td>227.927489</td>\n",
       "      <td>213.467160</td>\n",
       "      <td>203.681478</td>\n",
       "      <td>195.953325</td>\n",
       "      <td>198.566873</td>\n",
       "      <td>196.053946</td>\n",
       "      <td>196.361392</td>\n",
       "      <td>204.618810</td>\n",
       "      <td>208.477503</td>\n",
       "      <td>233.970471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>198.571122</td>\n",
       "      <td>170.062326</td>\n",
       "      <td>154.105896</td>\n",
       "      <td>139.399743</td>\n",
       "      <td>141.550392</td>\n",
       "      <td>132.445794</td>\n",
       "      <td>137.366086</td>\n",
       "      <td>124.895467</td>\n",
       "      <td>131.005762</td>\n",
       "      <td>144.287827</td>\n",
       "      <td>146.744332</td>\n",
       "      <td>158.278066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>357.404727</td>\n",
       "      <td>296.822161</td>\n",
       "      <td>316.884626</td>\n",
       "      <td>264.820470</td>\n",
       "      <td>256.954476</td>\n",
       "      <td>244.848909</td>\n",
       "      <td>243.499996</td>\n",
       "      <td>248.940124</td>\n",
       "      <td>257.986175</td>\n",
       "      <td>288.923817</td>\n",
       "      <td>315.123947</td>\n",
       "      <td>355.689528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>182.823569</td>\n",
       "      <td>157.255095</td>\n",
       "      <td>161.828029</td>\n",
       "      <td>137.752366</td>\n",
       "      <td>135.858984</td>\n",
       "      <td>136.176557</td>\n",
       "      <td>136.727754</td>\n",
       "      <td>129.852653</td>\n",
       "      <td>135.746500</td>\n",
       "      <td>148.789462</td>\n",
       "      <td>159.043583</td>\n",
       "      <td>168.106304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>671.263101</td>\n",
       "      <td>616.098921</td>\n",
       "      <td>721.104612</td>\n",
       "      <td>695.350114</td>\n",
       "      <td>599.803264</td>\n",
       "      <td>469.739116</td>\n",
       "      <td>459.681336</td>\n",
       "      <td>474.052822</td>\n",
       "      <td>513.013123</td>\n",
       "      <td>555.018594</td>\n",
       "      <td>574.409618</td>\n",
       "      <td>613.109886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>531.516944</td>\n",
       "      <td>428.682332</td>\n",
       "      <td>409.114584</td>\n",
       "      <td>377.619695</td>\n",
       "      <td>355.170272</td>\n",
       "      <td>259.076797</td>\n",
       "      <td>272.907422</td>\n",
       "      <td>280.308000</td>\n",
       "      <td>296.541445</td>\n",
       "      <td>336.301424</td>\n",
       "      <td>421.936677</td>\n",
       "      <td>518.773440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>416.227882</td>\n",
       "      <td>377.277653</td>\n",
       "      <td>337.285252</td>\n",
       "      <td>383.008153</td>\n",
       "      <td>211.886284</td>\n",
       "      <td>196.812078</td>\n",
       "      <td>189.342574</td>\n",
       "      <td>195.245499</td>\n",
       "      <td>221.327473</td>\n",
       "      <td>263.141374</td>\n",
       "      <td>321.445183</td>\n",
       "      <td>387.853796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>258.724397</td>\n",
       "      <td>220.511835</td>\n",
       "      <td>239.932473</td>\n",
       "      <td>221.450480</td>\n",
       "      <td>227.127136</td>\n",
       "      <td>212.906373</td>\n",
       "      <td>220.949570</td>\n",
       "      <td>225.442286</td>\n",
       "      <td>227.834750</td>\n",
       "      <td>239.319198</td>\n",
       "      <td>245.616968</td>\n",
       "      <td>248.971297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id         Jan         Feb  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c  139.575618  123.876521   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82  664.593476  637.335456   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734  287.738951  227.035148   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a  198.571122  170.062326   \n",
       "4     0x005958406351bb29580475df698b5f1070096397  357.404727  296.822161   \n",
       "...                                          ...         ...         ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f  182.823569  157.255095   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb  671.263101  616.098921   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5  531.516944  428.682332   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02  416.227882  377.277653   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4  258.724397  220.511835   \n",
       "\n",
       "             Mar         Apr         May         Jun         Jul         Aug  \\\n",
       "0     138.361733  110.934399  120.531687  112.008203  110.226784  121.813996   \n",
       "1     619.233330  509.289712  490.237883  437.166070  396.295499  430.125935   \n",
       "2     227.927489  213.467160  203.681478  195.953325  198.566873  196.053946   \n",
       "3     154.105896  139.399743  141.550392  132.445794  137.366086  124.895467   \n",
       "4     316.884626  264.820470  256.954476  244.848909  243.499996  248.940124   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3243  161.828029  137.752366  135.858984  136.176557  136.727754  129.852653   \n",
       "3244  721.104612  695.350114  599.803264  469.739116  459.681336  474.052822   \n",
       "3245  409.114584  377.619695  355.170272  259.076797  272.907422  280.308000   \n",
       "3246  337.285252  383.008153  211.886284  196.812078  189.342574  195.245499   \n",
       "3247  239.932473  221.450480  227.127136  212.906373  220.949570  225.442286   \n",
       "\n",
       "             Sep         Oct         Nov         Dec  \n",
       "0     120.473575  127.570597  102.373577  114.495704  \n",
       "1     483.971543  540.740062  612.775874  640.356772  \n",
       "2     196.361392  204.618810  208.477503  233.970471  \n",
       "3     131.005762  144.287827  146.744332  158.278066  \n",
       "4     257.986175  288.923817  315.123947  355.689528  \n",
       "...          ...         ...         ...         ...  \n",
       "3243  135.746500  148.789462  159.043583  168.106304  \n",
       "3244  513.013123  555.018594  574.409618  613.109886  \n",
       "3245  296.541445  336.301424  421.936677  518.773440  \n",
       "3246  221.327473  263.141374  321.445183  387.853796  \n",
       "3247  227.834750  239.319198  245.616968  248.971297  \n",
       "\n",
       "[3248 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#restructuring into the original multiple time series format\n",
    "#aggregating up the total sum of the months predictions\n",
    "df_monthly_forecasts = BEST_LGBM_FORECASTS.groupby([\"meter_id\", \"month_ord\"])[\"meter_reading\"].sum().unstack()\n",
    "\n",
    "#rename ordinal encoded month with its corresponding name\n",
    "df_monthly_forecasts.rename(columns={1:\"Jan\", 2:\"Feb\",3:\"Mar\",4:\"Apr\",5:\"May\",6:\"Jun\",7:\"Jul\",8:\"Aug\",9:\"Sep\",10:\"Oct\",11:\"Nov\",12:\"Dec\"}, inplace=True)\n",
    "#resetting the index \n",
    "df_monthly_forecasts.reset_index(inplace=True)\n",
    "df_monthly_forecasts.index.name = None # removing index column\n",
    "df_monthly_forecasts.columns.name = None # removing columns name\n",
    "\n",
    "display(df_monthly_forecasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving these monthly predictions to be submitted to competition\n",
    "* Saving predictions ready to be submitted so I can get the MAE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_forecasts.to_csv(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_best_model_monthly_forecasts.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting these monthly forecasts\n",
    "## Renaming months to dates for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "      <th>2018-05</th>\n",
       "      <th>2018-06</th>\n",
       "      <th>2018-07</th>\n",
       "      <th>2018-08</th>\n",
       "      <th>2018-09</th>\n",
       "      <th>2018-10</th>\n",
       "      <th>2018-11</th>\n",
       "      <th>2018-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>139.575618</td>\n",
       "      <td>123.876521</td>\n",
       "      <td>138.361733</td>\n",
       "      <td>110.934399</td>\n",
       "      <td>120.531687</td>\n",
       "      <td>112.008203</td>\n",
       "      <td>110.226784</td>\n",
       "      <td>121.813996</td>\n",
       "      <td>120.473575</td>\n",
       "      <td>127.570597</td>\n",
       "      <td>102.373577</td>\n",
       "      <td>114.495704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>664.593476</td>\n",
       "      <td>637.335456</td>\n",
       "      <td>619.233330</td>\n",
       "      <td>509.289712</td>\n",
       "      <td>490.237883</td>\n",
       "      <td>437.166070</td>\n",
       "      <td>396.295499</td>\n",
       "      <td>430.125935</td>\n",
       "      <td>483.971543</td>\n",
       "      <td>540.740062</td>\n",
       "      <td>612.775874</td>\n",
       "      <td>640.356772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>287.738951</td>\n",
       "      <td>227.035148</td>\n",
       "      <td>227.927489</td>\n",
       "      <td>213.467160</td>\n",
       "      <td>203.681478</td>\n",
       "      <td>195.953325</td>\n",
       "      <td>198.566873</td>\n",
       "      <td>196.053946</td>\n",
       "      <td>196.361392</td>\n",
       "      <td>204.618810</td>\n",
       "      <td>208.477503</td>\n",
       "      <td>233.970471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>198.571122</td>\n",
       "      <td>170.062326</td>\n",
       "      <td>154.105896</td>\n",
       "      <td>139.399743</td>\n",
       "      <td>141.550392</td>\n",
       "      <td>132.445794</td>\n",
       "      <td>137.366086</td>\n",
       "      <td>124.895467</td>\n",
       "      <td>131.005762</td>\n",
       "      <td>144.287827</td>\n",
       "      <td>146.744332</td>\n",
       "      <td>158.278066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>357.404727</td>\n",
       "      <td>296.822161</td>\n",
       "      <td>316.884626</td>\n",
       "      <td>264.820470</td>\n",
       "      <td>256.954476</td>\n",
       "      <td>244.848909</td>\n",
       "      <td>243.499996</td>\n",
       "      <td>248.940124</td>\n",
       "      <td>257.986175</td>\n",
       "      <td>288.923817</td>\n",
       "      <td>315.123947</td>\n",
       "      <td>355.689528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>182.823569</td>\n",
       "      <td>157.255095</td>\n",
       "      <td>161.828029</td>\n",
       "      <td>137.752366</td>\n",
       "      <td>135.858984</td>\n",
       "      <td>136.176557</td>\n",
       "      <td>136.727754</td>\n",
       "      <td>129.852653</td>\n",
       "      <td>135.746500</td>\n",
       "      <td>148.789462</td>\n",
       "      <td>159.043583</td>\n",
       "      <td>168.106304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>671.263101</td>\n",
       "      <td>616.098921</td>\n",
       "      <td>721.104612</td>\n",
       "      <td>695.350114</td>\n",
       "      <td>599.803264</td>\n",
       "      <td>469.739116</td>\n",
       "      <td>459.681336</td>\n",
       "      <td>474.052822</td>\n",
       "      <td>513.013123</td>\n",
       "      <td>555.018594</td>\n",
       "      <td>574.409618</td>\n",
       "      <td>613.109886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>531.516944</td>\n",
       "      <td>428.682332</td>\n",
       "      <td>409.114584</td>\n",
       "      <td>377.619695</td>\n",
       "      <td>355.170272</td>\n",
       "      <td>259.076797</td>\n",
       "      <td>272.907422</td>\n",
       "      <td>280.308000</td>\n",
       "      <td>296.541445</td>\n",
       "      <td>336.301424</td>\n",
       "      <td>421.936677</td>\n",
       "      <td>518.773440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>416.227882</td>\n",
       "      <td>377.277653</td>\n",
       "      <td>337.285252</td>\n",
       "      <td>383.008153</td>\n",
       "      <td>211.886284</td>\n",
       "      <td>196.812078</td>\n",
       "      <td>189.342574</td>\n",
       "      <td>195.245499</td>\n",
       "      <td>221.327473</td>\n",
       "      <td>263.141374</td>\n",
       "      <td>321.445183</td>\n",
       "      <td>387.853796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>258.724397</td>\n",
       "      <td>220.511835</td>\n",
       "      <td>239.932473</td>\n",
       "      <td>221.450480</td>\n",
       "      <td>227.127136</td>\n",
       "      <td>212.906373</td>\n",
       "      <td>220.949570</td>\n",
       "      <td>225.442286</td>\n",
       "      <td>227.834750</td>\n",
       "      <td>239.319198</td>\n",
       "      <td>245.616968</td>\n",
       "      <td>248.971297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id     2018-01     2018-02  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c  139.575618  123.876521   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82  664.593476  637.335456   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734  287.738951  227.035148   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a  198.571122  170.062326   \n",
       "4     0x005958406351bb29580475df698b5f1070096397  357.404727  296.822161   \n",
       "...                                          ...         ...         ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f  182.823569  157.255095   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb  671.263101  616.098921   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5  531.516944  428.682332   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02  416.227882  377.277653   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4  258.724397  220.511835   \n",
       "\n",
       "         2018-03     2018-04     2018-05     2018-06     2018-07     2018-08  \\\n",
       "0     138.361733  110.934399  120.531687  112.008203  110.226784  121.813996   \n",
       "1     619.233330  509.289712  490.237883  437.166070  396.295499  430.125935   \n",
       "2     227.927489  213.467160  203.681478  195.953325  198.566873  196.053946   \n",
       "3     154.105896  139.399743  141.550392  132.445794  137.366086  124.895467   \n",
       "4     316.884626  264.820470  256.954476  244.848909  243.499996  248.940124   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3243  161.828029  137.752366  135.858984  136.176557  136.727754  129.852653   \n",
       "3244  721.104612  695.350114  599.803264  469.739116  459.681336  474.052822   \n",
       "3245  409.114584  377.619695  355.170272  259.076797  272.907422  280.308000   \n",
       "3246  337.285252  383.008153  211.886284  196.812078  189.342574  195.245499   \n",
       "3247  239.932473  221.450480  227.127136  212.906373  220.949570  225.442286   \n",
       "\n",
       "         2018-09     2018-10     2018-11     2018-12  \n",
       "0     120.473575  127.570597  102.373577  114.495704  \n",
       "1     483.971543  540.740062  612.775874  640.356772  \n",
       "2     196.361392  204.618810  208.477503  233.970471  \n",
       "3     131.005762  144.287827  146.744332  158.278066  \n",
       "4     257.986175  288.923817  315.123947  355.689528  \n",
       "...          ...         ...         ...         ...  \n",
       "3243  135.746500  148.789462  159.043583  168.106304  \n",
       "3244  513.013123  555.018594  574.409618  613.109886  \n",
       "3245  296.541445  336.301424  421.936677  518.773440  \n",
       "3246  221.327473  263.141374  321.445183  387.853796  \n",
       "3247  227.834750  239.319198  245.616968  248.971297  \n",
       "\n",
       "[3248 rows x 13 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_monthly_forecasts.rename(columns={\"Jan\":\"2018-01\", \"Feb\":\"2018-02\",\"Mar\":\"2018-03\",\"Apr\":\"2018-04\",\"May\":\"2018-05\",\"Jun\":\"2018-06\",\"Jul\":\"2018-07\",\"Aug\":\"2018-08\",\"Sep\":\"2018-09\",\"Oct\":\"2018-10\",\"Nov\":\"2018-11\",\"Dec\":\"2018-12\"}, inplace=True)\n",
    "df_monthly_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructuring forecasts into daily predictions to plot on top of monthly preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <th>2018-01-02 00:00:00</th>\n",
       "      <th>2018-01-03 00:00:00</th>\n",
       "      <th>2018-01-04 00:00:00</th>\n",
       "      <th>2018-01-05 00:00:00</th>\n",
       "      <th>2018-01-06 00:00:00</th>\n",
       "      <th>2018-01-07 00:00:00</th>\n",
       "      <th>2018-01-08 00:00:00</th>\n",
       "      <th>2018-01-09 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-12-22 00:00:00</th>\n",
       "      <th>2018-12-23 00:00:00</th>\n",
       "      <th>2018-12-24 00:00:00</th>\n",
       "      <th>2018-12-25 00:00:00</th>\n",
       "      <th>2018-12-26 00:00:00</th>\n",
       "      <th>2018-12-27 00:00:00</th>\n",
       "      <th>2018-12-28 00:00:00</th>\n",
       "      <th>2018-12-29 00:00:00</th>\n",
       "      <th>2018-12-30 00:00:00</th>\n",
       "      <th>2018-12-31 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>4.738579</td>\n",
       "      <td>4.365489</td>\n",
       "      <td>4.047249</td>\n",
       "      <td>4.508192</td>\n",
       "      <td>4.893738</td>\n",
       "      <td>4.996247</td>\n",
       "      <td>4.864489</td>\n",
       "      <td>5.201156</td>\n",
       "      <td>5.032764</td>\n",
       "      <td>...</td>\n",
       "      <td>4.228803</td>\n",
       "      <td>3.693891</td>\n",
       "      <td>3.725401</td>\n",
       "      <td>3.619216</td>\n",
       "      <td>3.784420</td>\n",
       "      <td>3.829133</td>\n",
       "      <td>3.732509</td>\n",
       "      <td>3.729387</td>\n",
       "      <td>3.381031</td>\n",
       "      <td>3.349579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>18.381421</td>\n",
       "      <td>19.936947</td>\n",
       "      <td>21.771359</td>\n",
       "      <td>19.232847</td>\n",
       "      <td>20.408462</td>\n",
       "      <td>20.249264</td>\n",
       "      <td>21.666995</td>\n",
       "      <td>20.903368</td>\n",
       "      <td>21.213393</td>\n",
       "      <td>...</td>\n",
       "      <td>22.304647</td>\n",
       "      <td>21.901535</td>\n",
       "      <td>20.373675</td>\n",
       "      <td>16.855451</td>\n",
       "      <td>20.034802</td>\n",
       "      <td>22.872819</td>\n",
       "      <td>20.072164</td>\n",
       "      <td>16.685057</td>\n",
       "      <td>16.728079</td>\n",
       "      <td>17.706278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>10.205010</td>\n",
       "      <td>11.135671</td>\n",
       "      <td>10.341030</td>\n",
       "      <td>10.212482</td>\n",
       "      <td>9.895073</td>\n",
       "      <td>9.920332</td>\n",
       "      <td>9.859028</td>\n",
       "      <td>8.488840</td>\n",
       "      <td>8.685310</td>\n",
       "      <td>...</td>\n",
       "      <td>7.657777</td>\n",
       "      <td>7.733830</td>\n",
       "      <td>7.343346</td>\n",
       "      <td>7.514847</td>\n",
       "      <td>7.714924</td>\n",
       "      <td>7.977581</td>\n",
       "      <td>8.088113</td>\n",
       "      <td>7.839243</td>\n",
       "      <td>7.871248</td>\n",
       "      <td>8.120510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>6.824054</td>\n",
       "      <td>6.860957</td>\n",
       "      <td>6.622569</td>\n",
       "      <td>6.911233</td>\n",
       "      <td>7.050628</td>\n",
       "      <td>7.034670</td>\n",
       "      <td>6.727859</td>\n",
       "      <td>6.129213</td>\n",
       "      <td>6.268894</td>\n",
       "      <td>...</td>\n",
       "      <td>4.779600</td>\n",
       "      <td>4.038947</td>\n",
       "      <td>4.294349</td>\n",
       "      <td>4.689540</td>\n",
       "      <td>5.079143</td>\n",
       "      <td>5.373341</td>\n",
       "      <td>5.216118</td>\n",
       "      <td>5.557400</td>\n",
       "      <td>4.916445</td>\n",
       "      <td>5.178216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>10.966807</td>\n",
       "      <td>11.751438</td>\n",
       "      <td>12.379401</td>\n",
       "      <td>12.441908</td>\n",
       "      <td>11.829903</td>\n",
       "      <td>11.255959</td>\n",
       "      <td>11.777734</td>\n",
       "      <td>10.797027</td>\n",
       "      <td>10.884897</td>\n",
       "      <td>...</td>\n",
       "      <td>11.773357</td>\n",
       "      <td>11.169298</td>\n",
       "      <td>11.242780</td>\n",
       "      <td>11.145158</td>\n",
       "      <td>11.534882</td>\n",
       "      <td>10.935985</td>\n",
       "      <td>11.218835</td>\n",
       "      <td>11.301044</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>10.741031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>6.467735</td>\n",
       "      <td>6.195578</td>\n",
       "      <td>5.513758</td>\n",
       "      <td>5.924307</td>\n",
       "      <td>6.422251</td>\n",
       "      <td>6.615218</td>\n",
       "      <td>6.212173</td>\n",
       "      <td>6.339774</td>\n",
       "      <td>6.192596</td>\n",
       "      <td>...</td>\n",
       "      <td>5.581932</td>\n",
       "      <td>5.198511</td>\n",
       "      <td>5.003605</td>\n",
       "      <td>5.309052</td>\n",
       "      <td>5.008787</td>\n",
       "      <td>5.492848</td>\n",
       "      <td>5.525072</td>\n",
       "      <td>5.997656</td>\n",
       "      <td>5.650419</td>\n",
       "      <td>5.450417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>23.206972</td>\n",
       "      <td>23.644557</td>\n",
       "      <td>22.141005</td>\n",
       "      <td>22.102948</td>\n",
       "      <td>21.405626</td>\n",
       "      <td>20.563162</td>\n",
       "      <td>21.141723</td>\n",
       "      <td>21.190321</td>\n",
       "      <td>21.316664</td>\n",
       "      <td>...</td>\n",
       "      <td>18.103088</td>\n",
       "      <td>18.372421</td>\n",
       "      <td>18.424586</td>\n",
       "      <td>19.402721</td>\n",
       "      <td>20.385923</td>\n",
       "      <td>21.194914</td>\n",
       "      <td>20.667462</td>\n",
       "      <td>20.026569</td>\n",
       "      <td>19.454027</td>\n",
       "      <td>21.968686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>19.044381</td>\n",
       "      <td>18.255576</td>\n",
       "      <td>17.388882</td>\n",
       "      <td>16.657224</td>\n",
       "      <td>16.833838</td>\n",
       "      <td>16.273406</td>\n",
       "      <td>17.068433</td>\n",
       "      <td>17.682201</td>\n",
       "      <td>15.461590</td>\n",
       "      <td>...</td>\n",
       "      <td>15.005299</td>\n",
       "      <td>14.954275</td>\n",
       "      <td>16.076247</td>\n",
       "      <td>14.339415</td>\n",
       "      <td>15.398420</td>\n",
       "      <td>16.280296</td>\n",
       "      <td>15.851106</td>\n",
       "      <td>15.509594</td>\n",
       "      <td>15.299805</td>\n",
       "      <td>17.606388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>13.414793</td>\n",
       "      <td>13.031756</td>\n",
       "      <td>12.985126</td>\n",
       "      <td>12.788575</td>\n",
       "      <td>13.050720</td>\n",
       "      <td>13.059006</td>\n",
       "      <td>12.856864</td>\n",
       "      <td>13.346557</td>\n",
       "      <td>12.990170</td>\n",
       "      <td>...</td>\n",
       "      <td>11.040799</td>\n",
       "      <td>11.531352</td>\n",
       "      <td>13.744681</td>\n",
       "      <td>12.427467</td>\n",
       "      <td>12.576399</td>\n",
       "      <td>12.840776</td>\n",
       "      <td>12.333814</td>\n",
       "      <td>11.233325</td>\n",
       "      <td>11.664058</td>\n",
       "      <td>13.259635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>8.661632</td>\n",
       "      <td>8.598744</td>\n",
       "      <td>8.252715</td>\n",
       "      <td>8.167212</td>\n",
       "      <td>8.557266</td>\n",
       "      <td>8.664492</td>\n",
       "      <td>8.604994</td>\n",
       "      <td>8.717134</td>\n",
       "      <td>8.386272</td>\n",
       "      <td>...</td>\n",
       "      <td>8.159683</td>\n",
       "      <td>8.006011</td>\n",
       "      <td>8.034820</td>\n",
       "      <td>7.285578</td>\n",
       "      <td>8.057061</td>\n",
       "      <td>9.109693</td>\n",
       "      <td>8.572992</td>\n",
       "      <td>8.311508</td>\n",
       "      <td>8.462143</td>\n",
       "      <td>8.325416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id  2018-01-01 00:00:00  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c             4.738579   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82            18.381421   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734            10.205010   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a             6.824054   \n",
       "4     0x005958406351bb29580475df698b5f1070096397            10.966807   \n",
       "...                                          ...                  ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f             6.467735   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb            23.206972   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5            19.044381   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02            13.414793   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4             8.661632   \n",
       "\n",
       "      2018-01-02 00:00:00  2018-01-03 00:00:00  2018-01-04 00:00:00  \\\n",
       "0                4.365489             4.047249             4.508192   \n",
       "1               19.936947            21.771359            19.232847   \n",
       "2               11.135671            10.341030            10.212482   \n",
       "3                6.860957             6.622569             6.911233   \n",
       "4               11.751438            12.379401            12.441908   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             6.195578             5.513758             5.924307   \n",
       "3244            23.644557            22.141005            22.102948   \n",
       "3245            18.255576            17.388882            16.657224   \n",
       "3246            13.031756            12.985126            12.788575   \n",
       "3247             8.598744             8.252715             8.167212   \n",
       "\n",
       "      2018-01-05 00:00:00  2018-01-06 00:00:00  2018-01-07 00:00:00  \\\n",
       "0                4.893738             4.996247             4.864489   \n",
       "1               20.408462            20.249264            21.666995   \n",
       "2                9.895073             9.920332             9.859028   \n",
       "3                7.050628             7.034670             6.727859   \n",
       "4               11.829903            11.255959            11.777734   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             6.422251             6.615218             6.212173   \n",
       "3244            21.405626            20.563162            21.141723   \n",
       "3245            16.833838            16.273406            17.068433   \n",
       "3246            13.050720            13.059006            12.856864   \n",
       "3247             8.557266             8.664492             8.604994   \n",
       "\n",
       "      2018-01-08 00:00:00  2018-01-09 00:00:00  ...  2018-12-22 00:00:00  \\\n",
       "0                5.201156             5.032764  ...             4.228803   \n",
       "1               20.903368            21.213393  ...            22.304647   \n",
       "2                8.488840             8.685310  ...             7.657777   \n",
       "3                6.129213             6.268894  ...             4.779600   \n",
       "4               10.797027            10.884897  ...            11.773357   \n",
       "...                   ...                  ...  ...                  ...   \n",
       "3243             6.339774             6.192596  ...             5.581932   \n",
       "3244            21.190321            21.316664  ...            18.103088   \n",
       "3245            17.682201            15.461590  ...            15.005299   \n",
       "3246            13.346557            12.990170  ...            11.040799   \n",
       "3247             8.717134             8.386272  ...             8.159683   \n",
       "\n",
       "      2018-12-23 00:00:00  2018-12-24 00:00:00  2018-12-25 00:00:00  \\\n",
       "0                3.693891             3.725401             3.619216   \n",
       "1               21.901535            20.373675            16.855451   \n",
       "2                7.733830             7.343346             7.514847   \n",
       "3                4.038947             4.294349             4.689540   \n",
       "4               11.169298            11.242780            11.145158   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             5.198511             5.003605             5.309052   \n",
       "3244            18.372421            18.424586            19.402721   \n",
       "3245            14.954275            16.076247            14.339415   \n",
       "3246            11.531352            13.744681            12.427467   \n",
       "3247             8.006011             8.034820             7.285578   \n",
       "\n",
       "      2018-12-26 00:00:00  2018-12-27 00:00:00  2018-12-28 00:00:00  \\\n",
       "0                3.784420             3.829133             3.732509   \n",
       "1               20.034802            22.872819            20.072164   \n",
       "2                7.714924             7.977581             8.088113   \n",
       "3                5.079143             5.373341             5.216118   \n",
       "4               11.534882            10.935985            11.218835   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             5.008787             5.492848             5.525072   \n",
       "3244            20.385923            21.194914            20.667462   \n",
       "3245            15.398420            16.280296            15.851106   \n",
       "3246            12.576399            12.840776            12.333814   \n",
       "3247             8.057061             9.109693             8.572992   \n",
       "\n",
       "      2018-12-29 00:00:00  2018-12-30 00:00:00  2018-12-31 00:00:00  \n",
       "0                3.729387             3.381031             3.349579  \n",
       "1               16.685057            16.728079            17.706278  \n",
       "2                7.839243             7.871248             8.120510  \n",
       "3                5.557400             4.916445             5.178216  \n",
       "4               11.301044            11.700000            10.741031  \n",
       "...                   ...                  ...                  ...  \n",
       "3243             5.997656             5.650419             5.450417  \n",
       "3244            20.026569            19.454027            21.968686  \n",
       "3245            15.509594            15.299805            17.606388  \n",
       "3246            11.233325            11.664058            13.259635  \n",
       "3247             8.311508             8.462143             8.325416  \n",
       "\n",
       "[3248 rows x 366 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#daily forecasts to plot on top of monthly\n",
    "df_daily_forecasts = BEST_LGBM_FORECASTS.groupby([\"meter_id\",\"date\"])[\"meter_reading\"].sum().unstack()\n",
    "\n",
    "#resetting the index \n",
    "df_daily_forecasts.reset_index(inplace=True)\n",
    "df_daily_forecasts.index.name = None # removing index column\n",
    "df_daily_forecasts.columns.name = None # removing columns name\n",
    "\n",
    "df_daily_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading training data and aggregating into months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be55801c813e46e588d5446d51aadfd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2017-01-02</th>\n",
       "      <th>2017-01-03</th>\n",
       "      <th>2017-01-04</th>\n",
       "      <th>2017-01-05</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017-01-07</th>\n",
       "      <th>2017-01-08</th>\n",
       "      <th>2017-01-09</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-12-22</th>\n",
       "      <th>2017-12-23</th>\n",
       "      <th>2017-12-24</th>\n",
       "      <th>2017-12-25</th>\n",
       "      <th>2017-12-26</th>\n",
       "      <th>2017-12-27</th>\n",
       "      <th>2017-12-28</th>\n",
       "      <th>2017-12-29</th>\n",
       "      <th>2017-12-30</th>\n",
       "      <th>2017-12-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.030</td>\n",
       "      <td>5.397</td>\n",
       "      <td>5.1075</td>\n",
       "      <td>4.818</td>\n",
       "      <td>3.931</td>\n",
       "      <td>4.2170</td>\n",
       "      <td>4.503</td>\n",
       "      <td>4.8160</td>\n",
       "      <td>5.129</td>\n",
       "      <td>5.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x459c834d1f6cfb5b734b82aa9f5410fa97fb70da</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.101</td>\n",
       "      <td>14.327</td>\n",
       "      <td>14.6315</td>\n",
       "      <td>14.936</td>\n",
       "      <td>16.174</td>\n",
       "      <td>20.3960</td>\n",
       "      <td>24.618</td>\n",
       "      <td>19.8925</td>\n",
       "      <td>15.167</td>\n",
       "      <td>11.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x4a1ed36825360a058cec2bdd409fc2459e1ce54f</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.201</td>\n",
       "      <td>7.320</td>\n",
       "      <td>7.3520</td>\n",
       "      <td>7.384</td>\n",
       "      <td>14.425</td>\n",
       "      <td>16.0650</td>\n",
       "      <td>17.705</td>\n",
       "      <td>13.3355</td>\n",
       "      <td>8.966</td>\n",
       "      <td>4.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x5b76d3c0e0aefc6e0a8d1d031f96388a23263407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.833</td>\n",
       "      <td>12.477</td>\n",
       "      <td>11.7255</td>\n",
       "      <td>10.974</td>\n",
       "      <td>19.646</td>\n",
       "      <td>21.8195</td>\n",
       "      <td>23.993</td>\n",
       "      <td>19.9170</td>\n",
       "      <td>15.841</td>\n",
       "      <td>14.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x943ebe39ef2be6ef807c42c5a647e27112ca5b0f</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>39.440</td>\n",
       "      <td>35.538</td>\n",
       "      <td>21.9445</td>\n",
       "      <td>8.351</td>\n",
       "      <td>9.957</td>\n",
       "      <td>17.9140</td>\n",
       "      <td>25.871</td>\n",
       "      <td>36.0725</td>\n",
       "      <td>46.274</td>\n",
       "      <td>16.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0x7dd7a7b8ee1bec7c44b24f738c752482f6161065</td>\n",
       "      <td>2.317</td>\n",
       "      <td>2.301</td>\n",
       "      <td>2.352</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.229</td>\n",
       "      <td>2.354</td>\n",
       "      <td>2.397</td>\n",
       "      <td>2.397</td>\n",
       "      <td>2.269</td>\n",
       "      <td>...</td>\n",
       "      <td>9.390</td>\n",
       "      <td>9.231</td>\n",
       "      <td>9.2235</td>\n",
       "      <td>9.216</td>\n",
       "      <td>9.336</td>\n",
       "      <td>9.6840</td>\n",
       "      <td>10.032</td>\n",
       "      <td>9.8945</td>\n",
       "      <td>9.757</td>\n",
       "      <td>9.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xfdaf9f857621ec06f2cf801f42a020a322835090</td>\n",
       "      <td>14.437</td>\n",
       "      <td>16.274</td>\n",
       "      <td>7.031</td>\n",
       "      <td>17.018</td>\n",
       "      <td>17.603</td>\n",
       "      <td>15.005</td>\n",
       "      <td>8.987</td>\n",
       "      <td>8.490</td>\n",
       "      <td>10.136</td>\n",
       "      <td>...</td>\n",
       "      <td>4.141</td>\n",
       "      <td>2.828</td>\n",
       "      <td>3.8230</td>\n",
       "      <td>4.818</td>\n",
       "      <td>3.357</td>\n",
       "      <td>8.1315</td>\n",
       "      <td>12.906</td>\n",
       "      <td>8.0140</td>\n",
       "      <td>3.122</td>\n",
       "      <td>3.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xd28f2f001e0cd4d6c121a3cb2e1427207e170e18</td>\n",
       "      <td>7.824</td>\n",
       "      <td>7.517</td>\n",
       "      <td>5.398</td>\n",
       "      <td>6.788</td>\n",
       "      <td>7.360</td>\n",
       "      <td>6.898</td>\n",
       "      <td>7.321</td>\n",
       "      <td>8.042</td>\n",
       "      <td>8.207</td>\n",
       "      <td>...</td>\n",
       "      <td>6.767</td>\n",
       "      <td>5.919</td>\n",
       "      <td>5.9980</td>\n",
       "      <td>6.077</td>\n",
       "      <td>7.761</td>\n",
       "      <td>6.6080</td>\n",
       "      <td>5.455</td>\n",
       "      <td>5.5670</td>\n",
       "      <td>5.679</td>\n",
       "      <td>8.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0x47218b46abb2fcaade487a211911406dc6e13730</td>\n",
       "      <td>23.965</td>\n",
       "      <td>28.689</td>\n",
       "      <td>27.664</td>\n",
       "      <td>29.229</td>\n",
       "      <td>29.548</td>\n",
       "      <td>27.909</td>\n",
       "      <td>26.923</td>\n",
       "      <td>21.277</td>\n",
       "      <td>23.452</td>\n",
       "      <td>...</td>\n",
       "      <td>20.747</td>\n",
       "      <td>19.979</td>\n",
       "      <td>20.1925</td>\n",
       "      <td>20.406</td>\n",
       "      <td>23.668</td>\n",
       "      <td>27.7900</td>\n",
       "      <td>31.912</td>\n",
       "      <td>29.1125</td>\n",
       "      <td>26.313</td>\n",
       "      <td>24.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>11.302</td>\n",
       "      <td>14.178</td>\n",
       "      <td>15.499</td>\n",
       "      <td>11.853</td>\n",
       "      <td>17.431</td>\n",
       "      <td>14.506</td>\n",
       "      <td>12.812</td>\n",
       "      <td>10.472</td>\n",
       "      <td>10.879</td>\n",
       "      <td>...</td>\n",
       "      <td>14.036</td>\n",
       "      <td>15.990</td>\n",
       "      <td>15.5505</td>\n",
       "      <td>15.111</td>\n",
       "      <td>16.506</td>\n",
       "      <td>18.7585</td>\n",
       "      <td>21.011</td>\n",
       "      <td>19.2040</td>\n",
       "      <td>17.397</td>\n",
       "      <td>15.237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id  2017-01-01  2017-01-02  \\\n",
       "0     0xa62b9f23553ff183f61e2bf943aab3d5983d02d7       0.000       0.000   \n",
       "1     0x459c834d1f6cfb5b734b82aa9f5410fa97fb70da       0.000       0.000   \n",
       "2     0x4a1ed36825360a058cec2bdd409fc2459e1ce54f       0.000       0.000   \n",
       "3     0x5b76d3c0e0aefc6e0a8d1d031f96388a23263407       0.000       0.000   \n",
       "4     0x943ebe39ef2be6ef807c42c5a647e27112ca5b0f       0.000       0.000   \n",
       "...                                          ...         ...         ...   \n",
       "3243  0x7dd7a7b8ee1bec7c44b24f738c752482f6161065       2.317       2.301   \n",
       "3244  0xfdaf9f857621ec06f2cf801f42a020a322835090      14.437      16.274   \n",
       "3245  0xd28f2f001e0cd4d6c121a3cb2e1427207e170e18       7.824       7.517   \n",
       "3246  0x47218b46abb2fcaade487a211911406dc6e13730      23.965      28.689   \n",
       "3247  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd      11.302      14.178   \n",
       "\n",
       "      2017-01-03  2017-01-04  2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "0          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "1          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "2          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "3          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "4          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3243       2.352       2.516       2.229       2.354       2.397       2.397   \n",
       "3244       7.031      17.018      17.603      15.005       8.987       8.490   \n",
       "3245       5.398       6.788       7.360       6.898       7.321       8.042   \n",
       "3246      27.664      29.229      29.548      27.909      26.923      21.277   \n",
       "3247      15.499      11.853      17.431      14.506      12.812      10.472   \n",
       "\n",
       "      2017-01-09  ...  2017-12-22  2017-12-23  2017-12-24  2017-12-25  \\\n",
       "0          0.000  ...       4.030       5.397      5.1075       4.818   \n",
       "1          0.000  ...      13.101      14.327     14.6315      14.936   \n",
       "2          0.000  ...      10.201       7.320      7.3520       7.384   \n",
       "3          0.000  ...      14.833      12.477     11.7255      10.974   \n",
       "4          0.000  ...      39.440      35.538     21.9445       8.351   \n",
       "...          ...  ...         ...         ...         ...         ...   \n",
       "3243       2.269  ...       9.390       9.231      9.2235       9.216   \n",
       "3244      10.136  ...       4.141       2.828      3.8230       4.818   \n",
       "3245       8.207  ...       6.767       5.919      5.9980       6.077   \n",
       "3246      23.452  ...      20.747      19.979     20.1925      20.406   \n",
       "3247      10.879  ...      14.036      15.990     15.5505      15.111   \n",
       "\n",
       "      2017-12-26  2017-12-27  2017-12-28  2017-12-29  2017-12-30  2017-12-31  \n",
       "0          3.931      4.2170       4.503      4.8160       5.129       5.395  \n",
       "1         16.174     20.3960      24.618     19.8925      15.167      11.751  \n",
       "2         14.425     16.0650      17.705     13.3355       8.966       4.633  \n",
       "3         19.646     21.8195      23.993     19.9170      15.841      14.452  \n",
       "4          9.957     17.9140      25.871     36.0725      46.274      16.901  \n",
       "...          ...         ...         ...         ...         ...         ...  \n",
       "3243       9.336      9.6840      10.032      9.8945       9.757       9.480  \n",
       "3244       3.357      8.1315      12.906      8.0140       3.122       3.401  \n",
       "3245       7.761      6.6080       5.455      5.5670       5.679       8.148  \n",
       "3246      23.668     27.7900      31.912     29.1125      26.313      24.201  \n",
       "3247      16.506     18.7585      21.011     19.2040      17.397      15.237  \n",
       "\n",
       "[3248 rows x 366 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2017-01</th>\n",
       "      <th>2017-02</th>\n",
       "      <th>2017-03</th>\n",
       "      <th>2017-04</th>\n",
       "      <th>2017-05</th>\n",
       "      <th>2017-06</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.39450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>553.18400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>368.90957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>534.84650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>946.06400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>72.7050</td>\n",
       "      <td>63.245</td>\n",
       "      <td>68.4335</td>\n",
       "      <td>66.6265</td>\n",
       "      <td>69.0480</td>\n",
       "      <td>100.430</td>\n",
       "      <td>177.1735</td>\n",
       "      <td>177.4100</td>\n",
       "      <td>216.7245</td>\n",
       "      <td>279.164500</td>\n",
       "      <td>351.481000</td>\n",
       "      <td>312.08800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>371.4390</td>\n",
       "      <td>269.691</td>\n",
       "      <td>179.3430</td>\n",
       "      <td>141.6590</td>\n",
       "      <td>138.4835</td>\n",
       "      <td>122.910</td>\n",
       "      <td>164.2285</td>\n",
       "      <td>100.9610</td>\n",
       "      <td>118.0520</td>\n",
       "      <td>123.135500</td>\n",
       "      <td>187.140000</td>\n",
       "      <td>186.88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>209.8065</td>\n",
       "      <td>169.858</td>\n",
       "      <td>184.0130</td>\n",
       "      <td>166.7280</td>\n",
       "      <td>134.1760</td>\n",
       "      <td>169.489</td>\n",
       "      <td>157.5775</td>\n",
       "      <td>165.9640</td>\n",
       "      <td>177.0105</td>\n",
       "      <td>185.701833</td>\n",
       "      <td>192.288667</td>\n",
       "      <td>200.61950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>845.6630</td>\n",
       "      <td>608.449</td>\n",
       "      <td>588.7765</td>\n",
       "      <td>503.3050</td>\n",
       "      <td>291.1320</td>\n",
       "      <td>177.605</td>\n",
       "      <td>183.5345</td>\n",
       "      <td>182.0350</td>\n",
       "      <td>244.2255</td>\n",
       "      <td>371.458333</td>\n",
       "      <td>695.878667</td>\n",
       "      <td>858.83950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>428.7345</td>\n",
       "      <td>670.505</td>\n",
       "      <td>462.1050</td>\n",
       "      <td>354.8660</td>\n",
       "      <td>287.9950</td>\n",
       "      <td>200.321</td>\n",
       "      <td>227.0855</td>\n",
       "      <td>231.7585</td>\n",
       "      <td>246.3005</td>\n",
       "      <td>344.210167</td>\n",
       "      <td>516.290333</td>\n",
       "      <td>734.61800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id   2017-01  2017-02   2017-03  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c    0.0000    0.000    0.0000   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82    0.0000    0.000    0.0000   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734    0.0000    0.000    0.0000   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a    0.0000    0.000    0.0000   \n",
       "4     0x005958406351bb29580475df698b5f1070096397    0.0000    0.000    0.0000   \n",
       "...                                          ...       ...      ...       ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f   72.7050   63.245   68.4335   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb  371.4390  269.691  179.3430   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5  209.8065  169.858  184.0130   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02  845.6630  608.449  588.7765   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4  428.7345  670.505  462.1050   \n",
       "\n",
       "       2017-04   2017-05  2017-06   2017-07   2017-08   2017-09     2017-10  \\\n",
       "0       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "1       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "2       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "3       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "4       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "...        ...       ...      ...       ...       ...       ...         ...   \n",
       "3243   66.6265   69.0480  100.430  177.1735  177.4100  216.7245  279.164500   \n",
       "3244  141.6590  138.4835  122.910  164.2285  100.9610  118.0520  123.135500   \n",
       "3245  166.7280  134.1760  169.489  157.5775  165.9640  177.0105  185.701833   \n",
       "3246  503.3050  291.1320  177.605  183.5345  182.0350  244.2255  371.458333   \n",
       "3247  354.8660  287.9950  200.321  227.0855  231.7585  246.3005  344.210167   \n",
       "\n",
       "         2017-11    2017-12  \n",
       "0       0.000000  128.39450  \n",
       "1       0.000000  553.18400  \n",
       "2       0.000000  368.90957  \n",
       "3       0.000000  534.84650  \n",
       "4       0.000000  946.06400  \n",
       "...          ...        ...  \n",
       "3243  351.481000  312.08800  \n",
       "3244  187.140000  186.88400  \n",
       "3245  192.288667  200.61950  \n",
       "3246  695.878667  858.83950  \n",
       "3247  516.290333  734.61800  \n",
       "\n",
       "[3248 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading the training data\n",
    "print(\"training data\")\n",
    "df_train_daily = pd.read_pickle(\"../Data/Preprocessed_Data/consumption_daily_nan_interpolated.pkl\").fillna(0)\n",
    "\n",
    "#aggregating up into months\n",
    "meter_id=df_monthly_forecasts[\"meter_id\"]\n",
    "df_train_monthly = pd.DataFrame(columns=[\"meter_id\"])\n",
    "df_train_monthly[\"meter_id\"] = meter_id\n",
    "\n",
    "\n",
    "#for each month in the range of dates\n",
    "resample_size=\"M\"\n",
    "for new_sample in tqdm(pd.date_range(datetime.datetime(2017, 1, 1), datetime.datetime(2017, 12, 31), freq = resample_size),position=0):\n",
    "\n",
    "    #get this columns name as a string\n",
    "    columnName = str(new_sample.date())[:7]\n",
    "    #get all columns that relate to this new sample\n",
    "    columns = [i for i in df_train_daily.columns.values[1:] if i.startswith(columnName)]\n",
    "\n",
    "    #sum these up into a value for the new sample size\n",
    "    df_train_monthly[columnName] = df_train_daily[columns].sum(axis=1)\n",
    "\n",
    "display(df_train_daily)\n",
    "display(df_train_monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the predictions against the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713dc05283484500b13d59e272787aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_plots = 10\n",
    "for pid in tqdm(range(0,3248)):\n",
    "    if pid>num_plots:\n",
    "        break\n",
    "        \n",
    "    #getting the row corresponding to this meter_id\n",
    "    meter_id = df_daily_forecasts.iloc[pid,0]\n",
    "    this_train_month = df_train_monthly.loc[df_train_monthly['meter_id'] == meter_id].T[1:]\n",
    "    this_preds_month = df_monthly_forecasts.loc[df_train_monthly['meter_id'] == meter_id].T[1:]\n",
    "    \n",
    "    #converting index to datetime for ease of plots key\n",
    "    this_train_month.index=pd.to_datetime(this_train_month.index)\n",
    "    this_preds_month.index=pd.to_datetime(this_preds_month.index)\n",
    "    \n",
    "    #creating figure\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    \n",
    "    #plotting the monthly predictions\n",
    "    plt.title(\"Meter '\"+str(meter_id)+\"' monthly forecasts and historical data\", fontsize=15)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Energy Usage kWh\")\n",
    "    plt.plot(this_train_month, label=\"training monthly energy\", lw=1,color=\"skyblue\", marker=\"x\")\n",
    "    plt.plot(this_preds_month, label=\"forecast monthly energy\", lw=1,color=\"mediumorchid\", marker=\"x\")\n",
    "    \n",
    "    #annotations\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.locator_params(nbins=24)\n",
    "    \n",
    "    #plt.show()\n",
    "    fig.savefig(f\"..\\\\Results\\\\Genetic Algorithm\\\\Plots\\\\forecasts\\\\p{population_size}_g{number_of_generations}_forecasts_{pid}_{meter_id}.png\")\n",
    "\n",
    "    fig.clf()\n",
    "    fig.clear()\n",
    "    plt.close()\n",
    "    del fig, this_train_month, this_preds_month\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model based on the main effects\n",
    "* Running on the hyper params determined by main effects (setting that gave the lowest mean result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meter_id_ord True\n",
      "meter_id_binary True\n",
      "day_of_year_cyclic True\n",
      "day_of_week True\n",
      "day_of_month True\n",
      "month_ord True\n",
      "month_cyclic True\n",
      "is_weekend False\n",
      "energy_cluster True\n",
      "num_bedrooms True\n",
      "dwelling_type_ord True\n",
      "dwelling_type_onehot True\n",
      "['meter_id_ord', 'meter_id_binary', 'day_of_year_cyclic', 'day_of_week', 'day_of_month', 'month_ord', 'month_cyclic', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'dwelling_type_onehot']\n"
     ]
    }
   ],
   "source": [
    "# treating columns like main effects: accepting those whose mean error with the column is better than that without the column\n",
    "main_columm_types = []\n",
    "i=0\n",
    "for key in possible_columns.keys():\n",
    "    print(key,column_means[i]<columnless_means[i])\n",
    "    main_columm_types.append(key)\n",
    "    i+=1 \n",
    "print(main_columm_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learning_rate', 'num_leaves', 'max_depth', 'bagging_fraction', 'bagging_freq', 'feature_fraction', 'lambda_l1', 'lambda_l2']\n",
      "[array([0.0322]), array([1366.]), array([14.]), array([0.702]), array([22.]), array([0.7812]), array([20.]), array([9.])]\n"
     ]
    }
   ],
   "source": [
    "#inspecting the stored best values for each hyper as determined by the main effects plot\n",
    "#(value which resulted in the lowest average MAE on the val set)\n",
    "print(arr_hypers)\n",
    "print(arr_best_hypers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mRunning with main effects determined configuration\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mUsing the features\u001b[0m\n",
      "['meter_id_ord', 'meter_id_0', 'meter_id_1', 'meter_id_2', 'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7', 'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12', 'day_of_year_sin', 'day_of_year_cos', 'day_of_week', 'day_of_month', 'month_ord', 'month_sin', 'month_cos', 'is_weekend', 'energy_cluster', 'num_bedrooms', 'dwelling_type_ord', 'detached', 'flat', 'semi_detached', 'terraced']\n",
      "\u001b[1m\u001b[94m\u001b[4mUsing the main effects hyper parameters\u001b[0m\n",
      "{'bagging_fraction': 0.7020000000000001,\n",
      " 'bagging_freq': 22,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.7812,\n",
      " 'lambda_l1': 20,\n",
      " 'lambda_l2': 9,\n",
      " 'learning_rate': 0.0322,\n",
      " 'max_depth': 14,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 1366,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 1\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7020000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7020000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90048\n",
      "[6666]\tvalid_0's l1: 1.88891\n",
      "[9999]\tvalid_0's l1: 1.8826\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9878]\tvalid_0's l1: 1.88237\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 2\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7020000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7020000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.9011\n",
      "[6666]\tvalid_0's l1: 1.88832\n",
      "Early stopping, best iteration is:\n",
      "[8204]\tvalid_0's l1: 1.88474\n",
      "\u001b[1m\u001b[94m\u001b[4mFold 3\u001b[0m\n",
      "\u001b[96m\u001b[4mTraining the LGBM\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7812\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7020000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7020000000000001\n",
      "[LightGBM] [Warning] num_threads is set=-1, n_jobs=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] lambda_l2 is set=9, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9\n",
      "[LightGBM] [Warning] bagging_freq is set=22, subsample_freq=0 will be ignored. Current value: bagging_freq=22\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[3333]\tvalid_0's l1: 1.90834\n",
      "[6666]\tvalid_0's l1: 1.89563\n",
      "Early stopping, best iteration is:\n",
      "[7172]\tvalid_0's l1: 1.89356\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mTrained the model in 1:44:58\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}Running with main effects determined configuration{color.END}\")\n",
    "\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Using the features{color.END}\")\n",
    "X_cols =[]\n",
    "\n",
    "for key in main_columm_types:\n",
    "    X_cols+=(possible_columns[key])\n",
    "this_X_cats = list(set(X_cols).intersection(all_cat)) #getting the categorical values for this X\n",
    "print(X_cols)\n",
    "\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Using the main effects hyper parameters{color.END}\")\n",
    "this_params = params.copy()\n",
    "this_params[\"learning_rate\"] = arr_best_hypers[0][0]\n",
    "this_params[\"max_depth\"] = int(arr_best_hypers[2][0])\n",
    "this_params[\"num_leaves\"] = int(arr_best_hypers[1][0])\n",
    "this_params[\"bagging_fraction\"] = arr_best_hypers[3][0]\n",
    "this_params[\"bagging_freq\"] = int(arr_best_hypers[4][0])\n",
    "this_params[\"feature_fraction\"] = arr_best_hypers[5][0]\n",
    "this_params[\"lambda_l1\"] = int(arr_best_hypers[6][0])\n",
    "this_params[\"lambda_l2\"] = int(arr_best_hypers[7][0])\n",
    "pprint(this_params)\n",
    "\n",
    "#train the model with this hyper param config and store it's results\n",
    "results=((run_lgbm_skf_cv(False, False, SEED, num_folds, df_train.copy(), y_col, X_cols, this_X_cats, this_params),(X_cols,this_params)))\n",
    "print(\"\\n\\n\\n\")\n",
    "time_of_execution = time.time()-start_time\n",
    "print(f\"{color.BOLD}Trained the model in {str(datetime.timedelta(seconds=round(time_of_execution)))}{color.END}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting from the main effects model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>meter_id_ord</th>\n",
       "      <th>meter_id_0</th>\n",
       "      <th>meter_id_1</th>\n",
       "      <th>meter_id_2</th>\n",
       "      <th>meter_id_3</th>\n",
       "      <th>meter_id_4</th>\n",
       "      <th>meter_id_5</th>\n",
       "      <th>meter_id_6</th>\n",
       "      <th>meter_id_7</th>\n",
       "      <th>...</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>energy_cluster</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>dwelling_type_ord</th>\n",
       "      <th>detached</th>\n",
       "      <th>flat</th>\n",
       "      <th>semi_detached</th>\n",
       "      <th>terraced</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.782234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.015384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.521729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.493529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>terraced_house</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185515</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.866215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185516</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.848111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185517</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.849250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185518</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.970654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185519</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>2605</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>detached_house</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.630209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185520 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           meter_id meter_id_ord meter_id_0  \\\n",
       "0        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7         2073          0   \n",
       "1        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7         2073          0   \n",
       "2        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7         2073          0   \n",
       "3        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7         2073          0   \n",
       "4        0xa62b9f23553ff183f61e2bf943aab3d5983d02d7         2073          0   \n",
       "...                                             ...          ...        ...   \n",
       "1185515  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd         2605          0   \n",
       "1185516  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd         2605          0   \n",
       "1185517  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd         2605          0   \n",
       "1185518  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd         2605          0   \n",
       "1185519  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd         2605          0   \n",
       "\n",
       "        meter_id_1 meter_id_2 meter_id_3 meter_id_4 meter_id_5 meter_id_6  \\\n",
       "0                0          0          0          0          0          0   \n",
       "1                0          0          0          0          0          0   \n",
       "2                0          0          0          0          0          0   \n",
       "3                0          0          0          0          0          0   \n",
       "4                0          0          0          0          0          0   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "1185515          1          1          0          0          1          0   \n",
       "1185516          1          1          0          0          1          0   \n",
       "1185517          1          1          0          0          1          0   \n",
       "1185518          1          1          0          0          1          0   \n",
       "1185519          1          1          0          0          1          0   \n",
       "\n",
       "        meter_id_7  ... is_weekend energy_cluster num_bedrooms  \\\n",
       "0                0  ...          0              0          2.0   \n",
       "1                0  ...          0              0          2.0   \n",
       "2                0  ...          0              0          2.0   \n",
       "3                0  ...          0              0          2.0   \n",
       "4                0  ...          0              0          2.0   \n",
       "...            ...  ...        ...            ...          ...   \n",
       "1185515          1  ...          0              2          3.0   \n",
       "1185516          1  ...          0              2          3.0   \n",
       "1185517          1  ...          1              2          3.0   \n",
       "1185518          1  ...          1              2          3.0   \n",
       "1185519          1  ...          0              2          3.0   \n",
       "\n",
       "          dwelling_type dwelling_type_ord detached  flat  semi_detached  \\\n",
       "0        terraced_house                 4      0.0   0.0            0.0   \n",
       "1        terraced_house                 4      0.0   0.0            0.0   \n",
       "2        terraced_house                 4      0.0   0.0            0.0   \n",
       "3        terraced_house                 4      0.0   0.0            0.0   \n",
       "4        terraced_house                 4      0.0   0.0            0.0   \n",
       "...                 ...               ...      ...   ...            ...   \n",
       "1185515  detached_house                 1      1.0   0.0            0.0   \n",
       "1185516  detached_house                 1      1.0   0.0            0.0   \n",
       "1185517  detached_house                 1      1.0   0.0            0.0   \n",
       "1185518  detached_house                 1      1.0   0.0            0.0   \n",
       "1185519  detached_house                 1      1.0   0.0            0.0   \n",
       "\n",
       "        terraced meter_reading  \n",
       "0            1.0      5.782234  \n",
       "1            1.0      6.015384  \n",
       "2            1.0      5.521729  \n",
       "3            1.0      5.493529  \n",
       "4            1.0      5.507812  \n",
       "...          ...           ...  \n",
       "1185515      0.0     18.866215  \n",
       "1185516      0.0     18.848111  \n",
       "1185517      0.0     17.849250  \n",
       "1185518      0.0     17.970654  \n",
       "1185519      0.0     15.630209  \n",
       "\n",
       "[1185520 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#making predictions based on the best performing model and displaying it's information\n",
    "main_effects_models = results[0][2] #getting the lgbm_models from the best index\n",
    "main_effects_forecasts = df_preds.copy()\n",
    "\n",
    "#calculating the average preds by summing the weighted preds for each folds model\n",
    "for i in range(len(main_effects_models)):\n",
    "    pred_forecasts = main_effects_models[i].predict(main_effects_forecasts[results[1][0]], num_iteration=main_effects_models[i].best_iteration_) #predicting the unkown df_preds\n",
    "    main_effects_forecasts[y_col] += pred_forecasts / num_folds #weighting the predictions for BEST_LGBM_FORECASTS for this fold and adding to df_preds y column \n",
    "main_effects_forecasts[\"meter_reading\"] = main_effects_forecasts.meter_reading.clip(lower=0) #clip meter_reading so no predictions lower than 0\n",
    "\n",
    "display(main_effects_forecasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the val error of the main effects vs the best from genetic algorithm tuning\n",
    "## Genetic Algorithm summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mGA best model came from generation 7 individual 7\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mEvaluation and results\u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.7620903897052624\n",
      "\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper-parameters\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mX_cols:\u001b[0m\n",
      "\n",
      "['meter_id_ord',\n",
      " 'day_of_year_sin',\n",
      " 'day_of_year_cos',\n",
      " 'day_of_week',\n",
      " 'month_ord',\n",
      " 'is_weekend',\n",
      " 'energy_cluster',\n",
      " 'num_bedrooms',\n",
      " 'dwelling_type_ord']\n",
      "\u001b[1m\u001b[96m\u001b[4mmodel params:  \u001b[0m\n",
      "{'bagging_fraction': 0.7020000000000001,\n",
      " 'bagging_freq': 21,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.7812,\n",
      " 'lambda_l1': 8,\n",
      " 'lambda_l2': 10,\n",
      " 'learning_rate': 0.06,\n",
      " 'max_depth': 12,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 1764,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n"
     ]
    }
   ],
   "source": [
    "#printing the forecasts and other evaluation info\n",
    "print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}GA best model came from generation {int(best_index/population_size)} individual {best_index%population_size}{color.END}\")\n",
    "#displaying the results\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Evaluation and results{color.END}\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set:{color.END} {best_results[0][1]}\\n\")\n",
    "#displaying the hyperparameters\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Hyper-parameters{color.END}\")\n",
    "print(f\"\\n{color.BOLD}{color.CYAN}{color.UNDERLINE}X_cols:{color.END}\\n\")\n",
    "pprint(best_results[1][0])\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}model params:  {color.END}\")\n",
    "pprint(best_results[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main effects based model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mMain effects model based on results of GA\u001b[0m\n",
      "\u001b[1m\u001b[94m\u001b[4mEvaluation and results\u001b[0m\n",
      "\u001b[1m\u001b[96m\u001b[4mMean absolute error between OOF preds and meter_reading on training set:\u001b[0m 1.8868871780860033\n",
      "\n",
      "\u001b[1m\u001b[94m\u001b[4mHyper-parameters\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[96m\u001b[4mX_cols:\u001b[0m\n",
      "\n",
      "['meter_id_ord',\n",
      " 'meter_id_0',\n",
      " 'meter_id_1',\n",
      " 'meter_id_2',\n",
      " 'meter_id_3',\n",
      " 'meter_id_4',\n",
      " 'meter_id_5',\n",
      " 'meter_id_6',\n",
      " 'meter_id_7',\n",
      " 'meter_id_8',\n",
      " 'meter_id_9',\n",
      " 'meter_id_10',\n",
      " 'meter_id_11',\n",
      " 'meter_id_12',\n",
      " 'day_of_year_sin',\n",
      " 'day_of_year_cos',\n",
      " 'day_of_week',\n",
      " 'day_of_month',\n",
      " 'month_ord',\n",
      " 'month_sin',\n",
      " 'month_cos',\n",
      " 'is_weekend',\n",
      " 'energy_cluster',\n",
      " 'num_bedrooms',\n",
      " 'dwelling_type_ord',\n",
      " 'detached',\n",
      " 'flat',\n",
      " 'semi_detached',\n",
      " 'terraced']\n",
      "\u001b[1m\u001b[96m\u001b[4mmodel params:  \u001b[0m\n",
      "{'bagging_fraction': 0.7020000000000001,\n",
      " 'bagging_freq': 22,\n",
      " 'boosting_type': 'gbdt',\n",
      " 'device': 'cpu',\n",
      " 'feature_fraction': 0.7812,\n",
      " 'lambda_l1': 20,\n",
      " 'lambda_l2': 9,\n",
      " 'learning_rate': 0.0322,\n",
      " 'max_depth': 14,\n",
      " 'metric': 'mae',\n",
      " 'num_iterations': 10000,\n",
      " 'num_leaves': 1366,\n",
      " 'num_threads': -1,\n",
      " 'seed': 96}\n"
     ]
    }
   ],
   "source": [
    "#printing the forecasts and other evaluation info\n",
    "print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}Main effects model based on results of GA{color.END}\")\n",
    "#displaying the results\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Evaluation and results{color.END}\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set:{color.END} {results[0][1]}\\n\")\n",
    "#displaying the hyperparameters\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Hyper-parameters{color.END}\")\n",
    "print(f\"\\n{color.BOLD}{color.CYAN}{color.UNDERLINE}X_cols:{color.END}\\n\")\n",
    "pprint(results[1][0])\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}model params:  {color.END}\")\n",
    "pprint(results[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "the best model from the GA is way better than the main effects of the GA\n",
    "\n",
    "\n",
    "# Save the main effects description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE': 1.8868871780860033,\n",
      " 'features': ['meter_id_ord',\n",
      "              'meter_id_0',\n",
      "              'meter_id_1',\n",
      "              'meter_id_2',\n",
      "              'meter_id_3',\n",
      "              'meter_id_4',\n",
      "              'meter_id_5',\n",
      "              'meter_id_6',\n",
      "              'meter_id_7',\n",
      "              'meter_id_8',\n",
      "              'meter_id_9',\n",
      "              'meter_id_10',\n",
      "              'meter_id_11',\n",
      "              'meter_id_12',\n",
      "              'day_of_year_sin',\n",
      "              'day_of_year_cos',\n",
      "              'day_of_week',\n",
      "              'day_of_month',\n",
      "              'month_ord',\n",
      "              'month_sin',\n",
      "              'month_cos',\n",
      "              'is_weekend',\n",
      "              'energy_cluster',\n",
      "              'num_bedrooms',\n",
      "              'dwelling_type_ord',\n",
      "              'detached',\n",
      "              'flat',\n",
      "              'semi_detached',\n",
      "              'terraced'],\n",
      " 'params': {'bagging_fraction': 0.7020000000000001,\n",
      "            'bagging_freq': 22,\n",
      "            'boosting_type': 'gbdt',\n",
      "            'device': 'cpu',\n",
      "            'feature_fraction': 0.7812,\n",
      "            'lambda_l1': 20,\n",
      "            'lambda_l2': 9,\n",
      "            'learning_rate': 0.0322,\n",
      "            'max_depth': 14,\n",
      "            'metric': 'mae',\n",
      "            'num_iterations': 10000,\n",
      "            'num_leaves': 1366,\n",
      "            'num_threads': -1,\n",
      "            'seed': 96}}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "a = {'hello': 'world'}\n",
    "desc_disc = {\n",
    "    \"MAE\":results[0][1],\n",
    "    \"features\":results[1][0],\n",
    "    \"params\":results[1][1]\n",
    "}\n",
    "\n",
    "with open(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_main_effects_desc.pkl\", 'wb') as handle:\n",
    "    pickle.dump(desc_disc, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "pprint(desc_disc)\n",
    "    \n",
    "# verifying it saved correctly and can be loaded back\n",
    "with open(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_main_effects_desc.pkl\", 'rb') as handle:\n",
    "    desc_disc_loaded = pickle.load(handle)\n",
    "print(desc_disc == desc_disc_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting the main effects forecasts and saving them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting into monthly forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>148.103123</td>\n",
       "      <td>126.047486</td>\n",
       "      <td>117.925117</td>\n",
       "      <td>109.387841</td>\n",
       "      <td>110.934115</td>\n",
       "      <td>109.137093</td>\n",
       "      <td>109.774808</td>\n",
       "      <td>115.590481</td>\n",
       "      <td>117.942503</td>\n",
       "      <td>122.904572</td>\n",
       "      <td>106.357593</td>\n",
       "      <td>127.947633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>663.947407</td>\n",
       "      <td>615.413838</td>\n",
       "      <td>555.206666</td>\n",
       "      <td>474.893806</td>\n",
       "      <td>462.997069</td>\n",
       "      <td>424.632680</td>\n",
       "      <td>416.615935</td>\n",
       "      <td>419.407808</td>\n",
       "      <td>484.817919</td>\n",
       "      <td>538.426473</td>\n",
       "      <td>604.488745</td>\n",
       "      <td>648.407097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>281.661955</td>\n",
       "      <td>220.686334</td>\n",
       "      <td>217.999392</td>\n",
       "      <td>208.568788</td>\n",
       "      <td>203.172608</td>\n",
       "      <td>196.110522</td>\n",
       "      <td>198.580530</td>\n",
       "      <td>202.563643</td>\n",
       "      <td>199.765996</td>\n",
       "      <td>202.128198</td>\n",
       "      <td>210.005141</td>\n",
       "      <td>238.153385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>191.826094</td>\n",
       "      <td>158.906076</td>\n",
       "      <td>157.681381</td>\n",
       "      <td>136.260505</td>\n",
       "      <td>137.123556</td>\n",
       "      <td>136.923778</td>\n",
       "      <td>128.787736</td>\n",
       "      <td>127.673461</td>\n",
       "      <td>139.792119</td>\n",
       "      <td>148.939867</td>\n",
       "      <td>144.236723</td>\n",
       "      <td>172.507435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>352.760204</td>\n",
       "      <td>294.627843</td>\n",
       "      <td>304.077747</td>\n",
       "      <td>254.927531</td>\n",
       "      <td>250.524546</td>\n",
       "      <td>263.292773</td>\n",
       "      <td>260.921198</td>\n",
       "      <td>257.780558</td>\n",
       "      <td>249.459448</td>\n",
       "      <td>290.452804</td>\n",
       "      <td>303.802952</td>\n",
       "      <td>348.777766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>216.847058</td>\n",
       "      <td>167.058181</td>\n",
       "      <td>154.512254</td>\n",
       "      <td>135.929742</td>\n",
       "      <td>136.600318</td>\n",
       "      <td>125.325934</td>\n",
       "      <td>126.929325</td>\n",
       "      <td>132.860425</td>\n",
       "      <td>132.520613</td>\n",
       "      <td>145.897410</td>\n",
       "      <td>155.190635</td>\n",
       "      <td>175.917894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>659.869224</td>\n",
       "      <td>620.657962</td>\n",
       "      <td>706.220009</td>\n",
       "      <td>665.454411</td>\n",
       "      <td>592.306253</td>\n",
       "      <td>472.975237</td>\n",
       "      <td>469.123116</td>\n",
       "      <td>484.733388</td>\n",
       "      <td>519.891421</td>\n",
       "      <td>567.873309</td>\n",
       "      <td>572.101133</td>\n",
       "      <td>624.286265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>528.680889</td>\n",
       "      <td>418.647807</td>\n",
       "      <td>411.321297</td>\n",
       "      <td>370.840117</td>\n",
       "      <td>340.404054</td>\n",
       "      <td>265.169053</td>\n",
       "      <td>270.523217</td>\n",
       "      <td>276.889334</td>\n",
       "      <td>301.184396</td>\n",
       "      <td>352.258311</td>\n",
       "      <td>421.925735</td>\n",
       "      <td>518.361081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>398.197358</td>\n",
       "      <td>373.052613</td>\n",
       "      <td>340.143490</td>\n",
       "      <td>351.804384</td>\n",
       "      <td>219.967255</td>\n",
       "      <td>200.310985</td>\n",
       "      <td>192.886359</td>\n",
       "      <td>206.880501</td>\n",
       "      <td>222.482800</td>\n",
       "      <td>268.055811</td>\n",
       "      <td>317.407329</td>\n",
       "      <td>389.661978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>267.125199</td>\n",
       "      <td>228.718424</td>\n",
       "      <td>239.872865</td>\n",
       "      <td>219.698209</td>\n",
       "      <td>223.876639</td>\n",
       "      <td>213.046245</td>\n",
       "      <td>220.702182</td>\n",
       "      <td>222.153858</td>\n",
       "      <td>225.971998</td>\n",
       "      <td>231.866927</td>\n",
       "      <td>237.990553</td>\n",
       "      <td>241.023429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id         Jan         Feb  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c  148.103123  126.047486   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82  663.947407  615.413838   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734  281.661955  220.686334   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a  191.826094  158.906076   \n",
       "4     0x005958406351bb29580475df698b5f1070096397  352.760204  294.627843   \n",
       "...                                          ...         ...         ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f  216.847058  167.058181   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb  659.869224  620.657962   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5  528.680889  418.647807   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02  398.197358  373.052613   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4  267.125199  228.718424   \n",
       "\n",
       "             Mar         Apr         May         Jun         Jul         Aug  \\\n",
       "0     117.925117  109.387841  110.934115  109.137093  109.774808  115.590481   \n",
       "1     555.206666  474.893806  462.997069  424.632680  416.615935  419.407808   \n",
       "2     217.999392  208.568788  203.172608  196.110522  198.580530  202.563643   \n",
       "3     157.681381  136.260505  137.123556  136.923778  128.787736  127.673461   \n",
       "4     304.077747  254.927531  250.524546  263.292773  260.921198  257.780558   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3243  154.512254  135.929742  136.600318  125.325934  126.929325  132.860425   \n",
       "3244  706.220009  665.454411  592.306253  472.975237  469.123116  484.733388   \n",
       "3245  411.321297  370.840117  340.404054  265.169053  270.523217  276.889334   \n",
       "3246  340.143490  351.804384  219.967255  200.310985  192.886359  206.880501   \n",
       "3247  239.872865  219.698209  223.876639  213.046245  220.702182  222.153858   \n",
       "\n",
       "             Sep         Oct         Nov         Dec  \n",
       "0     117.942503  122.904572  106.357593  127.947633  \n",
       "1     484.817919  538.426473  604.488745  648.407097  \n",
       "2     199.765996  202.128198  210.005141  238.153385  \n",
       "3     139.792119  148.939867  144.236723  172.507435  \n",
       "4     249.459448  290.452804  303.802952  348.777766  \n",
       "...          ...         ...         ...         ...  \n",
       "3243  132.520613  145.897410  155.190635  175.917894  \n",
       "3244  519.891421  567.873309  572.101133  624.286265  \n",
       "3245  301.184396  352.258311  421.925735  518.361081  \n",
       "3246  222.482800  268.055811  317.407329  389.661978  \n",
       "3247  225.971998  231.866927  237.990553  241.023429  \n",
       "\n",
       "[3248 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#restructuring into the original multiple time series format\n",
    "#aggregating up the total sum of the months predictions\n",
    "df_monthly_forecasts = main_effects_forecasts.groupby([\"meter_id\", \"month_ord\"])[\"meter_reading\"].sum().unstack()\n",
    "\n",
    "#rename ordinal encoded month with its corresponding name\n",
    "df_monthly_forecasts.rename(columns={1:\"Jan\", 2:\"Feb\",3:\"Mar\",4:\"Apr\",5:\"May\",6:\"Jun\",7:\"Jul\",8:\"Aug\",9:\"Sep\",10:\"Oct\",11:\"Nov\",12:\"Dec\"}, inplace=True)\n",
    "#resetting the index \n",
    "df_monthly_forecasts.reset_index(inplace=True)\n",
    "df_monthly_forecasts.index.name = None # removing index column\n",
    "df_monthly_forecasts.columns.name = None # removing columns name\n",
    "\n",
    "display(df_monthly_forecasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving these monthly predictions to be submitted to competition\n",
    "* Saving predictions ready to be submitted so I can get the MAE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_forecasts.to_csv(f\"..\\\\Results\\\\Genetic Algorithm\\\\p{population_size}_g{number_of_generations}_main_effects_monthly_forecasts.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting these monthly forecasts\n",
    "## Renaming months to dates for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "      <th>2018-05</th>\n",
       "      <th>2018-06</th>\n",
       "      <th>2018-07</th>\n",
       "      <th>2018-08</th>\n",
       "      <th>2018-09</th>\n",
       "      <th>2018-10</th>\n",
       "      <th>2018-11</th>\n",
       "      <th>2018-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>148.103123</td>\n",
       "      <td>126.047486</td>\n",
       "      <td>117.925117</td>\n",
       "      <td>109.387841</td>\n",
       "      <td>110.934115</td>\n",
       "      <td>109.137093</td>\n",
       "      <td>109.774808</td>\n",
       "      <td>115.590481</td>\n",
       "      <td>117.942503</td>\n",
       "      <td>122.904572</td>\n",
       "      <td>106.357593</td>\n",
       "      <td>127.947633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>663.947407</td>\n",
       "      <td>615.413838</td>\n",
       "      <td>555.206666</td>\n",
       "      <td>474.893806</td>\n",
       "      <td>462.997069</td>\n",
       "      <td>424.632680</td>\n",
       "      <td>416.615935</td>\n",
       "      <td>419.407808</td>\n",
       "      <td>484.817919</td>\n",
       "      <td>538.426473</td>\n",
       "      <td>604.488745</td>\n",
       "      <td>648.407097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>281.661955</td>\n",
       "      <td>220.686334</td>\n",
       "      <td>217.999392</td>\n",
       "      <td>208.568788</td>\n",
       "      <td>203.172608</td>\n",
       "      <td>196.110522</td>\n",
       "      <td>198.580530</td>\n",
       "      <td>202.563643</td>\n",
       "      <td>199.765996</td>\n",
       "      <td>202.128198</td>\n",
       "      <td>210.005141</td>\n",
       "      <td>238.153385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>191.826094</td>\n",
       "      <td>158.906076</td>\n",
       "      <td>157.681381</td>\n",
       "      <td>136.260505</td>\n",
       "      <td>137.123556</td>\n",
       "      <td>136.923778</td>\n",
       "      <td>128.787736</td>\n",
       "      <td>127.673461</td>\n",
       "      <td>139.792119</td>\n",
       "      <td>148.939867</td>\n",
       "      <td>144.236723</td>\n",
       "      <td>172.507435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>352.760204</td>\n",
       "      <td>294.627843</td>\n",
       "      <td>304.077747</td>\n",
       "      <td>254.927531</td>\n",
       "      <td>250.524546</td>\n",
       "      <td>263.292773</td>\n",
       "      <td>260.921198</td>\n",
       "      <td>257.780558</td>\n",
       "      <td>249.459448</td>\n",
       "      <td>290.452804</td>\n",
       "      <td>303.802952</td>\n",
       "      <td>348.777766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>216.847058</td>\n",
       "      <td>167.058181</td>\n",
       "      <td>154.512254</td>\n",
       "      <td>135.929742</td>\n",
       "      <td>136.600318</td>\n",
       "      <td>125.325934</td>\n",
       "      <td>126.929325</td>\n",
       "      <td>132.860425</td>\n",
       "      <td>132.520613</td>\n",
       "      <td>145.897410</td>\n",
       "      <td>155.190635</td>\n",
       "      <td>175.917894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>659.869224</td>\n",
       "      <td>620.657962</td>\n",
       "      <td>706.220009</td>\n",
       "      <td>665.454411</td>\n",
       "      <td>592.306253</td>\n",
       "      <td>472.975237</td>\n",
       "      <td>469.123116</td>\n",
       "      <td>484.733388</td>\n",
       "      <td>519.891421</td>\n",
       "      <td>567.873309</td>\n",
       "      <td>572.101133</td>\n",
       "      <td>624.286265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>528.680889</td>\n",
       "      <td>418.647807</td>\n",
       "      <td>411.321297</td>\n",
       "      <td>370.840117</td>\n",
       "      <td>340.404054</td>\n",
       "      <td>265.169053</td>\n",
       "      <td>270.523217</td>\n",
       "      <td>276.889334</td>\n",
       "      <td>301.184396</td>\n",
       "      <td>352.258311</td>\n",
       "      <td>421.925735</td>\n",
       "      <td>518.361081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>398.197358</td>\n",
       "      <td>373.052613</td>\n",
       "      <td>340.143490</td>\n",
       "      <td>351.804384</td>\n",
       "      <td>219.967255</td>\n",
       "      <td>200.310985</td>\n",
       "      <td>192.886359</td>\n",
       "      <td>206.880501</td>\n",
       "      <td>222.482800</td>\n",
       "      <td>268.055811</td>\n",
       "      <td>317.407329</td>\n",
       "      <td>389.661978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>267.125199</td>\n",
       "      <td>228.718424</td>\n",
       "      <td>239.872865</td>\n",
       "      <td>219.698209</td>\n",
       "      <td>223.876639</td>\n",
       "      <td>213.046245</td>\n",
       "      <td>220.702182</td>\n",
       "      <td>222.153858</td>\n",
       "      <td>225.971998</td>\n",
       "      <td>231.866927</td>\n",
       "      <td>237.990553</td>\n",
       "      <td>241.023429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id     2018-01     2018-02  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c  148.103123  126.047486   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82  663.947407  615.413838   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734  281.661955  220.686334   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a  191.826094  158.906076   \n",
       "4     0x005958406351bb29580475df698b5f1070096397  352.760204  294.627843   \n",
       "...                                          ...         ...         ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f  216.847058  167.058181   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb  659.869224  620.657962   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5  528.680889  418.647807   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02  398.197358  373.052613   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4  267.125199  228.718424   \n",
       "\n",
       "         2018-03     2018-04     2018-05     2018-06     2018-07     2018-08  \\\n",
       "0     117.925117  109.387841  110.934115  109.137093  109.774808  115.590481   \n",
       "1     555.206666  474.893806  462.997069  424.632680  416.615935  419.407808   \n",
       "2     217.999392  208.568788  203.172608  196.110522  198.580530  202.563643   \n",
       "3     157.681381  136.260505  137.123556  136.923778  128.787736  127.673461   \n",
       "4     304.077747  254.927531  250.524546  263.292773  260.921198  257.780558   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3243  154.512254  135.929742  136.600318  125.325934  126.929325  132.860425   \n",
       "3244  706.220009  665.454411  592.306253  472.975237  469.123116  484.733388   \n",
       "3245  411.321297  370.840117  340.404054  265.169053  270.523217  276.889334   \n",
       "3246  340.143490  351.804384  219.967255  200.310985  192.886359  206.880501   \n",
       "3247  239.872865  219.698209  223.876639  213.046245  220.702182  222.153858   \n",
       "\n",
       "         2018-09     2018-10     2018-11     2018-12  \n",
       "0     117.942503  122.904572  106.357593  127.947633  \n",
       "1     484.817919  538.426473  604.488745  648.407097  \n",
       "2     199.765996  202.128198  210.005141  238.153385  \n",
       "3     139.792119  148.939867  144.236723  172.507435  \n",
       "4     249.459448  290.452804  303.802952  348.777766  \n",
       "...          ...         ...         ...         ...  \n",
       "3243  132.520613  145.897410  155.190635  175.917894  \n",
       "3244  519.891421  567.873309  572.101133  624.286265  \n",
       "3245  301.184396  352.258311  421.925735  518.361081  \n",
       "3246  222.482800  268.055811  317.407329  389.661978  \n",
       "3247  225.971998  231.866927  237.990553  241.023429  \n",
       "\n",
       "[3248 rows x 13 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_monthly_forecasts.rename(columns={\"Jan\":\"2018-01\", \"Feb\":\"2018-02\",\"Mar\":\"2018-03\",\"Apr\":\"2018-04\",\"May\":\"2018-05\",\"Jun\":\"2018-06\",\"Jul\":\"2018-07\",\"Aug\":\"2018-08\",\"Sep\":\"2018-09\",\"Oct\":\"2018-10\",\"Nov\":\"2018-11\",\"Dec\":\"2018-12\"}, inplace=True)\n",
    "df_monthly_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructuring forecasts into daily predictions to plot on top of monthly preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <th>2018-01-02 00:00:00</th>\n",
       "      <th>2018-01-03 00:00:00</th>\n",
       "      <th>2018-01-04 00:00:00</th>\n",
       "      <th>2018-01-05 00:00:00</th>\n",
       "      <th>2018-01-06 00:00:00</th>\n",
       "      <th>2018-01-07 00:00:00</th>\n",
       "      <th>2018-01-08 00:00:00</th>\n",
       "      <th>2018-01-09 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-12-22 00:00:00</th>\n",
       "      <th>2018-12-23 00:00:00</th>\n",
       "      <th>2018-12-24 00:00:00</th>\n",
       "      <th>2018-12-25 00:00:00</th>\n",
       "      <th>2018-12-26 00:00:00</th>\n",
       "      <th>2018-12-27 00:00:00</th>\n",
       "      <th>2018-12-28 00:00:00</th>\n",
       "      <th>2018-12-29 00:00:00</th>\n",
       "      <th>2018-12-30 00:00:00</th>\n",
       "      <th>2018-12-31 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>5.601605</td>\n",
       "      <td>5.200976</td>\n",
       "      <td>4.863585</td>\n",
       "      <td>4.983949</td>\n",
       "      <td>5.001535</td>\n",
       "      <td>5.315890</td>\n",
       "      <td>5.241535</td>\n",
       "      <td>4.940920</td>\n",
       "      <td>4.505834</td>\n",
       "      <td>...</td>\n",
       "      <td>4.310192</td>\n",
       "      <td>3.901896</td>\n",
       "      <td>3.745222</td>\n",
       "      <td>3.474947</td>\n",
       "      <td>3.622179</td>\n",
       "      <td>3.916982</td>\n",
       "      <td>4.338592</td>\n",
       "      <td>4.423198</td>\n",
       "      <td>4.366067</td>\n",
       "      <td>4.537346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>18.889148</td>\n",
       "      <td>20.570908</td>\n",
       "      <td>23.400067</td>\n",
       "      <td>19.873024</td>\n",
       "      <td>19.947454</td>\n",
       "      <td>22.310684</td>\n",
       "      <td>23.652742</td>\n",
       "      <td>21.562920</td>\n",
       "      <td>23.260296</td>\n",
       "      <td>...</td>\n",
       "      <td>22.465679</td>\n",
       "      <td>21.821293</td>\n",
       "      <td>20.311791</td>\n",
       "      <td>19.666670</td>\n",
       "      <td>20.502661</td>\n",
       "      <td>20.878894</td>\n",
       "      <td>22.769590</td>\n",
       "      <td>20.149115</td>\n",
       "      <td>19.559290</td>\n",
       "      <td>18.095068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>9.213611</td>\n",
       "      <td>9.510975</td>\n",
       "      <td>9.837153</td>\n",
       "      <td>9.061083</td>\n",
       "      <td>9.167414</td>\n",
       "      <td>9.244363</td>\n",
       "      <td>9.730296</td>\n",
       "      <td>8.506299</td>\n",
       "      <td>8.703815</td>\n",
       "      <td>...</td>\n",
       "      <td>7.652262</td>\n",
       "      <td>7.787030</td>\n",
       "      <td>7.765515</td>\n",
       "      <td>7.612030</td>\n",
       "      <td>7.837377</td>\n",
       "      <td>8.035604</td>\n",
       "      <td>7.991981</td>\n",
       "      <td>8.145852</td>\n",
       "      <td>7.765620</td>\n",
       "      <td>8.044913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>6.828198</td>\n",
       "      <td>6.895592</td>\n",
       "      <td>6.520277</td>\n",
       "      <td>6.202860</td>\n",
       "      <td>6.312021</td>\n",
       "      <td>6.493572</td>\n",
       "      <td>6.824862</td>\n",
       "      <td>5.809269</td>\n",
       "      <td>6.284561</td>\n",
       "      <td>...</td>\n",
       "      <td>5.386592</td>\n",
       "      <td>5.307350</td>\n",
       "      <td>5.234766</td>\n",
       "      <td>5.286835</td>\n",
       "      <td>4.913086</td>\n",
       "      <td>5.099872</td>\n",
       "      <td>5.557044</td>\n",
       "      <td>6.012659</td>\n",
       "      <td>6.191835</td>\n",
       "      <td>6.058385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>11.484664</td>\n",
       "      <td>11.447754</td>\n",
       "      <td>11.483776</td>\n",
       "      <td>11.551068</td>\n",
       "      <td>11.114295</td>\n",
       "      <td>11.449111</td>\n",
       "      <td>11.691893</td>\n",
       "      <td>11.405973</td>\n",
       "      <td>10.578846</td>\n",
       "      <td>...</td>\n",
       "      <td>11.667331</td>\n",
       "      <td>11.698336</td>\n",
       "      <td>11.077554</td>\n",
       "      <td>10.766456</td>\n",
       "      <td>10.499767</td>\n",
       "      <td>10.993051</td>\n",
       "      <td>11.437284</td>\n",
       "      <td>11.259045</td>\n",
       "      <td>11.968430</td>\n",
       "      <td>11.215782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>7.629359</td>\n",
       "      <td>7.467753</td>\n",
       "      <td>7.021680</td>\n",
       "      <td>7.083365</td>\n",
       "      <td>7.139527</td>\n",
       "      <td>7.904173</td>\n",
       "      <td>7.218516</td>\n",
       "      <td>7.447553</td>\n",
       "      <td>7.915600</td>\n",
       "      <td>...</td>\n",
       "      <td>5.903585</td>\n",
       "      <td>5.729163</td>\n",
       "      <td>5.723615</td>\n",
       "      <td>5.817318</td>\n",
       "      <td>5.593891</td>\n",
       "      <td>5.689046</td>\n",
       "      <td>5.636063</td>\n",
       "      <td>5.932465</td>\n",
       "      <td>6.157448</td>\n",
       "      <td>6.201729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>21.897864</td>\n",
       "      <td>22.949977</td>\n",
       "      <td>22.161411</td>\n",
       "      <td>20.605000</td>\n",
       "      <td>21.396796</td>\n",
       "      <td>21.289638</td>\n",
       "      <td>19.983368</td>\n",
       "      <td>21.033856</td>\n",
       "      <td>20.926243</td>\n",
       "      <td>...</td>\n",
       "      <td>18.720020</td>\n",
       "      <td>18.426798</td>\n",
       "      <td>18.791036</td>\n",
       "      <td>18.864096</td>\n",
       "      <td>19.615576</td>\n",
       "      <td>20.528484</td>\n",
       "      <td>20.925530</td>\n",
       "      <td>21.238038</td>\n",
       "      <td>20.494991</td>\n",
       "      <td>20.707161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>17.863026</td>\n",
       "      <td>19.348327</td>\n",
       "      <td>18.731639</td>\n",
       "      <td>15.815959</td>\n",
       "      <td>16.609406</td>\n",
       "      <td>16.882085</td>\n",
       "      <td>16.734164</td>\n",
       "      <td>17.940582</td>\n",
       "      <td>16.106912</td>\n",
       "      <td>...</td>\n",
       "      <td>14.623234</td>\n",
       "      <td>15.831387</td>\n",
       "      <td>16.129633</td>\n",
       "      <td>15.517975</td>\n",
       "      <td>15.863418</td>\n",
       "      <td>16.706768</td>\n",
       "      <td>16.852026</td>\n",
       "      <td>16.833590</td>\n",
       "      <td>16.953428</td>\n",
       "      <td>16.849844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>12.335679</td>\n",
       "      <td>13.093305</td>\n",
       "      <td>12.614274</td>\n",
       "      <td>13.020963</td>\n",
       "      <td>12.608432</td>\n",
       "      <td>13.612097</td>\n",
       "      <td>13.075167</td>\n",
       "      <td>12.947576</td>\n",
       "      <td>12.690896</td>\n",
       "      <td>...</td>\n",
       "      <td>12.160340</td>\n",
       "      <td>12.279589</td>\n",
       "      <td>12.999921</td>\n",
       "      <td>13.352255</td>\n",
       "      <td>11.972627</td>\n",
       "      <td>12.992933</td>\n",
       "      <td>12.604320</td>\n",
       "      <td>12.749718</td>\n",
       "      <td>12.271606</td>\n",
       "      <td>12.545465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>7.749924</td>\n",
       "      <td>8.966757</td>\n",
       "      <td>8.522623</td>\n",
       "      <td>8.246093</td>\n",
       "      <td>8.564469</td>\n",
       "      <td>9.037462</td>\n",
       "      <td>8.486989</td>\n",
       "      <td>8.754544</td>\n",
       "      <td>8.556355</td>\n",
       "      <td>...</td>\n",
       "      <td>8.026361</td>\n",
       "      <td>7.895596</td>\n",
       "      <td>7.396107</td>\n",
       "      <td>7.396064</td>\n",
       "      <td>7.675364</td>\n",
       "      <td>7.818420</td>\n",
       "      <td>8.251376</td>\n",
       "      <td>8.090346</td>\n",
       "      <td>7.768521</td>\n",
       "      <td>7.869512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id  2018-01-01 00:00:00  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c             5.601605   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82            18.889148   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734             9.213611   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a             6.828198   \n",
       "4     0x005958406351bb29580475df698b5f1070096397            11.484664   \n",
       "...                                          ...                  ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f             7.629359   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb            21.897864   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5            17.863026   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02            12.335679   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4             7.749924   \n",
       "\n",
       "      2018-01-02 00:00:00  2018-01-03 00:00:00  2018-01-04 00:00:00  \\\n",
       "0                5.200976             4.863585             4.983949   \n",
       "1               20.570908            23.400067            19.873024   \n",
       "2                9.510975             9.837153             9.061083   \n",
       "3                6.895592             6.520277             6.202860   \n",
       "4               11.447754            11.483776            11.551068   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             7.467753             7.021680             7.083365   \n",
       "3244            22.949977            22.161411            20.605000   \n",
       "3245            19.348327            18.731639            15.815959   \n",
       "3246            13.093305            12.614274            13.020963   \n",
       "3247             8.966757             8.522623             8.246093   \n",
       "\n",
       "      2018-01-05 00:00:00  2018-01-06 00:00:00  2018-01-07 00:00:00  \\\n",
       "0                5.001535             5.315890             5.241535   \n",
       "1               19.947454            22.310684            23.652742   \n",
       "2                9.167414             9.244363             9.730296   \n",
       "3                6.312021             6.493572             6.824862   \n",
       "4               11.114295            11.449111            11.691893   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             7.139527             7.904173             7.218516   \n",
       "3244            21.396796            21.289638            19.983368   \n",
       "3245            16.609406            16.882085            16.734164   \n",
       "3246            12.608432            13.612097            13.075167   \n",
       "3247             8.564469             9.037462             8.486989   \n",
       "\n",
       "      2018-01-08 00:00:00  2018-01-09 00:00:00  ...  2018-12-22 00:00:00  \\\n",
       "0                4.940920             4.505834  ...             4.310192   \n",
       "1               21.562920            23.260296  ...            22.465679   \n",
       "2                8.506299             8.703815  ...             7.652262   \n",
       "3                5.809269             6.284561  ...             5.386592   \n",
       "4               11.405973            10.578846  ...            11.667331   \n",
       "...                   ...                  ...  ...                  ...   \n",
       "3243             7.447553             7.915600  ...             5.903585   \n",
       "3244            21.033856            20.926243  ...            18.720020   \n",
       "3245            17.940582            16.106912  ...            14.623234   \n",
       "3246            12.947576            12.690896  ...            12.160340   \n",
       "3247             8.754544             8.556355  ...             8.026361   \n",
       "\n",
       "      2018-12-23 00:00:00  2018-12-24 00:00:00  2018-12-25 00:00:00  \\\n",
       "0                3.901896             3.745222             3.474947   \n",
       "1               21.821293            20.311791            19.666670   \n",
       "2                7.787030             7.765515             7.612030   \n",
       "3                5.307350             5.234766             5.286835   \n",
       "4               11.698336            11.077554            10.766456   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             5.729163             5.723615             5.817318   \n",
       "3244            18.426798            18.791036            18.864096   \n",
       "3245            15.831387            16.129633            15.517975   \n",
       "3246            12.279589            12.999921            13.352255   \n",
       "3247             7.895596             7.396107             7.396064   \n",
       "\n",
       "      2018-12-26 00:00:00  2018-12-27 00:00:00  2018-12-28 00:00:00  \\\n",
       "0                3.622179             3.916982             4.338592   \n",
       "1               20.502661            20.878894            22.769590   \n",
       "2                7.837377             8.035604             7.991981   \n",
       "3                4.913086             5.099872             5.557044   \n",
       "4               10.499767            10.993051            11.437284   \n",
       "...                   ...                  ...                  ...   \n",
       "3243             5.593891             5.689046             5.636063   \n",
       "3244            19.615576            20.528484            20.925530   \n",
       "3245            15.863418            16.706768            16.852026   \n",
       "3246            11.972627            12.992933            12.604320   \n",
       "3247             7.675364             7.818420             8.251376   \n",
       "\n",
       "      2018-12-29 00:00:00  2018-12-30 00:00:00  2018-12-31 00:00:00  \n",
       "0                4.423198             4.366067             4.537346  \n",
       "1               20.149115            19.559290            18.095068  \n",
       "2                8.145852             7.765620             8.044913  \n",
       "3                6.012659             6.191835             6.058385  \n",
       "4               11.259045            11.968430            11.215782  \n",
       "...                   ...                  ...                  ...  \n",
       "3243             5.932465             6.157448             6.201729  \n",
       "3244            21.238038            20.494991            20.707161  \n",
       "3245            16.833590            16.953428            16.849844  \n",
       "3246            12.749718            12.271606            12.545465  \n",
       "3247             8.090346             7.768521             7.869512  \n",
       "\n",
       "[3248 rows x 366 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#daily forecasts to plot on top of monthly\n",
    "df_daily_forecasts = main_effects_forecasts.groupby([\"meter_id\",\"date\"])[\"meter_reading\"].sum().unstack()\n",
    "\n",
    "#resetting the index \n",
    "df_daily_forecasts.reset_index(inplace=True)\n",
    "df_daily_forecasts.index.name = None # removing index column\n",
    "df_daily_forecasts.columns.name = None # removing columns name\n",
    "\n",
    "df_daily_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading training data and aggregating into months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d969c7425ac74724a3f2cf3d37d0f495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2017-01-02</th>\n",
       "      <th>2017-01-03</th>\n",
       "      <th>2017-01-04</th>\n",
       "      <th>2017-01-05</th>\n",
       "      <th>2017-01-06</th>\n",
       "      <th>2017-01-07</th>\n",
       "      <th>2017-01-08</th>\n",
       "      <th>2017-01-09</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-12-22</th>\n",
       "      <th>2017-12-23</th>\n",
       "      <th>2017-12-24</th>\n",
       "      <th>2017-12-25</th>\n",
       "      <th>2017-12-26</th>\n",
       "      <th>2017-12-27</th>\n",
       "      <th>2017-12-28</th>\n",
       "      <th>2017-12-29</th>\n",
       "      <th>2017-12-30</th>\n",
       "      <th>2017-12-31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xa62b9f23553ff183f61e2bf943aab3d5983d02d7</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.030</td>\n",
       "      <td>5.397</td>\n",
       "      <td>5.1075</td>\n",
       "      <td>4.818</td>\n",
       "      <td>3.931</td>\n",
       "      <td>4.2170</td>\n",
       "      <td>4.503</td>\n",
       "      <td>4.8160</td>\n",
       "      <td>5.129</td>\n",
       "      <td>5.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x459c834d1f6cfb5b734b82aa9f5410fa97fb70da</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.101</td>\n",
       "      <td>14.327</td>\n",
       "      <td>14.6315</td>\n",
       "      <td>14.936</td>\n",
       "      <td>16.174</td>\n",
       "      <td>20.3960</td>\n",
       "      <td>24.618</td>\n",
       "      <td>19.8925</td>\n",
       "      <td>15.167</td>\n",
       "      <td>11.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x4a1ed36825360a058cec2bdd409fc2459e1ce54f</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.201</td>\n",
       "      <td>7.320</td>\n",
       "      <td>7.3520</td>\n",
       "      <td>7.384</td>\n",
       "      <td>14.425</td>\n",
       "      <td>16.0650</td>\n",
       "      <td>17.705</td>\n",
       "      <td>13.3355</td>\n",
       "      <td>8.966</td>\n",
       "      <td>4.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x5b76d3c0e0aefc6e0a8d1d031f96388a23263407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.833</td>\n",
       "      <td>12.477</td>\n",
       "      <td>11.7255</td>\n",
       "      <td>10.974</td>\n",
       "      <td>19.646</td>\n",
       "      <td>21.8195</td>\n",
       "      <td>23.993</td>\n",
       "      <td>19.9170</td>\n",
       "      <td>15.841</td>\n",
       "      <td>14.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x943ebe39ef2be6ef807c42c5a647e27112ca5b0f</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>39.440</td>\n",
       "      <td>35.538</td>\n",
       "      <td>21.9445</td>\n",
       "      <td>8.351</td>\n",
       "      <td>9.957</td>\n",
       "      <td>17.9140</td>\n",
       "      <td>25.871</td>\n",
       "      <td>36.0725</td>\n",
       "      <td>46.274</td>\n",
       "      <td>16.901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0x7dd7a7b8ee1bec7c44b24f738c752482f6161065</td>\n",
       "      <td>2.317</td>\n",
       "      <td>2.301</td>\n",
       "      <td>2.352</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.229</td>\n",
       "      <td>2.354</td>\n",
       "      <td>2.397</td>\n",
       "      <td>2.397</td>\n",
       "      <td>2.269</td>\n",
       "      <td>...</td>\n",
       "      <td>9.390</td>\n",
       "      <td>9.231</td>\n",
       "      <td>9.2235</td>\n",
       "      <td>9.216</td>\n",
       "      <td>9.336</td>\n",
       "      <td>9.6840</td>\n",
       "      <td>10.032</td>\n",
       "      <td>9.8945</td>\n",
       "      <td>9.757</td>\n",
       "      <td>9.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xfdaf9f857621ec06f2cf801f42a020a322835090</td>\n",
       "      <td>14.437</td>\n",
       "      <td>16.274</td>\n",
       "      <td>7.031</td>\n",
       "      <td>17.018</td>\n",
       "      <td>17.603</td>\n",
       "      <td>15.005</td>\n",
       "      <td>8.987</td>\n",
       "      <td>8.490</td>\n",
       "      <td>10.136</td>\n",
       "      <td>...</td>\n",
       "      <td>4.141</td>\n",
       "      <td>2.828</td>\n",
       "      <td>3.8230</td>\n",
       "      <td>4.818</td>\n",
       "      <td>3.357</td>\n",
       "      <td>8.1315</td>\n",
       "      <td>12.906</td>\n",
       "      <td>8.0140</td>\n",
       "      <td>3.122</td>\n",
       "      <td>3.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xd28f2f001e0cd4d6c121a3cb2e1427207e170e18</td>\n",
       "      <td>7.824</td>\n",
       "      <td>7.517</td>\n",
       "      <td>5.398</td>\n",
       "      <td>6.788</td>\n",
       "      <td>7.360</td>\n",
       "      <td>6.898</td>\n",
       "      <td>7.321</td>\n",
       "      <td>8.042</td>\n",
       "      <td>8.207</td>\n",
       "      <td>...</td>\n",
       "      <td>6.767</td>\n",
       "      <td>5.919</td>\n",
       "      <td>5.9980</td>\n",
       "      <td>6.077</td>\n",
       "      <td>7.761</td>\n",
       "      <td>6.6080</td>\n",
       "      <td>5.455</td>\n",
       "      <td>5.5670</td>\n",
       "      <td>5.679</td>\n",
       "      <td>8.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0x47218b46abb2fcaade487a211911406dc6e13730</td>\n",
       "      <td>23.965</td>\n",
       "      <td>28.689</td>\n",
       "      <td>27.664</td>\n",
       "      <td>29.229</td>\n",
       "      <td>29.548</td>\n",
       "      <td>27.909</td>\n",
       "      <td>26.923</td>\n",
       "      <td>21.277</td>\n",
       "      <td>23.452</td>\n",
       "      <td>...</td>\n",
       "      <td>20.747</td>\n",
       "      <td>19.979</td>\n",
       "      <td>20.1925</td>\n",
       "      <td>20.406</td>\n",
       "      <td>23.668</td>\n",
       "      <td>27.7900</td>\n",
       "      <td>31.912</td>\n",
       "      <td>29.1125</td>\n",
       "      <td>26.313</td>\n",
       "      <td>24.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd</td>\n",
       "      <td>11.302</td>\n",
       "      <td>14.178</td>\n",
       "      <td>15.499</td>\n",
       "      <td>11.853</td>\n",
       "      <td>17.431</td>\n",
       "      <td>14.506</td>\n",
       "      <td>12.812</td>\n",
       "      <td>10.472</td>\n",
       "      <td>10.879</td>\n",
       "      <td>...</td>\n",
       "      <td>14.036</td>\n",
       "      <td>15.990</td>\n",
       "      <td>15.5505</td>\n",
       "      <td>15.111</td>\n",
       "      <td>16.506</td>\n",
       "      <td>18.7585</td>\n",
       "      <td>21.011</td>\n",
       "      <td>19.2040</td>\n",
       "      <td>17.397</td>\n",
       "      <td>15.237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id  2017-01-01  2017-01-02  \\\n",
       "0     0xa62b9f23553ff183f61e2bf943aab3d5983d02d7       0.000       0.000   \n",
       "1     0x459c834d1f6cfb5b734b82aa9f5410fa97fb70da       0.000       0.000   \n",
       "2     0x4a1ed36825360a058cec2bdd409fc2459e1ce54f       0.000       0.000   \n",
       "3     0x5b76d3c0e0aefc6e0a8d1d031f96388a23263407       0.000       0.000   \n",
       "4     0x943ebe39ef2be6ef807c42c5a647e27112ca5b0f       0.000       0.000   \n",
       "...                                          ...         ...         ...   \n",
       "3243  0x7dd7a7b8ee1bec7c44b24f738c752482f6161065       2.317       2.301   \n",
       "3244  0xfdaf9f857621ec06f2cf801f42a020a322835090      14.437      16.274   \n",
       "3245  0xd28f2f001e0cd4d6c121a3cb2e1427207e170e18       7.824       7.517   \n",
       "3246  0x47218b46abb2fcaade487a211911406dc6e13730      23.965      28.689   \n",
       "3247  0xcd19e6fe3d887bc5dcac7ca18d46199695463fdd      11.302      14.178   \n",
       "\n",
       "      2017-01-03  2017-01-04  2017-01-05  2017-01-06  2017-01-07  2017-01-08  \\\n",
       "0          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "1          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "2          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "3          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "4          0.000       0.000       0.000       0.000       0.000       0.000   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3243       2.352       2.516       2.229       2.354       2.397       2.397   \n",
       "3244       7.031      17.018      17.603      15.005       8.987       8.490   \n",
       "3245       5.398       6.788       7.360       6.898       7.321       8.042   \n",
       "3246      27.664      29.229      29.548      27.909      26.923      21.277   \n",
       "3247      15.499      11.853      17.431      14.506      12.812      10.472   \n",
       "\n",
       "      2017-01-09  ...  2017-12-22  2017-12-23  2017-12-24  2017-12-25  \\\n",
       "0          0.000  ...       4.030       5.397      5.1075       4.818   \n",
       "1          0.000  ...      13.101      14.327     14.6315      14.936   \n",
       "2          0.000  ...      10.201       7.320      7.3520       7.384   \n",
       "3          0.000  ...      14.833      12.477     11.7255      10.974   \n",
       "4          0.000  ...      39.440      35.538     21.9445       8.351   \n",
       "...          ...  ...         ...         ...         ...         ...   \n",
       "3243       2.269  ...       9.390       9.231      9.2235       9.216   \n",
       "3244      10.136  ...       4.141       2.828      3.8230       4.818   \n",
       "3245       8.207  ...       6.767       5.919      5.9980       6.077   \n",
       "3246      23.452  ...      20.747      19.979     20.1925      20.406   \n",
       "3247      10.879  ...      14.036      15.990     15.5505      15.111   \n",
       "\n",
       "      2017-12-26  2017-12-27  2017-12-28  2017-12-29  2017-12-30  2017-12-31  \n",
       "0          3.931      4.2170       4.503      4.8160       5.129       5.395  \n",
       "1         16.174     20.3960      24.618     19.8925      15.167      11.751  \n",
       "2         14.425     16.0650      17.705     13.3355       8.966       4.633  \n",
       "3         19.646     21.8195      23.993     19.9170      15.841      14.452  \n",
       "4          9.957     17.9140      25.871     36.0725      46.274      16.901  \n",
       "...          ...         ...         ...         ...         ...         ...  \n",
       "3243       9.336      9.6840      10.032      9.8945       9.757       9.480  \n",
       "3244       3.357      8.1315      12.906      8.0140       3.122       3.401  \n",
       "3245       7.761      6.6080       5.455      5.5670       5.679       8.148  \n",
       "3246      23.668     27.7900      31.912     29.1125      26.313      24.201  \n",
       "3247      16.506     18.7585      21.011     19.2040      17.397      15.237  \n",
       "\n",
       "[3248 rows x 366 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meter_id</th>\n",
       "      <th>2017-01</th>\n",
       "      <th>2017-02</th>\n",
       "      <th>2017-03</th>\n",
       "      <th>2017-04</th>\n",
       "      <th>2017-05</th>\n",
       "      <th>2017-06</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x0001f1c389823f953b2eaee0a61c33539744da0c</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.39450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x000f697092696c27b0bb489ea4c11280ef72ab82</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>553.18400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x0019979ee12c59accd24d1c83291528ced1bb734</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>368.90957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x001d6227832325ab6167b82d6d7175d254f57c3a</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>534.84650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x005958406351bb29580475df698b5f1070096397</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>946.06400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>0xffb4c5014834a46d09d0092e748c1ef5acd8733f</td>\n",
       "      <td>72.7050</td>\n",
       "      <td>63.245</td>\n",
       "      <td>68.4335</td>\n",
       "      <td>66.6265</td>\n",
       "      <td>69.0480</td>\n",
       "      <td>100.430</td>\n",
       "      <td>177.1735</td>\n",
       "      <td>177.4100</td>\n",
       "      <td>216.7245</td>\n",
       "      <td>279.164500</td>\n",
       "      <td>351.481000</td>\n",
       "      <td>312.08800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>0xffbdc1d9209f45668fb0be65b6d50cb999890ccb</td>\n",
       "      <td>371.4390</td>\n",
       "      <td>269.691</td>\n",
       "      <td>179.3430</td>\n",
       "      <td>141.6590</td>\n",
       "      <td>138.4835</td>\n",
       "      <td>122.910</td>\n",
       "      <td>164.2285</td>\n",
       "      <td>100.9610</td>\n",
       "      <td>118.0520</td>\n",
       "      <td>123.135500</td>\n",
       "      <td>187.140000</td>\n",
       "      <td>186.88400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5</td>\n",
       "      <td>209.8065</td>\n",
       "      <td>169.858</td>\n",
       "      <td>184.0130</td>\n",
       "      <td>166.7280</td>\n",
       "      <td>134.1760</td>\n",
       "      <td>169.489</td>\n",
       "      <td>157.5775</td>\n",
       "      <td>165.9640</td>\n",
       "      <td>177.0105</td>\n",
       "      <td>185.701833</td>\n",
       "      <td>192.288667</td>\n",
       "      <td>200.61950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02</td>\n",
       "      <td>845.6630</td>\n",
       "      <td>608.449</td>\n",
       "      <td>588.7765</td>\n",
       "      <td>503.3050</td>\n",
       "      <td>291.1320</td>\n",
       "      <td>177.605</td>\n",
       "      <td>183.5345</td>\n",
       "      <td>182.0350</td>\n",
       "      <td>244.2255</td>\n",
       "      <td>371.458333</td>\n",
       "      <td>695.878667</td>\n",
       "      <td>858.83950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>0xfff895258c21f1a58fc06538173d02b621021ad4</td>\n",
       "      <td>428.7345</td>\n",
       "      <td>670.505</td>\n",
       "      <td>462.1050</td>\n",
       "      <td>354.8660</td>\n",
       "      <td>287.9950</td>\n",
       "      <td>200.321</td>\n",
       "      <td>227.0855</td>\n",
       "      <td>231.7585</td>\n",
       "      <td>246.3005</td>\n",
       "      <td>344.210167</td>\n",
       "      <td>516.290333</td>\n",
       "      <td>734.61800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3248 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        meter_id   2017-01  2017-02   2017-03  \\\n",
       "0     0x0001f1c389823f953b2eaee0a61c33539744da0c    0.0000    0.000    0.0000   \n",
       "1     0x000f697092696c27b0bb489ea4c11280ef72ab82    0.0000    0.000    0.0000   \n",
       "2     0x0019979ee12c59accd24d1c83291528ced1bb734    0.0000    0.000    0.0000   \n",
       "3     0x001d6227832325ab6167b82d6d7175d254f57c3a    0.0000    0.000    0.0000   \n",
       "4     0x005958406351bb29580475df698b5f1070096397    0.0000    0.000    0.0000   \n",
       "...                                          ...       ...      ...       ...   \n",
       "3243  0xffb4c5014834a46d09d0092e748c1ef5acd8733f   72.7050   63.245   68.4335   \n",
       "3244  0xffbdc1d9209f45668fb0be65b6d50cb999890ccb  371.4390  269.691  179.3430   \n",
       "3245  0xffcbcdc7c3ce3451252b84c2aaf6f40d652d16d5  209.8065  169.858  184.0130   \n",
       "3246  0xffe91f021d145e1560fcad8c3af5ac0ef9d76a02  845.6630  608.449  588.7765   \n",
       "3247  0xfff895258c21f1a58fc06538173d02b621021ad4  428.7345  670.505  462.1050   \n",
       "\n",
       "       2017-04   2017-05  2017-06   2017-07   2017-08   2017-09     2017-10  \\\n",
       "0       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "1       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "2       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "3       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "4       0.0000    0.0000    0.000    0.0000    0.0000    0.0000    0.000000   \n",
       "...        ...       ...      ...       ...       ...       ...         ...   \n",
       "3243   66.6265   69.0480  100.430  177.1735  177.4100  216.7245  279.164500   \n",
       "3244  141.6590  138.4835  122.910  164.2285  100.9610  118.0520  123.135500   \n",
       "3245  166.7280  134.1760  169.489  157.5775  165.9640  177.0105  185.701833   \n",
       "3246  503.3050  291.1320  177.605  183.5345  182.0350  244.2255  371.458333   \n",
       "3247  354.8660  287.9950  200.321  227.0855  231.7585  246.3005  344.210167   \n",
       "\n",
       "         2017-11    2017-12  \n",
       "0       0.000000  128.39450  \n",
       "1       0.000000  553.18400  \n",
       "2       0.000000  368.90957  \n",
       "3       0.000000  534.84650  \n",
       "4       0.000000  946.06400  \n",
       "...          ...        ...  \n",
       "3243  351.481000  312.08800  \n",
       "3244  187.140000  186.88400  \n",
       "3245  192.288667  200.61950  \n",
       "3246  695.878667  858.83950  \n",
       "3247  516.290333  734.61800  \n",
       "\n",
       "[3248 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading the training data\n",
    "print(\"training data\")\n",
    "df_train_daily = pd.read_pickle(\"../Data/Preprocessed_Data/consumption_daily_nan_interpolated.pkl\").fillna(0)\n",
    "\n",
    "#aggregating up into months\n",
    "meter_id=df_monthly_forecasts[\"meter_id\"]\n",
    "df_train_monthly = pd.DataFrame(columns=[\"meter_id\"])\n",
    "df_train_monthly[\"meter_id\"] = meter_id\n",
    "\n",
    "\n",
    "#for each month in the range of dates\n",
    "resample_size=\"M\"\n",
    "for new_sample in tqdm(pd.date_range(datetime.datetime(2017, 1, 1), datetime.datetime(2017, 12, 31), freq = resample_size),position=0):\n",
    "\n",
    "    #get this columns name as a string\n",
    "    columnName = str(new_sample.date())[:7]\n",
    "    #get all columns that relate to this new sample\n",
    "    columns = [i for i in df_train_daily.columns.values[1:] if i.startswith(columnName)]\n",
    "\n",
    "    #sum these up into a value for the new sample size\n",
    "    df_train_monthly[columnName] = df_train_daily[columns].sum(axis=1)\n",
    "\n",
    "display(df_train_daily)\n",
    "display(df_train_monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the predictions against the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a5c6ea4a20437094aff02a1cb6ea7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_plots = 10\n",
    "for pid in tqdm(range(0,3248)):\n",
    "    if pid>num_plots:\n",
    "        break\n",
    "        \n",
    "    #getting the row corresponding to this meter_id\n",
    "    meter_id = df_daily_forecasts.iloc[pid,0]\n",
    "    this_train_month = df_train_monthly.loc[df_train_monthly['meter_id'] == meter_id].T[1:]\n",
    "    this_preds_month = df_monthly_forecasts.loc[df_train_monthly['meter_id'] == meter_id].T[1:]\n",
    "    \n",
    "    #converting index to datetime for ease of plots key\n",
    "    this_train_month.index=pd.to_datetime(this_train_month.index)\n",
    "    this_preds_month.index=pd.to_datetime(this_preds_month.index)\n",
    "    \n",
    "    #creating figure\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    \n",
    "    #plotting the monthly predictions\n",
    "    plt.title(\"Meter '\"+str(meter_id)+\"' monthly forecasts and historical data\", fontsize=15)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Energy Usage kWh\")\n",
    "    plt.plot(this_train_month, label=\"training monthly energy\", lw=1,color=\"skyblue\", marker=\"x\")\n",
    "    plt.plot(this_preds_month, label=\"forecast monthly energy\", lw=1,color=\"mediumorchid\", marker=\"x\")\n",
    "    \n",
    "    #annotations\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.locator_params(nbins=24)\n",
    "    \n",
    "    #plt.show()\n",
    "    fig.savefig(f\"..\\\\Results\\\\Genetic Algorithm\\\\Plots\\\\forecasts\\\\main_effects\\\\p{population_size}_g{number_of_generations}_forecasts_{pid}_{meter_id}.png\")\n",
    "\n",
    "    fig.clf()\n",
    "    fig.clear()\n",
    "    plt.close()\n",
    "    del fig, this_train_month, this_preds_month\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle_tf",
   "language": "python",
   "name": "mle_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
