{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM Model\n",
    "* RNN was far too slow and hence infeasible given the time limit I am constrained within\n",
    "* So going to use an LGBM\n",
    "\n",
    "# Misc / setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\psydm7\\Anaconda3\\envs\\mle_tf\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import time\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SEED = 137\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(\"../Data/Prepared_Data/supervised/consumption_all.pkl\")\n",
    "display(df_train)\n",
    "df_preds = pd.read_pickle(\"../Data/Prepared_Data/supervised/consumption_all_preds.pkl\")\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formatting the df's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing nans with 0 so we can aggregate up the OOF predictions\n",
    "df_preds[\"meter_reading\"] = df_preds[\"meter_reading\"].fillna(0) \n",
    "#dropping the \"energy n-k\" columns as they are needed for 3D RNN input not 2D LGBM input\n",
    "df_preds = df_preds.drop([\"energy n-7\",\"energy n-6\",\"energy n-5\",\"energy n-4\",\"energy n-3\",\"energy n-2\",\"energy n-1\"], axis=1)\n",
    "df_train = df_train.drop([\"energy n-7\",\"energy n-6\",\"energy n-5\",\"energy n-4\",\"energy n-3\",\"energy n-2\",\"energy n-1\"], axis=1)\n",
    "\n",
    "display(df_train)\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinally encoding the ID's\n",
    "* One hot / binary encoding can actually worsen performance of DT based algorithms\n",
    "* and LGBM supports categorical values; so no need to use the binary encoded meter_id which we planned for the RNN\n",
    "* Hence I will also now encode the ID ordinally and experiment with both to see which gives the best performing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the binary encoded ID's as LGBM supports categorical values hence we can just use ordinal encoded ID's for better performance\n",
    "#commented out for random search as will experiment with using both\n",
    "# binary_encoded_cols=[]\n",
    "# for i in range(13):\n",
    "#     binary_encoded_cols.append(f\"meter_id_{i}\")\n",
    "# df_train=df_train.drop(binary_encoded_cols,axis=1)\n",
    "# df_preds=df_preds.drop(binary_encoded_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordinally encoding id's\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_train[\"meter_id\"])\n",
    "\n",
    "#ordinally encoding with same encoder so will encode the same\n",
    "df_train.insert(1, \"meter_id_ord\", le.transform(df_train[\"meter_id\"]))\n",
    "df_preds.insert(1, \"meter_id_ord\", le.transform(df_preds[\"meter_id\"]))\n",
    "\n",
    "display(df_train)\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinally encoding the dwelling_type\n",
    "* same reasons for replacing the binary encoded meter_id with ordinal encoding; going to replace one hot encodede dwelling type with ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the binary encoded ID's as LGBM supports categorical values hence we can just use ordinal encoded ID's for better performance\n",
    "# not dropping the orginal random search will experiment with ordinal and onehot\n",
    "# onehot_encoded_cols = [\"detached\",\"flat\",\"terraced\",\"semi_detached\"]\n",
    "# df_train=df_train.drop(onehot_encoded_cols,axis=1)\n",
    "# df_preds=df_preds.drop(onehot_encoded_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordinally encoding dwelling_type\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_train[\"dwelling_type\"])\n",
    "\n",
    "#ordinally encoding with same encoder so will encode the same\n",
    "df_train.insert(27, \"dwelling_type_ord\", le.transform(df_train[\"dwelling_type\"]))\n",
    "df_preds.insert(27, \"dwelling_type_ord\", le.transform(df_preds[\"dwelling_type\"]))\n",
    "\n",
    "display(df_train)\n",
    "display(df_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKF-CV for training the LGBM\n",
    "* Using skf on df_train by meter_id with 3 folds\n",
    "    * Meaning for each iteration we use 2/3 of each meters data for training and 1/3 of each meters data for validating\n",
    "* using out of fold predictions, making predictions on each fold and aggregating them together for the final prediction\n",
    "\n",
    "* evaluates the model via OOF predictions made on the held out set on each fold\n",
    "* this score is returned and along with the 3 models\n",
    "* random search will then be used to find the LGBM hyper param config with the best val score and this will then be used to make predictions using the model which has the best validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#function for running the cross fold\n",
    "    #args:\n",
    "        #disp_fold_info = True if we want to print info for each fold\n",
    "        #disp_end_info = True if we want to display evaluation info at the end\n",
    "        #SEED = random seed used for fair repeatability\n",
    "        #num_folds = number of folds in skf (pretty certain going to keep this at 3 )\n",
    "        #df_train = training dataframe\n",
    "        #y_col = the name of the label we want to predict (meter_reading)\n",
    "        #X_cols = the name of the feature columns we are using\n",
    "        #X_cat = the name of these features which are categorical\n",
    "        #params = hyper params for the LGBM model\n",
    "    #returns:\n",
    "        #time_of_execution = how long it took to train the model on all folds; will be used as a point of comparison\n",
    "        #valid_score = MAE calculated using the Out-of-Fold Predictions on the df_train, used for hyper-param tuning\n",
    "        #lgbm_models = array of the different lgbm_models\n",
    "        \n",
    "def run_lgbm_skf_cv(disp_fold_info, disp_end_info, SEED, num_folds, df_train, y_col, X_cols, X_cat, params):\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state = SEED) # defining the SKF algorithm\n",
    "\n",
    "    lgbm_models = []\n",
    "    start_time = time.time()\n",
    "    fold_iter=1\n",
    "    #running the startified kfold, splitting df_train by meter_id, so we use 2/3 of each meters reading for training\n",
    "    for train_index, valid_index in skf.split(df_train, df_train[\"meter_id\"]):\n",
    "\n",
    "        print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Fold {fold_iter}{color.END}\")\n",
    "        \n",
    "        #splitting into the features and labels for the train and valid folds\n",
    "        X_train, X_valid = df_train.loc[train_index, X_cols], df_train.loc[valid_index, X_cols]\n",
    "        y_train, y_valid = df_train.loc[train_index, y_col], df_train.loc[valid_index, y_col]\n",
    "        \n",
    "        if(disp_fold_info):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}X_train{color.END}\")\n",
    "            display(X_train.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}y_train{color.END}\")\n",
    "            display(y_train.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}X_valid{color.END}\")\n",
    "            display(X_valid.head(5))\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}y_valid{color.END}\")\n",
    "            display(y_valid.head(5))\n",
    "            \n",
    "        print(f\"{color.CYAN}{color.UNDERLINE}Training the LGBM{color.END}\")\n",
    "        #instantiating a lgbm regressor with our params\n",
    "        lgbm_model = lgbm.LGBMRegressor(**params)\n",
    "        #fitting the lgbm model on the 2/3 train and evaluating on the 1/3 valid\n",
    "        #printing details every 1000 iters + stopping if no improvement made in 250 iters\n",
    "        lgbm_model.fit(X_train, y_train,\n",
    "                       eval_set=[(X_valid, y_valid)],\n",
    "                       categorical_feature=X_cat,\n",
    "                       verbose=1000,\n",
    "                       early_stopping_rounds=250)\n",
    "        \n",
    "        #saving the OOF prediction for the held out rows (valid rows from df_train) from the lgbm model with the best performing intrinisic parmams \n",
    "        oof_valid = lgbm_model.predict(X_valid, num_iteration=lgbm_model.best_iteration_) # making prediction on the held out rows, X_valid\n",
    "        df_train.loc[valid_index, \"oof\"] = oof_valid #storing the oof rows \n",
    "        if(disp_fold_info):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}df_train OOF predictions{color.END}\")\n",
    "            display(df_train.loc[valid_index, [\"meter_id\",\"oof\"]].head(5))\n",
    "               \n",
    "        #appending this lgbm\n",
    "        lgbm_models.append(lgbm_model)\n",
    "        if(disp_fold_info):\n",
    "            print(f\"{color.CYAN}{color.UNDERLINE}lgbm_models size{color.END}: {len(lgbm_models)}\")\n",
    "            \n",
    "        fold_iter+=1\n",
    "        \n",
    "    if(disp_end_info):\n",
    "        print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}training set OOF preds vs true{color.END}\")\n",
    "        display(df_train[[\"meter_id\",\"date\",\"meter_reading\",\"oof\"]])\n",
    "        print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution for skf-cv:  {color.END}{str(datetime.timedelta(seconds=round(LGBM_TOE)))}\\n\")\n",
    "        print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set:{color.END} {LGBM_MAE}\\n\")\n",
    "    \n",
    "    #calculating execution time and the MAE on the training set\n",
    "    time_of_execution = time.time() - start_time\n",
    "    valid_score=mean_absolute_error(df_train[y_col], df_train[\"oof\"]) \n",
    "    \n",
    "    \n",
    "    return (time_of_execution, valid_score, lgbm_models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running random search on the LGBM skf-cv function\n",
    "* going to run random search to find the hyper param config which gav the best MAE on OOF predictions on the train ste in skf-cv\n",
    "    * originally implemented grid search in an earlier commit but it was incredibly slow due to the exponential growth from the wide range of hyper paramaeters\n",
    "        * decided to use random search has it has been proven to be more efficient than grid search in research eg in the paper\" Random search for hyper-parameter optimization\" (James bergstra et al. 2012 Montreal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"meter_reading\" #we want to predict the meter_reading (this will always be the same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the column types and grouping ones together that should be grouped\n",
    "* Not specifying configurations anymore letting random search pick them itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary to hold all groups of columns which could be chosen\n",
    "#done as if we just pick columns completely random we may get just \"meter_id_3\" from the binary encoded meter_id's\n",
    "#wouldn't make any sense without the other respective binary encoded meter_id columns\n",
    "\n",
    "possible_columns = {}\n",
    "possible_columns[\"meter_id_ord\"] = [\"meter_id_ord\"]\n",
    "possible_columns[\"meter_id_binary\"] = ['meter_id_0', 'meter_id_1', 'meter_id_2',\n",
    "       'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7',\n",
    "       'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12']\n",
    "possible_columns[\"day_of_year_cyclic\"] = [\"day_of_year_sin\",\"day_of_year_cos\"]\n",
    "possible_columns[\"day_of_week\"] = [\"day_of_week\"]\n",
    "possible_columns[\"day_of_month\"] = [\"day_of_month\"]\n",
    "possible_columns[\"month_ord\"] = [\"month_ord\"]\n",
    "possible_columns[\"month_cyclic\"] = [\"month_sin\",\"month_cos\"]\n",
    "possible_columns[\"is_weekend\"] = [\"is_weekend\"]\n",
    "possible_columns[\"energy_cluster\"] = [\"energy_cluster\"]\n",
    "possible_columns[\"num_bedrooms\"] = [\"num_bedrooms\"]\n",
    "possible_columns[\"dwelling_type_ord\"] = [\"dwelling_type_ord\"]\n",
    "possible_columns[\"dwelling_type_onehot\"] = ['detached', 'flat', 'semi_detached', 'terraced']\n",
    "pprint(possible_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting categorical columns\n",
    "\n",
    "all_cat = [\"meter_id_ord\", 'meter_id_0', 'meter_id_1', 'meter_id_2',\n",
    "           'meter_id_3', 'meter_id_4', 'meter_id_5', 'meter_id_6', 'meter_id_7',\n",
    "           'meter_id_8', 'meter_id_9', 'meter_id_10', 'meter_id_11', 'meter_id_12',\n",
    "           \"day_of_week\", \"day_of_month\", \"month_ord\", \"is_weekend\", \"energy_cluster\",\n",
    "           \"dwelling_type_ord\", \"detached\", \"flat\", \"semi_detached\", \"terraced\"] #all categorical values\n",
    "\n",
    "# setting categorical columns in the dataframe to be categorical\n",
    "#X_cat[0] holds all columns (besides clusters but we aren't using that) \n",
    "for i in all_cat:\n",
    "    df_train[i] = df_train[i].astype('category')\n",
    "    df_preds[i] = df_preds[i].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model parameters for random search\n",
    "* sensible different combinations of params for the model\n",
    "\n",
    "* default values which make sense and the others have place holders as they will be found in random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default params (including ones we will override and those we won't)\n",
    "params = {\n",
    "    ### won't be tuned ###\n",
    "    'boosting_type': 'gbdt', #gbdt/rf/dart/goss\n",
    "    'metric': 'mae', \n",
    "    'num_threads': -1, # number of threads to run on for speed (auto)\n",
    "    'num_iterations': 10000, #defining the models runs\n",
    "    'seed': SEED, # all runs with same seed for better comparison between different hyper params\n",
    "    \n",
    "    \n",
    "    ### will be tuned (replace these with the best performing) ###\n",
    "    'learning_rate': 0.99999,\n",
    "    'num_leaves': 99999, # limit max numer of leaves in a tree\n",
    "    \"max_depth\":99999, # limit max depth of the tree to prevent overfitting\n",
    "    # fraction to be bagged/sampled every k iterations\n",
    "    'bagging_fraction': 0.99999,\n",
    "    'bagging_freq' : 99999,\n",
    "    'feature_fraction': 0.99999, # fraction of features to use at each tree node\n",
    "    #l1 & l2 regularization to prevent overfitting\n",
    "    \"lambda_l1\": 99999,\n",
    "    \"lambda_l2\": 99999\n",
    "}\n",
    "\n",
    "pprint(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 3 # 3 fold skf; so we use 2/3 of each meters readings for training at each iteration \n",
    "i=0 #just used to print the index of each skf-cv run\n",
    "all_results = [] # will hold array of all the tuples of results + hyper params\n",
    "\n",
    "#random search\n",
    "print(f\"{color.BOLD}Running random search hyper parameter optimization{color.END}\\n\")\n",
    "start_time = time.time()\n",
    "#going to test n hyper parameter configurations\n",
    "n=64\n",
    "for i in tqdm(range(n)):\n",
    "    print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}skf-cv LGBM run {i}{color.END}\")\n",
    "    #### randomly generate the hyper parameters for this model within a sensible range for each ####\n",
    "\n",
    "    #firstly randomly picking the features we will use\n",
    "    print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Picking random features{color.END}\")\n",
    "    X_cols = []#this will store the X_cols we use\n",
    "\n",
    "    #generating probability of accepting each column\n",
    "    prob_to_beat = random.randrange(30,100)/100 #between 0.3 and 1\n",
    "    #iterating through each column and randomly decide whether or not to pick it\n",
    "    for key in possible_columns.keys():\n",
    "        #randomly generate a decimal for this column group\n",
    "        this_prob = random.randrange(0,100)/100 #between 0 and 1\n",
    "        #if this is less than the probability to beat then accept it\n",
    "        if(this_prob<prob_to_beat):\n",
    "            print(key,this_prob,\"<=\",prob_to_beat)\n",
    "            X_cols+=(possible_columns[key])\n",
    "    print(X_cols)\n",
    "    \n",
    "    this_X_cats = list(set(X_cols).intersection(all_cat)) #getting the categorical values for this X\n",
    "    \n",
    "    #then get LGBM hyper parameters\n",
    "    this_params = params.copy()\n",
    "    this_params[\"learning_rate\"] = random.randrange(10,25)/1000 #between 0.01 and 0.025\n",
    "    this_params[\"max_depth\"] = random.randrange(6,12)\n",
    "    this_params[\"num_leaves\"] = random.randrange(np.round(2**(this_params[\"max_depth\"])*0.5), np.round(2**(this_params[\"max_depth\"])*0.9)) #picking a random max leaves less than 2^(max_depth) to prevent over fitting (between 50 and 90%)\n",
    "    this_params[\"bagging_fraction\"] = random.randrange(65,90)/100 #between 0.65 and 0.9\n",
    "    this_params[\"bagging_freq\"] = random.randrange(5,25)\n",
    "    this_params[\"feature_fraction\"] = random.randrange(65,90)/100 #between 0.65 and 0.9\n",
    "    this_params[\"lambda_l1\"] = random.randrange(8,18)\n",
    "    this_params[\"lambda_l2\"] = random.randrange(4,14)\n",
    "\n",
    "    #train the model with this hyper param config and store it's results\n",
    "\n",
    "    pprint(this_params)\n",
    "    all_results.append((run_lgbm_skf_cv(False, False, SEED, num_folds, df_train.copy(), y_col, X_cols, this_X_cats, this_params),(X_cols,this_params)))\n",
    "    print(\"\\n\\n\\n\")\n",
    "time_of_execution = time.time()-start_time\n",
    "print(f\"{color.BOLD}Random search ran {n} iterations in {str(datetime.timedelta(seconds=round(time_of_execution)))}{color.END}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising information from the random search results\n",
    "### Box plots of the MAE for the different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_maes = {} #dictionary of each columns maes\n",
    "#iterating through each column and randomly decide whether or not to pick it\n",
    "for key in tqdm(possible_columns.keys()):\n",
    "    column = possible_columns[key][0] # only want to check against one column for the 'in'\n",
    "    #iterating through every single models results\n",
    "    for i in range(len(all_results)):\n",
    "        #if this column was used by the model\n",
    "        if column in all_results[i][1][0]:\n",
    "            # if this column doesn't yet exist in the dict, create it\n",
    "            if key not in columns_maes:\n",
    "                columns_maes[key]=[]\n",
    "            # adding this models mae to the dict entry for this column\n",
    "            columns_maes[key].append(all_results[i][0][1])\n",
    "\n",
    "# print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}MAEs for each model which contains columns of eaach type{color.END}\")\n",
    "# pprint(columns_maes)\n",
    "\n",
    "#plotting a boxplot of these\n",
    "labels, data = columns_maes.keys(), columns_maes.values()\n",
    "fig = plt.figure(figsize=(25,10))\n",
    "plt.boxplot(data)\n",
    "\n",
    "plt.title(\"MAEs for the different columns\", fontsize=15)\n",
    "plt.xlabel(\"Column groups\", fontsize=13)\n",
    "plt.ylabel(\"MAE\", fontsize=13)\n",
    "\n",
    "plt.xticks(range(1, len(labels) + 1), labels)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f\"..\\\\Results\\\\Unclustered Random Search\\\\Plots\\\\{n}_Box_MAEs.png\")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line chart for performance of each param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#array of the hyperparameters we tuned\n",
    "arr_hypers = [\"learning_rate\",\"num_leaves\",\"max_depth\",\"bagging_fraction\",\"bagging_freq\",\"feature_fraction\",\"lambda_l1\",\"lambda_l2\"]\n",
    "\n",
    "#iterate through each of these hypers\n",
    "for hyper in tqdm(arr_hypers):\n",
    "\n",
    "    df_max_depth = pd.DataFrame(columns = [hyper,\"MAE\"])\n",
    "\n",
    "    #iterating through each column and randomly decide whether or not to pick it\n",
    "    #iterating through every single models results\n",
    "    for i in range(len(all_results)):\n",
    "        # adding this models mae to the dict entry for this column\n",
    "        df_max_depth.loc[i] = [all_results[i][1][1][hyper],all_results[i][0][1]]\n",
    "\n",
    "    #sort in ascending order by the params values\n",
    "    df_all = df_max_depth.sort_values(by=[hyper])\n",
    "    # display(df_all)\n",
    "\n",
    "    #grouping together by value and calculating mean\n",
    "    grouped_df = df_all.groupby(hyper)\n",
    "    mean_df = grouped_df.mean().reset_index()\n",
    "    # display(mean_df)\n",
    "\n",
    "    #plotting the stats for this param \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.plot(mean_df[hyper], mean_df.MAE, label=\"Line of all values mean MAE \", color=\"skyblue\") # line of means\n",
    "    plt.scatter(df_all[hyper], df_all.MAE, label=\"Scatter of all values MAE\", color=\"darkorange\", marker=\"x\") # scatter of values\n",
    "    plt.plot(np.unique(df_all[hyper]), \n",
    "             np.poly1d(np.polyfit(df_all[hyper], df_all.MAE, 3))\n",
    "             (np.unique(df_all[hyper])), label=\"3rd deg poly line of best fit\", color=\"mediumorchid\") # line of best fit from a simple regressor\n",
    "\n",
    "    plt.title(f\"MAEs for {hyper} values\", fontsize=15)\n",
    "    plt.xlabel(f\"{hyper} values\", fontsize=13)\n",
    "    plt.ylabel(\"MAE\", fontsize=13)\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(f\"..\\\\Results\\\\Unclustered Random Search\\\\Plots\\\\{n}_scatter_{hyper}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspecting stats on all models TOE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspecting the min/max/mean of time of execution of the models we tested in random search\n",
    "all_toes = []\n",
    "all_maes = [] \n",
    "\n",
    "for i in range(len(all_results)):\n",
    "    #getting the results for this model\n",
    "    all_toes.append(all_results[i][0][0])\n",
    "    all_maes.append(all_results[i][0][1])\n",
    "    \n",
    "print()\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}min time of execution = {color.END}{str(datetime.timedelta(seconds=round(min(all_toes))))}\")\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}max time of execution = {color.END}{str(datetime.timedelta(seconds=round(max(all_toes))))}\")\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}mean time of execution = {color.END}{str(datetime.timedelta(seconds=round(np.mean(all_toes))))}\")\n",
    "print()\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}min MAE = {color.END}{min(all_maes)}\")\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}max MAE= {color.END}{max(all_maes)}\")\n",
    "print(f\"{color.BOLD}{color.GREEN}{color.UNDERLINE}mean MAE = {color.END}{np.mean(all_maes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the results of the hyper parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = 0\n",
    "best_mae = 999999\n",
    "\n",
    "for i in range(len(all_results)):\n",
    "    #getting the results for this model\n",
    "    LGBM_TOE = all_results[i][0][0]\n",
    "    LGBM_MAE = all_results[i][0][1]\n",
    "    #displaying the results\n",
    "    print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}skf-cv run {i}{color.END}\")\n",
    "    print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution for skf-cv:{color.END} {str(datetime.timedelta(seconds=round(LGBM_TOE)))}\")\n",
    "    print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set:{color.END} {LGBM_MAE}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    #keeping track of the best performing model\n",
    "    if(LGBM_MAE<best_mae):\n",
    "        best_mae=LGBM_MAE\n",
    "        best_index = i\n",
    "print(\"best model is at index\",best_index,\"with a MAE of\",best_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions based on the best performing model and displaying it's information\n",
    "BEST_LGBM_MODELS = all_results[best_index][0][2] #getting the lgbm_models from the best index\n",
    "BEST_LGBM_FORECASTS = df_preds.copy()\n",
    "start_time = time.time() \n",
    "\n",
    "#calculating the average preds by summing the weighted preds for each folds model\n",
    "for i in range(len(BEST_LGBM_MODELS)):\n",
    "    pred_forecasts = BEST_LGBM_MODELS[i].predict(BEST_LGBM_FORECASTS[all_results[best_index][1][0]], num_iteration=BEST_LGBM_MODELS[i].best_iteration_) #predicting the unkown df_preds\n",
    "    BEST_LGBM_FORECASTS[y_col] += pred_forecasts / num_folds #weighting the predictions for BEST_LGBM_FORECASTS for this fold and adding to df_preds y column \n",
    "BEST_LGBM_FORECASTS[\"meter_reading\"] = BEST_LGBM_FORECASTS.meter_reading.clip(lower=0) #clip meter_reading so no predictions lower than 0\n",
    "execution_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting information on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#printing the forecasts and other evaluation info\n",
    "print(f\"{color.BOLD}{color.RED}{color.UNDERLINE}best model came from skf-cv run {best_index}{color.END}\")\n",
    "#displaying the results\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Evaluation and results{color.END}\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution for skf-cv:  {color.END}{str(datetime.timedelta(seconds=round(all_results[best_index][0][0])))}\\n\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Time of execution for predictions: {color.END}{str(datetime.timedelta(seconds=round(execution_time)))}\\n\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Total time of execution: {color.END}{str(datetime.timedelta(seconds=round(all_results[best_index][0][0]+execution_time)))}\\n\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}Mean absolute error between OOF preds and meter_reading on training set:{color.END} {all_results[best_index][0][1]}\\n\")\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}preds set with the next years forecasts for each meter{color.END}\")\n",
    "display(BEST_LGBM_FORECASTS[[\"meter_id\",\"date\",\"meter_reading\"]])\n",
    "#displaying the hyperparameters\n",
    "print(f\"{color.BOLD}{color.BLUE}{color.UNDERLINE}Hyper-parameters{color.END}\")\n",
    "print(f\"\\n{color.BOLD}{color.CYAN}{color.UNDERLINE}X_cols:{color.END}\\n\")\n",
    "pprint(all_results[best_index][1][0])\n",
    "print(f\"{color.BOLD}{color.CYAN}{color.UNDERLINE}model params:  {color.END}\")\n",
    "pprint(all_results[best_index][1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the description of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_LGBM_FORECASTS.to_pickle(f\"..\\\\Results\\\\Unclustered Random Search\\\\{n}_best_model_daily_forecasts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "a = {'hello': 'world'}\n",
    "desc_disc = {\n",
    "    \"time_of_execution_skf-cv\":str(datetime.timedelta(seconds=round(all_results[best_index][0][0]))),\n",
    "    \"time_of_execution_preds\":str(datetime.timedelta(seconds=round(execution_time))),\n",
    "    \"time_of_execution_total\":str(datetime.timedelta(seconds=round(all_results[best_index][0][0]+execution_time))),\n",
    "    \"MAE\":all_results[best_index][0][1],\n",
    "    \"features\":all_results[best_index][1][0],\n",
    "    \"params\":all_results[best_index][1][1]\n",
    "}\n",
    "\n",
    "with open(f\"..\\\\Results\\\\Unclustered Random Search\\\\{n}_best_model_desc.pkl\", 'wb') as handle:\n",
    "    pickle.dump(desc_disc, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "pprint(desc_disc)\n",
    "    \n",
    "# verifying it saved correctly and can be loaded back\n",
    "with open(f\"..\\\\Results\\\\Unclustered Random Search\\\\{n}_best_model_desc.pkl\", 'rb') as handle:\n",
    "    desc_disc_loaded = pickle.load(handle)\n",
    "print(desc_disc == desc_disc_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting into monthly forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restructuring into the original multiple time series format\n",
    "#aggregating up the total sum of the months predictions\n",
    "df_monthly_forecasts = BEST_LGBM_FORECASTS.groupby([\"meter_id\", \"month_ord\"])[\"meter_reading\"].sum().unstack()\n",
    "\n",
    "#rename ordinal encoded month with its corresponding name\n",
    "df_monthly_forecasts.rename(columns={1:\"Jan\", 2:\"Feb\",3:\"Mar\",4:\"Apr\",5:\"May\",6:\"Jun\",7:\"Jul\",8:\"Aug\",9:\"Sep\",10:\"Oct\",11:\"Nov\",12:\"Dec\"}, inplace=True)\n",
    "#resetting the index \n",
    "df_monthly_forecasts.reset_index(inplace=True)\n",
    "df_monthly_forecasts.index.name = None # removing index column\n",
    "df_monthly_forecasts.columns.name = None # removing columns name\n",
    "\n",
    "display(df_monthly_forecasts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving these monthly predictions to be submitted to competition\n",
    "* Saving predictions ready to be submitted so I can get the MAE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_forecasts.to_csv(f\"..\\\\Results\\\\Unclustered Random Search\\\\{n}_best_model_monthly_forecasts.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting these monthly forecasts\n",
    "## Renaming months to dates for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_monthly_forecasts.rename(columns={\"Jan\":\"2018-01\", \"Feb\":\"2018-02\",\"Mar\":\"2018-03\",\"Apr\":\"2018-04\",\"May\":\"2018-05\",\"Jun\":\"2018-06\",\"Jul\":\"2018-07\",\"Aug\":\"2018-08\",\"Sep\":\"2018-09\",\"Oct\":\"2018-10\",\"Nov\":\"2018-11\",\"Dec\":\"2018-12\"}, inplace=True)\n",
    "df_monthly_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restructuring forecasts into daily predictions to plot on top of monthly preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily forecasts to plot on top of monthly\n",
    "df_daily_forecasts = BEST_LGBM_FORECASTS.groupby([\"meter_id\",\"date\"])[\"meter_reading\"].sum().unstack()\n",
    "\n",
    "#resetting the index \n",
    "df_daily_forecasts.reset_index(inplace=True)\n",
    "df_daily_forecasts.index.name = None # removing index column\n",
    "df_daily_forecasts.columns.name = None # removing columns name\n",
    "\n",
    "df_daily_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading training data and aggregating into months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the training data\n",
    "print(\"training data\")\n",
    "df_train = pd.read_pickle(\"../Data/Preprocessed_Data/consumption_daily_nan_interpolated.pkl\").fillna(0)\n",
    "\n",
    "#aggregating up into months\n",
    "meter_id=df_monthly_forecasts[\"meter_id\"]\n",
    "df_train_monthly = pd.DataFrame(columns=[\"meter_id\"])\n",
    "df_train_monthly[\"meter_id\"] = meter_id\n",
    "\n",
    "\n",
    "#for each month in the range of dates\n",
    "resample_size=\"M\"\n",
    "for new_sample in tqdm(pd.date_range(datetime.datetime(2017, 1, 1), datetime.datetime(2017, 12, 31), freq = resample_size),position=0):\n",
    "\n",
    "    #get this columns name as a string\n",
    "    columnName = str(new_sample.date())[:7]\n",
    "    #get all columns that relate to this new sample\n",
    "    columns = [i for i in df_train.columns.values[1:] if i.startswith(columnName)]\n",
    "\n",
    "    #sum these up into a value for the new sample size\n",
    "    df_train_monthly[columnName] = df_train[columns].sum(axis=1)\n",
    "\n",
    "df_train_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the predictions against the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in tqdm(range(0,3248)):\n",
    "    #getting the row corresponding to this meter_id\n",
    "    meter_id = df_daily_forecasts.iloc[pid,0]\n",
    "    this_train_month = df_train_monthly.loc[df_train_monthly['meter_id'] == meter_id].T[1:]\n",
    "    this_preds_month = df_monthly_forecasts.loc[df_train_monthly['meter_id'] == meter_id].T[1:]\n",
    "    this_train_day = df_train.loc[df_train['meter_id'] == meter_id].T[1:]\n",
    "    this_preds_day = df_daily_forecasts.loc[df_daily_forecasts['meter_id'] == meter_id].T[1:]\n",
    "    \n",
    "    #converting index to datetime for ease of plots key\n",
    "    this_train_month.index=pd.to_datetime(this_train_month.index)\n",
    "    this_preds_month.index=pd.to_datetime(this_preds_month.index)\n",
    "    this_train_day.index=pd.to_datetime(this_train_day.index)\n",
    "    this_preds_day.index=pd.to_datetime(this_preds_day.index)\n",
    "    \n",
    "    #creating figure\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    \n",
    "    #plotting the monthly predictions\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.title(\"Meter '\"+str(meter_id)+\"' monthly forecasts and historical data\", fontsize=15)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Energy Usage kWh\")\n",
    "    plt.plot(this_train_month, label=\"training monthly energy\", lw=1,color=\"skyblue\", marker=\"x\")\n",
    "    plt.plot(this_preds_month, label=\"forecast monthly energy\", lw=1,color=\"mediumorchid\", marker=\"x\")\n",
    "    \n",
    "    \n",
    "    #plotting the daily predictions\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.title(\"Meter '\"+str(meter_id)+\"' daily forecasts and historical data\", fontsize=15)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Energy Usage kWh\")\n",
    "    plt.plot(this_train_day, label=\"training daily energy\", lw=1,color=\"skyblue\")\n",
    "    plt.plot(this_preds_day, label=\"forecast daily energy\", lw=1,color=\"mediumorchid\")\n",
    "\n",
    "    #annotations\n",
    "    plt.legend(fontsize=20)\n",
    "    \n",
    "    \n",
    "    #plt.show()\n",
    "\n",
    "    fig.savefig(f\"..\\\\Results\\\\Unclustered Random Search\\\\Plots\\\\forecasts\\\\{n}_forecasts_{pid}_{meter_id}.png\")\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle_tf",
   "language": "python",
   "name": "mle_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
